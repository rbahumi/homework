{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 goal\n",
    "[Assignment PDF](http://rail.eecs.berkeley.edu/deeprlcourse/static/homeworks/hw1.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Set matplotlib environment\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 9000)\n",
    "pd.options.display.max_colwidth = 9000\n",
    "\n",
    "plt.style.use('bmh')\n",
    "%pylab inline\n",
    "\n",
    "# Reload python module by default\n",
    "# https://iqbalnaved.wordpress.com/2013/10/18/ipython-tip-reloading-modified-code/\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def add_to_path(new_paths):\n",
    "    for new_path in paths_to_add:\n",
    "        if new_path not in sys.path:\n",
    "            sys.path.append(new_path)\n",
    "\n",
    "\n",
    "CWD = os.getcwd().replace('/hw1/notebooks', '')\n",
    "os.chdir(CWD)\n",
    "paths_to_add = [CWD]\n",
    "add_to_path(paths_to_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set Up environment with OpenAi Roboschool instead of MuJoCo\n",
    "In my fork to this homework repository I have added instruction of how to set up the environment with virtualenv or with a prebuild docker image. First setup the environment and then you will be able to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Behavioral Cloning\n",
    "The idea behind Behavioral Cloning is to apply Supervised Learning methods in order to learn a control policy. This basically means that we are not going to learn a state/action value function. Instead we will record a set of trajectories/rewards ran by an expert policy and try to imitate that continues action vector policy using a regretion model (in this case, an ANN with a regresion head).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw1.consts import EXPERT_DIR, AVAILABLE_ENVS, EXPERT_DATA_DIR\n",
    "from hw1.run_expert import run_expert_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -fr {EXPERT_DATA_DIR}\n",
    "!mkdir -p {EXPERT_DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running env RoboschoolAnt-v1\n",
      "Env description: Expert policy for module RoboschoolAnt-v1\n",
      "mean return 1818.8292998516504\n",
      "std of return 381.8678179633842\n",
      "CPU times: user 40 s, sys: 1min 3s, total: 1min 43s\n",
      "Wall time: 1min 44s\n",
      "Running env RoboschoolHumanoid-v1\n",
      "Env description: Expert policy for module RoboschoolHumanoid-v1\n",
      "mean return 2848.910280488764\n",
      "std of return 1033.9963047075728\n",
      "CPU times: user 2min 55s, sys: 7min 5s, total: 10min\n",
      "Wall time: 2min 30s\n",
      "Running env RoboschoolHalfCheetah-v1\n",
      "Env description: Expert policy for module RoboschoolHalfCheetah-v1\n",
      "mean return 2271.29843854231\n",
      "std of return 909.0033810184069\n",
      "CPU times: user 25.2 s, sys: 47.3 s, total: 1min 12s\n",
      "Wall time: 1min 12s\n",
      "Running env RoboschoolReacher-v1\n",
      "Env description: Expert policy for module RoboschoolReacher-v1\n",
      "mean return 18.612237270160552\n",
      "std of return 10.257759621234174\n",
      "CPU times: user 1.49 s, sys: 3.15 s, total: 4.64 s\n",
      "Wall time: 4.67 s\n",
      "Running env RoboschoolHopper-v1\n",
      "Env description: Expert policy for module RoboschoolHopper-v1\n",
      "mean return 1541.857022448628\n",
      "std of return 687.0205519391368\n",
      "CPU times: user 17.1 s, sys: 33.7 s, total: 50.8 s\n",
      "Wall time: 50.9 s\n",
      "Running env RoboschoolWalker2d-v1\n",
      "Env description: Expert policy for module RoboschoolWalker2d-v1\n",
      "mean return 2205.412557862982\n",
      "std of return 81.9400649404929\n",
      "CPU times: user 29.8 s, sys: 58.3 s, total: 1min 28s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "for env_name in AVAILABLE_ENVS:\n",
    "    print(\"Running env %s\" % env_name)\n",
    "    %time expert_data = run_expert_policy(num_rollouts=50, env_name=env_name, verbose=False)\n",
    "    with open(os.path.join(EXPERT_DATA_DIR, env_name + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(expert_data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper modules/functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hw1/manage_datasets.py: Helper functions for loading the specific domain tasks Datasets\n",
    "For example, load the train/test datasets with their labels, and show their input and output vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolAnt-v1\n",
      "Domain name: RoboschoolAnt-v1\n",
      "(45000, 28) (5000, 28) (45000, 8) (5000, 8)\n"
     ]
    }
   ],
   "source": [
    "from hw1.manage_datasets import get_datasets\n",
    "from hw1.consts import EXPERT_DATA_DIR\n",
    "\n",
    "\n",
    "dataset_name = 'RoboschoolAnt-v1'\n",
    "X_train, X_test, y_train, y_test = get_datasets(dataset_name=dataset_name, dataset_dir=EXPERT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12892047, -0.02399238,  0.99971217,  0.35790426,  0.30509418,\n",
       "        0.058642  ,  0.1139003 , -0.11415579,  0.43144047, -0.75470674,\n",
       "        1.0087281 , -0.03240158,  0.02628127,  0.6814454 , -0.2858721 ,\n",
       "        0.01521853, -0.68756235,  0.23606583,  0.5452577 ,  0.26748422,\n",
       "        0.42372003, -0.5583233 ,  0.58613735,  0.07699564,  0.        ,\n",
       "        1.        ,  1.        ,  1.        ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.77629344, -0.11997891, -0.30649464, -1.7593687 ,  0.69761764,\n",
       "        0.70613533, -0.05471253,  0.07859467])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'RoboschoolAnt-v1' domain has 28 input features (floats), and the actions vector (what we are trying to predict) have 8 features (floats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras_helpers/model_helper.py: Helper function for defining a Fully Connected (FC) new Keras model.\n",
    "For examople lets create a Fully connected network that has the input/output dimensions suitable for 'RoboschoolAnt-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_helpers.model_helper import create_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# Define model\n",
    "config_dict = dict(\n",
    "    input_dim=len(X_train[1, :]),\n",
    "    output_dim=len(y_train[1, :]),\n",
    "    units=100,\n",
    "    layers = 3,\n",
    "    l2_reg = 1e-04,\n",
    "    lr = 1e-03,\n",
    "    dropout=None,\n",
    "    use_batchnorm=False)\n",
    "\n",
    "model = create_model(**config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"387pt\" viewBox=\"0.00 0.00 311.00 387.00\" width=\"311pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-383 307,-383 307,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140099891363064 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140099891363064</title>\n",
       "<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 303,-378.5 303,-332.5 0,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"71.5\" y=\"-351.8\">input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"143,-332.5 143,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"143,-355.5 211,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"211,-332.5 211,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-363.3\">(None, 28)</text>\n",
       "<polyline fill=\"none\" points=\"211,-355.5 303,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-340.3\">(None, 28)</text>\n",
       "</g>\n",
       "<!-- 140099887672960 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140099887672960</title>\n",
       "<polygon fill=\"none\" points=\"3,-249.5 3,-295.5 300,-295.5 300,-249.5 3,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-268.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131,-249.5 131,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131,-272.5 199,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"199,-249.5 199,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-280.3\">(None, 28)</text>\n",
       "<polyline fill=\"none\" points=\"199,-272.5 300,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-257.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099891363064&#45;&gt;140099887672960 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140099891363064-&gt;140099887672960</title>\n",
       "<path d=\"M151.5,-332.366C151.5,-324.152 151.5,-314.658 151.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"155,-305.607 151.5,-295.607 148,-305.607 155,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099887672568 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140099887672568</title>\n",
       "<polygon fill=\"none\" points=\"3,-166.5 3,-212.5 300,-212.5 300,-166.5 3,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-185.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131,-166.5 131,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131,-189.5 199,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"199,-166.5 199,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-197.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"199,-189.5 300,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-174.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099887672960&#45;&gt;140099887672568 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140099887672960-&gt;140099887672568</title>\n",
       "<path d=\"M151.5,-249.366C151.5,-241.152 151.5,-231.658 151.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"155,-222.607 151.5,-212.607 148,-222.607 155,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099887372440 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140099887372440</title>\n",
       "<polygon fill=\"none\" points=\"3,-83.5 3,-129.5 300,-129.5 300,-83.5 3,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-102.8\">dense_3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131,-83.5 131,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131,-106.5 199,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"199,-83.5 199,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-114.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"199,-106.5 300,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-91.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099887672568&#45;&gt;140099887372440 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140099887672568-&gt;140099887372440</title>\n",
       "<path d=\"M151.5,-166.366C151.5,-158.152 151.5,-148.658 151.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"155,-139.607 151.5,-129.607 148,-139.607 155,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099887056040 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140099887056040</title>\n",
       "<polygon fill=\"none\" points=\"3,-0.5 3,-46.5 300,-46.5 300,-0.5 3,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-19.8\">dense_4: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131,-0.5 131,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131,-23.5 199,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"199,-0.5 199,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-31.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"199,-23.5 300,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-8.3\">(None, 8)</text>\n",
       "</g>\n",
       "<!-- 140099887372440&#45;&gt;140099887056040 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140099887372440-&gt;140099887056040</title>\n",
       "<path d=\"M151.5,-83.3664C151.5,-75.1516 151.5,-65.6579 151.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"155,-56.6068 151.5,-46.6068 148,-56.6069 155,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the model architecture\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily add dropout and batchnorm layers to this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"1051pt\" viewBox=\"0.00 0.00 509.00 1051.00\" width=\"509pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1047)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-1047 505,-1047 505,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140099886423960 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140099886423960</title>\n",
       "<polygon fill=\"none\" points=\"99,-996.5 99,-1042.5 402,-1042.5 402,-996.5 99,-996.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-1015.8\">input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"242,-996.5 242,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"242,-1019.5 310,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"310,-996.5 310,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"356\" y=\"-1027.3\">(None, 28)</text>\n",
       "<polyline fill=\"none\" points=\"310,-1019.5 402,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"356\" y=\"-1004.3\">(None, 28)</text>\n",
       "</g>\n",
       "<!-- 140099886423736 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140099886423736</title>\n",
       "<polygon fill=\"none\" points=\"4.5,-913.5 4.5,-959.5 496.5,-959.5 496.5,-913.5 4.5,-913.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-932.8\">batch_normalization_1: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"336.5,-913.5 336.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"370.5\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"336.5,-936.5 404.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"370.5\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"404.5,-913.5 404.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450.5\" y=\"-944.3\">(None, 28)</text>\n",
       "<polyline fill=\"none\" points=\"404.5,-936.5 496.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450.5\" y=\"-921.3\">(None, 28)</text>\n",
       "</g>\n",
       "<!-- 140099886423960&#45;&gt;140099886423736 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140099886423960-&gt;140099886423736</title>\n",
       "<path d=\"M250.5,-996.366C250.5,-988.152 250.5,-978.658 250.5,-969.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-969.607 250.5,-959.607 247,-969.607 254,-969.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099886421328 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140099886421328</title>\n",
       "<polygon fill=\"none\" points=\"92,-830.5 92,-876.5 409,-876.5 409,-830.5 92,-830.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-849.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"249,-830.5 249,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"249,-853.5 317,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"317,-830.5 317,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-861.3\">(None, 28)</text>\n",
       "<polyline fill=\"none\" points=\"317,-853.5 409,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-838.3\">(None, 28)</text>\n",
       "</g>\n",
       "<!-- 140099886423736&#45;&gt;140099886421328 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140099886423736-&gt;140099886421328</title>\n",
       "<path d=\"M250.5,-913.366C250.5,-905.152 250.5,-895.658 250.5,-886.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-886.607 250.5,-876.607 247,-886.607 254,-886.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099886422336 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140099886422336</title>\n",
       "<polygon fill=\"none\" points=\"102,-747.5 102,-793.5 399,-793.5 399,-747.5 102,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-766.8\">dense_5: Dense</text>\n",
       "<polyline fill=\"none\" points=\"230,-747.5 230,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"230,-770.5 298,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"298,-747.5 298,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-778.3\">(None, 28)</text>\n",
       "<polyline fill=\"none\" points=\"298,-770.5 399,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-755.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099886421328&#45;&gt;140099886422336 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140099886421328-&gt;140099886422336</title>\n",
       "<path d=\"M250.5,-830.366C250.5,-822.152 250.5,-812.658 250.5,-803.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-803.607 250.5,-793.607 247,-803.607 254,-803.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099887573480 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140099887573480</title>\n",
       "<polygon fill=\"none\" points=\"0,-664.5 0,-710.5 501,-710.5 501,-664.5 0,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-683.8\">batch_normalization_2: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"332,-664.5 332,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"332,-687.5 400,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"400,-664.5 400,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450.5\" y=\"-695.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"400,-687.5 501,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450.5\" y=\"-672.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099886422336&#45;&gt;140099887573480 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140099886422336-&gt;140099887573480</title>\n",
       "<path d=\"M250.5,-747.366C250.5,-739.152 250.5,-729.658 250.5,-720.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-720.607 250.5,-710.607 247,-720.607 254,-720.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099886944664 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140099886944664</title>\n",
       "<polygon fill=\"none\" points=\"87.5,-581.5 87.5,-627.5 413.5,-627.5 413.5,-581.5 87.5,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-600.8\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"244.5,-581.5 244.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"244.5,-604.5 312.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"312.5,-581.5 312.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-612.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"312.5,-604.5 413.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-589.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099887573480&#45;&gt;140099886944664 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140099887573480-&gt;140099886944664</title>\n",
       "<path d=\"M250.5,-664.366C250.5,-656.152 250.5,-646.658 250.5,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-637.607 250.5,-627.607 247,-637.607 254,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099891362280 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140099891362280</title>\n",
       "<polygon fill=\"none\" points=\"102,-498.5 102,-544.5 399,-544.5 399,-498.5 102,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-517.8\">dense_6: Dense</text>\n",
       "<polyline fill=\"none\" points=\"230,-498.5 230,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"230,-521.5 298,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"298,-498.5 298,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-529.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"298,-521.5 399,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-506.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099886944664&#45;&gt;140099891362280 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140099886944664-&gt;140099891362280</title>\n",
       "<path d=\"M250.5,-581.366C250.5,-573.152 250.5,-563.658 250.5,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-554.607 250.5,-544.607 247,-554.607 254,-554.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099886609520 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140099886609520</title>\n",
       "<polygon fill=\"none\" points=\"0,-415.5 0,-461.5 501,-461.5 501,-415.5 0,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-434.8\">batch_normalization_3: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"332,-415.5 332,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"332,-438.5 400,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"400,-415.5 400,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450.5\" y=\"-446.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"400,-438.5 501,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450.5\" y=\"-423.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099891362280&#45;&gt;140099886609520 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140099891362280-&gt;140099886609520</title>\n",
       "<path d=\"M250.5,-498.366C250.5,-490.152 250.5,-480.658 250.5,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-471.607 250.5,-461.607 247,-471.607 254,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099886610416 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140099886610416</title>\n",
       "<polygon fill=\"none\" points=\"87.5,-332.5 87.5,-378.5 413.5,-378.5 413.5,-332.5 87.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-351.8\">dropout_3: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"244.5,-332.5 244.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"244.5,-355.5 312.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"312.5,-332.5 312.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-363.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"312.5,-355.5 413.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-340.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099886609520&#45;&gt;140099886610416 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140099886609520-&gt;140099886610416</title>\n",
       "<path d=\"M250.5,-415.366C250.5,-407.152 250.5,-397.658 250.5,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-388.607 250.5,-378.607 247,-388.607 254,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099886286720 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140099886286720</title>\n",
       "<polygon fill=\"none\" points=\"102,-249.5 102,-295.5 399,-295.5 399,-249.5 102,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-268.8\">dense_7: Dense</text>\n",
       "<polyline fill=\"none\" points=\"230,-249.5 230,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"230,-272.5 298,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"298,-249.5 298,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-280.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"298,-272.5 399,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-257.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099886610416&#45;&gt;140099886286720 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140099886610416-&gt;140099886286720</title>\n",
       "<path d=\"M250.5,-332.366C250.5,-324.152 250.5,-314.658 250.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-305.607 250.5,-295.607 247,-305.607 254,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099885956512 -->\n",
       "<g class=\"node\" id=\"node11\"><title>140099885956512</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 501,-212.5 501,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-185.8\">batch_normalization_4: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"332,-166.5 332,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"332,-189.5 400,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"400,-166.5 400,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450.5\" y=\"-197.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"400,-189.5 501,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"450.5\" y=\"-174.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099886286720&#45;&gt;140099885956512 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>140099886286720-&gt;140099885956512</title>\n",
       "<path d=\"M250.5,-249.366C250.5,-241.152 250.5,-231.658 250.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-222.607 250.5,-212.607 247,-222.607 254,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099886674664 -->\n",
       "<g class=\"node\" id=\"node12\"><title>140099886674664</title>\n",
       "<polygon fill=\"none\" points=\"87.5,-83.5 87.5,-129.5 413.5,-129.5 413.5,-83.5 87.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-102.8\">dropout_4: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"244.5,-83.5 244.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"244.5,-106.5 312.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"312.5,-83.5 312.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-114.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"312.5,-106.5 413.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-91.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140099885956512&#45;&gt;140099886674664 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>140099885956512-&gt;140099886674664</title>\n",
       "<path d=\"M250.5,-166.366C250.5,-158.152 250.5,-148.658 250.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-139.607 250.5,-129.607 247,-139.607 254,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140099882738688 -->\n",
       "<g class=\"node\" id=\"node13\"><title>140099882738688</title>\n",
       "<polygon fill=\"none\" points=\"102,-0.5 102,-46.5 399,-46.5 399,-0.5 102,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-19.8\">dense_8: Dense</text>\n",
       "<polyline fill=\"none\" points=\"230,-0.5 230,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"230,-23.5 298,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"298,-0.5 298,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-31.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"298,-23.5 399,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-8.3\">(None, 8)</text>\n",
       "</g>\n",
       "<!-- 140099886674664&#45;&gt;140099882738688 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>140099886674664-&gt;140099882738688</title>\n",
       "<path d=\"M250.5,-83.3664C250.5,-75.1516 250.5,-65.6579 250.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254,-56.6068 250.5,-46.6068 247,-56.6069 254,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model\n",
    "config_dict = dict(\n",
    "    input_dim=len(X_train[1, :]),\n",
    "    output_dim=len(y_train[1, :]),\n",
    "    units=100,\n",
    "    layers = 3,\n",
    "    l2_reg = 1e-04,\n",
    "    lr = 1e-03,\n",
    "    dropout=0.1,\n",
    "    use_batchnorm=True)\n",
    "\n",
    "model = create_model(**config_dict)\n",
    "# Plot the model architecture\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a FC ANN for each domain\n",
    "For each domain, we will train an ANN with the same network architecture. I did not perform hyperparameters tunning because it is not the main scope of the task. However, you can try resizing the network or add  regularization/dropout/batchnorm layers in order to improve the loss of each of the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_dir_if_not_exists(name):\n",
    "    if not os.path.exists(name):\n",
    "        os.makedirs(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a FC ANN for env RoboschoolAnt-v1\n",
      "loading dataset RoboschoolAnt-v1\n",
      "Domain name: RoboschoolAnt-v1\n",
      "(45000, 28) (5000, 28) (45000, 8) (5000, 8)\n",
      "model_name='model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 5s 108us/step - loss: 0.7790 - mean_squared_error: 0.7545 - val_loss: 0.3454 - val_mean_squared_error: 0.3211\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.5092 - mean_squared_error: 0.4851 - val_loss: 0.2928 - val_mean_squared_error: 0.2689\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 4s 81us/step - loss: 0.4559 - mean_squared_error: 0.4324 - val_loss: 0.2733 - val_mean_squared_error: 0.2501\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.4320 - mean_squared_error: 0.4092 - val_loss: 0.2597 - val_mean_squared_error: 0.2373\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 4s 79us/step - loss: 0.4126 - mean_squared_error: 0.3905 - val_loss: 0.2445 - val_mean_squared_error: 0.2228\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3996 - mean_squared_error: 0.3782 - val_loss: 0.2416 - val_mean_squared_error: 0.2204\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 4s 78us/step - loss: 0.3930 - mean_squared_error: 0.3720 - val_loss: 0.2293 - val_mean_squared_error: 0.2086\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3866 - mean_squared_error: 0.3661 - val_loss: 0.2316 - val_mean_squared_error: 0.2112\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3784 - mean_squared_error: 0.3583 - val_loss: 0.2198 - val_mean_squared_error: 0.1998\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3734 - mean_squared_error: 0.3535 - val_loss: 0.2201 - val_mean_squared_error: 0.2004\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3691 - mean_squared_error: 0.3496 - val_loss: 0.2107 - val_mean_squared_error: 0.1913\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 4s 79us/step - loss: 0.3665 - mean_squared_error: 0.3472 - val_loss: 0.2137 - val_mean_squared_error: 0.1945\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3644 - mean_squared_error: 0.3453 - val_loss: 0.2136 - val_mean_squared_error: 0.1946\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3618 - mean_squared_error: 0.3428 - val_loss: 0.2129 - val_mean_squared_error: 0.1940\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3596 - mean_squared_error: 0.3408 - val_loss: 0.2119 - val_mean_squared_error: 0.1931\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3592 - mean_squared_error: 0.3405 - val_loss: 0.2019 - val_mean_squared_error: 0.1832\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3554 - mean_squared_error: 0.3368 - val_loss: 0.2103 - val_mean_squared_error: 0.1918\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3550 - mean_squared_error: 0.3365 - val_loss: 0.2003 - val_mean_squared_error: 0.1818\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3530 - mean_squared_error: 0.3346 - val_loss: 0.2044 - val_mean_squared_error: 0.1860\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 4s 81us/step - loss: 0.3535 - mean_squared_error: 0.3351 - val_loss: 0.2053 - val_mean_squared_error: 0.1869\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3523 - mean_squared_error: 0.3339 - val_loss: 0.2024 - val_mean_squared_error: 0.1840\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 4s 79us/step - loss: 0.3510 - mean_squared_error: 0.3326 - val_loss: 0.2058 - val_mean_squared_error: 0.1875\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3488 - mean_squared_error: 0.3305 - val_loss: 0.1968 - val_mean_squared_error: 0.1785\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3481 - mean_squared_error: 0.3298 - val_loss: 0.2078 - val_mean_squared_error: 0.1895\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - ETA: 0s - loss: 0.3474 - mean_squared_error: 0.32 - 3s 75us/step - loss: 0.3476 - mean_squared_error: 0.3294 - val_loss: 0.2038 - val_mean_squared_error: 0.1855\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3463 - mean_squared_error: 0.3280 - val_loss: 0.1961 - val_mean_squared_error: 0.1778\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 3s 78us/step - loss: 0.3454 - mean_squared_error: 0.3271 - val_loss: 0.2026 - val_mean_squared_error: 0.1842\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3446 - mean_squared_error: 0.3262 - val_loss: 0.2007 - val_mean_squared_error: 0.1824\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3444 - mean_squared_error: 0.3262 - val_loss: 0.2014 - val_mean_squared_error: 0.1831\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3420 - mean_squared_error: 0.3237 - val_loss: 0.1992 - val_mean_squared_error: 0.1809\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3415 - mean_squared_error: 0.3232 - val_loss: 0.1969 - val_mean_squared_error: 0.1786\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3349 - mean_squared_error: 0.3168 - val_loss: 0.1887 - val_mean_squared_error: 0.1708\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 4s 78us/step - loss: 0.3318 - mean_squared_error: 0.3141 - val_loss: 0.1867 - val_mean_squared_error: 0.1692\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 3s 78us/step - loss: 0.3318 - mean_squared_error: 0.3145 - val_loss: 0.1859 - val_mean_squared_error: 0.1688\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3318 - mean_squared_error: 0.3148 - val_loss: 0.1872 - val_mean_squared_error: 0.1703\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3290 - mean_squared_error: 0.3123 - val_loss: 0.1836 - val_mean_squared_error: 0.1671\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3294 - mean_squared_error: 0.3130 - val_loss: 0.1868 - val_mean_squared_error: 0.1705\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3277 - mean_squared_error: 0.3115 - val_loss: 0.1831 - val_mean_squared_error: 0.1670\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3272 - mean_squared_error: 0.3113 - val_loss: 0.1842 - val_mean_squared_error: 0.1684\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3268 - mean_squared_error: 0.3111 - val_loss: 0.1861 - val_mean_squared_error: 0.1704\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 4s 91us/step - loss: 0.3298 - mean_squared_error: 0.3142 - val_loss: 0.1827 - val_mean_squared_error: 0.1673\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3235 - mean_squared_error: 0.3082 - val_loss: 0.1788 - val_mean_squared_error: 0.1635\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 3s 78us/step - loss: 0.3225 - mean_squared_error: 0.3074 - val_loss: 0.1774 - val_mean_squared_error: 0.1623\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3176 - mean_squared_error: 0.3026 - val_loss: 0.1749 - val_mean_squared_error: 0.1600\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3195 - mean_squared_error: 0.3047 - val_loss: 0.1784 - val_mean_squared_error: 0.1638\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3207 - mean_squared_error: 0.3061 - val_loss: 0.1734 - val_mean_squared_error: 0.1589\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3184 - mean_squared_error: 0.3040 - val_loss: 0.1752 - val_mean_squared_error: 0.1608\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3182 - mean_squared_error: 0.3039 - val_loss: 0.1740 - val_mean_squared_error: 0.1598\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3171 - mean_squared_error: 0.3030 - val_loss: 0.1730 - val_mean_squared_error: 0.1590\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3185 - mean_squared_error: 0.3046 - val_loss: 0.1742 - val_mean_squared_error: 0.1604\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3192 - mean_squared_error: 0.3054 - val_loss: 0.1750 - val_mean_squared_error: 0.1613\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3163 - mean_squared_error: 0.3026 - val_loss: 0.1735 - val_mean_squared_error: 0.1599\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3152 - mean_squared_error: 0.3016 - val_loss: 0.1708 - val_mean_squared_error: 0.1573\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 4s 78us/step - loss: 0.3137 - mean_squared_error: 0.3002 - val_loss: 0.1715 - val_mean_squared_error: 0.1581\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3134 - mean_squared_error: 0.3000 - val_loss: 0.1703 - val_mean_squared_error: 0.1570\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3151 - mean_squared_error: 0.3018 - val_loss: 0.1728 - val_mean_squared_error: 0.1596\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3134 - mean_squared_error: 0.3002 - val_loss: 0.1703 - val_mean_squared_error: 0.1572\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3133 - mean_squared_error: 0.3003 - val_loss: 0.1700 - val_mean_squared_error: 0.1569\n",
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3131 - mean_squared_error: 0.3001 - val_loss: 0.1715 - val_mean_squared_error: 0.1585\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3138 - mean_squared_error: 0.3008 - val_loss: 0.1720 - val_mean_squared_error: 0.1592\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3152 - mean_squared_error: 0.3024 - val_loss: 0.1711 - val_mean_squared_error: 0.1583\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3124 - mean_squared_error: 0.2997 - val_loss: 0.1694 - val_mean_squared_error: 0.1567\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3136 - mean_squared_error: 0.3009 - val_loss: 0.1679 - val_mean_squared_error: 0.1553\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3104 - mean_squared_error: 0.2978 - val_loss: 0.1689 - val_mean_squared_error: 0.1564\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3127 - mean_squared_error: 0.3002 - val_loss: 0.1697 - val_mean_squared_error: 0.1572\n",
      "Epoch 66/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3132 - mean_squared_error: 0.3008 - val_loss: 0.1693 - val_mean_squared_error: 0.1570\n",
      "Epoch 67/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3132 - mean_squared_error: 0.3008 - val_loss: 0.1685 - val_mean_squared_error: 0.1562\n",
      "Epoch 68/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3130 - mean_squared_error: 0.3008 - val_loss: 0.1697 - val_mean_squared_error: 0.1575\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 69/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3096 - mean_squared_error: 0.2974 - val_loss: 0.1688 - val_mean_squared_error: 0.1566\n",
      "Epoch 70/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3087 - mean_squared_error: 0.2965 - val_loss: 0.1673 - val_mean_squared_error: 0.1552\n",
      "Epoch 71/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3091 - mean_squared_error: 0.2969 - val_loss: 0.1669 - val_mean_squared_error: 0.1548\n",
      "Epoch 72/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3099 - mean_squared_error: 0.2978 - val_loss: 0.1665 - val_mean_squared_error: 0.1544\n",
      "Epoch 73/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3077 - mean_squared_error: 0.2957 - val_loss: 0.1664 - val_mean_squared_error: 0.1544\n",
      "Epoch 74/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3093 - mean_squared_error: 0.2973 - val_loss: 0.1674 - val_mean_squared_error: 0.1554\n",
      "Epoch 75/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3103 - mean_squared_error: 0.2984 - val_loss: 0.1676 - val_mean_squared_error: 0.1557\n",
      "Epoch 76/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3106 - mean_squared_error: 0.2987 - val_loss: 0.1668 - val_mean_squared_error: 0.1549\n",
      "Epoch 77/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3100 - mean_squared_error: 0.2981 - val_loss: 0.1679 - val_mean_squared_error: 0.1560\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 78/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3078 - mean_squared_error: 0.2959 - val_loss: 0.1668 - val_mean_squared_error: 0.1550\n",
      "Epoch 79/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3080 - mean_squared_error: 0.2962 - val_loss: 0.1672 - val_mean_squared_error: 0.1554\n",
      "Epoch 80/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3081 - mean_squared_error: 0.2963 - val_loss: 0.1673 - val_mean_squared_error: 0.1555\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 0.3096 - mean_squared_error: 0.2979 - val_loss: 0.1660 - val_mean_squared_error: 0.1542\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3063 - mean_squared_error: 0.2946 - val_loss: 0.1653 - val_mean_squared_error: 0.1536\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3069 - mean_squared_error: 0.2952 - val_loss: 0.1661 - val_mean_squared_error: 0.1544\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3059 - mean_squared_error: 0.2942 - val_loss: 0.1656 - val_mean_squared_error: 0.1539\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3099 - mean_squared_error: 0.2983 - val_loss: 0.1659 - val_mean_squared_error: 0.1543\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3080 - mean_squared_error: 0.2964 - val_loss: 0.1669 - val_mean_squared_error: 0.1552\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3091 - mean_squared_error: 0.2975 - val_loss: 0.1666 - val_mean_squared_error: 0.1550\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3093 - mean_squared_error: 0.2977 - val_loss: 0.1662 - val_mean_squared_error: 0.1546\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3074 - mean_squared_error: 0.2958 - val_loss: 0.1666 - val_mean_squared_error: 0.1550\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 4s 79us/step - loss: 0.3066 - mean_squared_error: 0.2950 - val_loss: 0.1665 - val_mean_squared_error: 0.1549\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.3085 - mean_squared_error: 0.2969 - val_loss: 0.1669 - val_mean_squared_error: 0.1553\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 4s 81us/step - loss: 0.3090 - mean_squared_error: 0.2974 - val_loss: 0.1660 - val_mean_squared_error: 0.1544\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3069 - mean_squared_error: 0.2954 - val_loss: 0.1658 - val_mean_squared_error: 0.1543\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3066 - mean_squared_error: 0.2951 - val_loss: 0.1650 - val_mean_squared_error: 0.1535\n",
      "Epoch 95/100\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3081 - mean_squared_error: 0.2966 - val_loss: 0.1663 - val_mean_squared_error: 0.1547\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3066 - mean_squared_error: 0.2950 - val_loss: 0.1657 - val_mean_squared_error: 0.1542\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3093 - mean_squared_error: 0.2978 - val_loss: 0.1664 - val_mean_squared_error: 0.1548\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 3s 74us/step - loss: 0.3086 - mean_squared_error: 0.2971 - val_loss: 0.1654 - val_mean_squared_error: 0.1539\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3069 - mean_squared_error: 0.2954 - val_loss: 0.1656 - val_mean_squared_error: 0.1541\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 3s 75us/step - loss: 0.3099 - mean_squared_error: 0.2984 - val_loss: 0.1658 - val_mean_squared_error: 0.1543\n",
      "hw1/models/model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolAnt-v1\n",
      "{'model_name': 'model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'dataset_name': 'RoboschoolAnt-v1', 'model_path': 'hw1/models/model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'train_mse': 0.1483872233621715, 'test_mse': 0.15426578611820307}\n",
      "Training a FC ANN for env RoboschoolHumanoid-v1\n",
      "loading dataset RoboschoolHumanoid-v1\n",
      "Domain name: RoboschoolHumanoid-v1\n",
      "(39999, 44) (4445, 44) (39999, 17) (4445, 17)\n",
      "model_name='model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "Train on 39999 samples, validate on 4445 samples\n",
      "Epoch 1/100\n",
      "39999/39999 [==============================] - 5s 114us/step - loss: 0.3019 - mean_squared_error: 0.2757 - val_loss: 0.0860 - val_mean_squared_error: 0.0603\n",
      "Epoch 2/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.1168 - mean_squared_error: 0.0921 - val_loss: 0.0750 - val_mean_squared_error: 0.0514\n",
      "Epoch 3/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0944 - mean_squared_error: 0.0721 - val_loss: 0.0673 - val_mean_squared_error: 0.0465\n",
      "Epoch 4/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0834 - mean_squared_error: 0.0641 - val_loss: 0.0590 - val_mean_squared_error: 0.0414\n",
      "Epoch 5/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0760 - mean_squared_error: 0.0601 - val_loss: 0.0537 - val_mean_squared_error: 0.0396\n",
      "Epoch 6/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0691 - mean_squared_error: 0.0566 - val_loss: 0.0470 - val_mean_squared_error: 0.0361\n",
      "Epoch 7/100\n",
      "39999/39999 [==============================] - 3s 87us/step - loss: 0.0641 - mean_squared_error: 0.0546 - val_loss: 0.0443 - val_mean_squared_error: 0.0360\n",
      "Epoch 8/100\n",
      "39999/39999 [==============================] - 3s 81us/step - loss: 0.0599 - mean_squared_error: 0.0526 - val_loss: 0.0400 - val_mean_squared_error: 0.0336\n",
      "Epoch 9/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0570 - mean_squared_error: 0.0512 - val_loss: 0.0381 - val_mean_squared_error: 0.0328\n",
      "Epoch 10/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0554 - mean_squared_error: 0.0504 - val_loss: 0.0376 - val_mean_squared_error: 0.0328\n",
      "Epoch 11/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0546 - mean_squared_error: 0.0500 - val_loss: 0.0363 - val_mean_squared_error: 0.0319\n",
      "Epoch 12/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0537 - mean_squared_error: 0.0494 - val_loss: 0.0355 - val_mean_squared_error: 0.0312\n",
      "Epoch 13/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0531 - mean_squared_error: 0.0489 - val_loss: 0.0351 - val_mean_squared_error: 0.0310\n",
      "Epoch 14/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0529 - mean_squared_error: 0.0488 - val_loss: 0.0352 - val_mean_squared_error: 0.0312\n",
      "Epoch 15/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0526 - mean_squared_error: 0.0486 - val_loss: 0.0350 - val_mean_squared_error: 0.0310\n",
      "Epoch 16/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0520 - mean_squared_error: 0.0480 - val_loss: 0.0342 - val_mean_squared_error: 0.0302\n",
      "Epoch 17/100\n",
      "39999/39999 [==============================] - 3s 83us/step - loss: 0.0519 - mean_squared_error: 0.0479 - val_loss: 0.0346 - val_mean_squared_error: 0.0306\n",
      "Epoch 18/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0516 - mean_squared_error: 0.0476 - val_loss: 0.0338 - val_mean_squared_error: 0.0298\n",
      "Epoch 19/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0513 - mean_squared_error: 0.0474 - val_loss: 0.0336 - val_mean_squared_error: 0.0296\n",
      "Epoch 20/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0511 - mean_squared_error: 0.0471 - val_loss: 0.0337 - val_mean_squared_error: 0.0298\n",
      "Epoch 21/100\n",
      "39999/39999 [==============================] - 4s 89us/step - loss: 0.0509 - mean_squared_error: 0.0469 - val_loss: 0.0342 - val_mean_squared_error: 0.0302\n",
      "Epoch 22/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0510 - mean_squared_error: 0.0470 - val_loss: 0.0335 - val_mean_squared_error: 0.0296\n",
      "Epoch 23/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0507 - mean_squared_error: 0.0467 - val_loss: 0.0337 - val_mean_squared_error: 0.0298\n",
      "Epoch 24/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0508 - mean_squared_error: 0.0468 - val_loss: 0.0332 - val_mean_squared_error: 0.0292\n",
      "Epoch 25/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0503 - mean_squared_error: 0.0463 - val_loss: 0.0331 - val_mean_squared_error: 0.0291\n",
      "Epoch 26/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0507 - mean_squared_error: 0.0468 - val_loss: 0.0329 - val_mean_squared_error: 0.0289\n",
      "Epoch 27/100\n",
      "39999/39999 [==============================] - 3s 81us/step - loss: 0.0507 - mean_squared_error: 0.0467 - val_loss: 0.0340 - val_mean_squared_error: 0.0300\n",
      "Epoch 28/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0504 - mean_squared_error: 0.0464 - val_loss: 0.0330 - val_mean_squared_error: 0.0290\n",
      "Epoch 29/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0503 - mean_squared_error: 0.0463 - val_loss: 0.0327 - val_mean_squared_error: 0.0287\n",
      "Epoch 30/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0504 - mean_squared_error: 0.0464 - val_loss: 0.0334 - val_mean_squared_error: 0.0294\n",
      "Epoch 31/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0503 - mean_squared_error: 0.0463 - val_loss: 0.0331 - val_mean_squared_error: 0.0291\n",
      "Epoch 32/100\n",
      "39999/39999 [==============================] - 3s 84us/step - loss: 0.0502 - mean_squared_error: 0.0462 - val_loss: 0.0338 - val_mean_squared_error: 0.0298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "39999/39999 [==============================] - 3s 81us/step - loss: 0.0501 - mean_squared_error: 0.0461 - val_loss: 0.0332 - val_mean_squared_error: 0.0292\n",
      "Epoch 34/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0502 - mean_squared_error: 0.0462 - val_loss: 0.0332 - val_mean_squared_error: 0.0292\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 35/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0479 - mean_squared_error: 0.0441 - val_loss: 0.0306 - val_mean_squared_error: 0.0269\n",
      "Epoch 36/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0473 - mean_squared_error: 0.0438 - val_loss: 0.0312 - val_mean_squared_error: 0.0278\n",
      "Epoch 37/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0474 - mean_squared_error: 0.0441 - val_loss: 0.0302 - val_mean_squared_error: 0.0269\n",
      "Epoch 38/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0470 - mean_squared_error: 0.0438 - val_loss: 0.0302 - val_mean_squared_error: 0.0270\n",
      "Epoch 39/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0471 - mean_squared_error: 0.0440 - val_loss: 0.0302 - val_mean_squared_error: 0.0271\n",
      "Epoch 40/100\n",
      "39999/39999 [==============================] - 3s 83us/step - loss: 0.0470 - mean_squared_error: 0.0439 - val_loss: 0.0306 - val_mean_squared_error: 0.0276\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 41/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0456 - mean_squared_error: 0.0426 - val_loss: 0.0286 - val_mean_squared_error: 0.0258\n",
      "Epoch 42/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0452 - mean_squared_error: 0.0424 - val_loss: 0.0288 - val_mean_squared_error: 0.0261\n",
      "Epoch 43/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0453 - mean_squared_error: 0.0426 - val_loss: 0.0288 - val_mean_squared_error: 0.0261\n",
      "Epoch 44/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0451 - mean_squared_error: 0.0425 - val_loss: 0.0285 - val_mean_squared_error: 0.0259\n",
      "Epoch 45/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0449 - mean_squared_error: 0.0424 - val_loss: 0.0282 - val_mean_squared_error: 0.0258\n",
      "Epoch 46/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0450 - mean_squared_error: 0.0425 - val_loss: 0.0282 - val_mean_squared_error: 0.0257\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 47/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0444 - mean_squared_error: 0.0420 - val_loss: 0.0273 - val_mean_squared_error: 0.0249\n",
      "Epoch 48/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0438 - mean_squared_error: 0.0415 - val_loss: 0.0270 - val_mean_squared_error: 0.0247\n",
      "Epoch 49/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0438 - mean_squared_error: 0.0415 - val_loss: 0.0272 - val_mean_squared_error: 0.0250\n",
      "Epoch 50/100\n",
      "39999/39999 [==============================] - 3s 76us/step - loss: 0.0438 - mean_squared_error: 0.0416 - val_loss: 0.0269 - val_mean_squared_error: 0.0247\n",
      "Epoch 51/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0434 - mean_squared_error: 0.0412 - val_loss: 0.0266 - val_mean_squared_error: 0.0244\n",
      "Epoch 52/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0433 - mean_squared_error: 0.0412 - val_loss: 0.0268 - val_mean_squared_error: 0.0246\n",
      "Epoch 53/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0436 - mean_squared_error: 0.0415 - val_loss: 0.0266 - val_mean_squared_error: 0.0245\n",
      "Epoch 54/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0434 - mean_squared_error: 0.0414 - val_loss: 0.0268 - val_mean_squared_error: 0.0248\n",
      "Epoch 55/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0436 - mean_squared_error: 0.0415 - val_loss: 0.0265 - val_mean_squared_error: 0.0245\n",
      "Epoch 56/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0437 - mean_squared_error: 0.0417 - val_loss: 0.0266 - val_mean_squared_error: 0.0247\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 57/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0430 - mean_squared_error: 0.0410 - val_loss: 0.0265 - val_mean_squared_error: 0.0246\n",
      "Epoch 58/100\n",
      "39999/39999 [==============================] - 3s 76us/step - loss: 0.0426 - mean_squared_error: 0.0407 - val_loss: 0.0262 - val_mean_squared_error: 0.0243\n",
      "Epoch 59/100\n",
      "39999/39999 [==============================] - 3s 81us/step - loss: 0.0431 - mean_squared_error: 0.0411 - val_loss: 0.0261 - val_mean_squared_error: 0.0242\n",
      "Epoch 60/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0430 - mean_squared_error: 0.0411 - val_loss: 0.0261 - val_mean_squared_error: 0.0242\n",
      "Epoch 61/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0427 - mean_squared_error: 0.0408 - val_loss: 0.0258 - val_mean_squared_error: 0.0239\n",
      "Epoch 62/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0427 - mean_squared_error: 0.0409 - val_loss: 0.0261 - val_mean_squared_error: 0.0242\n",
      "Epoch 63/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0428 - mean_squared_error: 0.0409 - val_loss: 0.0262 - val_mean_squared_error: 0.0244\n",
      "Epoch 64/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0427 - mean_squared_error: 0.0408 - val_loss: 0.0260 - val_mean_squared_error: 0.0242\n",
      "Epoch 65/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0428 - mean_squared_error: 0.0410 - val_loss: 0.0260 - val_mean_squared_error: 0.0242\n",
      "Epoch 66/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0427 - mean_squared_error: 0.0409 - val_loss: 0.0260 - val_mean_squared_error: 0.0242\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 67/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0425 - mean_squared_error: 0.0408 - val_loss: 0.0259 - val_mean_squared_error: 0.0241\n",
      "Epoch 68/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0423 - mean_squared_error: 0.0406 - val_loss: 0.0258 - val_mean_squared_error: 0.0240\n",
      "Epoch 69/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0424 - mean_squared_error: 0.0407 - val_loss: 0.0257 - val_mean_squared_error: 0.0240\n",
      "Epoch 70/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0422 - mean_squared_error: 0.0404 - val_loss: 0.0256 - val_mean_squared_error: 0.0239\n",
      "Epoch 71/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0424 - mean_squared_error: 0.0407 - val_loss: 0.0258 - val_mean_squared_error: 0.0241\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 72/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0423 - mean_squared_error: 0.0406 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "Epoch 73/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0418 - mean_squared_error: 0.0401 - val_loss: 0.0257 - val_mean_squared_error: 0.0240\n",
      "Epoch 74/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0421 - mean_squared_error: 0.0404 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "Epoch 75/100\n",
      "39999/39999 [==============================] - 3s 81us/step - loss: 0.0424 - mean_squared_error: 0.0407 - val_loss: 0.0256 - val_mean_squared_error: 0.0239\n",
      "Epoch 76/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0423 - mean_squared_error: 0.0406 - val_loss: 0.0256 - val_mean_squared_error: 0.0239\n",
      "Epoch 77/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0424 - mean_squared_error: 0.0407 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0419 - mean_squared_error: 0.0402 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "Epoch 79/100\n",
      "39999/39999 [==============================] - 3s 82us/step - loss: 0.0425 - mean_squared_error: 0.0408 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "Epoch 80/100\n",
      "39999/39999 [==============================] - 3s 82us/step - loss: 0.0419 - mean_squared_error: 0.0402 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "Epoch 81/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0419 - mean_squared_error: 0.0402 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "Epoch 82/100\n",
      "39999/39999 [==============================] - 3s 76us/step - loss: 0.0419 - mean_squared_error: 0.0402 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 83/100\n",
      "39999/39999 [==============================] - 3s 80us/step - loss: 0.0420 - mean_squared_error: 0.0403 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "Epoch 84/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0421 - mean_squared_error: 0.0405 - val_loss: 0.0254 - val_mean_squared_error: 0.0237\n",
      "Epoch 85/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0422 - mean_squared_error: 0.0405 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "Epoch 86/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0419 - mean_squared_error: 0.0402 - val_loss: 0.0255 - val_mean_squared_error: 0.0239\n",
      "Epoch 87/100\n",
      "39999/39999 [==============================] - 3s 79us/step - loss: 0.0423 - mean_squared_error: 0.0406 - val_loss: 0.0254 - val_mean_squared_error: 0.0237\n",
      "Epoch 88/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0419 - mean_squared_error: 0.0402 - val_loss: 0.0254 - val_mean_squared_error: 0.0238\n",
      "Epoch 89/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0419 - mean_squared_error: 0.0402 - val_loss: 0.0254 - val_mean_squared_error: 0.0237\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 90/100\n",
      "39999/39999 [==============================] - 3s 85us/step - loss: 0.0419 - mean_squared_error: 0.0402 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "Epoch 91/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0423 - mean_squared_error: 0.0406 - val_loss: 0.0254 - val_mean_squared_error: 0.0238\n",
      "Epoch 92/100\n",
      "39999/39999 [==============================] - 3s 76us/step - loss: 0.0419 - mean_squared_error: 0.0402 - val_loss: 0.0254 - val_mean_squared_error: 0.0237\n",
      "Epoch 93/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0418 - mean_squared_error: 0.0402 - val_loss: 0.0254 - val_mean_squared_error: 0.0237\n",
      "Epoch 94/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0420 - mean_squared_error: 0.0403 - val_loss: 0.0254 - val_mean_squared_error: 0.0237\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 95/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0419 - mean_squared_error: 0.0402 - val_loss: 0.0254 - val_mean_squared_error: 0.0238\n",
      "Epoch 96/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0417 - mean_squared_error: 0.0400 - val_loss: 0.0255 - val_mean_squared_error: 0.0238\n",
      "Epoch 97/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0423 - mean_squared_error: 0.0406 - val_loss: 0.0253 - val_mean_squared_error: 0.0237\n",
      "Epoch 98/100\n",
      "39999/39999 [==============================] - 3s 78us/step - loss: 0.0419 - mean_squared_error: 0.0402 - val_loss: 0.0253 - val_mean_squared_error: 0.0237\n",
      "Epoch 99/100\n",
      "39999/39999 [==============================] - 3s 77us/step - loss: 0.0420 - mean_squared_error: 0.0403 - val_loss: 0.0254 - val_mean_squared_error: 0.0238\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 100/100\n",
      "39999/39999 [==============================] - 3s 76us/step - loss: 0.0420 - mean_squared_error: 0.0403 - val_loss: 0.0254 - val_mean_squared_error: 0.0237\n",
      "hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolHumanoid-v1\n",
      "{'model_name': 'model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'dataset_name': 'RoboschoolHumanoid-v1', 'model_path': 'hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'train_mse': 0.022663329521807992, 'test_mse': 0.023701544806814134}\n",
      "Training a FC ANN for env RoboschoolHalfCheetah-v1\n",
      "loading dataset RoboschoolHalfCheetah-v1\n",
      "Domain name: RoboschoolHalfCheetah-v1\n",
      "(38341, 26) (4261, 26) (38341, 6) (4261, 6)\n",
      "model_name='model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "Train on 38341 samples, validate on 4261 samples\n",
      "Epoch 1/100\n",
      "38341/38341 [==============================] - 5s 119us/step - loss: 0.5337 - mean_squared_error: 0.5102 - val_loss: 0.1833 - val_mean_squared_error: 0.1603\n",
      "Epoch 2/100\n",
      "38341/38341 [==============================] - ETA: 0s - loss: 0.3174 - mean_squared_error: 0.29 - 3s 78us/step - loss: 0.3178 - mean_squared_error: 0.2951 - val_loss: 0.1624 - val_mean_squared_error: 0.1400\n",
      "Epoch 3/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.2766 - mean_squared_error: 0.2546 - val_loss: 0.1448 - val_mean_squared_error: 0.1233\n",
      "Epoch 4/100\n",
      "38341/38341 [==============================] - 3s 81us/step - loss: 0.2562 - mean_squared_error: 0.2351 - val_loss: 0.1313 - val_mean_squared_error: 0.1106\n",
      "Epoch 5/100\n",
      "38341/38341 [==============================] - 3s 80us/step - loss: 0.2419 - mean_squared_error: 0.2217 - val_loss: 0.1274 - val_mean_squared_error: 0.1078\n",
      "Epoch 6/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.2328 - mean_squared_error: 0.2137 - val_loss: 0.1234 - val_mean_squared_error: 0.1048\n",
      "Epoch 7/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.2233 - mean_squared_error: 0.2051 - val_loss: 0.1214 - val_mean_squared_error: 0.1037\n",
      "Epoch 8/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.2177 - mean_squared_error: 0.2003 - val_loss: 0.1142 - val_mean_squared_error: 0.0972\n",
      "Epoch 9/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.2135 - mean_squared_error: 0.1968 - val_loss: 0.1200 - val_mean_squared_error: 0.1036\n",
      "Epoch 10/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.2067 - mean_squared_error: 0.1907 - val_loss: 0.1183 - val_mean_squared_error: 0.1026\n",
      "Epoch 11/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.2012 - mean_squared_error: 0.1857 - val_loss: 0.1100 - val_mean_squared_error: 0.0948\n",
      "Epoch 12/100\n",
      "38341/38341 [==============================] - 3s 77us/step - loss: 0.2001 - mean_squared_error: 0.1851 - val_loss: 0.1147 - val_mean_squared_error: 0.0999\n",
      "Epoch 13/100\n",
      "38341/38341 [==============================] - 3s 81us/step - loss: 0.1988 - mean_squared_error: 0.1841 - val_loss: 0.1049 - val_mean_squared_error: 0.0903\n",
      "Epoch 14/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1945 - mean_squared_error: 0.1801 - val_loss: 0.1012 - val_mean_squared_error: 0.0870\n",
      "Epoch 15/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1935 - mean_squared_error: 0.1793 - val_loss: 0.1116 - val_mean_squared_error: 0.0976\n",
      "Epoch 16/100\n",
      "38341/38341 [==============================] - 3s 77us/step - loss: 0.1919 - mean_squared_error: 0.1779 - val_loss: 0.1041 - val_mean_squared_error: 0.0902\n",
      "Epoch 17/100\n",
      "38341/38341 [==============================] - 3s 80us/step - loss: 0.1895 - mean_squared_error: 0.1757 - val_loss: 0.0967 - val_mean_squared_error: 0.0831\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1902 - mean_squared_error: 0.1765 - val_loss: 0.0933 - val_mean_squared_error: 0.0797\n",
      "Epoch 19/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1875 - mean_squared_error: 0.1739 - val_loss: 0.1008 - val_mean_squared_error: 0.0874\n",
      "Epoch 20/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1883 - mean_squared_error: 0.1748 - val_loss: 0.1054 - val_mean_squared_error: 0.0920\n",
      "Epoch 21/100\n",
      "38341/38341 [==============================] - 3s 80us/step - loss: 0.1841 - mean_squared_error: 0.1707 - val_loss: 0.0972 - val_mean_squared_error: 0.0840\n",
      "Epoch 22/100\n",
      "38341/38341 [==============================] - 3s 80us/step - loss: 0.1825 - mean_squared_error: 0.1693 - val_loss: 0.1079 - val_mean_squared_error: 0.0948\n",
      "Epoch 23/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1829 - mean_squared_error: 0.1697 - val_loss: 0.1122 - val_mean_squared_error: 0.0991\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 24/100\n",
      "38341/38341 [==============================] - 3s 83us/step - loss: 0.1759 - mean_squared_error: 0.1630 - val_loss: 0.0935 - val_mean_squared_error: 0.0808\n",
      "Epoch 25/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1739 - mean_squared_error: 0.1614 - val_loss: 0.0946 - val_mean_squared_error: 0.0823\n",
      "Epoch 26/100\n",
      "38341/38341 [==============================] - 3s 82us/step - loss: 0.1738 - mean_squared_error: 0.1615 - val_loss: 0.0944 - val_mean_squared_error: 0.0823\n",
      "Epoch 27/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1754 - mean_squared_error: 0.1634 - val_loss: 0.0935 - val_mean_squared_error: 0.0817\n",
      "Epoch 28/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1755 - mean_squared_error: 0.1637 - val_loss: 0.0984 - val_mean_squared_error: 0.0868\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 29/100\n",
      "38341/38341 [==============================] - 3s 81us/step - loss: 0.1705 - mean_squared_error: 0.1590 - val_loss: 0.0884 - val_mean_squared_error: 0.0770\n",
      "Epoch 30/100\n",
      "38341/38341 [==============================] - 3s 85us/step - loss: 0.1669 - mean_squared_error: 0.1556 - val_loss: 0.0951 - val_mean_squared_error: 0.0839\n",
      "Epoch 31/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1646 - mean_squared_error: 0.1535 - val_loss: 0.0891 - val_mean_squared_error: 0.0781\n",
      "Epoch 32/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1674 - mean_squared_error: 0.1564 - val_loss: 0.0856 - val_mean_squared_error: 0.0748\n",
      "Epoch 33/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1647 - mean_squared_error: 0.1539 - val_loss: 0.0918 - val_mean_squared_error: 0.0811\n",
      "Epoch 34/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1672 - mean_squared_error: 0.1565 - val_loss: 0.0864 - val_mean_squared_error: 0.0758\n",
      "Epoch 35/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1647 - mean_squared_error: 0.1542 - val_loss: 0.0891 - val_mean_squared_error: 0.0788\n",
      "Epoch 36/100\n",
      "38341/38341 [==============================] - ETA: 0s - loss: 0.1642 - mean_squared_error: 0.15 - 3s 77us/step - loss: 0.1643 - mean_squared_error: 0.1540 - val_loss: 0.0890 - val_mean_squared_error: 0.0787\n",
      "Epoch 37/100\n",
      "38341/38341 [==============================] - 3s 80us/step - loss: 0.1645 - mean_squared_error: 0.1543 - val_loss: 0.0885 - val_mean_squared_error: 0.0784\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 38/100\n",
      "38341/38341 [==============================] - 3s 80us/step - loss: 0.1622 - mean_squared_error: 0.1522 - val_loss: 0.0856 - val_mean_squared_error: 0.0756\n",
      "Epoch 39/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1607 - mean_squared_error: 0.1507 - val_loss: 0.0867 - val_mean_squared_error: 0.0768\n",
      "Epoch 40/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1612 - mean_squared_error: 0.1513 - val_loss: 0.0871 - val_mean_squared_error: 0.0772\n",
      "Epoch 41/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1622 - mean_squared_error: 0.1524 - val_loss: 0.0868 - val_mean_squared_error: 0.0771\n",
      "Epoch 42/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1620 - mean_squared_error: 0.1523 - val_loss: 0.0843 - val_mean_squared_error: 0.0747\n",
      "Epoch 43/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1610 - mean_squared_error: 0.1513 - val_loss: 0.0848 - val_mean_squared_error: 0.0752\n",
      "Epoch 44/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1628 - mean_squared_error: 0.1533 - val_loss: 0.0853 - val_mean_squared_error: 0.0758\n",
      "Epoch 45/100\n",
      "38341/38341 [==============================] - 3s 77us/step - loss: 0.1612 - mean_squared_error: 0.1517 - val_loss: 0.0860 - val_mean_squared_error: 0.0766\n",
      "Epoch 46/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1619 - mean_squared_error: 0.1525 - val_loss: 0.0828 - val_mean_squared_error: 0.0735\n",
      "Epoch 47/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1615 - mean_squared_error: 0.1522 - val_loss: 0.0873 - val_mean_squared_error: 0.0780\n",
      "Epoch 48/100\n",
      "38341/38341 [==============================] - 3s 81us/step - loss: 0.1604 - mean_squared_error: 0.1511 - val_loss: 0.0858 - val_mean_squared_error: 0.0766\n",
      "Epoch 49/100\n",
      "38341/38341 [==============================] - 3s 81us/step - loss: 0.1600 - mean_squared_error: 0.1509 - val_loss: 0.0868 - val_mean_squared_error: 0.0777\n",
      "Epoch 50/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1588 - mean_squared_error: 0.1497 - val_loss: 0.0804 - val_mean_squared_error: 0.0713\n",
      "Epoch 51/100\n",
      "38341/38341 [==============================] - 3s 77us/step - loss: 0.1594 - mean_squared_error: 0.1504 - val_loss: 0.0846 - val_mean_squared_error: 0.0756\n",
      "Epoch 52/100\n",
      "38341/38341 [==============================] - 3s 77us/step - loss: 0.1583 - mean_squared_error: 0.1493 - val_loss: 0.0842 - val_mean_squared_error: 0.0753\n",
      "Epoch 53/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1592 - mean_squared_error: 0.1503 - val_loss: 0.0848 - val_mean_squared_error: 0.0759\n",
      "Epoch 54/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1608 - mean_squared_error: 0.1519 - val_loss: 0.0855 - val_mean_squared_error: 0.0767\n",
      "Epoch 55/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1591 - mean_squared_error: 0.1503 - val_loss: 0.0831 - val_mean_squared_error: 0.0743\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 56/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1590 - mean_squared_error: 0.1502 - val_loss: 0.0838 - val_mean_squared_error: 0.0751\n",
      "Epoch 57/100\n",
      "38341/38341 [==============================] - 3s 82us/step - loss: 0.1584 - mean_squared_error: 0.1497 - val_loss: 0.0826 - val_mean_squared_error: 0.0740\n",
      "Epoch 58/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1559 - mean_squared_error: 0.1472 - val_loss: 0.0819 - val_mean_squared_error: 0.0732\n",
      "Epoch 59/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1584 - mean_squared_error: 0.1497 - val_loss: 0.0827 - val_mean_squared_error: 0.0740\n",
      "Epoch 60/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1566 - mean_squared_error: 0.1480 - val_loss: 0.0828 - val_mean_squared_error: 0.0742\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 61/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1585 - mean_squared_error: 0.1500 - val_loss: 0.0836 - val_mean_squared_error: 0.0751\n",
      "Epoch 62/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1567 - mean_squared_error: 0.1482 - val_loss: 0.0827 - val_mean_squared_error: 0.0742\n",
      "Epoch 63/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1585 - mean_squared_error: 0.1499 - val_loss: 0.0837 - val_mean_squared_error: 0.0752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1572 - mean_squared_error: 0.1487 - val_loss: 0.0838 - val_mean_squared_error: 0.0753\n",
      "Epoch 65/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1567 - mean_squared_error: 0.1482 - val_loss: 0.0827 - val_mean_squared_error: 0.0742\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 66/100\n",
      "38341/38341 [==============================] - 3s 77us/step - loss: 0.1571 - mean_squared_error: 0.1486 - val_loss: 0.0806 - val_mean_squared_error: 0.0721\n",
      "Epoch 67/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1579 - mean_squared_error: 0.1494 - val_loss: 0.0802 - val_mean_squared_error: 0.0717\n",
      "Epoch 68/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1551 - mean_squared_error: 0.1467 - val_loss: 0.0813 - val_mean_squared_error: 0.0729\n",
      "Epoch 69/100\n",
      "38341/38341 [==============================] - 3s 77us/step - loss: 0.1563 - mean_squared_error: 0.1478 - val_loss: 0.0813 - val_mean_squared_error: 0.0729\n",
      "Epoch 70/100\n",
      "38341/38341 [==============================] - 3s 81us/step - loss: 0.1556 - mean_squared_error: 0.1472 - val_loss: 0.0811 - val_mean_squared_error: 0.0727\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 71/100\n",
      "38341/38341 [==============================] - 3s 80us/step - loss: 0.1563 - mean_squared_error: 0.1478 - val_loss: 0.0826 - val_mean_squared_error: 0.0742\n",
      "Epoch 72/100\n",
      "38341/38341 [==============================] - 3s 80us/step - loss: 0.1566 - mean_squared_error: 0.1482 - val_loss: 0.0829 - val_mean_squared_error: 0.0744\n",
      "Epoch 73/100\n",
      "38341/38341 [==============================] - 3s 82us/step - loss: 0.1557 - mean_squared_error: 0.1473 - val_loss: 0.0821 - val_mean_squared_error: 0.0737\n",
      "Epoch 74/100\n",
      "38341/38341 [==============================] - 3s 81us/step - loss: 0.1570 - mean_squared_error: 0.1485 - val_loss: 0.0818 - val_mean_squared_error: 0.0734\n",
      "Epoch 75/100\n",
      "38341/38341 [==============================] - 3s 81us/step - loss: 0.1559 - mean_squared_error: 0.1475 - val_loss: 0.0812 - val_mean_squared_error: 0.0728\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 76/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1540 - mean_squared_error: 0.1456 - val_loss: 0.0824 - val_mean_squared_error: 0.0740\n",
      "Epoch 77/100\n",
      "38341/38341 [==============================] - 3s 84us/step - loss: 0.1567 - mean_squared_error: 0.1483 - val_loss: 0.0810 - val_mean_squared_error: 0.0726\n",
      "Epoch 78/100\n",
      "38341/38341 [==============================] - 3s 80us/step - loss: 0.1558 - mean_squared_error: 0.1474 - val_loss: 0.0822 - val_mean_squared_error: 0.0738\n",
      "Epoch 79/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1553 - mean_squared_error: 0.1469 - val_loss: 0.0815 - val_mean_squared_error: 0.0731\n",
      "Epoch 80/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1559 - mean_squared_error: 0.1475 - val_loss: 0.0816 - val_mean_squared_error: 0.0732\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 81/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1551 - mean_squared_error: 0.1467 - val_loss: 0.0812 - val_mean_squared_error: 0.0728\n",
      "Epoch 82/100\n",
      "38341/38341 [==============================] - 3s 77us/step - loss: 0.1560 - mean_squared_error: 0.1476 - val_loss: 0.0816 - val_mean_squared_error: 0.0732\n",
      "Epoch 83/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1567 - mean_squared_error: 0.1483 - val_loss: 0.0819 - val_mean_squared_error: 0.0735\n",
      "Epoch 84/100\n",
      "38341/38341 [==============================] - 3s 77us/step - loss: 0.1553 - mean_squared_error: 0.1469 - val_loss: 0.0810 - val_mean_squared_error: 0.0726\n",
      "Epoch 85/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1559 - mean_squared_error: 0.1475 - val_loss: 0.0811 - val_mean_squared_error: 0.0727\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 86/100\n",
      "38341/38341 [==============================] - 3s 77us/step - loss: 0.1555 - mean_squared_error: 0.1471 - val_loss: 0.0807 - val_mean_squared_error: 0.0723\n",
      "Epoch 87/100\n",
      "38341/38341 [==============================] - 3s 89us/step - loss: 0.1559 - mean_squared_error: 0.1475 - val_loss: 0.0816 - val_mean_squared_error: 0.0732\n",
      "Epoch 88/100\n",
      "38341/38341 [==============================] - 3s 77us/step - loss: 0.1549 - mean_squared_error: 0.1465 - val_loss: 0.0807 - val_mean_squared_error: 0.0723\n",
      "Epoch 89/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1569 - mean_squared_error: 0.1485 - val_loss: 0.0821 - val_mean_squared_error: 0.0737\n",
      "Epoch 90/100\n",
      "38341/38341 [==============================] - 3s 82us/step - loss: 0.1574 - mean_squared_error: 0.1490 - val_loss: 0.0807 - val_mean_squared_error: 0.0723\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 91/100\n",
      "38341/38341 [==============================] - 3s 80us/step - loss: 0.1552 - mean_squared_error: 0.1468 - val_loss: 0.0817 - val_mean_squared_error: 0.0733\n",
      "Epoch 92/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1555 - mean_squared_error: 0.1471 - val_loss: 0.0808 - val_mean_squared_error: 0.0724\n",
      "Epoch 93/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1573 - mean_squared_error: 0.1489 - val_loss: 0.0798 - val_mean_squared_error: 0.0714\n",
      "Epoch 94/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1570 - mean_squared_error: 0.1486 - val_loss: 0.0806 - val_mean_squared_error: 0.0723\n",
      "Epoch 95/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1552 - mean_squared_error: 0.1468 - val_loss: 0.0822 - val_mean_squared_error: 0.0738\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 96/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1557 - mean_squared_error: 0.1473 - val_loss: 0.0803 - val_mean_squared_error: 0.0719\n",
      "Epoch 97/100\n",
      "38341/38341 [==============================] - 3s 83us/step - loss: 0.1558 - mean_squared_error: 0.1474 - val_loss: 0.0797 - val_mean_squared_error: 0.0713\n",
      "Epoch 98/100\n",
      "38341/38341 [==============================] - 3s 78us/step - loss: 0.1566 - mean_squared_error: 0.1482 - val_loss: 0.0806 - val_mean_squared_error: 0.0722\n",
      "Epoch 99/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1550 - mean_squared_error: 0.1466 - val_loss: 0.0816 - val_mean_squared_error: 0.0732\n",
      "Epoch 100/100\n",
      "38341/38341 [==============================] - 3s 79us/step - loss: 0.1558 - mean_squared_error: 0.1474 - val_loss: 0.0811 - val_mean_squared_error: 0.0727\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "hw1/models/model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolHalfCheetah-v1\n",
      "{'model_name': 'model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'dataset_name': 'RoboschoolHalfCheetah-v1', 'model_path': 'hw1/models/model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'train_mse': 0.07219472002511503, 'test_mse': 0.0726893770226361}\n",
      "Training a FC ANN for env RoboschoolReacher-v1\n",
      "loading dataset RoboschoolReacher-v1\n",
      "Domain name: RoboschoolReacher-v1\n",
      "(6750, 9) (750, 9) (6750, 2) (750, 2)\n",
      "model_name='model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/100\n",
      "6750/6750 [==============================] - 2s 312us/step - loss: 0.5837 - mean_squared_error: 0.5620 - val_loss: 0.1570 - val_mean_squared_error: 0.1353\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.3034 - mean_squared_error: 0.2817 - val_loss: 0.1124 - val_mean_squared_error: 0.0907\n",
      "Epoch 3/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.2238 - mean_squared_error: 0.2021 - val_loss: 0.1042 - val_mean_squared_error: 0.0824\n",
      "Epoch 4/100\n",
      "6750/6750 [==============================] - 1s 83us/step - loss: 0.1781 - mean_squared_error: 0.1564 - val_loss: 0.0964 - val_mean_squared_error: 0.0747\n",
      "Epoch 5/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.1609 - mean_squared_error: 0.1393 - val_loss: 0.0929 - val_mean_squared_error: 0.0713\n",
      "Epoch 6/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.1395 - mean_squared_error: 0.1179 - val_loss: 0.0910 - val_mean_squared_error: 0.0694\n",
      "Epoch 7/100\n",
      "6750/6750 [==============================] - 1s 77us/step - loss: 0.1297 - mean_squared_error: 0.1082 - val_loss: 0.0900 - val_mean_squared_error: 0.0685\n",
      "Epoch 8/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.1182 - mean_squared_error: 0.0968 - val_loss: 0.0898 - val_mean_squared_error: 0.0685\n",
      "Epoch 9/100\n",
      "6750/6750 [==============================] - 1s 78us/step - loss: 0.1155 - mean_squared_error: 0.0942 - val_loss: 0.0893 - val_mean_squared_error: 0.0681\n",
      "Epoch 10/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.1114 - mean_squared_error: 0.0902 - val_loss: 0.0897 - val_mean_squared_error: 0.0685\n",
      "Epoch 11/100\n",
      "6750/6750 [==============================] - 1s 82us/step - loss: 0.1093 - mean_squared_error: 0.0882 - val_loss: 0.0885 - val_mean_squared_error: 0.0674\n",
      "Epoch 12/100\n",
      "6750/6750 [==============================] - 1s 85us/step - loss: 0.1045 - mean_squared_error: 0.0835 - val_loss: 0.0888 - val_mean_squared_error: 0.0679\n",
      "Epoch 13/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.1030 - mean_squared_error: 0.0822 - val_loss: 0.0865 - val_mean_squared_error: 0.0658\n",
      "Epoch 14/100\n",
      "6750/6750 [==============================] - 1s 76us/step - loss: 0.0979 - mean_squared_error: 0.0772 - val_loss: 0.0848 - val_mean_squared_error: 0.0642\n",
      "Epoch 15/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0981 - mean_squared_error: 0.0776 - val_loss: 0.0854 - val_mean_squared_error: 0.0650\n",
      "Epoch 16/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0974 - mean_squared_error: 0.0771 - val_loss: 0.0815 - val_mean_squared_error: 0.0613\n",
      "Epoch 17/100\n",
      "6750/6750 [==============================] - 1s 84us/step - loss: 0.0973 - mean_squared_error: 0.0771 - val_loss: 0.0846 - val_mean_squared_error: 0.0645\n",
      "Epoch 18/100\n",
      "6750/6750 [==============================] - 1s 85us/step - loss: 0.0980 - mean_squared_error: 0.0780 - val_loss: 0.0828 - val_mean_squared_error: 0.0629\n",
      "Epoch 19/100\n",
      "6750/6750 [==============================] - 1s 83us/step - loss: 0.0944 - mean_squared_error: 0.0746 - val_loss: 0.0812 - val_mean_squared_error: 0.0614\n",
      "Epoch 20/100\n",
      "6750/6750 [==============================] - 1s 84us/step - loss: 0.0905 - mean_squared_error: 0.0709 - val_loss: 0.0828 - val_mean_squared_error: 0.0633\n",
      "Epoch 21/100\n",
      "6750/6750 [==============================] - 1s 78us/step - loss: 0.0910 - mean_squared_error: 0.0716 - val_loss: 0.0779 - val_mean_squared_error: 0.0585\n",
      "Epoch 22/100\n",
      "6750/6750 [==============================] - 1s 82us/step - loss: 0.0904 - mean_squared_error: 0.0712 - val_loss: 0.0789 - val_mean_squared_error: 0.0598\n",
      "Epoch 23/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0908 - mean_squared_error: 0.0718 - val_loss: 0.0803 - val_mean_squared_error: 0.0614\n",
      "Epoch 24/100\n",
      "6750/6750 [==============================] - 1s 78us/step - loss: 0.0893 - mean_squared_error: 0.0705 - val_loss: 0.0778 - val_mean_squared_error: 0.0591\n",
      "Epoch 25/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0888 - mean_squared_error: 0.0702 - val_loss: 0.0757 - val_mean_squared_error: 0.0572\n",
      "Epoch 26/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0884 - mean_squared_error: 0.0700 - val_loss: 0.0744 - val_mean_squared_error: 0.0561\n",
      "Epoch 27/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0864 - mean_squared_error: 0.0683 - val_loss: 0.0703 - val_mean_squared_error: 0.0522\n",
      "Epoch 28/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0826 - mean_squared_error: 0.0646 - val_loss: 0.0690 - val_mean_squared_error: 0.0512\n",
      "Epoch 29/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0871 - mean_squared_error: 0.0694 - val_loss: 0.0731 - val_mean_squared_error: 0.0555\n",
      "Epoch 30/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0840 - mean_squared_error: 0.0666 - val_loss: 0.0701 - val_mean_squared_error: 0.0527\n",
      "Epoch 31/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0836 - mean_squared_error: 0.0663 - val_loss: 0.0695 - val_mean_squared_error: 0.0524\n",
      "Epoch 32/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0813 - mean_squared_error: 0.0643 - val_loss: 0.0714 - val_mean_squared_error: 0.0546\n",
      "Epoch 33/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0799 - mean_squared_error: 0.0631 - val_loss: 0.0663 - val_mean_squared_error: 0.0497\n",
      "Epoch 34/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0810 - mean_squared_error: 0.0645 - val_loss: 0.0661 - val_mean_squared_error: 0.0497\n",
      "Epoch 35/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0845 - mean_squared_error: 0.0682 - val_loss: 0.0626 - val_mean_squared_error: 0.0465\n",
      "Epoch 36/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0810 - mean_squared_error: 0.0649 - val_loss: 0.0614 - val_mean_squared_error: 0.0455\n",
      "Epoch 37/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0808 - mean_squared_error: 0.0650 - val_loss: 0.0599 - val_mean_squared_error: 0.0443\n",
      "Epoch 38/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0792 - mean_squared_error: 0.0637 - val_loss: 0.0677 - val_mean_squared_error: 0.0523\n",
      "Epoch 39/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0767 - mean_squared_error: 0.0614 - val_loss: 0.0599 - val_mean_squared_error: 0.0446\n",
      "Epoch 40/100\n",
      "6750/6750 [==============================] - 1s 82us/step - loss: 0.0781 - mean_squared_error: 0.0630 - val_loss: 0.0591 - val_mean_squared_error: 0.0441\n",
      "Epoch 41/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0786 - mean_squared_error: 0.0637 - val_loss: 0.0654 - val_mean_squared_error: 0.0506\n",
      "Epoch 42/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0777 - mean_squared_error: 0.0631 - val_loss: 0.0601 - val_mean_squared_error: 0.0455\n",
      "Epoch 43/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0789 - mean_squared_error: 0.0644 - val_loss: 0.0578 - val_mean_squared_error: 0.0435\n",
      "Epoch 44/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0770 - mean_squared_error: 0.0627 - val_loss: 0.0592 - val_mean_squared_error: 0.0451\n",
      "Epoch 45/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0748 - mean_squared_error: 0.0608 - val_loss: 0.0588 - val_mean_squared_error: 0.0450\n",
      "Epoch 46/100\n",
      "6750/6750 [==============================] - 1s 82us/step - loss: 0.0734 - mean_squared_error: 0.0596 - val_loss: 0.0599 - val_mean_squared_error: 0.0462\n",
      "Epoch 47/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0767 - mean_squared_error: 0.0631 - val_loss: 0.0584 - val_mean_squared_error: 0.0450\n",
      "Epoch 48/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0712 - mean_squared_error: 0.0578 - val_loss: 0.0546 - val_mean_squared_error: 0.0414\n",
      "Epoch 49/100\n",
      "6750/6750 [==============================] - 1s 82us/step - loss: 0.0746 - mean_squared_error: 0.0614 - val_loss: 0.0624 - val_mean_squared_error: 0.0493\n",
      "Epoch 50/100\n",
      "6750/6750 [==============================] - 1s 76us/step - loss: 0.0768 - mean_squared_error: 0.0638 - val_loss: 0.0597 - val_mean_squared_error: 0.0468\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0733 - mean_squared_error: 0.0605 - val_loss: 0.0547 - val_mean_squared_error: 0.0420\n",
      "Epoch 52/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0694 - mean_squared_error: 0.0568 - val_loss: 0.0584 - val_mean_squared_error: 0.0459\n",
      "Epoch 53/100\n",
      "6750/6750 [==============================] - 1s 82us/step - loss: 0.0736 - mean_squared_error: 0.0612 - val_loss: 0.0538 - val_mean_squared_error: 0.0415\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 54/100\n",
      "6750/6750 [==============================] - 1s 82us/step - loss: 0.0713 - mean_squared_error: 0.0590 - val_loss: 0.0527 - val_mean_squared_error: 0.0406\n",
      "Epoch 55/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0661 - mean_squared_error: 0.0540 - val_loss: 0.0512 - val_mean_squared_error: 0.0392\n",
      "Epoch 56/100\n",
      "6750/6750 [==============================] - 1s 83us/step - loss: 0.0657 - mean_squared_error: 0.0537 - val_loss: 0.0500 - val_mean_squared_error: 0.0381\n",
      "Epoch 57/100\n",
      "6750/6750 [==============================] - 1s 76us/step - loss: 0.0691 - mean_squared_error: 0.0572 - val_loss: 0.0510 - val_mean_squared_error: 0.0392\n",
      "Epoch 58/100\n",
      "6750/6750 [==============================] - 1s 83us/step - loss: 0.0631 - mean_squared_error: 0.0514 - val_loss: 0.0500 - val_mean_squared_error: 0.0383\n",
      "Epoch 59/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0665 - mean_squared_error: 0.0549 - val_loss: 0.0510 - val_mean_squared_error: 0.0395\n",
      "Epoch 60/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0675 - mean_squared_error: 0.0560 - val_loss: 0.0504 - val_mean_squared_error: 0.0390\n",
      "Epoch 61/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0645 - mean_squared_error: 0.0531 - val_loss: 0.0495 - val_mean_squared_error: 0.0383\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 62/100\n",
      "6750/6750 [==============================] - 1s 77us/step - loss: 0.0650 - mean_squared_error: 0.0538 - val_loss: 0.0471 - val_mean_squared_error: 0.0359\n",
      "Epoch 63/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0632 - mean_squared_error: 0.0520 - val_loss: 0.0461 - val_mean_squared_error: 0.0349\n",
      "Epoch 64/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0623 - mean_squared_error: 0.0512 - val_loss: 0.0475 - val_mean_squared_error: 0.0364\n",
      "Epoch 65/100\n",
      "6750/6750 [==============================] - 1s 82us/step - loss: 0.0638 - mean_squared_error: 0.0528 - val_loss: 0.0470 - val_mean_squared_error: 0.0360\n",
      "Epoch 66/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0635 - mean_squared_error: 0.0526 - val_loss: 0.0468 - val_mean_squared_error: 0.0359\n",
      "Epoch 67/100\n",
      "6750/6750 [==============================] - 1s 77us/step - loss: 0.0617 - mean_squared_error: 0.0509 - val_loss: 0.0462 - val_mean_squared_error: 0.0353\n",
      "Epoch 68/100\n",
      "6750/6750 [==============================] - 0s 71us/step - loss: 0.0600 - mean_squared_error: 0.0492 - val_loss: 0.0456 - val_mean_squared_error: 0.0348\n",
      "Epoch 69/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0612 - mean_squared_error: 0.0505 - val_loss: 0.0459 - val_mean_squared_error: 0.0352\n",
      "Epoch 70/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0625 - mean_squared_error: 0.0518 - val_loss: 0.0444 - val_mean_squared_error: 0.0338\n",
      "Epoch 71/100\n",
      "6750/6750 [==============================] - 1s 76us/step - loss: 0.0592 - mean_squared_error: 0.0486 - val_loss: 0.0438 - val_mean_squared_error: 0.0332\n",
      "Epoch 72/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0606 - mean_squared_error: 0.0501 - val_loss: 0.0426 - val_mean_squared_error: 0.0321\n",
      "Epoch 73/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0608 - mean_squared_error: 0.0503 - val_loss: 0.0455 - val_mean_squared_error: 0.0350\n",
      "Epoch 74/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0594 - mean_squared_error: 0.0490 - val_loss: 0.0421 - val_mean_squared_error: 0.0318\n",
      "Epoch 75/100\n",
      "6750/6750 [==============================] - 1s 78us/step - loss: 0.0564 - mean_squared_error: 0.0461 - val_loss: 0.0423 - val_mean_squared_error: 0.0320\n",
      "Epoch 76/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0605 - mean_squared_error: 0.0503 - val_loss: 0.0426 - val_mean_squared_error: 0.0323\n",
      "Epoch 77/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0600 - mean_squared_error: 0.0498 - val_loss: 0.0402 - val_mean_squared_error: 0.0300\n",
      "Epoch 78/100\n",
      "6750/6750 [==============================] - 1s 100us/step - loss: 0.0610 - mean_squared_error: 0.0508 - val_loss: 0.0428 - val_mean_squared_error: 0.0327\n",
      "Epoch 79/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0591 - mean_squared_error: 0.0490 - val_loss: 0.0427 - val_mean_squared_error: 0.0327\n",
      "Epoch 80/100\n",
      "6750/6750 [==============================] - 1s 83us/step - loss: 0.0597 - mean_squared_error: 0.0496 - val_loss: 0.0428 - val_mean_squared_error: 0.0328\n",
      "Epoch 81/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0587 - mean_squared_error: 0.0487 - val_loss: 0.0406 - val_mean_squared_error: 0.0307\n",
      "Epoch 82/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0600 - mean_squared_error: 0.0501 - val_loss: 0.0445 - val_mean_squared_error: 0.0346\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 83/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0603 - mean_squared_error: 0.0504 - val_loss: 0.0436 - val_mean_squared_error: 0.0338\n",
      "Epoch 84/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0570 - mean_squared_error: 0.0472 - val_loss: 0.0424 - val_mean_squared_error: 0.0326\n",
      "Epoch 85/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0554 - mean_squared_error: 0.0456 - val_loss: 0.0434 - val_mean_squared_error: 0.0336\n",
      "Epoch 86/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0566 - mean_squared_error: 0.0468 - val_loss: 0.0429 - val_mean_squared_error: 0.0331\n",
      "Epoch 87/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0579 - mean_squared_error: 0.0482 - val_loss: 0.0427 - val_mean_squared_error: 0.0330\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 88/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0553 - mean_squared_error: 0.0456 - val_loss: 0.0416 - val_mean_squared_error: 0.0319\n",
      "Epoch 89/100\n",
      "6750/6750 [==============================] - 1s 81us/step - loss: 0.0561 - mean_squared_error: 0.0464 - val_loss: 0.0407 - val_mean_squared_error: 0.0310\n",
      "Epoch 90/100\n",
      "6750/6750 [==============================] - 1s 82us/step - loss: 0.0555 - mean_squared_error: 0.0458 - val_loss: 0.0391 - val_mean_squared_error: 0.0295\n",
      "Epoch 91/100\n",
      "6750/6750 [==============================] - 1s 78us/step - loss: 0.0585 - mean_squared_error: 0.0488 - val_loss: 0.0397 - val_mean_squared_error: 0.0301\n",
      "Epoch 92/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0540 - mean_squared_error: 0.0443 - val_loss: 0.0395 - val_mean_squared_error: 0.0299\n",
      "Epoch 93/100\n",
      "6750/6750 [==============================] - 1s 78us/step - loss: 0.0544 - mean_squared_error: 0.0448 - val_loss: 0.0395 - val_mean_squared_error: 0.0299\n",
      "Epoch 94/100\n",
      "6750/6750 [==============================] - 1s 79us/step - loss: 0.0553 - mean_squared_error: 0.0457 - val_loss: 0.0400 - val_mean_squared_error: 0.0304\n",
      "Epoch 95/100\n",
      "6750/6750 [==============================] - 1s 82us/step - loss: 0.0549 - mean_squared_error: 0.0453 - val_loss: 0.0397 - val_mean_squared_error: 0.0301\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 96/100\n",
      "6750/6750 [==============================] - 1s 76us/step - loss: 0.0596 - mean_squared_error: 0.0500 - val_loss: 0.0393 - val_mean_squared_error: 0.0297\n",
      "Epoch 97/100\n",
      "6750/6750 [==============================] - 1s 85us/step - loss: 0.0547 - mean_squared_error: 0.0451 - val_loss: 0.0392 - val_mean_squared_error: 0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "6750/6750 [==============================] - 1s 85us/step - loss: 0.0577 - mean_squared_error: 0.0481 - val_loss: 0.0392 - val_mean_squared_error: 0.0296\n",
      "Epoch 99/100\n",
      "6750/6750 [==============================] - 1s 80us/step - loss: 0.0544 - mean_squared_error: 0.0449 - val_loss: 0.0394 - val_mean_squared_error: 0.0298\n",
      "Epoch 100/100\n",
      "6750/6750 [==============================] - 1s 77us/step - loss: 0.0561 - mean_squared_error: 0.0465 - val_loss: 0.0396 - val_mean_squared_error: 0.0300\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "hw1/models/model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolReacher-v1\n",
      "{'model_name': 'model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'dataset_name': 'RoboschoolReacher-v1', 'model_path': 'hw1/models/model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'train_mse': 0.01873875946542024, 'test_mse': 0.030032101617213987}\n",
      "Training a FC ANN for env RoboschoolHopper-v1\n",
      "loading dataset RoboschoolHopper-v1\n",
      "Domain name: RoboschoolHopper-v1\n",
      "(32200, 15) (3578, 15) (32200, 3) (3578, 3)\n",
      "model_name='model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "Train on 32200 samples, validate on 3578 samples\n",
      "Epoch 1/100\n",
      "32200/32200 [==============================] - 4s 128us/step - loss: 0.7905 - mean_squared_error: 0.7678 - val_loss: 0.2463 - val_mean_squared_error: 0.2236\n",
      "Epoch 2/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.3885 - mean_squared_error: 0.3659 - val_loss: 0.1953 - val_mean_squared_error: 0.1728\n",
      "Epoch 3/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.3225 - mean_squared_error: 0.3001 - val_loss: 0.1536 - val_mean_squared_error: 0.1313\n",
      "Epoch 4/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.2965 - mean_squared_error: 0.2744 - val_loss: 0.1428 - val_mean_squared_error: 0.1208\n",
      "Epoch 5/100\n",
      "32200/32200 [==============================] - 3s 86us/step - loss: 0.2772 - mean_squared_error: 0.2554 - val_loss: 0.1334 - val_mean_squared_error: 0.1117\n",
      "Epoch 6/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.2580 - mean_squared_error: 0.2365 - val_loss: 0.1291 - val_mean_squared_error: 0.1078\n",
      "Epoch 7/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.2498 - mean_squared_error: 0.2287 - val_loss: 0.2066 - val_mean_squared_error: 0.1858\n",
      "Epoch 8/100\n",
      "32200/32200 [==============================] - 3s 92us/step - loss: 0.2401 - mean_squared_error: 0.2194 - val_loss: 0.1533 - val_mean_squared_error: 0.1329\n",
      "Epoch 9/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.2324 - mean_squared_error: 0.2122 - val_loss: 0.1174 - val_mean_squared_error: 0.0974\n",
      "Epoch 10/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.2272 - mean_squared_error: 0.2074 - val_loss: 0.1318 - val_mean_squared_error: 0.1122\n",
      "Epoch 11/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.2293 - mean_squared_error: 0.2099 - val_loss: 0.1088 - val_mean_squared_error: 0.0896\n",
      "Epoch 12/100\n",
      "32200/32200 [==============================] - 3s 83us/step - loss: 0.2226 - mean_squared_error: 0.2036 - val_loss: 0.1327 - val_mean_squared_error: 0.1139\n",
      "Epoch 13/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.2133 - mean_squared_error: 0.1947 - val_loss: 0.1614 - val_mean_squared_error: 0.1430\n",
      "Epoch 14/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.2106 - mean_squared_error: 0.1924 - val_loss: 0.1535 - val_mean_squared_error: 0.1354\n",
      "Epoch 15/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.2086 - mean_squared_error: 0.1906 - val_loss: 0.1496 - val_mean_squared_error: 0.1318\n",
      "Epoch 16/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.2052 - mean_squared_error: 0.1875 - val_loss: 0.1548 - val_mean_squared_error: 0.1373\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 17/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.2018 - mean_squared_error: 0.1845 - val_loss: 0.1341 - val_mean_squared_error: 0.1170\n",
      "Epoch 18/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1974 - mean_squared_error: 0.1804 - val_loss: 0.1183 - val_mean_squared_error: 0.1015\n",
      "Epoch 19/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1942 - mean_squared_error: 0.1776 - val_loss: 0.1314 - val_mean_squared_error: 0.1149\n",
      "Epoch 20/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1935 - mean_squared_error: 0.1773 - val_loss: 0.1124 - val_mean_squared_error: 0.0963\n",
      "Epoch 21/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1916 - mean_squared_error: 0.1757 - val_loss: 0.1326 - val_mean_squared_error: 0.1168\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 22/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1873 - mean_squared_error: 0.1716 - val_loss: 0.1163 - val_mean_squared_error: 0.1008\n",
      "Epoch 23/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1870 - mean_squared_error: 0.1715 - val_loss: 0.1233 - val_mean_squared_error: 0.1080\n",
      "Epoch 24/100\n",
      "32200/32200 [==============================] - 3s 78us/step - loss: 0.1854 - mean_squared_error: 0.1701 - val_loss: 0.1274 - val_mean_squared_error: 0.1122\n",
      "Epoch 25/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1847 - mean_squared_error: 0.1696 - val_loss: 0.1246 - val_mean_squared_error: 0.1097\n",
      "Epoch 26/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1803 - mean_squared_error: 0.1655 - val_loss: 0.1141 - val_mean_squared_error: 0.0993\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 27/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1827 - mean_squared_error: 0.1680 - val_loss: 0.1249 - val_mean_squared_error: 0.1103\n",
      "Epoch 28/100\n",
      "32200/32200 [==============================] - 3s 79us/step - loss: 0.1798 - mean_squared_error: 0.1652 - val_loss: 0.1083 - val_mean_squared_error: 0.0937\n",
      "Epoch 29/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1792 - mean_squared_error: 0.1647 - val_loss: 0.1267 - val_mean_squared_error: 0.1122\n",
      "Epoch 30/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1801 - mean_squared_error: 0.1657 - val_loss: 0.1189 - val_mean_squared_error: 0.1045\n",
      "Epoch 31/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1786 - mean_squared_error: 0.1643 - val_loss: 0.1083 - val_mean_squared_error: 0.0941\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 32/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1772 - mean_squared_error: 0.1630 - val_loss: 0.1074 - val_mean_squared_error: 0.0932\n",
      "Epoch 33/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1765 - mean_squared_error: 0.1623 - val_loss: 0.1185 - val_mean_squared_error: 0.1044\n",
      "Epoch 34/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1745 - mean_squared_error: 0.1604 - val_loss: 0.1194 - val_mean_squared_error: 0.1053\n",
      "Epoch 35/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1777 - mean_squared_error: 0.1637 - val_loss: 0.1125 - val_mean_squared_error: 0.0985\n",
      "Epoch 36/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1787 - mean_squared_error: 0.1647 - val_loss: 0.1151 - val_mean_squared_error: 0.1011\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 37/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1765 - mean_squared_error: 0.1625 - val_loss: 0.1140 - val_mean_squared_error: 0.1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1793 - mean_squared_error: 0.1654 - val_loss: 0.1221 - val_mean_squared_error: 0.1082\n",
      "Epoch 39/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1798 - mean_squared_error: 0.1659 - val_loss: 0.1189 - val_mean_squared_error: 0.1050\n",
      "Epoch 40/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1753 - mean_squared_error: 0.1614 - val_loss: 0.1199 - val_mean_squared_error: 0.1061\n",
      "Epoch 41/100\n",
      "32200/32200 [==============================] - 3s 89us/step - loss: 0.1723 - mean_squared_error: 0.1585 - val_loss: 0.1099 - val_mean_squared_error: 0.0961\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 42/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1732 - mean_squared_error: 0.1594 - val_loss: 0.1122 - val_mean_squared_error: 0.0984\n",
      "Epoch 43/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1730 - mean_squared_error: 0.1592 - val_loss: 0.1158 - val_mean_squared_error: 0.1020\n",
      "Epoch 44/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1740 - mean_squared_error: 0.1602 - val_loss: 0.1130 - val_mean_squared_error: 0.0992\n",
      "Epoch 45/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1726 - mean_squared_error: 0.1588 - val_loss: 0.1167 - val_mean_squared_error: 0.1029\n",
      "Epoch 46/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1742 - mean_squared_error: 0.1604 - val_loss: 0.1185 - val_mean_squared_error: 0.1047\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 47/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1772 - mean_squared_error: 0.1635 - val_loss: 0.1171 - val_mean_squared_error: 0.1033\n",
      "Epoch 48/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1724 - mean_squared_error: 0.1587 - val_loss: 0.1158 - val_mean_squared_error: 0.1021\n",
      "Epoch 49/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1744 - mean_squared_error: 0.1606 - val_loss: 0.1187 - val_mean_squared_error: 0.1050\n",
      "Epoch 50/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1774 - mean_squared_error: 0.1637 - val_loss: 0.1156 - val_mean_squared_error: 0.1019\n",
      "Epoch 51/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1743 - mean_squared_error: 0.1606 - val_loss: 0.1147 - val_mean_squared_error: 0.1010\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 52/100\n",
      "32200/32200 [==============================] - 3s 86us/step - loss: 0.1711 - mean_squared_error: 0.1574 - val_loss: 0.1158 - val_mean_squared_error: 0.1021\n",
      "Epoch 53/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1733 - mean_squared_error: 0.1596 - val_loss: 0.1160 - val_mean_squared_error: 0.1023\n",
      "Epoch 54/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1753 - mean_squared_error: 0.1616 - val_loss: 0.1157 - val_mean_squared_error: 0.1020\n",
      "Epoch 55/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1737 - mean_squared_error: 0.1600 - val_loss: 0.1147 - val_mean_squared_error: 0.1009\n",
      "Epoch 56/100\n",
      "32200/32200 [==============================] - 3s 85us/step - loss: 0.1732 - mean_squared_error: 0.1595 - val_loss: 0.1157 - val_mean_squared_error: 0.1019\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 57/100\n",
      "32200/32200 [==============================] - 3s 83us/step - loss: 0.1771 - mean_squared_error: 0.1634 - val_loss: 0.1167 - val_mean_squared_error: 0.1030\n",
      "Epoch 58/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1767 - mean_squared_error: 0.1630 - val_loss: 0.1156 - val_mean_squared_error: 0.1019\n",
      "Epoch 59/100\n",
      "32200/32200 [==============================] - 3s 79us/step - loss: 0.1737 - mean_squared_error: 0.1600 - val_loss: 0.1173 - val_mean_squared_error: 0.1036\n",
      "Epoch 60/100\n",
      "32200/32200 [==============================] - 3s 79us/step - loss: 0.1728 - mean_squared_error: 0.1591 - val_loss: 0.1123 - val_mean_squared_error: 0.0986\n",
      "Epoch 61/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1721 - mean_squared_error: 0.1584 - val_loss: 0.1212 - val_mean_squared_error: 0.1075\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 62/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1733 - mean_squared_error: 0.1596 - val_loss: 0.1118 - val_mean_squared_error: 0.0981\n",
      "Epoch 63/100\n",
      "32200/32200 [==============================] - 3s 84us/step - loss: 0.1735 - mean_squared_error: 0.1598 - val_loss: 0.1106 - val_mean_squared_error: 0.0969\n",
      "Epoch 64/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1751 - mean_squared_error: 0.1614 - val_loss: 0.1159 - val_mean_squared_error: 0.1022\n",
      "Epoch 65/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1754 - mean_squared_error: 0.1617 - val_loss: 0.1172 - val_mean_squared_error: 0.1035\n",
      "Epoch 66/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1739 - mean_squared_error: 0.1603 - val_loss: 0.1128 - val_mean_squared_error: 0.0991\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 67/100\n",
      "32200/32200 [==============================] - 3s 83us/step - loss: 0.1739 - mean_squared_error: 0.1602 - val_loss: 0.1170 - val_mean_squared_error: 0.1033\n",
      "Epoch 68/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1771 - mean_squared_error: 0.1634 - val_loss: 0.1169 - val_mean_squared_error: 0.1032\n",
      "Epoch 69/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1739 - mean_squared_error: 0.1602 - val_loss: 0.1160 - val_mean_squared_error: 0.1023\n",
      "Epoch 70/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1733 - mean_squared_error: 0.1596 - val_loss: 0.1161 - val_mean_squared_error: 0.1024\n",
      "Epoch 71/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1738 - mean_squared_error: 0.1601 - val_loss: 0.1162 - val_mean_squared_error: 0.1025\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 72/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1708 - mean_squared_error: 0.1571 - val_loss: 0.1159 - val_mean_squared_error: 0.1022\n",
      "Epoch 73/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1734 - mean_squared_error: 0.1597 - val_loss: 0.1171 - val_mean_squared_error: 0.1034\n",
      "Epoch 74/100\n",
      "32200/32200 [==============================] - 3s 83us/step - loss: 0.1719 - mean_squared_error: 0.1582 - val_loss: 0.1149 - val_mean_squared_error: 0.1012\n",
      "Epoch 75/100\n",
      "32200/32200 [==============================] - 3s 79us/step - loss: 0.1740 - mean_squared_error: 0.1603 - val_loss: 0.1138 - val_mean_squared_error: 0.1002\n",
      "Epoch 76/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1784 - mean_squared_error: 0.1647 - val_loss: 0.1171 - val_mean_squared_error: 0.1034\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 77/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1713 - mean_squared_error: 0.1576 - val_loss: 0.1142 - val_mean_squared_error: 0.1005\n",
      "Epoch 78/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1735 - mean_squared_error: 0.1599 - val_loss: 0.1148 - val_mean_squared_error: 0.1012\n",
      "Epoch 79/100\n",
      "32200/32200 [==============================] - 3s 85us/step - loss: 0.1745 - mean_squared_error: 0.1608 - val_loss: 0.1189 - val_mean_squared_error: 0.1052\n",
      "Epoch 80/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1700 - mean_squared_error: 0.1563 - val_loss: 0.1221 - val_mean_squared_error: 0.1084\n",
      "Epoch 81/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1743 - mean_squared_error: 0.1606 - val_loss: 0.1159 - val_mean_squared_error: 0.1022\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1723 - mean_squared_error: 0.1586 - val_loss: 0.1143 - val_mean_squared_error: 0.1006\n",
      "Epoch 83/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1737 - mean_squared_error: 0.1600 - val_loss: 0.1163 - val_mean_squared_error: 0.1026\n",
      "Epoch 84/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1771 - mean_squared_error: 0.1634 - val_loss: 0.1133 - val_mean_squared_error: 0.0996\n",
      "Epoch 85/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1752 - mean_squared_error: 0.1615 - val_loss: 0.1121 - val_mean_squared_error: 0.0984\n",
      "Epoch 86/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1736 - mean_squared_error: 0.1599 - val_loss: 0.1131 - val_mean_squared_error: 0.0994\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 87/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1728 - mean_squared_error: 0.1591 - val_loss: 0.1156 - val_mean_squared_error: 0.1019\n",
      "Epoch 88/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1727 - mean_squared_error: 0.1590 - val_loss: 0.1171 - val_mean_squared_error: 0.1034\n",
      "Epoch 89/100\n",
      "32200/32200 [==============================] - 3s 79us/step - loss: 0.1763 - mean_squared_error: 0.1626 - val_loss: 0.1165 - val_mean_squared_error: 0.1028\n",
      "Epoch 90/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1765 - mean_squared_error: 0.1628 - val_loss: 0.1147 - val_mean_squared_error: 0.1010\n",
      "Epoch 91/100\n",
      "32200/32200 [==============================] - 3s 79us/step - loss: 0.1763 - mean_squared_error: 0.1626 - val_loss: 0.1139 - val_mean_squared_error: 0.1002\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 92/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1713 - mean_squared_error: 0.1576 - val_loss: 0.1179 - val_mean_squared_error: 0.1043\n",
      "Epoch 93/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1711 - mean_squared_error: 0.1574 - val_loss: 0.1096 - val_mean_squared_error: 0.0959\n",
      "Epoch 94/100\n",
      "32200/32200 [==============================] - 3s 84us/step - loss: 0.1747 - mean_squared_error: 0.1610 - val_loss: 0.1150 - val_mean_squared_error: 0.1014\n",
      "Epoch 95/100\n",
      "32200/32200 [==============================] - 3s 83us/step - loss: 0.1731 - mean_squared_error: 0.1594 - val_loss: 0.1151 - val_mean_squared_error: 0.1014\n",
      "Epoch 96/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1725 - mean_squared_error: 0.1588 - val_loss: 0.1127 - val_mean_squared_error: 0.0991\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 97/100\n",
      "32200/32200 [==============================] - 3s 82us/step - loss: 0.1759 - mean_squared_error: 0.1622 - val_loss: 0.1159 - val_mean_squared_error: 0.1022\n",
      "Epoch 98/100\n",
      "32200/32200 [==============================] - 3s 80us/step - loss: 0.1745 - mean_squared_error: 0.1608 - val_loss: 0.1130 - val_mean_squared_error: 0.0993\n",
      "Epoch 99/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1765 - mean_squared_error: 0.1628 - val_loss: 0.1220 - val_mean_squared_error: 0.1083\n",
      "Epoch 100/100\n",
      "32200/32200 [==============================] - 3s 81us/step - loss: 0.1767 - mean_squared_error: 0.1630 - val_loss: 0.1141 - val_mean_squared_error: 0.1004\n",
      "hw1/models/model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolHopper-v1\n",
      "{'model_name': 'model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'dataset_name': 'RoboschoolHopper-v1', 'model_path': 'hw1/models/model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'train_mse': 0.09262651542766813, 'test_mse': 0.1004299768907963}\n",
      "Training a FC ANN for env RoboschoolWalker2d-v1\n",
      "loading dataset RoboschoolWalker2d-v1\n",
      "Domain name: RoboschoolWalker2d-v1\n",
      "(45000, 22) (5000, 22) (45000, 6) (5000, 6)\n",
      "model_name='model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm'\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 6s 129us/step - loss: 0.3113 - mean_squared_error: 0.2878 - val_loss: 0.0864 - val_mean_squared_error: 0.0635\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 4s 89us/step - loss: 0.1480 - mean_squared_error: 0.1258 - val_loss: 0.0767 - val_mean_squared_error: 0.0552\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 4s 99us/step - loss: 0.1260 - mean_squared_error: 0.1055 - val_loss: 0.0667 - val_mean_squared_error: 0.0471\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 4s 90us/step - loss: 0.1156 - mean_squared_error: 0.0972 - val_loss: 0.0613 - val_mean_squared_error: 0.0440\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.1071 - mean_squared_error: 0.0910 - val_loss: 0.0569 - val_mean_squared_error: 0.0419\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 4s 89us/step - loss: 0.1004 - mean_squared_error: 0.0865 - val_loss: 0.0499 - val_mean_squared_error: 0.0371\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 4s 81us/step - loss: 0.0950 - mean_squared_error: 0.0831 - val_loss: 0.0471 - val_mean_squared_error: 0.0360\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0911 - mean_squared_error: 0.0807 - val_loss: 0.0475 - val_mean_squared_error: 0.0377\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0878 - mean_squared_error: 0.0785 - val_loss: 0.0472 - val_mean_squared_error: 0.0383\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.0857 - mean_squared_error: 0.0770 - val_loss: 0.0474 - val_mean_squared_error: 0.0390\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 4s 82us/step - loss: 0.0839 - mean_squared_error: 0.0758 - val_loss: 0.0431 - val_mean_squared_error: 0.0353\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.0822 - mean_squared_error: 0.0745 - val_loss: 0.0453 - val_mean_squared_error: 0.0377\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 5s 105us/step - loss: 0.0823 - mean_squared_error: 0.0748 - val_loss: 0.0450 - val_mean_squared_error: 0.0376\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0800 - mean_squared_error: 0.0727 - val_loss: 0.0420 - val_mean_squared_error: 0.0348\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0802 - mean_squared_error: 0.0731 - val_loss: 0.0401 - val_mean_squared_error: 0.0330\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0786 - mean_squared_error: 0.0716 - val_loss: 0.0396 - val_mean_squared_error: 0.0326\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 4s 82us/step - loss: 0.0784 - mean_squared_error: 0.0714 - val_loss: 0.0387 - val_mean_squared_error: 0.0318\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 4s 82us/step - loss: 0.0779 - mean_squared_error: 0.0710 - val_loss: 0.0408 - val_mean_squared_error: 0.0340\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0771 - mean_squared_error: 0.0702 - val_loss: 0.0414 - val_mean_squared_error: 0.0345\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 4s 82us/step - loss: 0.0775 - mean_squared_error: 0.0707 - val_loss: 0.0401 - val_mean_squared_error: 0.0333\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0762 - mean_squared_error: 0.0693 - val_loss: 0.0404 - val_mean_squared_error: 0.0336\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 4s 82us/step - loss: 0.0763 - mean_squared_error: 0.0695 - val_loss: 0.0404 - val_mean_squared_error: 0.0336\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0731 - mean_squared_error: 0.0666 - val_loss: 0.0351 - val_mean_squared_error: 0.0287\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.0719 - mean_squared_error: 0.0657 - val_loss: 0.0361 - val_mean_squared_error: 0.0300\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0710 - mean_squared_error: 0.0650 - val_loss: 0.0346 - val_mean_squared_error: 0.0288\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 4s 90us/step - loss: 0.0703 - mean_squared_error: 0.0646 - val_loss: 0.0356 - val_mean_squared_error: 0.0300\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 4s 91us/step - loss: 0.0706 - mean_squared_error: 0.0650 - val_loss: 0.0350 - val_mean_squared_error: 0.0295\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.0693 - mean_squared_error: 0.0639 - val_loss: 0.0341 - val_mean_squared_error: 0.0288\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0684 - mean_squared_error: 0.0632 - val_loss: 0.0326 - val_mean_squared_error: 0.0274\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0674 - mean_squared_error: 0.0623 - val_loss: 0.0323 - val_mean_squared_error: 0.0273\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.0681 - mean_squared_error: 0.0631 - val_loss: 0.0332 - val_mean_squared_error: 0.0283\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0672 - mean_squared_error: 0.0624 - val_loss: 0.0319 - val_mean_squared_error: 0.0272\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0670 - mean_squared_error: 0.0623 - val_loss: 0.0329 - val_mean_squared_error: 0.0283\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.0665 - mean_squared_error: 0.0619 - val_loss: 0.0305 - val_mean_squared_error: 0.0260\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0660 - mean_squared_error: 0.0615 - val_loss: 0.0312 - val_mean_squared_error: 0.0267\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.0662 - mean_squared_error: 0.0618 - val_loss: 0.0319 - val_mean_squared_error: 0.0275\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0658 - mean_squared_error: 0.0615 - val_loss: 0.0319 - val_mean_squared_error: 0.0276\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0652 - mean_squared_error: 0.0609 - val_loss: 0.0331 - val_mean_squared_error: 0.0288\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0658 - mean_squared_error: 0.0616 - val_loss: 0.0316 - val_mean_squared_error: 0.0275\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0651 - mean_squared_error: 0.0610 - val_loss: 0.0301 - val_mean_squared_error: 0.0260\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0648 - mean_squared_error: 0.0607 - val_loss: 0.0306 - val_mean_squared_error: 0.0266\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.0644 - mean_squared_error: 0.0604 - val_loss: 0.0298 - val_mean_squared_error: 0.0258\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0646 - mean_squared_error: 0.0606 - val_loss: 0.0296 - val_mean_squared_error: 0.0256\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0644 - mean_squared_error: 0.0605 - val_loss: 0.0300 - val_mean_squared_error: 0.0261\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0641 - mean_squared_error: 0.0602 - val_loss: 0.0301 - val_mean_squared_error: 0.0262\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0643 - mean_squared_error: 0.0605 - val_loss: 0.0285 - val_mean_squared_error: 0.0247\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0645 - mean_squared_error: 0.0607 - val_loss: 0.0293 - val_mean_squared_error: 0.0256\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0635 - mean_squared_error: 0.0598 - val_loss: 0.0287 - val_mean_squared_error: 0.0250\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0634 - mean_squared_error: 0.0597 - val_loss: 0.0307 - val_mean_squared_error: 0.0270\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 4s 89us/step - loss: 0.0642 - mean_squared_error: 0.0605 - val_loss: 0.0284 - val_mean_squared_error: 0.0248\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0638 - mean_squared_error: 0.0602 - val_loss: 0.0297 - val_mean_squared_error: 0.0261\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0631 - mean_squared_error: 0.0596 - val_loss: 0.0280 - val_mean_squared_error: 0.0244\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.0631 - mean_squared_error: 0.0596 - val_loss: 0.0279 - val_mean_squared_error: 0.0244\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0632 - mean_squared_error: 0.0597 - val_loss: 0.0287 - val_mean_squared_error: 0.0252\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.0627 - mean_squared_error: 0.0592 - val_loss: 0.0286 - val_mean_squared_error: 0.0252\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.0623 - mean_squared_error: 0.0588 - val_loss: 0.0289 - val_mean_squared_error: 0.0254\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0624 - mean_squared_error: 0.0590 - val_loss: 0.0289 - val_mean_squared_error: 0.0255\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0631 - mean_squared_error: 0.0597 - val_loss: 0.0280 - val_mean_squared_error: 0.0245\n",
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 4s 99us/step - loss: 0.0621 - mean_squared_error: 0.0587 - val_loss: 0.0282 - val_mean_squared_error: 0.0248\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0619 - mean_squared_error: 0.0585 - val_loss: 0.0279 - val_mean_squared_error: 0.0245\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 4s 82us/step - loss: 0.0626 - mean_squared_error: 0.0592 - val_loss: 0.0278 - val_mean_squared_error: 0.0244\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0618 - mean_squared_error: 0.0584 - val_loss: 0.0282 - val_mean_squared_error: 0.0249\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0621 - mean_squared_error: 0.0587 - val_loss: 0.0277 - val_mean_squared_error: 0.0243\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 4s 88us/step - loss: 0.0620 - mean_squared_error: 0.0586 - val_loss: 0.0280 - val_mean_squared_error: 0.0247\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0622 - mean_squared_error: 0.0589 - val_loss: 0.0278 - val_mean_squared_error: 0.0244\n",
      "Epoch 66/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0622 - mean_squared_error: 0.0589 - val_loss: 0.0281 - val_mean_squared_error: 0.0248\n",
      "Epoch 67/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0616 - mean_squared_error: 0.0582 - val_loss: 0.0272 - val_mean_squared_error: 0.0239\n",
      "Epoch 68/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0626 - mean_squared_error: 0.0593 - val_loss: 0.0276 - val_mean_squared_error: 0.0243\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0614 - mean_squared_error: 0.0581 - val_loss: 0.0277 - val_mean_squared_error: 0.0244\n",
      "Epoch 70/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0614 - mean_squared_error: 0.0581 - val_loss: 0.0278 - val_mean_squared_error: 0.0245\n",
      "Epoch 71/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0615 - mean_squared_error: 0.0582 - val_loss: 0.0277 - val_mean_squared_error: 0.0244\n",
      "Epoch 72/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0616 - mean_squared_error: 0.0583 - val_loss: 0.0278 - val_mean_squared_error: 0.0245\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 73/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0621 - mean_squared_error: 0.0588 - val_loss: 0.0280 - val_mean_squared_error: 0.0247\n",
      "Epoch 74/100\n",
      "45000/45000 [==============================] - 4s 90us/step - loss: 0.0621 - mean_squared_error: 0.0588 - val_loss: 0.0274 - val_mean_squared_error: 0.0241\n",
      "Epoch 75/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.0617 - mean_squared_error: 0.0585 - val_loss: 0.0278 - val_mean_squared_error: 0.0246\n",
      "Epoch 76/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.0620 - mean_squared_error: 0.0587 - val_loss: 0.0276 - val_mean_squared_error: 0.0243\n",
      "Epoch 77/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0611 - mean_squared_error: 0.0578 - val_loss: 0.0277 - val_mean_squared_error: 0.0244\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 78/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.0612 - mean_squared_error: 0.0580 - val_loss: 0.0272 - val_mean_squared_error: 0.0240\n",
      "Epoch 79/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0613 - mean_squared_error: 0.0581 - val_loss: 0.0277 - val_mean_squared_error: 0.0244\n",
      "Epoch 80/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0615 - mean_squared_error: 0.0582 - val_loss: 0.0281 - val_mean_squared_error: 0.0248\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.0616 - mean_squared_error: 0.0583 - val_loss: 0.0282 - val_mean_squared_error: 0.0249\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0612 - mean_squared_error: 0.0580 - val_loss: 0.0280 - val_mean_squared_error: 0.0247\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.0613 - mean_squared_error: 0.0580 - val_loss: 0.0277 - val_mean_squared_error: 0.0244\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.0620 - mean_squared_error: 0.0588 - val_loss: 0.0275 - val_mean_squared_error: 0.0242\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0607 - mean_squared_error: 0.0574 - val_loss: 0.0280 - val_mean_squared_error: 0.0247\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0613 - mean_squared_error: 0.0580 - val_loss: 0.0279 - val_mean_squared_error: 0.0246\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0614 - mean_squared_error: 0.0581 - val_loss: 0.0273 - val_mean_squared_error: 0.0241\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0614 - mean_squared_error: 0.0582 - val_loss: 0.0275 - val_mean_squared_error: 0.0243\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.0616 - mean_squared_error: 0.0583 - val_loss: 0.0276 - val_mean_squared_error: 0.0243\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 4s 87us/step - loss: 0.0614 - mean_squared_error: 0.0581 - val_loss: 0.0273 - val_mean_squared_error: 0.0241\n",
      "Epoch 91/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0614 - mean_squared_error: 0.0581 - val_loss: 0.0277 - val_mean_squared_error: 0.0244\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0614 - mean_squared_error: 0.0581 - val_loss: 0.0273 - val_mean_squared_error: 0.0241\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0619 - mean_squared_error: 0.0586 - val_loss: 0.0275 - val_mean_squared_error: 0.0243\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.0609 - mean_squared_error: 0.0577 - val_loss: 0.0275 - val_mean_squared_error: 0.0243\n",
      "Epoch 95/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0614 - mean_squared_error: 0.0582 - val_loss: 0.0277 - val_mean_squared_error: 0.0245\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0612 - mean_squared_error: 0.0580 - val_loss: 0.0275 - val_mean_squared_error: 0.0242\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 4s 86us/step - loss: 0.0618 - mean_squared_error: 0.0585 - val_loss: 0.0275 - val_mean_squared_error: 0.0243\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0627 - mean_squared_error: 0.0595 - val_loss: 0.0277 - val_mean_squared_error: 0.0245\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 4s 85us/step - loss: 0.0623 - mean_squared_error: 0.0591 - val_loss: 0.0277 - val_mean_squared_error: 0.0244\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 4s 84us/step - loss: 0.0621 - mean_squared_error: 0.0588 - val_loss: 0.0276 - val_mean_squared_error: 0.0244\n",
      "hw1/models/model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolWalker2d-v1\n",
      "{'model_name': 'model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'dataset_name': 'RoboschoolWalker2d-v1', 'model_path': 'hw1/models/model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm', 'train_mse': 0.023571605123564307, 'test_mse': 0.024358383879318764}\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback, LambdaCallback, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from hw1.manage_datasets import get_datasets\n",
    "from keras_helpers.model_helper import create_model, get_model_name, calc_mse\n",
    "from keras_helpers.keras_train_stats import KerasTrainStats\n",
    "\n",
    "\n",
    "SAVED_MODELS_DIR = 'hw1/models'\n",
    "MODEL_FILE_NAME = \"base.hdf5\"\n",
    "create_dir_if_not_exists(SAVED_MODELS_DIR)\n",
    "\n",
    "model_mse = []\n",
    "\n",
    "for env_name in AVAILABLE_ENVS:\n",
    "    print(\"Training a FC ANN for env %s\" % env_name)\n",
    "    \n",
    "    # Load the datasets\n",
    "    X_train, X_test, y_train, y_test = get_datasets(dataset_name=env_name, dataset_dir=EXPERT_DATA_DIR)\n",
    "    \n",
    "    # Define the model params\n",
    "    config_dict = dict(\n",
    "        input_dim=len(X_train[1, :]),\n",
    "        output_dim=len(y_train[1, :]),\n",
    "        units=100,\n",
    "        num_hidden=3,\n",
    "        l2_reg=1e-04,\n",
    "        optimizer_cls=keras.optimizers.Adam,\n",
    "        lr = 1e-03,\n",
    "        dropout=0.1,\n",
    "        use_batchnorm=True)\n",
    "    \n",
    "    # Create the model\n",
    "    model = create_model(**config_dict)\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = config_dict['optimizer_cls'](lr=config_dict['lr'])\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    \n",
    "    # Set a unique name/directory for the model\n",
    "    model_name = get_model_name(base_name=env_name, **config_dict)\n",
    "    model_path = os.path.join(SAVED_MODELS_DIR, model_name)\n",
    "    print(\"model_name='%s'\" % model_name)\n",
    "    print(\"model_path='%s'\" % model_path)\n",
    "    create_dir_if_not_exists(model_path)\n",
    "    model_filename = os.path.join(model_path, MODEL_FILE_NAME)\n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_mean_squared_error', factor=0.5, patience=5, verbose=1)\n",
    "    tf_board = TensorBoard()\n",
    "\n",
    "    # Define a train_stats object\n",
    "    train_stats = KerasTrainStats(model_name=model_name, history_dir=model_path)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "\n",
    "    _ = model.fit([X_train], y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              callbacks=[train_stats.print_callback, reduce_lr, tf_board],\n",
    "              validation_data=([X_test], y_test)\n",
    "              )\n",
    "    \n",
    "    \n",
    "    # Save the model\n",
    "    model.save(model_filename)\n",
    "    print(model_filename)\n",
    "    \n",
    "    # Calculate the MSE for each \n",
    "    res = calc_mse(model, env_name, X_train, X_test, y_train, y_test)\n",
    "    res['model_name'] = model_name\n",
    "    res['model_path'] = model_path\n",
    "    model_mse.append(res)\n",
    "    print(\"Done training model for %s\" % env_name)\n",
    "    #print(\"KerasTrainStats(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='%s MSE')\" % dataset_name)\n",
    "    print(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>train_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RoboschoolAnt-v1</td>\n",
       "      <td>0.154266</td>\n",
       "      <td>0.148387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RoboschoolHumanoid-v1</td>\n",
       "      <td>0.023702</td>\n",
       "      <td>0.022663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RoboschoolHalfCheetah-v1</td>\n",
       "      <td>0.072689</td>\n",
       "      <td>0.072195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RoboschoolReacher-v1</td>\n",
       "      <td>0.030032</td>\n",
       "      <td>0.018739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RoboschoolHopper-v1</td>\n",
       "      <td>0.100430</td>\n",
       "      <td>0.092627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RoboschoolWalker2d-v1</td>\n",
       "      <td>0.024358</td>\n",
       "      <td>0.023572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset_name  test_mse  train_mse\n",
       "0          RoboschoolAnt-v1  0.154266   0.148387\n",
       "1     RoboschoolHumanoid-v1  0.023702   0.022663\n",
       "2  RoboschoolHalfCheetah-v1  0.072689   0.072195\n",
       "3      RoboschoolReacher-v1  0.030032   0.018739\n",
       "4       RoboschoolHopper-v1  0.100430   0.092627\n",
       "5     RoboschoolWalker2d-v1  0.024358   0.023572"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the MSE error on both train/test sets\n",
    "df = pd.DataFrame(model_mse)\n",
    "df[['dataset_name', 'test_mse', 'train_mse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset_name': 'RoboschoolAnt-v1',\n",
       "  'model_name': 'model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'test_mse': 0.15426578611820307,\n",
       "  'train_mse': 0.1483872233621715},\n",
       " {'dataset_name': 'RoboschoolHumanoid-v1',\n",
       "  'model_name': 'model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'test_mse': 0.023701544806814134,\n",
       "  'train_mse': 0.022663329521807992},\n",
       " {'dataset_name': 'RoboschoolHalfCheetah-v1',\n",
       "  'model_name': 'model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'test_mse': 0.0726893770226361,\n",
       "  'train_mse': 0.07219472002511503},\n",
       " {'dataset_name': 'RoboschoolReacher-v1',\n",
       "  'model_name': 'model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'test_mse': 0.030032101617213987,\n",
       "  'train_mse': 0.01873875946542024},\n",
       " {'dataset_name': 'RoboschoolHopper-v1',\n",
       "  'model_name': 'model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'test_mse': 0.1004299768907963,\n",
       "  'train_mse': 0.09262651542766813},\n",
       " {'dataset_name': 'RoboschoolWalker2d-v1',\n",
       "  'model_name': 'model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_0.1_dropout_with_batchnorm',\n",
       "  'test_mse': 0.024358383879318764,\n",
       "  'train_mse': 0.023571605123564307}]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try without dropout and batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a FC ANN for env RoboschoolAnt-v1\n",
      "loading dataset RoboschoolAnt-v1\n",
      "Domain name: RoboschoolAnt-v1\n",
      "(45000, 28) (5000, 28) (45000, 8) (5000, 8)\n",
      "model_name='model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.3689 - mean_squared_error: 0.3411 - val_loss: 0.2209 - val_mean_squared_error: 0.1907\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 1s 27us/step - loss: 0.1969 - mean_squared_error: 0.1657 - val_loss: 0.1777 - val_mean_squared_error: 0.1457\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.1652 - mean_squared_error: 0.1329 - val_loss: 0.1656 - val_mean_squared_error: 0.1330\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.1495 - mean_squared_error: 0.1168 - val_loss: 0.1421 - val_mean_squared_error: 0.1094\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.1380 - mean_squared_error: 0.1053 - val_loss: 0.1309 - val_mean_squared_error: 0.0983\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.1310 - mean_squared_error: 0.0986 - val_loss: 0.1285 - val_mean_squared_error: 0.0963\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 1s 27us/step - loss: 0.1248 - mean_squared_error: 0.0927 - val_loss: 0.1227 - val_mean_squared_error: 0.0909\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.1201 - mean_squared_error: 0.0884 - val_loss: 0.1201 - val_mean_squared_error: 0.0887\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 0.1159 - mean_squared_error: 0.0847 - val_loss: 0.1156 - val_mean_squared_error: 0.0847\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.1127 - mean_squared_error: 0.0820 - val_loss: 0.1147 - val_mean_squared_error: 0.0842\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.1100 - mean_squared_error: 0.0796 - val_loss: 0.1148 - val_mean_squared_error: 0.0847\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.1069 - mean_squared_error: 0.0770 - val_loss: 0.1076 - val_mean_squared_error: 0.0779\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.1044 - mean_squared_error: 0.0749 - val_loss: 0.1053 - val_mean_squared_error: 0.0760\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.1023 - mean_squared_error: 0.0732 - val_loss: 0.1063 - val_mean_squared_error: 0.0774\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.1006 - mean_squared_error: 0.0718 - val_loss: 0.1034 - val_mean_squared_error: 0.0748\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0985 - mean_squared_error: 0.0701 - val_loss: 0.1013 - val_mean_squared_error: 0.0730\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0971 - mean_squared_error: 0.0690 - val_loss: 0.1010 - val_mean_squared_error: 0.0731\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0953 - mean_squared_error: 0.0675 - val_loss: 0.0988 - val_mean_squared_error: 0.0712\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0936 - mean_squared_error: 0.0662 - val_loss: 0.0953 - val_mean_squared_error: 0.0680\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0929 - mean_squared_error: 0.0658 - val_loss: 0.0968 - val_mean_squared_error: 0.0697\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0911 - mean_squared_error: 0.0642 - val_loss: 0.0932 - val_mean_squared_error: 0.0664\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0904 - mean_squared_error: 0.0638 - val_loss: 0.0920 - val_mean_squared_error: 0.0655\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0893 - mean_squared_error: 0.0628 - val_loss: 0.0929 - val_mean_squared_error: 0.0666\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0884 - mean_squared_error: 0.0623 - val_loss: 0.0898 - val_mean_squared_error: 0.0638\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 1s 26us/step - loss: 0.0872 - mean_squared_error: 0.0613 - val_loss: 0.0921 - val_mean_squared_error: 0.0663\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 2s 33us/step - loss: 0.0866 - mean_squared_error: 0.0609 - val_loss: 0.0889 - val_mean_squared_error: 0.0633\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.0854 - mean_squared_error: 0.0598 - val_loss: 0.0863 - val_mean_squared_error: 0.0609\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 2s 36us/step - loss: 0.0853 - mean_squared_error: 0.0600 - val_loss: 0.0877 - val_mean_squared_error: 0.0624\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0841 - mean_squared_error: 0.0589 - val_loss: 0.0879 - val_mean_squared_error: 0.0628\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0834 - mean_squared_error: 0.0584 - val_loss: 0.0873 - val_mean_squared_error: 0.0623\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 1s 27us/step - loss: 0.0827 - mean_squared_error: 0.0579 - val_loss: 0.0923 - val_mean_squared_error: 0.0675\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.0826 - mean_squared_error: 0.0579 - val_loss: 0.0874 - val_mean_squared_error: 0.0628\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.0760 - mean_squared_error: 0.0515 - val_loss: 0.0808 - val_mean_squared_error: 0.0563\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 2s 34us/step - loss: 0.0753 - mean_squared_error: 0.0510 - val_loss: 0.0799 - val_mean_squared_error: 0.0556\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0750 - mean_squared_error: 0.0507 - val_loss: 0.0807 - val_mean_squared_error: 0.0565\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0747 - mean_squared_error: 0.0506 - val_loss: 0.0810 - val_mean_squared_error: 0.0570\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.0745 - mean_squared_error: 0.0505 - val_loss: 0.0783 - val_mean_squared_error: 0.0544\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0741 - mean_squared_error: 0.0503 - val_loss: 0.0799 - val_mean_squared_error: 0.0561\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0739 - mean_squared_error: 0.0502 - val_loss: 0.0786 - val_mean_squared_error: 0.0549\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0733 - mean_squared_error: 0.0497 - val_loss: 0.0775 - val_mean_squared_error: 0.0540loss: 0.0730 - mean_squared_e\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0730 - mean_squared_error: 0.0495 - val_loss: 0.0803 - val_mean_squared_error: 0.0569\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0727 - mean_squared_error: 0.0494 - val_loss: 0.0771 - val_mean_squared_error: 0.0538\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0723 - mean_squared_error: 0.0490 - val_loss: 0.0780 - val_mean_squared_error: 0.0548\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0720 - mean_squared_error: 0.0488 - val_loss: 0.0771 - val_mean_squared_error: 0.0540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0716 - mean_squared_error: 0.0485 - val_loss: 0.0784 - val_mean_squared_error: 0.0554\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 1s 27us/step - loss: 0.0715 - mean_squared_error: 0.0485 - val_loss: 0.0767 - val_mean_squared_error: 0.0538\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 1s 27us/step - loss: 0.0711 - mean_squared_error: 0.0483 - val_loss: 0.0785 - val_mean_squared_error: 0.0558\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0677 - mean_squared_error: 0.0449 - val_loss: 0.0737 - val_mean_squared_error: 0.0510\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 1s 27us/step - loss: 0.0675 - mean_squared_error: 0.0448 - val_loss: 0.0730 - val_mean_squared_error: 0.0504\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 1s 27us/step - loss: 0.0675 - mean_squared_error: 0.0448 - val_loss: 0.0729 - val_mean_squared_error: 0.0503\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 1s 27us/step - loss: 0.0674 - mean_squared_error: 0.0448 - val_loss: 0.0731 - val_mean_squared_error: 0.0505\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0672 - mean_squared_error: 0.0446 - val_loss: 0.0729 - val_mean_squared_error: 0.0504\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.0670 - mean_squared_error: 0.0445 - val_loss: 0.0726 - val_mean_squared_error: 0.0502\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.0667 - mean_squared_error: 0.0443 - val_loss: 0.0728 - val_mean_squared_error: 0.0504\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 2s 34us/step - loss: 0.0666 - mean_squared_error: 0.0443 - val_loss: 0.0719 - val_mean_squared_error: 0.0496\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0664 - mean_squared_error: 0.0441 - val_loss: 0.0717 - val_mean_squared_error: 0.0495\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0663 - mean_squared_error: 0.0441 - val_loss: 0.0722 - val_mean_squared_error: 0.0500\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0661 - mean_squared_error: 0.0440 - val_loss: 0.0717 - val_mean_squared_error: 0.0496\n",
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0660 - mean_squared_error: 0.0439 - val_loss: 0.0719 - val_mean_squared_error: 0.0498\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0658 - mean_squared_error: 0.0438 - val_loss: 0.0720 - val_mean_squared_error: 0.0500\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0656 - mean_squared_error: 0.0436 - val_loss: 0.0718 - val_mean_squared_error: 0.0499\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0639 - mean_squared_error: 0.0420 - val_loss: 0.0702 - val_mean_squared_error: 0.0483\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0638 - mean_squared_error: 0.0419 - val_loss: 0.0696 - val_mean_squared_error: 0.0477\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0637 - mean_squared_error: 0.0418 - val_loss: 0.0697 - val_mean_squared_error: 0.0479\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0636 - mean_squared_error: 0.0418 - val_loss: 0.0708 - val_mean_squared_error: 0.0490\n",
      "Epoch 66/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0636 - mean_squared_error: 0.0418 - val_loss: 0.0705 - val_mean_squared_error: 0.0487\n",
      "Epoch 67/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0636 - mean_squared_error: 0.0418 - val_loss: 0.0690 - val_mean_squared_error: 0.0472\n",
      "Epoch 68/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0634 - mean_squared_error: 0.0417 - val_loss: 0.0700 - val_mean_squared_error: 0.0483\n",
      "Epoch 69/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0633 - mean_squared_error: 0.0416 - val_loss: 0.0697 - val_mean_squared_error: 0.0480\n",
      "Epoch 70/100\n",
      "45000/45000 [==============================] - 1s 27us/step - loss: 0.0632 - mean_squared_error: 0.0415 - val_loss: 0.0693 - val_mean_squared_error: 0.0477\n",
      "Epoch 71/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0632 - mean_squared_error: 0.0415 - val_loss: 0.0695 - val_mean_squared_error: 0.0479\n",
      "Epoch 72/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0630 - mean_squared_error: 0.0414 - val_loss: 0.0690 - val_mean_squared_error: 0.0474\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 73/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0621 - mean_squared_error: 0.0405 - val_loss: 0.0685 - val_mean_squared_error: 0.0470\n",
      "Epoch 74/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0621 - mean_squared_error: 0.0405 - val_loss: 0.0684 - val_mean_squared_error: 0.0468\n",
      "Epoch 75/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0620 - mean_squared_error: 0.0405 - val_loss: 0.0685 - val_mean_squared_error: 0.0469\n",
      "Epoch 76/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0620 - mean_squared_error: 0.0404 - val_loss: 0.0684 - val_mean_squared_error: 0.0469\n",
      "Epoch 77/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0619 - mean_squared_error: 0.0404 - val_loss: 0.0685 - val_mean_squared_error: 0.0470\n",
      "Epoch 78/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0619 - mean_squared_error: 0.0404 - val_loss: 0.0683 - val_mean_squared_error: 0.0468\n",
      "Epoch 79/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0618 - mean_squared_error: 0.0404 - val_loss: 0.0684 - val_mean_squared_error: 0.0469\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 80/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0614 - mean_squared_error: 0.0399 - val_loss: 0.0679 - val_mean_squared_error: 0.0464\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0613 - mean_squared_error: 0.0398 - val_loss: 0.0678 - val_mean_squared_error: 0.0463\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0613 - mean_squared_error: 0.0398 - val_loss: 0.0678 - val_mean_squared_error: 0.0463\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0613 - mean_squared_error: 0.0398 - val_loss: 0.0680 - val_mean_squared_error: 0.0465\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0612 - mean_squared_error: 0.0398 - val_loss: 0.0678 - val_mean_squared_error: 0.0464\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0612 - mean_squared_error: 0.0398 - val_loss: 0.0677 - val_mean_squared_error: 0.0463\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0612 - mean_squared_error: 0.0398 - val_loss: 0.0679 - val_mean_squared_error: 0.0464\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0612 - mean_squared_error: 0.0398 - val_loss: 0.0679 - val_mean_squared_error: 0.0465\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0609 - mean_squared_error: 0.0395 - val_loss: 0.0676 - val_mean_squared_error: 0.0462\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0609 - mean_squared_error: 0.0395 - val_loss: 0.0676 - val_mean_squared_error: 0.0462\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0609 - mean_squared_error: 0.0395 - val_loss: 0.0676 - val_mean_squared_error: 0.0462\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0609 - mean_squared_error: 0.0395 - val_loss: 0.0676 - val_mean_squared_error: 0.0462\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0609 - mean_squared_error: 0.0395 - val_loss: 0.0676 - val_mean_squared_error: 0.0462\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 1s 27us/step - loss: 0.0608 - mean_squared_error: 0.0395 - val_loss: 0.0676 - val_mean_squared_error: 0.0462\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0607 - mean_squared_error: 0.0393 - val_loss: 0.0675 - val_mean_squared_error: 0.0461\n",
      "Epoch 95/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0607 - mean_squared_error: 0.0393 - val_loss: 0.0675 - val_mean_squared_error: 0.0461\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0607 - mean_squared_error: 0.0393 - val_loss: 0.0675 - val_mean_squared_error: 0.0461\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0607 - mean_squared_error: 0.0393 - val_loss: 0.0674 - val_mean_squared_error: 0.0461\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0607 - mean_squared_error: 0.0393 - val_loss: 0.0675 - val_mean_squared_error: 0.0461\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0607 - mean_squared_error: 0.0393 - val_loss: 0.0675 - val_mean_squared_error: 0.0461\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0607 - mean_squared_error: 0.0393 - val_loss: 0.0674 - val_mean_squared_error: 0.0461\n",
      "hw1/models/model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolAnt-v1\n",
      "{'model_path': 'hw1/models/model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'train_mse': 0.03920499955367748, 'model_name': 'model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'dataset_name': 'RoboschoolAnt-v1', 'test_mse': 0.046053225442220666}\n",
      "Training a FC ANN for env RoboschoolHumanoid-v1\n",
      "loading dataset RoboschoolHumanoid-v1\n",
      "Domain name: RoboschoolHumanoid-v1\n",
      "(39999, 44) (4445, 44) (39999, 17) (4445, 17)\n",
      "model_name='model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "Train on 39999 samples, validate on 4445 samples\n",
      "Epoch 1/100\n",
      "39999/39999 [==============================] - 1s 34us/step - loss: 0.0825 - mean_squared_error: 0.0641 - val_loss: 0.0556 - val_mean_squared_error: 0.0390\n",
      "Epoch 2/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0504 - mean_squared_error: 0.0344 - val_loss: 0.0464 - val_mean_squared_error: 0.0310\n",
      "Epoch 3/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0446 - mean_squared_error: 0.0296 - val_loss: 0.0423 - val_mean_squared_error: 0.0279\n",
      "Epoch 4/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0411 - mean_squared_error: 0.0271 - val_loss: 0.0408 - val_mean_squared_error: 0.0270\n",
      "Epoch 5/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0389 - mean_squared_error: 0.0255 - val_loss: 0.0381 - val_mean_squared_error: 0.0250\n",
      "Epoch 6/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0371 - mean_squared_error: 0.0241 - val_loss: 0.0368 - val_mean_squared_error: 0.0241\n",
      "Epoch 7/100\n",
      "39999/39999 [==============================] - 1s 32us/step - loss: 0.0357 - mean_squared_error: 0.0232 - val_loss: 0.0354 - val_mean_squared_error: 0.0232\n",
      "Epoch 8/100\n",
      "39999/39999 [==============================] - 1s 34us/step - loss: 0.0345 - mean_squared_error: 0.0225 - val_loss: 0.0348 - val_mean_squared_error: 0.0229\n",
      "Epoch 9/100\n",
      "39999/39999 [==============================] - 1s 37us/step - loss: 0.0336 - mean_squared_error: 0.0218 - val_loss: 0.0330 - val_mean_squared_error: 0.0214\n",
      "Epoch 10/100\n",
      "39999/39999 [==============================] - 2s 38us/step - loss: 0.0327 - mean_squared_error: 0.0213 - val_loss: 0.0332 - val_mean_squared_error: 0.0219\n",
      "Epoch 11/100\n",
      "39999/39999 [==============================] - 1s 36us/step - loss: 0.0320 - mean_squared_error: 0.0208 - val_loss: 0.0314 - val_mean_squared_error: 0.0204\n",
      "Epoch 12/100\n",
      "39999/39999 [==============================] - 2s 38us/step - loss: 0.0315 - mean_squared_error: 0.0205 - val_loss: 0.0312 - val_mean_squared_error: 0.0204\n",
      "Epoch 13/100\n",
      "39999/39999 [==============================] - 1s 35us/step - loss: 0.0308 - mean_squared_error: 0.0200 - val_loss: 0.0309 - val_mean_squared_error: 0.0203\n",
      "Epoch 14/100\n",
      "39999/39999 [==============================] - 1s 32us/step - loss: 0.0302 - mean_squared_error: 0.0197 - val_loss: 0.0308 - val_mean_squared_error: 0.0204\n",
      "Epoch 15/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0297 - mean_squared_error: 0.0193 - val_loss: 0.0304 - val_mean_squared_error: 0.0201\n",
      "Epoch 16/100\n",
      "39999/39999 [==============================] - 1s 33us/step - loss: 0.0293 - mean_squared_error: 0.0191 - val_loss: 0.0300 - val_mean_squared_error: 0.0199\n",
      "Epoch 17/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0290 - mean_squared_error: 0.0189 - val_loss: 0.0292 - val_mean_squared_error: 0.0192\n",
      "Epoch 18/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0285 - mean_squared_error: 0.0186 - val_loss: 0.0293 - val_mean_squared_error: 0.0195\n",
      "Epoch 19/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0281 - mean_squared_error: 0.0184 - val_loss: 0.0282 - val_mean_squared_error: 0.0185\n",
      "Epoch 20/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0278 - mean_squared_error: 0.0182 - val_loss: 0.0282 - val_mean_squared_error: 0.0186\n",
      "Epoch 21/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0275 - mean_squared_error: 0.0180 - val_loss: 0.0287 - val_mean_squared_error: 0.0192\n",
      "Epoch 22/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0273 - mean_squared_error: 0.0179 - val_loss: 0.0277 - val_mean_squared_error: 0.0183\n",
      "Epoch 23/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0270 - mean_squared_error: 0.0176 - val_loss: 0.0280 - val_mean_squared_error: 0.0187\n",
      "Epoch 24/100\n",
      "39999/39999 [==============================] - 1s 29us/step - loss: 0.0269 - mean_squared_error: 0.0176 - val_loss: 0.0282 - val_mean_squared_error: 0.0190\n",
      "Epoch 25/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0265 - mean_squared_error: 0.0174 - val_loss: 0.0276 - val_mean_squared_error: 0.0185\n",
      "Epoch 26/100\n",
      "39999/39999 [==============================] - 1s 32us/step - loss: 0.0262 - mean_squared_error: 0.0171 - val_loss: 0.0265 - val_mean_squared_error: 0.0175\n",
      "Epoch 27/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0261 - mean_squared_error: 0.0171 - val_loss: 0.0270 - val_mean_squared_error: 0.0180\n",
      "Epoch 28/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0259 - mean_squared_error: 0.0170 - val_loss: 0.0271 - val_mean_squared_error: 0.0182\n",
      "Epoch 29/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0256 - mean_squared_error: 0.0168 - val_loss: 0.0256 - val_mean_squared_error: 0.0168\n",
      "Epoch 30/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0255 - mean_squared_error: 0.0168 - val_loss: 0.0259 - val_mean_squared_error: 0.0172\n",
      "Epoch 31/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0253 - mean_squared_error: 0.0166 - val_loss: 0.0270 - val_mean_squared_error: 0.0184\n",
      "Epoch 32/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0251 - mean_squared_error: 0.0165 - val_loss: 0.0258 - val_mean_squared_error: 0.0172\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0250 - mean_squared_error: 0.0165 - val_loss: 0.0255 - val_mean_squared_error: 0.0170\n",
      "Epoch 34/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0248 - mean_squared_error: 0.0163 - val_loss: 0.0265 - val_mean_squared_error: 0.0181\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 35/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0235 - mean_squared_error: 0.0150 - val_loss: 0.0240 - val_mean_squared_error: 0.0156\n",
      "Epoch 36/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0234 - mean_squared_error: 0.0149 - val_loss: 0.0244 - val_mean_squared_error: 0.0160\n",
      "Epoch 37/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0233 - mean_squared_error: 0.0149 - val_loss: 0.0240 - val_mean_squared_error: 0.0157\n",
      "Epoch 38/100\n",
      "39999/39999 [==============================] - 1s 29us/step - loss: 0.0232 - mean_squared_error: 0.0149 - val_loss: 0.0243 - val_mean_squared_error: 0.0159\n",
      "Epoch 39/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0231 - mean_squared_error: 0.0148 - val_loss: 0.0239 - val_mean_squared_error: 0.0156\n",
      "Epoch 40/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0229 - mean_squared_error: 0.0147 - val_loss: 0.0235 - val_mean_squared_error: 0.0153\n",
      "Epoch 41/100\n",
      "39999/39999 [==============================] - 1s 29us/step - loss: 0.0229 - mean_squared_error: 0.0147 - val_loss: 0.0241 - val_mean_squared_error: 0.0159\n",
      "Epoch 42/100\n",
      "39999/39999 [==============================] - 1s 29us/step - loss: 0.0228 - mean_squared_error: 0.0146 - val_loss: 0.0236 - val_mean_squared_error: 0.0154\n",
      "Epoch 43/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0227 - mean_squared_error: 0.0145 - val_loss: 0.0239 - val_mean_squared_error: 0.0158\n",
      "Epoch 44/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0226 - mean_squared_error: 0.0145 - val_loss: 0.0239 - val_mean_squared_error: 0.0158\n",
      "Epoch 45/100\n",
      "39999/39999 [==============================] - 1s 32us/step - loss: 0.0225 - mean_squared_error: 0.0145 - val_loss: 0.0234 - val_mean_squared_error: 0.0153\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 46/100\n",
      "39999/39999 [==============================] - 1s 32us/step - loss: 0.0218 - mean_squared_error: 0.0137 - val_loss: 0.0227 - val_mean_squared_error: 0.0147\n",
      "Epoch 47/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0217 - mean_squared_error: 0.0136 - val_loss: 0.0226 - val_mean_squared_error: 0.0146\n",
      "Epoch 48/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0217 - mean_squared_error: 0.0137 - val_loss: 0.0229 - val_mean_squared_error: 0.0148\n",
      "Epoch 49/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0216 - mean_squared_error: 0.0136 - val_loss: 0.0226 - val_mean_squared_error: 0.0146\n",
      "Epoch 50/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0216 - mean_squared_error: 0.0136 - val_loss: 0.0227 - val_mean_squared_error: 0.0147\n",
      "Epoch 51/100\n",
      "39999/39999 [==============================] - 1s 32us/step - loss: 0.0215 - mean_squared_error: 0.0136 - val_loss: 0.0225 - val_mean_squared_error: 0.0146\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 52/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0211 - mean_squared_error: 0.0131 - val_loss: 0.0222 - val_mean_squared_error: 0.0142\n",
      "Epoch 53/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0211 - mean_squared_error: 0.0131 - val_loss: 0.0221 - val_mean_squared_error: 0.0141\n",
      "Epoch 54/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0210 - mean_squared_error: 0.0131 - val_loss: 0.0221 - val_mean_squared_error: 0.0142\n",
      "Epoch 55/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0210 - mean_squared_error: 0.0131 - val_loss: 0.0219 - val_mean_squared_error: 0.0140\n",
      "Epoch 56/100\n",
      "39999/39999 [==============================] - 1s 29us/step - loss: 0.0210 - mean_squared_error: 0.0130 - val_loss: 0.0221 - val_mean_squared_error: 0.0142\n",
      "Epoch 57/100\n",
      "39999/39999 [==============================] - 1s 29us/step - loss: 0.0210 - mean_squared_error: 0.0131 - val_loss: 0.0221 - val_mean_squared_error: 0.0142\n",
      "Epoch 58/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0209 - mean_squared_error: 0.0130 - val_loss: 0.0221 - val_mean_squared_error: 0.0142\n",
      "Epoch 59/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0209 - mean_squared_error: 0.0130 - val_loss: 0.0221 - val_mean_squared_error: 0.0141\n",
      "Epoch 60/100\n",
      "39999/39999 [==============================] - 1s 29us/step - loss: 0.0209 - mean_squared_error: 0.0130 - val_loss: 0.0221 - val_mean_squared_error: 0.0142\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 61/100\n",
      "39999/39999 [==============================] - 1s 32us/step - loss: 0.0207 - mean_squared_error: 0.0128 - val_loss: 0.0217 - val_mean_squared_error: 0.0138\n",
      "Epoch 62/100\n",
      "39999/39999 [==============================] - 1s 32us/step - loss: 0.0206 - mean_squared_error: 0.0127 - val_loss: 0.0217 - val_mean_squared_error: 0.0138\n",
      "Epoch 63/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0206 - mean_squared_error: 0.0127 - val_loss: 0.0218 - val_mean_squared_error: 0.0139\n",
      "Epoch 64/100\n",
      "39999/39999 [==============================] - 2s 38us/step - loss: 0.0206 - mean_squared_error: 0.0127 - val_loss: 0.0218 - val_mean_squared_error: 0.0139\n",
      "Epoch 65/100\n",
      "39999/39999 [==============================] - 1s 36us/step - loss: 0.0206 - mean_squared_error: 0.0127 - val_loss: 0.0218 - val_mean_squared_error: 0.0139\n",
      "Epoch 66/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0206 - mean_squared_error: 0.0127 - val_loss: 0.0218 - val_mean_squared_error: 0.0139\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 67/100\n",
      "39999/39999 [==============================] - 1s 34us/step - loss: 0.0205 - mean_squared_error: 0.0126 - val_loss: 0.0216 - val_mean_squared_error: 0.0137\n",
      "Epoch 68/100\n",
      "39999/39999 [==============================] - 2s 38us/step - loss: 0.0204 - mean_squared_error: 0.0126 - val_loss: 0.0216 - val_mean_squared_error: 0.0137\n",
      "Epoch 69/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0204 - mean_squared_error: 0.0126 - val_loss: 0.0216 - val_mean_squared_error: 0.0137\n",
      "Epoch 70/100\n",
      "39999/39999 [==============================] - 1s 32us/step - loss: 0.0204 - mean_squared_error: 0.0126 - val_loss: 0.0216 - val_mean_squared_error: 0.0137\n",
      "Epoch 71/100\n",
      "39999/39999 [==============================] - 1s 34us/step - loss: 0.0204 - mean_squared_error: 0.0126 - val_loss: 0.0216 - val_mean_squared_error: 0.0137\n",
      "Epoch 72/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0204 - mean_squared_error: 0.0126 - val_loss: 0.0216 - val_mean_squared_error: 0.0137\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 73/100\n",
      "39999/39999 [==============================] - 1s 29us/step - loss: 0.0204 - mean_squared_error: 0.0125 - val_loss: 0.0215 - val_mean_squared_error: 0.0137\n",
      "Epoch 74/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0203 - mean_squared_error: 0.0125 - val_loss: 0.0215 - val_mean_squared_error: 0.0137\n",
      "Epoch 75/100\n",
      "39999/39999 [==============================] - 1s 37us/step - loss: 0.0203 - mean_squared_error: 0.0125 - val_loss: 0.0215 - val_mean_squared_error: 0.0137\n",
      "Epoch 76/100\n",
      "39999/39999 [==============================] - 1s 37us/step - loss: 0.0203 - mean_squared_error: 0.0125 - val_loss: 0.0215 - val_mean_squared_error: 0.0137\n",
      "Epoch 77/100\n",
      "39999/39999 [==============================] - 1s 34us/step - loss: 0.0203 - mean_squared_error: 0.0125 - val_loss: 0.0215 - val_mean_squared_error: 0.0137\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39999/39999 [==============================] - 1s 33us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0137\n",
      "Epoch 79/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 80/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0137\n",
      "Epoch 81/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 82/100\n",
      "39999/39999 [==============================] - 1s 32us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 83/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 84/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 85/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 86/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 87/100\n",
      "39999/39999 [==============================] - 1s 32us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 88/100\n",
      "39999/39999 [==============================] - 1s 33us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 89/100\n",
      "39999/39999 [==============================] - 1s 35us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 90/100\n",
      "39999/39999 [==============================] - 1s 33us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 91/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 92/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 93/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0203 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 94/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0202 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 95/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0202 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 96/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0202 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 97/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0202 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 98/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0202 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 99/100\n",
      "39999/39999 [==============================] - 1s 31us/step - loss: 0.0202 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 100/100\n",
      "39999/39999 [==============================] - 1s 30us/step - loss: 0.0202 - mean_squared_error: 0.0124 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolHumanoid-v1\n",
      "{'model_path': 'hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'train_mse': 0.012396673013696149, 'model_name': 'model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013617273586400507}\n",
      "Training a FC ANN for env RoboschoolHalfCheetah-v1\n",
      "loading dataset RoboschoolHalfCheetah-v1\n",
      "Domain name: RoboschoolHalfCheetah-v1\n",
      "(38341, 26) (4261, 26) (38341, 6) (4261, 6)\n",
      "model_name='model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "Train on 38341 samples, validate on 4261 samples\n",
      "Epoch 1/100\n",
      "38341/38341 [==============================] - 1s 37us/step - loss: 0.2186 - mean_squared_error: 0.1955 - val_loss: 0.1090 - val_mean_squared_error: 0.0851\n",
      "Epoch 2/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0895 - mean_squared_error: 0.0654 - val_loss: 0.0773 - val_mean_squared_error: 0.0531\n",
      "Epoch 3/100\n",
      "38341/38341 [==============================] - 1s 34us/step - loss: 0.0730 - mean_squared_error: 0.0489 - val_loss: 0.0677 - val_mean_squared_error: 0.0438\n",
      "Epoch 4/100\n",
      "38341/38341 [==============================] - 1s 35us/step - loss: 0.0647 - mean_squared_error: 0.0410 - val_loss: 0.0658 - val_mean_squared_error: 0.0423\n",
      "Epoch 5/100\n",
      "38341/38341 [==============================] - 1s 36us/step - loss: 0.0595 - mean_squared_error: 0.0363 - val_loss: 0.0613 - val_mean_squared_error: 0.0384\n",
      "Epoch 6/100\n",
      "38341/38341 [==============================] - 1s 35us/step - loss: 0.0554 - mean_squared_error: 0.0328 - val_loss: 0.0550 - val_mean_squared_error: 0.0327\n",
      "Epoch 7/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0520 - mean_squared_error: 0.0300 - val_loss: 0.0532 - val_mean_squared_error: 0.0315\n",
      "Epoch 8/100\n",
      "38341/38341 [==============================] - 1s 36us/step - loss: 0.0494 - mean_squared_error: 0.0280 - val_loss: 0.0482 - val_mean_squared_error: 0.0271\n",
      "Epoch 9/100\n",
      "38341/38341 [==============================] - 1s 35us/step - loss: 0.0473 - mean_squared_error: 0.0265 - val_loss: 0.0490 - val_mean_squared_error: 0.0285\n",
      "Epoch 10/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0459 - mean_squared_error: 0.0257 - val_loss: 0.0483 - val_mean_squared_error: 0.0284\n",
      "Epoch 11/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0444 - mean_squared_error: 0.0247 - val_loss: 0.0523 - val_mean_squared_error: 0.0329\n",
      "Epoch 12/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0431 - mean_squared_error: 0.0239 - val_loss: 0.0542 - val_mean_squared_error: 0.0353\n",
      "Epoch 13/100\n",
      "38341/38341 [==============================] - 1s 34us/step - loss: 0.0421 - mean_squared_error: 0.0233 - val_loss: 0.0432 - val_mean_squared_error: 0.0247\n",
      "Epoch 14/100\n",
      "38341/38341 [==============================] - 1s 34us/step - loss: 0.0406 - mean_squared_error: 0.0224 - val_loss: 0.0419 - val_mean_squared_error: 0.0239\n",
      "Epoch 15/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0397 - mean_squared_error: 0.0219 - val_loss: 0.0444 - val_mean_squared_error: 0.0268\n",
      "Epoch 16/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0388 - mean_squared_error: 0.0214 - val_loss: 0.0394 - val_mean_squared_error: 0.0222\n",
      "Epoch 17/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0376 - mean_squared_error: 0.0205 - val_loss: 0.0417 - val_mean_squared_error: 0.0248\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38341/38341 [==============================] - 1s 30us/step - loss: 0.0376 - mean_squared_error: 0.0209 - val_loss: 0.0404 - val_mean_squared_error: 0.0238\n",
      "Epoch 19/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0365 - mean_squared_error: 0.0201 - val_loss: 0.0376 - val_mean_squared_error: 0.0214\n",
      "Epoch 20/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0359 - mean_squared_error: 0.0198 - val_loss: 0.0403 - val_mean_squared_error: 0.0243\n",
      "Epoch 21/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0357 - mean_squared_error: 0.0198 - val_loss: 0.0390 - val_mean_squared_error: 0.0233\n",
      "Epoch 22/100\n",
      "38341/38341 [==============================] - 1s 30us/step - loss: 0.0345 - mean_squared_error: 0.0190 - val_loss: 0.0380 - val_mean_squared_error: 0.0226\n",
      "Epoch 23/100\n",
      "38341/38341 [==============================] - 1s 30us/step - loss: 0.0341 - mean_squared_error: 0.0187 - val_loss: 0.0362 - val_mean_squared_error: 0.0210\n",
      "Epoch 24/100\n",
      "38341/38341 [==============================] - 1s 30us/step - loss: 0.0338 - mean_squared_error: 0.0187 - val_loss: 0.0410 - val_mean_squared_error: 0.0260\n",
      "Epoch 25/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0333 - mean_squared_error: 0.0184 - val_loss: 0.0335 - val_mean_squared_error: 0.0187\n",
      "Epoch 26/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0326 - mean_squared_error: 0.0180 - val_loss: 0.0330 - val_mean_squared_error: 0.0184\n",
      "Epoch 27/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0327 - mean_squared_error: 0.0182 - val_loss: 0.0358 - val_mean_squared_error: 0.0214\n",
      "Epoch 28/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0323 - mean_squared_error: 0.0180 - val_loss: 0.0326 - val_mean_squared_error: 0.0184\n",
      "Epoch 29/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0317 - mean_squared_error: 0.0176 - val_loss: 0.0337 - val_mean_squared_error: 0.0196\n",
      "Epoch 30/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0314 - mean_squared_error: 0.0175 - val_loss: 0.0361 - val_mean_squared_error: 0.0222\n",
      "Epoch 31/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0311 - mean_squared_error: 0.0172 - val_loss: 0.0361 - val_mean_squared_error: 0.0224\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 32/100\n",
      "38341/38341 [==============================] - 1s 34us/step - loss: 0.0282 - mean_squared_error: 0.0145 - val_loss: 0.0291 - val_mean_squared_error: 0.0154\n",
      "Epoch 33/100\n",
      "38341/38341 [==============================] - 1s 34us/step - loss: 0.0279 - mean_squared_error: 0.0143 - val_loss: 0.0297 - val_mean_squared_error: 0.0162\n",
      "Epoch 34/100\n",
      "38341/38341 [==============================] - 1s 34us/step - loss: 0.0277 - mean_squared_error: 0.0143 - val_loss: 0.0286 - val_mean_squared_error: 0.0152\n",
      "Epoch 35/100\n",
      "38341/38341 [==============================] - 1s 34us/step - loss: 0.0276 - mean_squared_error: 0.0143 - val_loss: 0.0288 - val_mean_squared_error: 0.0155\n",
      "Epoch 36/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0275 - mean_squared_error: 0.0143 - val_loss: 0.0303 - val_mean_squared_error: 0.0171\n",
      "Epoch 37/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0272 - mean_squared_error: 0.0140 - val_loss: 0.0301 - val_mean_squared_error: 0.0171\n",
      "Epoch 38/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0271 - mean_squared_error: 0.0141 - val_loss: 0.0283 - val_mean_squared_error: 0.0153\n",
      "Epoch 39/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0270 - mean_squared_error: 0.0141 - val_loss: 0.0276 - val_mean_squared_error: 0.0148\n",
      "Epoch 40/100\n",
      "38341/38341 [==============================] - 2s 47us/step - loss: 0.0267 - mean_squared_error: 0.0139 - val_loss: 0.0281 - val_mean_squared_error: 0.0152\n",
      "Epoch 41/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0266 - mean_squared_error: 0.0138 - val_loss: 0.0288 - val_mean_squared_error: 0.0161\n",
      "Epoch 42/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0265 - mean_squared_error: 0.0138 - val_loss: 0.0268 - val_mean_squared_error: 0.0142\n",
      "Epoch 43/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0262 - mean_squared_error: 0.0136 - val_loss: 0.0274 - val_mean_squared_error: 0.0149\n",
      "Epoch 44/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0261 - mean_squared_error: 0.0136 - val_loss: 0.0275 - val_mean_squared_error: 0.0150\n",
      "Epoch 45/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0258 - mean_squared_error: 0.0134 - val_loss: 0.0269 - val_mean_squared_error: 0.0145\n",
      "Epoch 46/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0259 - mean_squared_error: 0.0135 - val_loss: 0.0265 - val_mean_squared_error: 0.0142\n",
      "Epoch 47/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0256 - mean_squared_error: 0.0133 - val_loss: 0.0289 - val_mean_squared_error: 0.0166\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 48/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0242 - mean_squared_error: 0.0120 - val_loss: 0.0254 - val_mean_squared_error: 0.0132\n",
      "Epoch 49/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0241 - mean_squared_error: 0.0119 - val_loss: 0.0263 - val_mean_squared_error: 0.0141\n",
      "Epoch 50/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0240 - mean_squared_error: 0.0119 - val_loss: 0.0265 - val_mean_squared_error: 0.0144\n",
      "Epoch 51/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0240 - mean_squared_error: 0.0119 - val_loss: 0.0258 - val_mean_squared_error: 0.0137\n",
      "Epoch 52/100\n",
      "38341/38341 [==============================] - 1s 30us/step - loss: 0.0239 - mean_squared_error: 0.0118 - val_loss: 0.0257 - val_mean_squared_error: 0.0137\n",
      "Epoch 53/100\n",
      "38341/38341 [==============================] - 1s 30us/step - loss: 0.0238 - mean_squared_error: 0.0118 - val_loss: 0.0251 - val_mean_squared_error: 0.0131\n",
      "Epoch 54/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0237 - mean_squared_error: 0.0118 - val_loss: 0.0252 - val_mean_squared_error: 0.0132\n",
      "Epoch 55/100\n",
      "38341/38341 [==============================] - 1s 30us/step - loss: 0.0236 - mean_squared_error: 0.0117 - val_loss: 0.0247 - val_mean_squared_error: 0.0128\n",
      "Epoch 56/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0235 - mean_squared_error: 0.0117 - val_loss: 0.0248 - val_mean_squared_error: 0.0129\n",
      "Epoch 57/100\n",
      "38341/38341 [==============================] - 1s 37us/step - loss: 0.0234 - mean_squared_error: 0.0116 - val_loss: 0.0245 - val_mean_squared_error: 0.0127\n",
      "Epoch 58/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0234 - mean_squared_error: 0.0116 - val_loss: 0.0247 - val_mean_squared_error: 0.0130\n",
      "Epoch 59/100\n",
      "38341/38341 [==============================] - 1s 28us/step - loss: 0.0234 - mean_squared_error: 0.0116 - val_loss: 0.0249 - val_mean_squared_error: 0.0132\n",
      "Epoch 60/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0232 - mean_squared_error: 0.0115 - val_loss: 0.0240 - val_mean_squared_error: 0.0123\n",
      "Epoch 61/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0231 - mean_squared_error: 0.0114 - val_loss: 0.0247 - val_mean_squared_error: 0.0130\n",
      "Epoch 62/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0231 - mean_squared_error: 0.0115 - val_loss: 0.0248 - val_mean_squared_error: 0.0132\n",
      "Epoch 63/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0230 - mean_squared_error: 0.0114 - val_loss: 0.0251 - val_mean_squared_error: 0.0136\n",
      "Epoch 64/100\n",
      "38341/38341 [==============================] - 1s 30us/step - loss: 0.0229 - mean_squared_error: 0.0114 - val_loss: 0.0252 - val_mean_squared_error: 0.0137\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38341/38341 [==============================] - 1s 30us/step - loss: 0.0228 - mean_squared_error: 0.0113 - val_loss: 0.0237 - val_mean_squared_error: 0.0123\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 66/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0221 - mean_squared_error: 0.0106 - val_loss: 0.0234 - val_mean_squared_error: 0.0119\n",
      "Epoch 67/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0220 - mean_squared_error: 0.0106 - val_loss: 0.0234 - val_mean_squared_error: 0.0120\n",
      "Epoch 68/100\n",
      "38341/38341 [==============================] - 1s 34us/step - loss: 0.0220 - mean_squared_error: 0.0105 - val_loss: 0.0236 - val_mean_squared_error: 0.0122\n",
      "Epoch 69/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0220 - mean_squared_error: 0.0106 - val_loss: 0.0232 - val_mean_squared_error: 0.0118\n",
      "Epoch 70/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0219 - mean_squared_error: 0.0105 - val_loss: 0.0234 - val_mean_squared_error: 0.0120\n",
      "Epoch 71/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0219 - mean_squared_error: 0.0105 - val_loss: 0.0233 - val_mean_squared_error: 0.0119\n",
      "Epoch 72/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0218 - mean_squared_error: 0.0105 - val_loss: 0.0230 - val_mean_squared_error: 0.0116\n",
      "Epoch 73/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0218 - mean_squared_error: 0.0105 - val_loss: 0.0232 - val_mean_squared_error: 0.0119\n",
      "Epoch 74/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0217 - mean_squared_error: 0.0104 - val_loss: 0.0232 - val_mean_squared_error: 0.0119\n",
      "Epoch 75/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0217 - mean_squared_error: 0.0104 - val_loss: 0.0229 - val_mean_squared_error: 0.0116\n",
      "Epoch 76/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0217 - mean_squared_error: 0.0104 - val_loss: 0.0228 - val_mean_squared_error: 0.0116\n",
      "Epoch 77/100\n",
      "38341/38341 [==============================] - 1s 30us/step - loss: 0.0216 - mean_squared_error: 0.0104 - val_loss: 0.0227 - val_mean_squared_error: 0.0115\n",
      "Epoch 78/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0216 - mean_squared_error: 0.0104 - val_loss: 0.0229 - val_mean_squared_error: 0.0117\n",
      "Epoch 79/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0216 - mean_squared_error: 0.0103 - val_loss: 0.0228 - val_mean_squared_error: 0.0116\n",
      "Epoch 80/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0215 - mean_squared_error: 0.0103 - val_loss: 0.0228 - val_mean_squared_error: 0.0116\n",
      "Epoch 81/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0215 - mean_squared_error: 0.0103 - val_loss: 0.0227 - val_mean_squared_error: 0.0115\n",
      "Epoch 82/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0215 - mean_squared_error: 0.0103 - val_loss: 0.0227 - val_mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 83/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0210 - mean_squared_error: 0.0099 - val_loss: 0.0223 - val_mean_squared_error: 0.0112\n",
      "Epoch 84/100\n",
      "38341/38341 [==============================] - 1s 28us/step - loss: 0.0210 - mean_squared_error: 0.0099 - val_loss: 0.0222 - val_mean_squared_error: 0.0111\n",
      "Epoch 85/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0210 - mean_squared_error: 0.0099 - val_loss: 0.0222 - val_mean_squared_error: 0.0111\n",
      "Epoch 86/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0210 - mean_squared_error: 0.0099 - val_loss: 0.0223 - val_mean_squared_error: 0.0112\n",
      "Epoch 87/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0209 - mean_squared_error: 0.0099 - val_loss: 0.0222 - val_mean_squared_error: 0.0112\n",
      "Epoch 88/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0209 - mean_squared_error: 0.0099 - val_loss: 0.0222 - val_mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 89/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0207 - mean_squared_error: 0.0096 - val_loss: 0.0221 - val_mean_squared_error: 0.0110\n",
      "Epoch 90/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0207 - mean_squared_error: 0.0096 - val_loss: 0.0221 - val_mean_squared_error: 0.0110\n",
      "Epoch 91/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0207 - mean_squared_error: 0.0096 - val_loss: 0.0220 - val_mean_squared_error: 0.0110\n",
      "Epoch 92/100\n",
      "38341/38341 [==============================] - 1s 28us/step - loss: 0.0207 - mean_squared_error: 0.0096 - val_loss: 0.0221 - val_mean_squared_error: 0.0110\n",
      "Epoch 93/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0207 - mean_squared_error: 0.0096 - val_loss: 0.0220 - val_mean_squared_error: 0.0110\n",
      "Epoch 94/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0206 - mean_squared_error: 0.0096 - val_loss: 0.0220 - val_mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 95/100\n",
      "38341/38341 [==============================] - 1s 29us/step - loss: 0.0205 - mean_squared_error: 0.0095 - val_loss: 0.0219 - val_mean_squared_error: 0.0109\n",
      "Epoch 96/100\n",
      "38341/38341 [==============================] - 1s 31us/step - loss: 0.0205 - mean_squared_error: 0.0095 - val_loss: 0.0220 - val_mean_squared_error: 0.0109\n",
      "Epoch 97/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0205 - mean_squared_error: 0.0095 - val_loss: 0.0219 - val_mean_squared_error: 0.0109\n",
      "Epoch 98/100\n",
      "38341/38341 [==============================] - 1s 34us/step - loss: 0.0205 - mean_squared_error: 0.0095 - val_loss: 0.0219 - val_mean_squared_error: 0.0109\n",
      "Epoch 99/100\n",
      "38341/38341 [==============================] - 1s 33us/step - loss: 0.0205 - mean_squared_error: 0.0095 - val_loss: 0.0219 - val_mean_squared_error: 0.0109\n",
      "Epoch 100/100\n",
      "38341/38341 [==============================] - 1s 32us/step - loss: 0.0205 - mean_squared_error: 0.0095 - val_loss: 0.0219 - val_mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "hw1/models/model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolHalfCheetah-v1\n",
      "{'model_path': 'hw1/models/model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'train_mse': 0.009462605794146534, 'model_name': 'model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'dataset_name': 'RoboschoolHalfCheetah-v1', 'test_mse': 0.010912294609807542}\n",
      "Training a FC ANN for env RoboschoolReacher-v1\n",
      "loading dataset RoboschoolReacher-v1\n",
      "Domain name: RoboschoolReacher-v1\n",
      "(6750, 9) (750, 9) (6750, 2) (750, 2)\n",
      "model_name='model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/100\n",
      "6750/6750 [==============================] - 1s 75us/step - loss: 0.1121 - mean_squared_error: 0.0930 - val_loss: 0.1046 - val_mean_squared_error: 0.0871\n",
      "Epoch 2/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0916 - mean_squared_error: 0.0747 - val_loss: 0.0921 - val_mean_squared_error: 0.0757\n",
      "Epoch 3/100\n",
      "6750/6750 [==============================] - 0s 33us/step - loss: 0.0800 - mean_squared_error: 0.0639 - val_loss: 0.0784 - val_mean_squared_error: 0.0624\n",
      "Epoch 4/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0707 - mean_squared_error: 0.0547 - val_loss: 0.0688 - val_mean_squared_error: 0.0529\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0614 - mean_squared_error: 0.0455 - val_loss: 0.0623 - val_mean_squared_error: 0.0463\n",
      "Epoch 6/100\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0540 - mean_squared_error: 0.0380 - val_loss: 0.0571 - val_mean_squared_error: 0.0410\n",
      "Epoch 7/100\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0495 - mean_squared_error: 0.0335 - val_loss: 0.0512 - val_mean_squared_error: 0.0351\n",
      "Epoch 8/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0453 - mean_squared_error: 0.0293 - val_loss: 0.0511 - val_mean_squared_error: 0.0350\n",
      "Epoch 9/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0416 - mean_squared_error: 0.0254 - val_loss: 0.0436 - val_mean_squared_error: 0.0275\n",
      "Epoch 10/100\n",
      "6750/6750 [==============================] - 0s 33us/step - loss: 0.0392 - mean_squared_error: 0.0231 - val_loss: 0.0475 - val_mean_squared_error: 0.0314\n",
      "Epoch 11/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0372 - mean_squared_error: 0.0213 - val_loss: 0.0454 - val_mean_squared_error: 0.0294\n",
      "Epoch 12/100\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0353 - mean_squared_error: 0.0193 - val_loss: 0.0371 - val_mean_squared_error: 0.0211\n",
      "Epoch 13/100\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0320 - mean_squared_error: 0.0161 - val_loss: 0.0349 - val_mean_squared_error: 0.0191\n",
      "Epoch 14/100\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0310 - mean_squared_error: 0.0152 - val_loss: 0.0327 - val_mean_squared_error: 0.0170\n",
      "Epoch 15/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0286 - mean_squared_error: 0.0130 - val_loss: 0.0347 - val_mean_squared_error: 0.0191\n",
      "Epoch 16/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0280 - mean_squared_error: 0.0125 - val_loss: 0.0336 - val_mean_squared_error: 0.0182\n",
      "Epoch 17/100\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0271 - mean_squared_error: 0.0118 - val_loss: 0.0310 - val_mean_squared_error: 0.0158\n",
      "Epoch 18/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0272 - mean_squared_error: 0.0120 - val_loss: 0.0311 - val_mean_squared_error: 0.0160\n",
      "Epoch 19/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0263 - mean_squared_error: 0.0114 - val_loss: 0.0297 - val_mean_squared_error: 0.0149\n",
      "Epoch 20/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0253 - mean_squared_error: 0.0105 - val_loss: 0.0301 - val_mean_squared_error: 0.0154\n",
      "Epoch 21/100\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.0247 - mean_squared_error: 0.0102 - val_loss: 0.0306 - val_mean_squared_error: 0.0161\n",
      "Epoch 22/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0244 - mean_squared_error: 0.0100 - val_loss: 0.0309 - val_mean_squared_error: 0.0167\n",
      "Epoch 23/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0241 - mean_squared_error: 0.0099 - val_loss: 0.0296 - val_mean_squared_error: 0.0156\n",
      "Epoch 24/100\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0227 - mean_squared_error: 0.0088 - val_loss: 0.0275 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/100\n",
      "6750/6750 [==============================] - 0s 33us/step - loss: 0.0223 - mean_squared_error: 0.0085 - val_loss: 0.0275 - val_mean_squared_error: 0.0137\n",
      "Epoch 26/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0221 - mean_squared_error: 0.0085 - val_loss: 0.0274 - val_mean_squared_error: 0.0138\n",
      "Epoch 27/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0214 - mean_squared_error: 0.0079 - val_loss: 0.0261 - val_mean_squared_error: 0.0128\n",
      "Epoch 28/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0217 - mean_squared_error: 0.0085 - val_loss: 0.0274 - val_mean_squared_error: 0.0143\n",
      "Epoch 29/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0211 - mean_squared_error: 0.0080 - val_loss: 0.0257 - val_mean_squared_error: 0.0128\n",
      "Epoch 30/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0206 - mean_squared_error: 0.0077 - val_loss: 0.0260 - val_mean_squared_error: 0.0132\n",
      "Epoch 31/100\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0207 - mean_squared_error: 0.0079 - val_loss: 0.0285 - val_mean_squared_error: 0.0159\n",
      "Epoch 32/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0203 - mean_squared_error: 0.0077 - val_loss: 0.0256 - val_mean_squared_error: 0.0131\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 33/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0185 - mean_squared_error: 0.0060 - val_loss: 0.0243 - val_mean_squared_error: 0.0118\n",
      "Epoch 34/100\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0178 - mean_squared_error: 0.0054 - val_loss: 0.0236 - val_mean_squared_error: 0.0112\n",
      "Epoch 35/100\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0178 - mean_squared_error: 0.0055 - val_loss: 0.0241 - val_mean_squared_error: 0.0118\n",
      "Epoch 36/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0175 - mean_squared_error: 0.0053 - val_loss: 0.0238 - val_mean_squared_error: 0.0116\n",
      "Epoch 37/100\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0176 - mean_squared_error: 0.0054 - val_loss: 0.0229 - val_mean_squared_error: 0.0108\n",
      "Epoch 38/100\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0173 - mean_squared_error: 0.0052 - val_loss: 0.0234 - val_mean_squared_error: 0.0113\n",
      "Epoch 39/100\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0172 - mean_squared_error: 0.0052 - val_loss: 0.0235 - val_mean_squared_error: 0.0115\n",
      "Epoch 40/100\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0174 - mean_squared_error: 0.0055 - val_loss: 0.0238 - val_mean_squared_error: 0.0119\n",
      "Epoch 41/100\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0169 - mean_squared_error: 0.0051 - val_loss: 0.0232 - val_mean_squared_error: 0.0114\n",
      "Epoch 42/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0170 - mean_squared_error: 0.0053 - val_loss: 0.0224 - val_mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 43/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0160 - mean_squared_error: 0.0044 - val_loss: 0.0216 - val_mean_squared_error: 0.0100\n",
      "Epoch 44/100\n",
      "6750/6750 [==============================] - 0s 33us/step - loss: 0.0160 - mean_squared_error: 0.0044 - val_loss: 0.0219 - val_mean_squared_error: 0.0103\n",
      "Epoch 45/100\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0159 - mean_squared_error: 0.0043 - val_loss: 0.0220 - val_mean_squared_error: 0.0104\n",
      "Epoch 46/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0157 - mean_squared_error: 0.0042 - val_loss: 0.0226 - val_mean_squared_error: 0.0111\n",
      "Epoch 47/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0156 - mean_squared_error: 0.0041 - val_loss: 0.0217 - val_mean_squared_error: 0.0102\n",
      "Epoch 48/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0158 - mean_squared_error: 0.0044 - val_loss: 0.0220 - val_mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 49/100\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0152 - mean_squared_error: 0.0038 - val_loss: 0.0216 - val_mean_squared_error: 0.0102\n",
      "Epoch 50/100\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0152 - mean_squared_error: 0.0038 - val_loss: 0.0214 - val_mean_squared_error: 0.0100\n",
      "Epoch 51/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0151 - mean_squared_error: 0.0037 - val_loss: 0.0215 - val_mean_squared_error: 0.0101\n",
      "Epoch 52/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0151 - mean_squared_error: 0.0038 - val_loss: 0.0213 - val_mean_squared_error: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0151 - mean_squared_error: 0.0037 - val_loss: 0.0214 - val_mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 54/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0149 - mean_squared_error: 0.0036 - val_loss: 0.0210 - val_mean_squared_error: 0.0097\n",
      "Epoch 55/100\n",
      "6750/6750 [==============================] - 0s 33us/step - loss: 0.0148 - mean_squared_error: 0.0035 - val_loss: 0.0210 - val_mean_squared_error: 0.0097\n",
      "Epoch 56/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0148 - mean_squared_error: 0.0036 - val_loss: 0.0211 - val_mean_squared_error: 0.0098\n",
      "Epoch 57/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0148 - mean_squared_error: 0.0035 - val_loss: 0.0210 - val_mean_squared_error: 0.0098\n",
      "Epoch 58/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0148 - mean_squared_error: 0.0035 - val_loss: 0.0210 - val_mean_squared_error: 0.0098\n",
      "Epoch 59/100\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0148 - mean_squared_error: 0.0035 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 60/100\n",
      "6750/6750 [==============================] - 0s 33us/step - loss: 0.0147 - mean_squared_error: 0.0034 - val_loss: 0.0210 - val_mean_squared_error: 0.0097\n",
      "Epoch 61/100\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0146 - mean_squared_error: 0.0034 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "Epoch 62/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0146 - mean_squared_error: 0.0034 - val_loss: 0.0210 - val_mean_squared_error: 0.0098\n",
      "Epoch 63/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0146 - mean_squared_error: 0.0034 - val_loss: 0.0210 - val_mean_squared_error: 0.0097\n",
      "Epoch 64/100\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0146 - mean_squared_error: 0.0034 - val_loss: 0.0210 - val_mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 65/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0145 - mean_squared_error: 0.0033 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "Epoch 66/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0145 - mean_squared_error: 0.0033 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "Epoch 67/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0145 - mean_squared_error: 0.0033 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "Epoch 68/100\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0145 - mean_squared_error: 0.0033 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "Epoch 69/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0145 - mean_squared_error: 0.0033 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 70/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0145 - mean_squared_error: 0.0033 - val_loss: 0.0208 - val_mean_squared_error: 0.0096\n",
      "Epoch 71/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0145 - mean_squared_error: 0.0033 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "Epoch 72/100\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0145 - mean_squared_error: 0.0033 - val_loss: 0.0208 - val_mean_squared_error: 0.0096\n",
      "Epoch 73/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0145 - mean_squared_error: 0.0033 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "Epoch 74/100\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0145 - mean_squared_error: 0.0033 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 75/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0033 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "Epoch 76/100\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0144 - mean_squared_error: 0.0033 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "Epoch 77/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0033 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 78/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0144 - mean_squared_error: 0.0033 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "Epoch 79/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0033 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 80/100\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0209 - val_mean_squared_error: 0.0097\n",
      "Epoch 81/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 82/100\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 83/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 84/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 85/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 86/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 87/100\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 88/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 89/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 90/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 91/100\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 92/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 93/100\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 94/100\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 95/100\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 96/100\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 97/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "Epoch 99/100\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 100/100\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0144 - mean_squared_error: 0.0032 - val_loss: 0.0208 - val_mean_squared_error: 0.0097\n",
      "hw1/models/model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolReacher-v1\n",
      "{'model_path': 'hw1/models/model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'train_mse': 0.0032350545394820955, 'model_name': 'model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'dataset_name': 'RoboschoolReacher-v1', 'test_mse': 0.00966193485294975}\n",
      "Training a FC ANN for env RoboschoolHopper-v1\n",
      "loading dataset RoboschoolHopper-v1\n",
      "Domain name: RoboschoolHopper-v1\n",
      "(32200, 15) (3578, 15) (32200, 3) (3578, 3)\n",
      "model_name='model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "Train on 32200 samples, validate on 3578 samples\n",
      "Epoch 1/100\n",
      "32200/32200 [==============================] - 1s 35us/step - loss: 0.3224 - mean_squared_error: 0.3027 - val_loss: 0.1097 - val_mean_squared_error: 0.0888\n",
      "Epoch 2/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0955 - mean_squared_error: 0.0739 - val_loss: 0.0768 - val_mean_squared_error: 0.0547\n",
      "Epoch 3/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0713 - mean_squared_error: 0.0492 - val_loss: 0.0624 - val_mean_squared_error: 0.0402\n",
      "Epoch 4/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0605 - mean_squared_error: 0.0384 - val_loss: 0.0534 - val_mean_squared_error: 0.0315\n",
      "Epoch 5/100\n",
      "32200/32200 [==============================] - 1s 29us/step - loss: 0.0539 - mean_squared_error: 0.0321 - val_loss: 0.0561 - val_mean_squared_error: 0.0345\n",
      "Epoch 6/100\n",
      "32200/32200 [==============================] - 1s 29us/step - loss: 0.0496 - mean_squared_error: 0.0283 - val_loss: 0.0511 - val_mean_squared_error: 0.0300\n",
      "Epoch 7/100\n",
      "32200/32200 [==============================] - 1s 29us/step - loss: 0.0460 - mean_squared_error: 0.0252 - val_loss: 0.0463 - val_mean_squared_error: 0.0257\n",
      "Epoch 8/100\n",
      "32200/32200 [==============================] - 1s 29us/step - loss: 0.0435 - mean_squared_error: 0.0232 - val_loss: 0.0426 - val_mean_squared_error: 0.0226\n",
      "Epoch 9/100\n",
      "32200/32200 [==============================] - 1s 28us/step - loss: 0.0420 - mean_squared_error: 0.0223 - val_loss: 0.0401 - val_mean_squared_error: 0.0206\n",
      "Epoch 10/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0393 - mean_squared_error: 0.0201 - val_loss: 0.0384 - val_mean_squared_error: 0.0194\n",
      "Epoch 11/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0386 - mean_squared_error: 0.0198 - val_loss: 0.0353 - val_mean_squared_error: 0.0168\n",
      "Epoch 12/100\n",
      "32200/32200 [==============================] - 1s 29us/step - loss: 0.0373 - mean_squared_error: 0.0190 - val_loss: 0.0364 - val_mean_squared_error: 0.0183\n",
      "Epoch 13/100\n",
      "32200/32200 [==============================] - 1s 29us/step - loss: 0.0366 - mean_squared_error: 0.0187 - val_loss: 0.0355 - val_mean_squared_error: 0.0178\n",
      "Epoch 14/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0347 - mean_squared_error: 0.0172 - val_loss: 0.0324 - val_mean_squared_error: 0.0152\n",
      "Epoch 15/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0341 - mean_squared_error: 0.0169 - val_loss: 0.0344 - val_mean_squared_error: 0.0174\n",
      "Epoch 16/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0327 - mean_squared_error: 0.0159 - val_loss: 0.0334 - val_mean_squared_error: 0.0168\n",
      "Epoch 17/100\n",
      "32200/32200 [==============================] - 1s 33us/step - loss: 0.0328 - mean_squared_error: 0.0163 - val_loss: 0.0317 - val_mean_squared_error: 0.0154\n",
      "Epoch 18/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0323 - mean_squared_error: 0.0161 - val_loss: 0.0338 - val_mean_squared_error: 0.0178\n",
      "Epoch 19/100\n",
      "32200/32200 [==============================] - 1s 33us/step - loss: 0.0310 - mean_squared_error: 0.0152 - val_loss: 0.0330 - val_mean_squared_error: 0.0173\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 20/100\n",
      "32200/32200 [==============================] - 1s 32us/step - loss: 0.0275 - mean_squared_error: 0.0118 - val_loss: 0.0269 - val_mean_squared_error: 0.0114\n",
      "Epoch 21/100\n",
      "32200/32200 [==============================] - 1s 33us/step - loss: 0.0272 - mean_squared_error: 0.0117 - val_loss: 0.0265 - val_mean_squared_error: 0.0111\n",
      "Epoch 22/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0266 - mean_squared_error: 0.0113 - val_loss: 0.0274 - val_mean_squared_error: 0.0122\n",
      "Epoch 23/100\n",
      "32200/32200 [==============================] - 1s 33us/step - loss: 0.0264 - mean_squared_error: 0.0113 - val_loss: 0.0297 - val_mean_squared_error: 0.0147\n",
      "Epoch 24/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0261 - mean_squared_error: 0.0111 - val_loss: 0.0269 - val_mean_squared_error: 0.0120\n",
      "Epoch 25/100\n",
      "32200/32200 [==============================] - 1s 35us/step - loss: 0.0259 - mean_squared_error: 0.0111 - val_loss: 0.0272 - val_mean_squared_error: 0.0125\n",
      "Epoch 26/100\n",
      "32200/32200 [==============================] - 1s 32us/step - loss: 0.0256 - mean_squared_error: 0.0109 - val_loss: 0.0247 - val_mean_squared_error: 0.0102\n",
      "Epoch 27/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0251 - mean_squared_error: 0.0106 - val_loss: 0.0248 - val_mean_squared_error: 0.0104\n",
      "Epoch 28/100\n",
      "32200/32200 [==============================] - 1s 35us/step - loss: 0.0248 - mean_squared_error: 0.0105 - val_loss: 0.0251 - val_mean_squared_error: 0.0108\n",
      "Epoch 29/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0245 - mean_squared_error: 0.0104 - val_loss: 0.0270 - val_mean_squared_error: 0.0130\n",
      "Epoch 30/100\n",
      "32200/32200 [==============================] - 1s 35us/step - loss: 0.0246 - mean_squared_error: 0.0106 - val_loss: 0.0251 - val_mean_squared_error: 0.0112\n",
      "Epoch 31/100\n",
      "32200/32200 [==============================] - 1s 33us/step - loss: 0.0246 - mean_squared_error: 0.0107 - val_loss: 0.0241 - val_mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 32/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0225 - mean_squared_error: 0.0087 - val_loss: 0.0227 - val_mean_squared_error: 0.0089\n",
      "Epoch 33/100\n",
      "32200/32200 [==============================] - 1s 33us/step - loss: 0.0224 - mean_squared_error: 0.0087 - val_loss: 0.0226 - val_mean_squared_error: 0.0089\n",
      "Epoch 34/100\n",
      "32200/32200 [==============================] - 1s 32us/step - loss: 0.0222 - mean_squared_error: 0.0086 - val_loss: 0.0233 - val_mean_squared_error: 0.0097\n",
      "Epoch 35/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0221 - mean_squared_error: 0.0086 - val_loss: 0.0232 - val_mean_squared_error: 0.0097\n",
      "Epoch 36/100\n",
      "32200/32200 [==============================] - 1s 33us/step - loss: 0.0219 - mean_squared_error: 0.0084 - val_loss: 0.0230 - val_mean_squared_error: 0.0096\n",
      "Epoch 37/100\n",
      "32200/32200 [==============================] - 1s 32us/step - loss: 0.0219 - mean_squared_error: 0.0085 - val_loss: 0.0220 - val_mean_squared_error: 0.0087\n",
      "Epoch 38/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0217 - mean_squared_error: 0.0083 - val_loss: 0.0230 - val_mean_squared_error: 0.0097\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0216 - mean_squared_error: 0.0084 - val_loss: 0.0222 - val_mean_squared_error: 0.0090\n",
      "Epoch 40/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0214 - mean_squared_error: 0.0082 - val_loss: 0.0224 - val_mean_squared_error: 0.0093\n",
      "Epoch 41/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0213 - mean_squared_error: 0.0082 - val_loss: 0.0215 - val_mean_squared_error: 0.0084\n",
      "Epoch 42/100\n",
      "32200/32200 [==============================] - 1s 32us/step - loss: 0.0211 - mean_squared_error: 0.0081 - val_loss: 0.0221 - val_mean_squared_error: 0.0092\n",
      "Epoch 43/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0210 - mean_squared_error: 0.0081 - val_loss: 0.0215 - val_mean_squared_error: 0.0086\n",
      "Epoch 44/100\n",
      "32200/32200 [==============================] - 1s 33us/step - loss: 0.0208 - mean_squared_error: 0.0079 - val_loss: 0.0210 - val_mean_squared_error: 0.0082\n",
      "Epoch 45/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0207 - mean_squared_error: 0.0079 - val_loss: 0.0210 - val_mean_squared_error: 0.0082\n",
      "Epoch 46/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0206 - mean_squared_error: 0.0079 - val_loss: 0.0234 - val_mean_squared_error: 0.0108\n",
      "Epoch 47/100\n",
      "32200/32200 [==============================] - 1s 33us/step - loss: 0.0205 - mean_squared_error: 0.0079 - val_loss: 0.0208 - val_mean_squared_error: 0.0082\n",
      "Epoch 48/100\n",
      "32200/32200 [==============================] - 1s 40us/step - loss: 0.0204 - mean_squared_error: 0.0078 - val_loss: 0.0213 - val_mean_squared_error: 0.0088\n",
      "Epoch 49/100\n",
      "32200/32200 [==============================] - 1s 33us/step - loss: 0.0203 - mean_squared_error: 0.0077 - val_loss: 0.0225 - val_mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 50/100\n",
      "32200/32200 [==============================] - 1s 32us/step - loss: 0.0196 - mean_squared_error: 0.0071 - val_loss: 0.0203 - val_mean_squared_error: 0.0078\n",
      "Epoch 51/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0195 - mean_squared_error: 0.0070 - val_loss: 0.0199 - val_mean_squared_error: 0.0075\n",
      "Epoch 52/100\n",
      "32200/32200 [==============================] - 1s 32us/step - loss: 0.0194 - mean_squared_error: 0.0070 - val_loss: 0.0199 - val_mean_squared_error: 0.0075\n",
      "Epoch 53/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0194 - mean_squared_error: 0.0070 - val_loss: 0.0200 - val_mean_squared_error: 0.0076\n",
      "Epoch 54/100\n",
      "32200/32200 [==============================] - 1s 37us/step - loss: 0.0193 - mean_squared_error: 0.0070 - val_loss: 0.0200 - val_mean_squared_error: 0.0076\n",
      "Epoch 55/100\n",
      "32200/32200 [==============================] - 1s 37us/step - loss: 0.0193 - mean_squared_error: 0.0070 - val_loss: 0.0202 - val_mean_squared_error: 0.0079\n",
      "Epoch 56/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0192 - mean_squared_error: 0.0069 - val_loss: 0.0195 - val_mean_squared_error: 0.0073\n",
      "Epoch 57/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0191 - mean_squared_error: 0.0069 - val_loss: 0.0196 - val_mean_squared_error: 0.0074\n",
      "Epoch 58/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0191 - mean_squared_error: 0.0069 - val_loss: 0.0202 - val_mean_squared_error: 0.0080\n",
      "Epoch 59/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0191 - mean_squared_error: 0.0070 - val_loss: 0.0202 - val_mean_squared_error: 0.0081\n",
      "Epoch 60/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0190 - mean_squared_error: 0.0069 - val_loss: 0.0196 - val_mean_squared_error: 0.0075\n",
      "Epoch 61/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0189 - mean_squared_error: 0.0068 - val_loss: 0.0199 - val_mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 62/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0186 - mean_squared_error: 0.0065 - val_loss: 0.0194 - val_mean_squared_error: 0.0074\n",
      "Epoch 63/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0185 - mean_squared_error: 0.0065 - val_loss: 0.0195 - val_mean_squared_error: 0.0074\n",
      "Epoch 64/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0185 - mean_squared_error: 0.0065 - val_loss: 0.0193 - val_mean_squared_error: 0.0073\n",
      "Epoch 65/100\n",
      "32200/32200 [==============================] - 1s 29us/step - loss: 0.0185 - mean_squared_error: 0.0065 - val_loss: 0.0194 - val_mean_squared_error: 0.0074\n",
      "Epoch 66/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0184 - mean_squared_error: 0.0064 - val_loss: 0.0193 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 67/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0183 - mean_squared_error: 0.0063 - val_loss: 0.0191 - val_mean_squared_error: 0.0071\n",
      "Epoch 68/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0182 - mean_squared_error: 0.0063 - val_loss: 0.0191 - val_mean_squared_error: 0.0071\n",
      "Epoch 69/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0182 - mean_squared_error: 0.0063 - val_loss: 0.0190 - val_mean_squared_error: 0.0071\n",
      "Epoch 70/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0182 - mean_squared_error: 0.0062 - val_loss: 0.0190 - val_mean_squared_error: 0.0071\n",
      "Epoch 71/100\n",
      "32200/32200 [==============================] - 1s 29us/step - loss: 0.0182 - mean_squared_error: 0.0063 - val_loss: 0.0190 - val_mean_squared_error: 0.0070\n",
      "Epoch 72/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0182 - mean_squared_error: 0.0062 - val_loss: 0.0190 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 73/100\n",
      "32200/32200 [==============================] - 1s 29us/step - loss: 0.0181 - mean_squared_error: 0.0061 - val_loss: 0.0189 - val_mean_squared_error: 0.0069\n",
      "Epoch 74/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0181 - mean_squared_error: 0.0061 - val_loss: 0.0189 - val_mean_squared_error: 0.0070\n",
      "Epoch 75/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0180 - mean_squared_error: 0.0061 - val_loss: 0.0189 - val_mean_squared_error: 0.0070\n",
      "Epoch 76/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0180 - mean_squared_error: 0.0061 - val_loss: 0.0189 - val_mean_squared_error: 0.0070\n",
      "Epoch 77/100\n",
      "32200/32200 [==============================] - 1s 34us/step - loss: 0.0180 - mean_squared_error: 0.0061 - val_loss: 0.0189 - val_mean_squared_error: 0.0070\n",
      "Epoch 78/100\n",
      "32200/32200 [==============================] - 1s 33us/step - loss: 0.0180 - mean_squared_error: 0.0061 - val_loss: 0.0189 - val_mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 79/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0180 - mean_squared_error: 0.0061 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 80/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0180 - mean_squared_error: 0.0061 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 81/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0180 - mean_squared_error: 0.0061 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 82/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0180 - mean_squared_error: 0.0061 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 83/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0179 - mean_squared_error: 0.0061 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 84/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 86/100\n",
      "32200/32200 [==============================] - 1s 29us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 87/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 88/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 89/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 90/100\n",
      "32200/32200 [==============================] - 1s 29us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 91/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 92/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 93/100\n",
      "32200/32200 [==============================] - 1s 32us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 94/100\n",
      "32200/32200 [==============================] - 1s 35us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 95/100\n",
      "32200/32200 [==============================] - 1s 32us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 96/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 97/100\n",
      "32200/32200 [==============================] - 1s 35us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 98/100\n",
      "32200/32200 [==============================] - 1s 31us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 99/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "Epoch 100/100\n",
      "32200/32200 [==============================] - 1s 30us/step - loss: 0.0179 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0069\n",
      "hw1/models/model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolHopper-v1\n",
      "{'model_path': 'hw1/models/model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'train_mse': 0.006004824829383159, 'model_name': 'model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'dataset_name': 'RoboschoolHopper-v1', 'test_mse': 0.006888282813782915}\n",
      "Training a FC ANN for env RoboschoolWalker2d-v1\n",
      "loading dataset RoboschoolWalker2d-v1\n",
      "Domain name: RoboschoolWalker2d-v1\n",
      "(45000, 22) (5000, 22) (45000, 6) (5000, 6)\n",
      "model_name='model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 2s 36us/step - loss: 0.1188 - mean_squared_error: 0.1002 - val_loss: 0.0601 - val_mean_squared_error: 0.0410\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0509 - mean_squared_error: 0.0318 - val_loss: 0.0499 - val_mean_squared_error: 0.0311\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.0426 - mean_squared_error: 0.0242 - val_loss: 0.0404 - val_mean_squared_error: 0.0224\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0380 - mean_squared_error: 0.0205 - val_loss: 0.0364 - val_mean_squared_error: 0.0193\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.0353 - mean_squared_error: 0.0186 - val_loss: 0.0354 - val_mean_squared_error: 0.0192\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.0330 - mean_squared_error: 0.0171 - val_loss: 0.0334 - val_mean_squared_error: 0.0179\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0313 - mean_squared_error: 0.0161 - val_loss: 0.0315 - val_mean_squared_error: 0.0166\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.0297 - mean_squared_error: 0.0151 - val_loss: 0.0316 - val_mean_squared_error: 0.0173s - loss: 0.0297 - mean_squared_err\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.0286 - mean_squared_error: 0.0145 - val_loss: 0.0341 - val_mean_squared_error: 0.0204\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.0274 - mean_squared_error: 0.0138 - val_loss: 0.0273 - val_mean_squared_error: 0.0140\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.0267 - mean_squared_error: 0.0136 - val_loss: 0.0271 - val_mean_squared_error: 0.0142\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 2s 33us/step - loss: 0.0257 - mean_squared_error: 0.0130 - val_loss: 0.0250 - val_mean_squared_error: 0.0125\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0250 - mean_squared_error: 0.0126 - val_loss: 0.0269 - val_mean_squared_error: 0.0147\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 0.0244 - mean_squared_error: 0.0124 - val_loss: 0.0238 - val_mean_squared_error: 0.0120\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 0.0237 - mean_squared_error: 0.0120 - val_loss: 0.0249 - val_mean_squared_error: 0.0134\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 2s 34us/step - loss: 0.0233 - mean_squared_error: 0.0118 - val_loss: 0.0240 - val_mean_squared_error: 0.0127\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 2s 34us/step - loss: 0.0227 - mean_squared_error: 0.0116 - val_loss: 0.0236 - val_mean_squared_error: 0.0126\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 2s 37us/step - loss: 0.0222 - mean_squared_error: 0.0112 - val_loss: 0.0221 - val_mean_squared_error: 0.0113\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.0219 - mean_squared_error: 0.0112 - val_loss: 0.0243 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 2s 33us/step - loss: 0.0215 - mean_squared_error: 0.0110 - val_loss: 0.0230 - val_mean_squared_error: 0.0126\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.0211 - mean_squared_error: 0.0108 - val_loss: 0.0213 - val_mean_squared_error: 0.0111\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 2s 34us/step - loss: 0.0208 - mean_squared_error: 0.0107 - val_loss: 0.0220 - val_mean_squared_error: 0.0120\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 0.0207 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0115\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 2s 37us/step - loss: 0.0204 - mean_squared_error: 0.0106 - val_loss: 0.0210 - val_mean_squared_error: 0.0112\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 0.0200 - mean_squared_error: 0.0103 - val_loss: 0.0213 - val_mean_squared_error: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 2s 33us/step - loss: 0.0197 - mean_squared_error: 0.0102 - val_loss: 0.0204 - val_mean_squared_error: 0.0109\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 0.0195 - mean_squared_error: 0.0101 - val_loss: 0.0213 - val_mean_squared_error: 0.0119\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.0193 - mean_squared_error: 0.0100 - val_loss: 0.0204 - val_mean_squared_error: 0.0111\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 0.0191 - mean_squared_error: 0.0099 - val_loss: 0.0206 - val_mean_squared_error: 0.0114\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 2s 38us/step - loss: 0.0190 - mean_squared_error: 0.0099 - val_loss: 0.0191 - val_mean_squared_error: 0.0101\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 0.0187 - mean_squared_error: 0.0097 - val_loss: 0.0189 - val_mean_squared_error: 0.0100\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 2s 36us/step - loss: 0.0184 - mean_squared_error: 0.0095 - val_loss: 0.0188 - val_mean_squared_error: 0.0099\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 2s 34us/step - loss: 0.0183 - mean_squared_error: 0.0095 - val_loss: 0.0196 - val_mean_squared_error: 0.0108\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 0.0182 - mean_squared_error: 0.0094 - val_loss: 0.0205 - val_mean_squared_error: 0.0118\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0181 - mean_squared_error: 0.0094 - val_loss: 0.0183 - val_mean_squared_error: 0.0097\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0180 - mean_squared_error: 0.0094 - val_loss: 0.0185 - val_mean_squared_error: 0.0100\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0176 - mean_squared_error: 0.0091 - val_loss: 0.0183 - val_mean_squared_error: 0.0099\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0176 - mean_squared_error: 0.0092 - val_loss: 0.0199 - val_mean_squared_error: 0.0115\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0175 - mean_squared_error: 0.0091 - val_loss: 0.0186 - val_mean_squared_error: 0.0103\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0173 - mean_squared_error: 0.0090 - val_loss: 0.0183 - val_mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0159 - mean_squared_error: 0.0076 - val_loss: 0.0174 - val_mean_squared_error: 0.0092\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0158 - mean_squared_error: 0.0077 - val_loss: 0.0164 - val_mean_squared_error: 0.0083\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0157 - mean_squared_error: 0.0076 - val_loss: 0.0162 - val_mean_squared_error: 0.0081\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0157 - mean_squared_error: 0.0076 - val_loss: 0.0176 - val_mean_squared_error: 0.0096\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0156 - mean_squared_error: 0.0076 - val_loss: 0.0164 - val_mean_squared_error: 0.0084\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0155 - mean_squared_error: 0.0075 - val_loss: 0.0163 - val_mean_squared_error: 0.0083\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0154 - mean_squared_error: 0.0074 - val_loss: 0.0158 - val_mean_squared_error: 0.0079\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 2s 45us/step - loss: 0.0154 - mean_squared_error: 0.0075 - val_loss: 0.0154 - val_mean_squared_error: 0.0075\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0153 - mean_squared_error: 0.0074 - val_loss: 0.0162 - val_mean_squared_error: 0.0084\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 1s 28us/step - loss: 0.0151 - mean_squared_error: 0.0073 - val_loss: 0.0160 - val_mean_squared_error: 0.0082\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0151 - mean_squared_error: 0.0073 - val_loss: 0.0165 - val_mean_squared_error: 0.0088\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0150 - mean_squared_error: 0.0073 - val_loss: 0.0162 - val_mean_squared_error: 0.0085\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0150 - mean_squared_error: 0.0073 - val_loss: 0.0158 - val_mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0142 - mean_squared_error: 0.0066 - val_loss: 0.0149 - val_mean_squared_error: 0.0073\n",
      "Epoch 55/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0148 - val_mean_squared_error: 0.0072\n",
      "Epoch 56/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0142 - mean_squared_error: 0.0065 - val_loss: 0.0150 - val_mean_squared_error: 0.0073\n",
      "Epoch 57/100\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0146 - val_mean_squared_error: 0.0070\n",
      "Epoch 58/100\n",
      "45000/45000 [==============================] - 2s 34us/step - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0152 - val_mean_squared_error: 0.0077\n",
      "Epoch 59/100\n",
      "45000/45000 [==============================] - 2s 34us/step - loss: 0.0140 - mean_squared_error: 0.0064 - val_loss: 0.0151 - val_mean_squared_error: 0.0075\n",
      "Epoch 60/100\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.0140 - mean_squared_error: 0.0065 - val_loss: 0.0147 - val_mean_squared_error: 0.0072\n",
      "Epoch 61/100\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0146 - val_mean_squared_error: 0.0071\n",
      "Epoch 62/100\n",
      "45000/45000 [==============================] - 2s 37us/step - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0148 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 63/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0141 - val_mean_squared_error: 0.0066\n",
      "Epoch 64/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0143 - val_mean_squared_error: 0.0068\n",
      "Epoch 65/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0141 - val_mean_squared_error: 0.0067\n",
      "Epoch 66/100\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0142 - val_mean_squared_error: 0.0068\n",
      "Epoch 67/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0139 - val_mean_squared_error: 0.0065\n",
      "Epoch 68/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0140 - val_mean_squared_error: 0.0066\n",
      "Epoch 69/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0133 - mean_squared_error: 0.0060 - val_loss: 0.0139 - val_mean_squared_error: 0.0065\n",
      "Epoch 70/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0140 - val_mean_squared_error: 0.0066\n",
      "Epoch 71/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0138 - val_mean_squared_error: 0.0065\n",
      "Epoch 72/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0138 - val_mean_squared_error: 0.0064\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0130 - mean_squared_error: 0.0057 - val_loss: 0.0136 - val_mean_squared_error: 0.0063\n",
      "Epoch 74/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0130 - mean_squared_error: 0.0057 - val_loss: 0.0136 - val_mean_squared_error: 0.0063\n",
      "Epoch 75/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0130 - mean_squared_error: 0.0057 - val_loss: 0.0136 - val_mean_squared_error: 0.0063\n",
      "Epoch 76/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0130 - mean_squared_error: 0.0057 - val_loss: 0.0136 - val_mean_squared_error: 0.0062\n",
      "Epoch 77/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0130 - mean_squared_error: 0.0057 - val_loss: 0.0136 - val_mean_squared_error: 0.0063\n",
      "Epoch 78/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0130 - mean_squared_error: 0.0057 - val_loss: 0.0136 - val_mean_squared_error: 0.0063\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 79/100\n",
      "45000/45000 [==============================] - 2s 34us/step - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0135 - val_mean_squared_error: 0.0062\n",
      "Epoch 80/100\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0136 - val_mean_squared_error: 0.0063\n",
      "Epoch 81/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0135 - val_mean_squared_error: 0.0062\n",
      "Epoch 82/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0135 - val_mean_squared_error: 0.0062\n",
      "Epoch 83/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0128 - mean_squared_error: 0.0056 - val_loss: 0.0135 - val_mean_squared_error: 0.0062\n",
      "Epoch 84/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0128 - mean_squared_error: 0.0056 - val_loss: 0.0135 - val_mean_squared_error: 0.0062s - loss: 0.0128 - mean\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 85/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "Epoch 86/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "Epoch 87/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "Epoch 88/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "Epoch 89/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 90/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0127 - mean_squared_error: 0.0055 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "Epoch 91/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "Epoch 92/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "Epoch 93/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "Epoch 94/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 95/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0133 - val_mean_squared_error: 0.0061\n",
      "Epoch 96/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "Epoch 97/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "Epoch 98/100\n",
      "45000/45000 [==============================] - 1s 29us/step - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0133 - val_mean_squared_error: 0.0061\n",
      "Epoch 99/100\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0134 - val_mean_squared_error: 0.0061\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 100/100\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0133 - val_mean_squared_error: 0.0061\n",
      "hw1/models/model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolWalker2d-v1\n",
      "{'model_path': 'hw1/models/model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'train_mse': 0.005413676085240551, 'model_name': 'model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'dataset_name': 'RoboschoolWalker2d-v1', 'test_mse': 0.006073426993102298}\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import Callback, LambdaCallback, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from hw1.manage_datasets import get_datasets\n",
    "from keras_helpers.model_helper import create_model, get_model_name, calc_mse\n",
    "from keras_helpers.keras_train_stats import KerasTrainStats\n",
    "\n",
    "\n",
    "SAVED_MODELS_DIR = 'hw1/models'\n",
    "MODEL_FILE_NAME = \"base.hdf5\"\n",
    "create_dir_if_not_exists(SAVED_MODELS_DIR)\n",
    "\n",
    "model_mse = []\n",
    "\n",
    "for env_name in AVAILABLE_ENVS:\n",
    "    print(\"Training a FC ANN for env %s\" % env_name)\n",
    "    \n",
    "    # Load the datasets\n",
    "    X_train, X_test, y_train, y_test = get_datasets(dataset_name=env_name, dataset_dir=EXPERT_DATA_DIR)\n",
    "    \n",
    "    # Define the model params    \n",
    "    config_dict = dict(\n",
    "        input_dim=len(X_train[1, :]),\n",
    "        output_dim=len(y_train[1, :]),\n",
    "        units=100,\n",
    "        layers = 3,\n",
    "        l2_reg = 1e-04,\n",
    "        optimizer_cls=keras.optimizers.Adam,\n",
    "        lr = 1e-03,\n",
    "        dropout=None,\n",
    "        use_batchnorm=False)\n",
    "    \n",
    "    # Create the model\n",
    "    model = create_model(**config_dict)\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = config_dict['optimizer_cls'](lr=config_dict['lr'])\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    \n",
    "    # Set a unique name/directory for the model\n",
    "    model_name = get_model_name(base_name=env_name, **config_dict)\n",
    "    model_path = os.path.join(SAVED_MODELS_DIR, model_name)\n",
    "    print(\"model_name='%s'\" % model_name)\n",
    "    print(\"model_path='%s'\" % model_path)\n",
    "    create_dir_if_not_exists(model_path)\n",
    "    model_filename = os.path.join(model_path, MODEL_FILE_NAME)\n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_mean_squared_error', factor=0.5, patience=5, verbose=1)\n",
    "    tf_board = TensorBoard()\n",
    "\n",
    "    # Define a train_stats object\n",
    "    train_stats = KerasTrainStats(model_name=model_name, history_dir=model_path)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "\n",
    "    _ = model.fit([X_train], y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[train_stats.print_callback, reduce_lr, tf_board],\n",
    "        validation_data=([X_test], y_test)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # Save the model\n",
    "    model.save(model_filename)\n",
    "    print(model_filename)\n",
    "    \n",
    "    # Calculate the MSE for each \n",
    "    res = calc_mse(model, env_name, X_train, X_test, y_train, y_test)\n",
    "    res['model_name'] = model_name\n",
    "    res['model_path'] = model_path\n",
    "    model_mse.append(res)\n",
    "    print(\"Done training model for %s\" % env_name)\n",
    "    #print(\"KerasTrainStats(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='%s MSE')\" % dataset_name)\n",
    "    print(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>train_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RoboschoolAnt-v1</td>\n",
       "      <td>0.046053</td>\n",
       "      <td>0.039205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RoboschoolHumanoid-v1</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>0.012397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RoboschoolHalfCheetah-v1</td>\n",
       "      <td>0.010912</td>\n",
       "      <td>0.009463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RoboschoolReacher-v1</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.003235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RoboschoolHopper-v1</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>0.006005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RoboschoolWalker2d-v1</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.005414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset_name  test_mse  train_mse\n",
       "0          RoboschoolAnt-v1  0.046053   0.039205\n",
       "1     RoboschoolHumanoid-v1  0.013617   0.012397\n",
       "2  RoboschoolHalfCheetah-v1  0.010912   0.009463\n",
       "3      RoboschoolReacher-v1  0.009662   0.003235\n",
       "4       RoboschoolHopper-v1  0.006888   0.006005\n",
       "5     RoboschoolWalker2d-v1  0.006073   0.005414"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the MSE error on both train/test sets\n",
    "df = pd.DataFrame(model_mse)\n",
    "df[['dataset_name', 'test_mse', 'train_mse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset_name': 'RoboschoolAnt-v1',\n",
       "  'model_name': 'model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'test_mse': 0.046053225442220666,\n",
       "  'train_mse': 0.03920499955367748},\n",
       " {'dataset_name': 'RoboschoolHumanoid-v1',\n",
       "  'model_name': 'model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'test_mse': 0.013617273586400507,\n",
       "  'train_mse': 0.012396673013696149},\n",
       " {'dataset_name': 'RoboschoolHalfCheetah-v1',\n",
       "  'model_name': 'model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'test_mse': 0.010912294609807542,\n",
       "  'train_mse': 0.009462605794146534},\n",
       " {'dataset_name': 'RoboschoolReacher-v1',\n",
       "  'model_name': 'model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'test_mse': 0.00966193485294975,\n",
       "  'train_mse': 0.0032350545394820955},\n",
       " {'dataset_name': 'RoboschoolHopper-v1',\n",
       "  'model_name': 'model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'test_mse': 0.006888282813782915,\n",
       "  'train_mse': 0.006004824829383159},\n",
       " {'dataset_name': 'RoboschoolWalker2d-v1',\n",
       "  'model_name': 'model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'model_path': 'hw1/models/model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm',\n",
       "  'test_mse': 0.006073426993102298,\n",
       "  'train_mse': 0.005413676085240551}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets define a policy based on the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RoboschoolAnt-v1': 'hw1/models/model_RoboschoolAnt-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5',\n",
       " 'RoboschoolHalfCheetah-v1': 'hw1/models/model_RoboschoolHalfCheetah-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5',\n",
       " 'RoboschoolHopper-v1': 'hw1/models/model_RoboschoolHopper-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5',\n",
       " 'RoboschoolHumanoid-v1': 'hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5',\n",
       " 'RoboschoolReacher-v1': 'hw1/models/model_RoboschoolReacher-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5',\n",
       " 'RoboschoolWalker2d-v1': 'hw1/models/model_RoboschoolWalker2d-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping between environment name to the model's full path\n",
    "env_to_model = {i['dataset_name']: os.path.join(i['model_path'], MODEL_FILE_NAME) for i in df.to_dict(\"records\")}\n",
    "env_to_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SupervisedModelPolicy():\n",
    "#     \"\"\"\n",
    "#     A policy class that is based on the ANN trained for each environment\n",
    "#     \"\"\"\n",
    "#     def __init__(self, env_name, model_filename=None):\n",
    "#         self._env_name = env_name\n",
    "        \n",
    "#         if model_filename is None:\n",
    "#             model_filename = env_to_model[env_name]\n",
    "#         self._model = tf.keras.models.load_model(model_filename)\n",
    "        \n",
    "#     def act(self, ob):\n",
    "#         action = self._model.predict(ob.reshape(1, ob.shape[0]))\n",
    "#         return action[0]\n",
    "    \n",
    "#     @property\n",
    "#     def model(self):\n",
    "#         return self._model\n",
    "    \n",
    "    \n",
    "# import gym\n",
    "# import roboschool\n",
    "# from hw1.run_expert import run_policy\n",
    "\n",
    "# def run_supervised_model_policy(num_rollouts, env_name, max_timesteps=None, render=False, verbose=True):\n",
    "#     assert env_name in AVAILABLE_ENVS\n",
    "#     env = gym.make(env_name)\n",
    "#     policy = SupervisedModelPolicy(env_name)\n",
    "#     description = \"Supervised model policy for module %s\" % env_name\n",
    "#     return run_policy(env=env, policy=policy, num_rollouts=num_rollouts, description=description, max_timesteps=max_timesteps, render=render, verbose=verbose)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class SupervisedModelPolicy():\n",
    "    \"\"\"\n",
    "    A policy class that is based on a pre trained Keras model for the specific environment\n",
    "    \"\"\"\n",
    "    def __init__(self, env_name, model_filename):\n",
    "        self._env_name = env_name  \n",
    "        self._model = tf.keras.models.load_model(model_filename)\n",
    "\n",
    "    def act(self, ob):\n",
    "        action = self._model.predict(ob.reshape(1, ob.shape[0]))\n",
    "        return action[0]\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "\n",
    "\n",
    "import gym\n",
    "import roboschool\n",
    "from hw1.run_expert import run_policy\n",
    "\n",
    "\n",
    "def run_supervised_model_policy(num_rollouts, env_name, max_timesteps=None, render=False, verbose=True):\n",
    "    assert env_name in AVAILABLE_ENVS\n",
    "    model_filename = env_to_model[env_name]\n",
    "    env = gym.make(env_name)\n",
    "    policy = SupervisedModelPolicy(env_name, model_filename)\n",
    "    description = \"Supervised model policy for module %s\" % env_name\n",
    "    return run_policy(env=env, policy=policy, num_rollouts=num_rollouts, description=description,\n",
    "                      max_timesteps=max_timesteps, render=render, verbose=verbose)\n",
    "\n",
    "def run_supervised_model_policy(num_rollouts, env_name, model_filename, max_timesteps=None, render=False, verbose=True):\n",
    "    env = gym.make(env_name)\n",
    "    policy = SupervisedModelPolicy(env_name, model_filename)\n",
    "    description = \"Supervised model policy for module %s\" % env_name\n",
    "    return run_policy(env=env, policy=policy, num_rollouts=num_rollouts, description=description,\n",
    "                      max_timesteps=max_timesteps, render=render, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now run the trajectories for each environment based on our model based policies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time expert_data = run_expert_policy(num_rollouts=50, env_name=env_name, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUPERVISED_MODELD_DATA_DIR = 'hw1/supervised_modeled_data'\n",
    "SUPERVISED_MODELD_DATA_DIR = 'hw1/supervised_modeled_data2'\n",
    "!mkdir -p {SUPERVISED_MODELD_DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running env RoboschoolAnt-v1 on supervised modeled data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Env description: Supervised model policy for module RoboschoolAnt-v1\n",
      "mean return 1844.2839543155878\n",
      "std of return 307.36087352377564\n",
      "CPU times: user 2min 28s, sys: 1min 8s, total: 3min 37s\n",
      "Wall time: 3min 29s\n",
      "Running env RoboschoolHumanoid-v1 on supervised modeled data\n",
      "Env description: Supervised model policy for module RoboschoolHumanoid-v1\n",
      "mean return 54.54620379127341\n",
      "std of return 14.689183234600167\n",
      "CPU times: user 11.7 s, sys: 4.41 s, total: 16.1 s\n",
      "Wall time: 15.8 s\n",
      "Running env RoboschoolHalfCheetah-v1 on supervised modeled data\n",
      "Env description: Supervised model policy for module RoboschoolHalfCheetah-v1\n",
      "mean return 2243.4067376308208\n",
      "std of return 947.1486822476894\n",
      "CPU times: user 2min, sys: 51.9 s, total: 2min 52s\n",
      "Wall time: 2min 45s\n",
      "Running env RoboschoolReacher-v1 on supervised modeled data\n",
      "Env description: Supervised model policy for module RoboschoolReacher-v1\n",
      "mean return 20.090711362381356\n",
      "std of return 8.078745416517629\n",
      "CPU times: user 21.3 s, sys: 4.48 s, total: 25.8 s\n",
      "Wall time: 24.7 s\n",
      "Running env RoboschoolHopper-v1 on supervised modeled data\n",
      "Env description: Supervised model policy for module RoboschoolHopper-v1\n",
      "mean return 1581.1752526376104\n",
      "std of return 634.9600572705551\n",
      "CPU times: user 1min 49s, sys: 42.1 s, total: 2min 31s\n",
      "Wall time: 2min 25s\n",
      "Running env RoboschoolWalker2d-v1 on supervised modeled data\n",
      "Env description: Supervised model policy for module RoboschoolWalker2d-v1\n",
      "mean return 2146.176259769251\n",
      "std of return 309.94530429902795\n",
      "CPU times: user 2min 35s, sys: 1min 7s, total: 3min 42s\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "for env_name in AVAILABLE_ENVS:\n",
    "    print(\"Running env %s on supervised modeled data\" % env_name)\n",
    "    model_filename = env_to_model[env_name]\n",
    "    %time supervised_modeled_data = run_supervised_model_policy(num_rollouts=50, env_name=env_name, model_filename=model_filename, verbose=False)\n",
    "    with open(os.path.join(SUPERVISED_MODELD_DATA_DIR, env_name + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(supervised_modeled_data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with dropout and batchnorm...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running env RoboschoolAnt-v1 on supervised modeled data\n",
      "Env description: Supervised model policy for module RoboschoolAnt-v1\n",
      "mean return 1155.2994265112447\n",
      "std of return 549.2614299613704\n",
      "CPU times: user 4min 28s, sys: 1min 18s, total: 5min 47s\n",
      "Wall time: 5min 27s\n",
      "Running env RoboschoolHumanoid-v1 on supervised modeled data\n",
      "Env description: Supervised model policy for module RoboschoolHumanoid-v1\n",
      "mean return 20.5863684169896\n",
      "std of return 7.856814573700111\n",
      "CPU times: user 38.2 s, sys: 2.66 s, total: 40.8 s\n",
      "Wall time: 40.1 s\n",
      "Running env RoboschoolHalfCheetah-v1 on supervised modeled data\n",
      "Env description: Supervised model policy for module RoboschoolHalfCheetah-v1\n",
      "mean return 139.41710379712438\n",
      "std of return 125.29263427061986\n",
      "CPU times: user 49.5 s, sys: 5.93 s, total: 55.5 s\n",
      "Wall time: 53.7 s\n",
      "Running env RoboschoolReacher-v1 on supervised modeled data\n",
      "Env description: Supervised model policy for module RoboschoolReacher-v1\n",
      "mean return 10.669455088047755\n",
      "std of return 10.375653339859674\n",
      "CPU times: user 56.6 s, sys: 4.6 s, total: 1min 1s\n",
      "Wall time: 59.1 s\n",
      "Running env RoboschoolHopper-v1 on supervised modeled data\n",
      "Env description: Supervised model policy for module RoboschoolHopper-v1\n",
      "mean return 685.327099958322\n",
      "std of return 617.3834606088823\n",
      "CPU times: user 1min 50s, sys: 21.1 s, total: 2min 11s\n",
      "Wall time: 2min 5s\n",
      "Running env RoboschoolWalker2d-v1 on supervised modeled data\n",
      "Env description: Supervised model policy for module RoboschoolWalker2d-v1\n",
      "mean return 159.5248567734963\n",
      "std of return 91.89797655885194\n",
      "CPU times: user 59.4 s, sys: 6.7 s, total: 1min 6s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "for env_name in AVAILABLE_ENVS:\n",
    "    print(\"Running env %s on supervised modeled data\" % env_name)\n",
    "    model_filename = env_to_model[env_name]\n",
    "    %time supervised_modeled_data = run_supervised_model_policy(num_rollouts=50, env_name=env_name, model_filename=model_filename, verbose=False)\n",
    "    with open(os.path.join(SUPERVISED_MODELD_DATA_DIR, env_name + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(supervised_modeled_data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoboschoolAnt-v1.pkl\t      RoboschoolHumanoid-v1.pkl\r\n",
      "RoboschoolHalfCheetah-v1.pkl  RoboschoolReacher-v1.pkl\r\n",
      "RoboschoolHopper-v1.pkl       RoboschoolWalker2d-v1.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls {SUPERVISED_MODELD_DATA_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the Model vs Expert performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the returns for expert/model for each environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolAnt-v1\n",
      "loading dataset RoboschoolAnt-v1\n",
      "loading dataset RoboschoolHumanoid-v1\n",
      "loading dataset RoboschoolHumanoid-v1\n",
      "loading dataset RoboschoolHalfCheetah-v1\n",
      "loading dataset RoboschoolHalfCheetah-v1\n",
      "loading dataset RoboschoolReacher-v1\n",
      "loading dataset RoboschoolReacher-v1\n",
      "loading dataset RoboschoolHopper-v1\n",
      "loading dataset RoboschoolHopper-v1\n",
      "loading dataset RoboschoolWalker2d-v1\n",
      "loading dataset RoboschoolWalker2d-v1\n"
     ]
    }
   ],
   "source": [
    "from hw1.manage_datasets import load_dataset\n",
    "\n",
    "returns = {}\n",
    "for env_name in AVAILABLE_ENVS:\n",
    "    returns[env_name] = {}\n",
    "    returns[env_name]['expert'] = load_dataset(dataset_name=env_name, dataset_dir=EXPERT_DATA_DIR)['returns']\n",
    "    returns[env_name]['model'] = load_dataset(dataset_name=env_name, dataset_dir=SUPERVISED_MODELD_DATA_DIR)['returns']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the returns histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "def grid_iterator(n_rows, n_cols, axis_size=2.5, total=None, fig_title=None):\n",
    "    fig = plt.figure()\n",
    "    gs = gridspec.GridSpec(n_rows, n_cols, top=1., bottom=0., right=1., left=0., hspace=0.15, wspace=0.1)\n",
    "    \n",
    "    count = 0\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            ax = fig.add_subplot(gs[r, c])\n",
    "            yield ax\n",
    "            \n",
    "            count+=1\n",
    "            # Allowing for not filling all spots\n",
    "            if total and count>=total:\n",
    "                break\n",
    "    \n",
    "    width, height = n_cols * axis_size, n_rows * axis_size\n",
    "    fig.set_size_inches(width, height)\n",
    "    \n",
    "    # Add title to the figure\n",
    "    if fig_title is not None:\n",
    "        fig.suptitle(fig_title, fontsize=16, y=1.05)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwQAAASJCAYAAABmcttqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsvXt8HXWd//98N5c2tGnaprHFgsBCtRZcUJGCYL1UENQVublVQVRYL1t0VdYFWUVEcb2suu7Xy29dcAFFEVlZUQFFAStYClJBKVhboKWFpk3SNPc0t8/vj5kJp0OSnpyc6eRF38/H4zxyZuYzc57vz5nM+XxmPhcLIeA4juM4juM4zr7JlLwFHMdxHMdxHMfJD68QOI7jOI7jOM4+jFcIHMdxHMdxHGcfxisEjuM4juM4jrMP4xUCx3Ecx3Ecx9mH8QqB4ziO4ziO4+zDeIXAcRxZzOzdZhZGee3M2280zGyWmV1mZi+bBC5Xx/m1xcye9ZtgZp8uyNPKMn1m8r0dXMK+wcwuK1i+zMw2lsNrIpjZwbHL3+Tt4jiOM17KcnF3HMfJmbOALal1A3mIFMks4NNEzmtydgHoBvYHXgv8JrXtXUAHULu3pcQ4mOg7vRt4PF8Vx3Gc8eEVAsdxngs8GELYkLdEMZjZ1LwdRqAV+AtwDgUVAjM7ATgEuBY4Nx+1/DCzqSGEXfu6g+M4z328yZDjOM9pzGyKmd1lZhvNrK5g/UvMrMfMvlywbqOZfd/M/sHMNphZr5mtMbPXjnDcV5vZb8ysw8y6zOyXZnZEKs1dZna3mf2dmf3RzHYB/wg8ESf574LmOO8exf/jZtZnZvUjbHvEzH4av680s8+a2WOxd3P82ScUmVXXAmeY2X4F694F/A7YOMJnV5nZ5+I864v/fs7MqlLp/sbMfmFm3WbWZGZfB0asFJnZ+8zsoQL/q8xsTpH+yTFKyocxvqvkmJ8ws7+Y2S4ze9rMvmJm0+LtrwHujA91e8F3+pp4+27NnOJ1B6e/97j51hYzO87Mfm9mPcCX4m3JubnczB6Nz7k/pOMys1eY2e1m1hKf34+b2bfGk4eO4+x7eIXAcZznAhVxoa3wNQUghDAEnE3U5OW/AMysBrgeWAv8a+pYrwE+Fq9fDuwCbjWzFyUJzOxNRHfSO+NjvyM+/u/M7MDU8V4I/Cfw/4A3AHcAp8fb/g04Ln79YpTYfgBUAH9fuNLMXg68mKggD3AR8NH4s94AvCd2LLZA/b+AAW+Njz+NqCnWtaOkvwa4ON7+ZuDq2OGaAsdq4HbgpcAK4N1ETxw+mT6YmX0B+Cbwa+AtwMeBk4nyvmI06RDCZSGEgwtWTSQf0t9V8rTk+7HzD4A3EX1v5wHXxdvXxPEBfJhnvtNSmoPVEZ2bPwROiT8z4VXAhcCniM6HCuDnZjYLwMxmAL8EBony+hTgcrw1gOM4eyKE4C9/+ctfki+iQk8Y5fXzVNrT4vXvAb5D1C5+YSrNRqAPOLBgXS2wA/hewboNwG9S+84EmoH/KFh3FzAEHJVKe3Dscn6Rcd4OrEqt+w+ipj5T4+WfAz8pIQ+vBrbE768Fbovfv42ob8FM4LLYtzLedkS8fFnqWJ+M1/9tvPwP8fKxBWmmEFXEAnBwQX4MApemjnd8nO6tBeue9bmpfUrNh9G+q1fFn/mu1Pp3xuuPipdfEy+/foRjj5RXyTnw7tR3EYBTRzjGxvj7nl2w7ug4/TtSy3+bx/+jv/zlL92XPyFwHOe5wGnAK1KvjxQmCCHcRPSE4NtEBdUPhxDWj3Cse0MImwv26yC6e38cgJktBA4Frit8IkFUeF4FLE0db2MI4cEJxnctcKyZHRY7VAJvB24Iz7Qvvx94o5ldYWYnxHfnS/mc15vZfKLmQj8NIbSPkC6J8fup9cnyq+O/xwGbQwj3JglC9MTmhtR+JxJVFNJ5upqo4pbO07GYSD6M9F2dTFRJvDHl9qt4+3jciqGfqFIzEqtCCK0Fy3+O/74g/rse2An8l5mdPcLTKsdxnBHxCoHjOM8FHg4h/CH1GqmT8TVE7de3s3tTjEK2jbJuQfz+efHfq4gKb4WvNwPptv5biw9jVH4CdBF1+gU4KfYobM7zeaJRbt5C1O6/xcz+x8zmjuNz7iDy/ShRk5nRmgslzW/SsTWmtu/P6PlZSJKnG3h2ntby7Dwdi4nkw0jf1fOAaqL8L/TaHm8fj1sxNIUQBkfZtqNwoaAyOC1ebiMaKepp4FvAk2b2sJmdUWZHx3GeY3i7Qsdx9gnizrLfBR4GFgJfICr4ppk3yrqn4vct8d9PELV3T9OXWg7jlk0fIIQuM7uJqJnKp4n6LTweQrinIE0/8EXgi/Ed/jcDXwX2I9X/YIzPGTKz64ja72/nmbvgaZKC6XzgsYL181PbtwKHj7B/Oo+TPD2JqFlMmpYR1o3IBPNhpO+qBeglajo0Ek8XobWLqFJRyGgViQmdL/ETjjPipxhHE52nN5jZkSGEhydybMdxnrt4hcBxnH2FrxPd5T+KqJD4H2Z2Wwjhl6l0x5rZgUmzITOrJepImnT6XUfUnvvwEMIXSnRJ7uzWjGOfa4GzzewNRB1/vzxawhBCI3Clmb2RqL3/ePgusAi4fYw71Svjv8uBKwrWvzP+e1f8dxXwHjM7Nmk2FHf2flvqeLcTtd9/QQjh9nH6jsoE8yHhNqKOynUhhPQcDYWM9Z1uGuHz31SiT1GEEAaAe83sU0RPS15MVBl2HMd5Fl4hcBznucBRozQJ+UMIYSBuMnE+cE4I4XHgP83sJOAaM/vbEML2gn22Ab+Kh4ncRVQYnA58FiCEEMxsBfDTuH36DUSdiecBrwSeDCF8dQ++24juPC83sz8RNUd5IoQw1p3w3xDdjb6KqND5vcKNFg0/+hDRyDatRCP7nEw8slKxhBD+SjzS0BhpHjazHwKXxXeif0/UX+BTwA9DCEnb9mQkop+Y2SVETx0+QNRRufB4j5nZF4FvxKM5/ZborvyBRP0Lrgwh3EkRlCsfCtzuimO90cy+CtxHVHk5GHgjcFGcZ38lmgzvvWa2g+jcWRf3Qbke+KSZ/StwL9HThreX4jMWZvZm4H3A/xENbTudaNSjDqLKmeM4zoh4hcBxnOcCPx5lfUM8xOh/A9eFEAo7wb4H+BNwtZm9KYSQNNX4LdEd7s8DBwCPAKfEhT4AQgi3mNlSoqFJryQqoDcSFfZ+tCfZuGnO+fFn/JroWvweolFmxtrnB8A/E3UuTfeRWEk0TOgKouYxTxKNYX8F2fBuohl530s0utDTRE11PlPg3GdmJwLfIGrT3kXUd+MXwP9XeLAQwiVm9mjsv4Ko6cxmoorQSJ2/RyOLfDgb+BBRrP9KVNjfSDTE57bYv8XMLiCqQP6WaEjQ1xKdS/9GNDv1BUQVpFuI+oOsnoDTSKwHeogqZvsTVQTuB04MIaRn8nYcxxnGnvkNdBzH2bcxs43A3SGEs/N2cRzHcZy9hY8y5DiO4ziO4zj7MF4hcBzHcRzHcZx9GG8y5DiO4ziO4zj7MP6EwHEcx3Ecx3H2YbxC4DiO4ziO4zj7MF4hcBzHcRzHcZx9GK8QOI7jOI7jOM4+jFcIHMdxHMdxHGcfxisEjuM4juM4jrMP4xUCx3Ecx3Ecx9mH8QqB4ziO4ziO4+zDeIXAcRzHcRzHcfZhvELgOI7jOI7jOPswXiFwHMdxHMdxnH0YrxA4juM4juM4zj6MVwgcx3Ecx3EcZx/GKwSO4ziO4ziOsw/jFQLHcRzHcRzH2YfxCoHjOI7jOI7j7MN4hcBxHMdxHMdx9mG8QuA4juM4juM4+zBeIXAcx3Ecx3GcfRivEDiO4ziO4zjOPoxXCBzHcRzHcRxnH8YrBI4EZnawmQUzOyFnj41m9sm98DmTIl7HcRyYPNckvwbvPczsajP79R7SvNvMBvaWk5MdXiFwMie+qIT4NWhmW8zsWjNbkLebImZ2UZyPXy5x/wPi7+I1ZfJZamY/NbNN8XEz/7F2HKd4/BpcHuL8O3uE9c/VQvE/AWftjQ/y35H88QqBs7f4HbA/8ALgHcBLgR/naiSImRnwD8DngXPNrDpnJYAZwCPAvwCNObs4jjMyfg12xkUIoS2E0LqXPs5/R3LGKwTO3qIvhNAYQngqhLAS+A5wnJnNBDCzWjP7LzNrMrNdZvYHMztphOMcbGa/MbMeM3vczJYXbjSzF5nZL8ysM379zMwOK9g+08z+x8wa48/ZbGZfTR1jhZk9Em/fbmb/m3KoNrOvm9kOM9tmZl8zs8qC/avM7Atm9pSZ9cXHekfqM/Y3s+vNbGccy11mdnQR+biM6ML5GaAZOC113NfEd1dONLOVZtYdf/4pBck2x3/vjNNuHOmDzGyKmT1pZpek1k81s1YzOx8ghHBLCOETIYQfAbuKiMFxnL2PX4N3/4xSr8F7ZKQnBpZ6MltwrX6jma2KHR4ws8Pj193x9fs+M1tccJzZZvb9+NrcY2brzOxCM7OCNFeb2a/N7H0W3XFvN7ObzWxeyuncOG/6LHpq9LlUPu7WZCj+Tfhs/J10mtmPgNl7yAv/HRHBKwTOXsfMng+cCQzGL4DvAm8AzgaOAu4Bfm5mi1K7fylOexTwA+A6M3tpfNwa4FfANODV8WsGcJs9cyf9c8DLgFOBhcDfA48WuH0G+CLwLeAlwMnAmpTDh4CtwJL4/QXAuQXbP090F/8jwBHA94Hvm9my+DMM+D9gEfBm4BhgG3C7mc3dQ/a9H7guhDAAXBMvj8S/xx5HAquBH5lZcuF+Wfz3DKI7hq8Y6QAhhKHY/ZzUplOJ8tjvLjqOIH4NntA1uNxcAfwr8HKgD/gh8G3g0wXr/qcg/VTgYeCtwGLgs0Q3iN6dOu4rgNcCbyL6Xl9C9LsAgJm9ieh7/B5RHl0IrIg/dzQ+BHwM+DjRd/jAHtL774gSIQR/+SvTF3A1MAB0At1AiF//Hm8/LF5+Y2q/NcB34/cHx2k+m0rze+B78fvz4uPPLdg+D+gB3hUv/xS4ehTP6XHafx4jlo3Azal1twI/jN/vR3R34x9TaW4C7ojfL4tjWVywfSrRD9ylqXhPKEjzPKIfh5fEywvifF1YkOY18X6np/IgAG+Ilw+Il19TxHe3KE77ioJ1P0/iHSV/Ppn3Oecvf/nrmZdfg8t2DQ5Ab5yPha9eYKAg3bsLl+N1u113C67Vby1Ic1a87oyCdafF62aMkSdfB25Pfd/bgakF6y4CthYs/w64IXWcf4rzv7rgOL8u2L4FuCK1z43pWEfw898RgZc/IXD2FquJ7igdQ3RHYxWQdBpKHoeuTO2zEjg8tW5VavmegjSHA4+EEJqTjSGEbcC6gjTfAs40s4fjR86nmNmUgv2nEd3hGosHU8tPE/3oQfTDWj1CLL9NebaEEB4p8NxFlEfpeAt5D/DnEMKf432eAn4DvG8sxzgPBgscR6TgEX+nmd0a7/sX4D7iuztm9jyiu03XjnUsx3EmHX4Nnvg1GKK7+UelXpfuYZ+xeKjgfdJ2/k8jrHseDDfBudjMHjSzZjPrBD4AHJQ67l/imBIK8wiiOEfKo2nAoWlJi5qWLSCqABZydyqd/46IUrnnJI5TFnpCCBvi9w+b2aHA/yN6rLvXCCH80sxeQHQxeg3Ro8w/J4+Si6QvfVgybn4XP+L+B+BvUm1TpwAvNbN/DSEUeqUdk7RjcVTB+56C99cCnzazC4k6Izaz5x9sx3EmF34NLg/bCvIRADPbnkozNMJ+VaMcr7/gfRhjXRLfhcAngI8CfwQ64vdvSh13pDwyssd/R0TxJwROXlwGvCfuxLU2Xrc0lWYpUVvJQo5NLb+SaGQC4uMsLmwDGneielHhcUIIO0IIPwwhvJ/oIvpqojtkjxA9+h2pI12xbCB6XJ2O5dUFDmuB+lRHsalE7WHT8SYsI3qEfTy735l6KVBDqnPxHkh+KCoKV4YQNhS8nirY9EOgjqgt77uI+jAM4jiOMpfh1+DxXIPHw3agItWJ92WjJR4nS4HbQgjfDSH8Ma6cLCzhOGsZOY96gMfSiUMI7cBTRN93Icen0vnviCj+hMDJhRDCejP7GVF7xDeY2Y+Bb5nZ+4FNwAeJOjq9I7XreWb2F+APRJ3fjiPq6ARRB7dLiTrQfpzobsi/E13EfgRgZlcQdYRaS3QX551EbUCfDCF0mtlXgMvMrAe4naiw/cYQwr8VGVe3mf0n8FkzayJ6HHwmUQeqE+NkdxA9Pv2Bma0A2oBPET2q/fYoh34/8NsQQvpxPXE+vj+JsQiaiWI+yczWArvCGEPLhRB2mNkvgMuJKiGFnfcwsxlEj+khelQ/38yOAjrTd9Icx5kc+DV43Nfg8XAf0Z37L5jZ54ma4EykWVEh64BzzOy1RPn6LqKKzHiHB/034GdmdjHwE6Jr+2XAV1JPmwv5ClG+/gW4F3gL8PpiPsx/RwTIuxODv577L1IdkwrWv5K4kxUwE/gvoIno7s4fgJMK0h4cpz0HuIvoLtITwDtSx3wRcAvPdPb6OXBYwfZPEd0B6iT6Efgtu3caM6KOVeuI7qRvA35csH0jqc5OwJXAXQXLVcAXiC7WfUR3vdKe+wPXAzuJ7sj8Fjh6hHhP4JnOxO8fJX9PJfphXcgzHdUOSKUZAN5dsPyuOP8GgI1FfIenxsf94wjbks9Mv+7a03H95S9/Zf/ya/DErsEF6wJw9gj5+G6e3Yn4TUSjJ/UQ9bN4Q5LX8fZnXavj630ADi5Yd2y87rB4uQ64AWgHWoBvEvUJ2TjW901UeQupdefGjn1xXl0BVI52HKJWJZ8nuqnURdSh+KPp2Mc4D/13ZBK/LP4iHMdxHMdxHMfZB/E+BI7jOI7jOI6zD1NUhcDMTrZoNrwNcXuz9PapZvajePtqMzu4YNsn4vXrzOwN8bppFs2+95CZrY0nIknSX21mT8RDaj0YtyFzHMdxHMdxHCcD9tip2MwqiNqonUg0KcX9ZnZzKBi/l2gyktYQwmEWTWP+ReDv4x78y4nGu30+8GszeyFR+8TXhagDURVwt5ndGkK4Nz7ex0MIN5YrSMdxHMdxHMdxRqaYJwTHABtCCI+HqOf59UQdQwo5Fbgmfn8jsCweN/1U4PoQwq4QwhNEw4EdEyI64/RV8cs7MziO4ziO4zjOXqaYYUcXAJsLlrcQDXE1YpoQwoCZtQH18fp7U/sugOEnDw8QDTP1zRDC6oJ0V5jZpUSzsF4cdp9tj9tuuy1s3boVMyOEwOzZs2loaKC/v5+Kimho9cHBQaqqqhgYiOZwqqysLGl7f38/ZkZFRQUDAwNUVFQQQmBoaGh4+5QpU5gyZQoDAwNUVlYyNDQ0vL2vr4+KiopRtyf7mxmDg4NUVlYyODhICGF4+96IaWhoaLfPHCumYrdnFVNfXx+VlZVl/Z6yimkiMe/NmAYGBqiqqsrl3BtvTIX7T9b/pySmiooKBgcHJ/X/U+Hx+/r6mpctW9bAJOCuu+4KU6dOLdvxhoaGmDJFs9ucqruqN7h7Hqh6g457d3f3qNf43OYhCNGEFEeZ2SzgJjM7IoTwMNEMfI1E49B+B7iIaNzaYaZNm8Zb3/rWva1cEps2beKgg9Izik8+VDzBXbNAxRPcNQsSzzVr1mzK2yVh6tSpLFq0qGzHU/kuRkLVXdUb3D0PVL1Bx32sa3wx1ZmngAMLlg+I142YxswqicbJbSlm3xDCTuBOotnrCCFsjZsU7QL+h6jJ0m4kd7sUmDlzZt4KRaHiCe6aBSqe4K5ZoOI5EZRjVHVX9QZ3zwNVb9B2TyimQnA/sNDMDjGzaqJOwjen0tzMM7POnQncEaIJDm4GlsejEB1CNHHSfWbWED8ZwMxqiDos/yVe3j/+a8BbKc804rkxOKgxM7eKJ7hrFqh4grtmgYrnRFCOUdVd1RvcPQ9UvUHbPWGPFYIQwgBwAfBLohntbgghrDWzy83sLXGyq4B6M9sAfAy4ON53LdGMeo8AtwEr4qZC+wN3mtmfiCoct4cQfh4f6zoz+zPwZ2Au8Lm0k1LGd3V15a1QFCqe4K5ZoOIJ7poFKp4TQTlGVXdVb3D3PFD1Bm33hKL6EIQQbiGairxw3aUF73uBs0bZ9wqi6bAL1/0JeOko6V+3J5+qqqqR9qOzszOZAnvSMHPmTNrb2/f655oZM2bMIHrQsmfmz5+fsVH5cNfyo+IJ7poFKp4TQTlGVXdVb3D3PJiod57lwLzKeqMx3jIg5NipeCL09/c/a11nZydTp06luro6B6PR2bVrF+UcKaNY+vr66OzspLa2tqj0jY2NEh1iwF2zQMUT3DULVDwngnKMqu6q3uDueTBR7zzLgXmV9UZjvGVAKHKm4snGSDWeEMKkqwzAyK57g+rq6nHVkkd66jJZcdfyo+IJ7poFKp4TQTlGVXdVb3D3PJiod57lwLzKeqMx3jIgiFYIlEYZUnGtq6vLW6Fo3LX8qHiCu2aBiudEUI5R1V3VG9w9D1S9QaesNxaSFYJkUh0FVFybm5vzVigady0/Kp7grlmg4jkRlGNUdVf1BnfPA1Vv0CnrjYVkH4JiamInXfnHsn7mr84fsQ/0Hsmy1viLX/yCQw89tCyT9yjVzN21/Kh4grtmgYrnRFCOUdVd1RvcPQ/K7b03y4F5PSEoZzlQ8gnBZBtJaCyych0YGOCWW25h3bp1ZTleX19fWY6zN3DX8qPiCe6aBSqeE0E5RlV3VW9w9zxQ9YZ8yqXlLgdKVgiGhobyVhiVG264gde//vUsXbqUj370o2zatImjjz6alpYWhoaGeOMb38gdd9zBk08+yZIlS3jf+97HkiVLOPfcc+nu7gbgwQcf5M1vfjOvfe1rOeOMM2hsbATg7/7u7/jEJz7B6173Or7+9a9z66238ulPf5qlS5fyxBNPTMi7p6dnwrHvLdy1/Kh4grtmgYrnRFCOUdVd1RvcPQ9UvWH3cmm6HLh582aJcqBkhWCy9qBft24dN910E7feeisrV66koqKC+++/nw9/+MNceOGFfOMb3+BFL3oRr3tdNNXC+vXree9738vq1aupra3lqquuor+/n4suuoirr76aO++8k3e+85187nPPzM3W39/PHXfcwYUXXsgpp5zCZz7zGVauXMkhhxwyIXelcYvdtfyoeIK7ZoGK50RQjlHVXdUb3D0PVL3hmXLpSOXAe+65R6IcKFkhGGkegsnAypUreeihh1i2bBlLly5l5cqVPP7447zrXe+io6ODq6++mssvv3w4/YIFCzj22GMBeNvb3sbq1atZv349jz76KKeffjpLly7lK1/5Ck8//fTwPqeddlom7kntUwF3LT8qnuCuWaDiORGUY1R1V/UGd88DVW94plw6Ujlw48aNEuVAyU7FU6ZMznpMCIHly5dz6aXDkzjT19dHd3f38JfZ1dU1PFFEetzaZHnRokX86le/GvEz9ttvvyzUJ+UcDqPhruVHxRPcNQtUPCeCcoyq7qre4O55oOoNz5TfRioHAhLlQK8QlJGlS5dy9tln88EPfpCGhgZaW1tpa2vj29/+NmeddRYHHnggH/nIR7j++usB2LJlC/fddx/HHHMMN954I0uWLOGwww6jpaVleH1/fz8bNmzgxS9+8bM+b8aMGXR2dpbFfTyz2eWNu5YfFU/Iz7WUESt+snxhBiblR+n7LxXlGFXdVb3B3fNA1RueGWVopHJgZ2cn3/jGNyZ9OVCyQlDMeK+lDhM6ERYtWsQll1zCGWecwdDQEFVVVVx66aWsWbOG2267jYqKCn72s59x3XXX8apXvYqFCxdy1VVX8aEPfYgXvehFvPe976W6upqrr76aiy++mPb2dgYGBvjABz4w4olw2mmn8ZGPfITvfOc7XH311RNqP9bS0sKMGTMmEv5ew13Lj4onuGsWqHhOBOUYVd1VvcHd86Dc3nuzHDgwMEBFRcWI5cDPfe5zEuVAUxrCM+Huu+8Ohx9++G7r2tvbmTlzZk5GozM4ODji+LRPPvkky5cv5/e//31mnz2ePJms+TcS7lp+VDwhP9dSnhDc+LZDJfI1ydM1a9Y8sGzZsqPz9gFYtWpVKMfY2glK53gaVXdVb3D3PJiod55xj1bWG4usy4Ej5cdY1/jJ2fZmD0zmYUfTqLgqDfflruVHxRPcNQtUPCeCcoyq7qre4O55oOoNOmW9sfAKQcaM5vqCF7wg06cD46W3tzdvhaJx1/Kj4gnumgUqnhNBOUZVd1VvcPc8UPWG0sqlk60cKFkhmKzzEIyEiqvS+L/uWn5UPMFds0DFcyIox6jqruoN7p4Hqt6gU9YbC8kKwWSdh2AkVFyVxv911/Kj4gnumgUqnhNBOUZVd1VvcPc8UPUGnbLeWEhWCCbrsKMjoeI6bdq0vBWKxl3Lj4onuGsWqHhOBOUYVd1VvcHd80DVG3TKemMhGYFSxqu41tTU5K1QNO5aflQ8wV2zQMVzIijHqOqu6g3ungeq3qBT1huL5+w8BOu/fGVZP3Phx88vab9kbNrxcuSRR3LHHXdQX18/oTTF0traKjNMmbuWHxVPcNcsUPGcCMoxqrqreoO750G5vfdmObDUst5Y7O1yoGSVprJSpx6j4lqOk2lv4a7lR8UT3DULVDwngnKMqu6q3uDueaDqDTplvbGQrBBM1mFHn3zySZYsWcKKFSt4xStewfve9z7uvPNOTj75ZI4++mgeeOABWltbOfvssznhhBM48cQTWbt2LQA7duzg9NNP57jjjuPDH/4whRPG3XDDDbz+9a9n6dKlfPSjH2VwcLDs7h0dHWU/Zla4a/lR8QR3zQIVz4mgHKOqu6o3uHseqHoDw+WykcqBd911l0Q50CsEZebxxx9nxYoVrF69mvXr1/OTn/yEW2+9lcsvv5yvfe1rfOELX+AlL3kJd999N5/61Kf44Ac/CMCXvvQljj32WFatWsWb3/xmtmzZAsC6deu46aabuPXWW1m5ciUVFRX8+Mc/Lrt3X19f2Y+ZFe5aflQ8wV2zQMVzIijHqOqu6g3ungeq3sBuhfd0OfDGG2+UKAdKPuOYzOO9HnTQQSxevBiARYsW8epXvxozY/HixTz55JNs3ryZa665BoClS5dcTM1UAAAgAElEQVSyY8cO2tvb+f3vf8+1114LwEknncSsWbMAWLlyJQ899BDLli0Dook75s6dW3ZvpfF/3bX8qHiCu2aBiudEUI5R1V3VG9w9D1S9YfdyqWo5UPIJwWQe77W6unr4/ZQpU4bblU2ZMqWoztBpQggsX76clStXsnLlSu677z4uvvjisvkmKI3/667lR8UT3DULVDwngnKMqu6q3uDueaDqDbuXS9PlwGR5spcDJSsESsM7mdluy8cdd9zwo567776b+vp6Zs6cyStf+UpuvPFGAG6//XZ27twJRLXHm2++maamJiDqhb958+ayeyoN9+Wu5UfFE9w1C1Q8J4JyjKruqt7g7nmg6g3jK5dO1nKgZJOhdCF7JEodJrTcpF0vuugiPvShD3HCCSdQU1PDt771LQD+5V/+hfPPP5/jjjuOY445hgMOOACIHjddcsklnHHGGQwNDVFVVcWXvvQlDjzwwLJ6FtZoJzvuWn5UPMFds0DFcyIox6jqruoN7p4H5fbem+XAYsqlCZO1HGiFHSFUuOuuu8KRRx6527r29vZJOe7url27mDp1ai6fPZ482bRpEwcddFDGRuXBXcuPiifk53rSlX8c9z7/feIciXxN8nTNmjUPLFu27Ohi9jGzk4GvAxXAlSGEL6S2TwWuBV4OtAB/H0LYaGYHA48C6+Kk94YQPpA+/qpVq8KiRYtKDelZKJ3jaVTdVb3B3fNgot55lgPzLOuNxkj5MdY1XvIJgdJ4ryquWXRQyQp3LT8qnuCuWTBeTzOrAL4JnAhsAe43s5tDCI8UJDsPaA0hHGZmy4EvAn8fb3sshHDUxM2LR+W7GAlVd1VvcPc8UPUGnbLeWOg0xi8gi/FXs0LFta2tLW+FonHX8qPiCe6aBSV4HgNsCCE8HkLoA64HTk2lORW4Jn5/I7DMxvNcvcyofBcjoequ6g3ungeq3qBT1hsLySqNUjMnFdfJPHJTGnctPyqe4K5ZUILnAqCwV9sWYMloaUIIA2bWBiRTkR5iZn8E2oFPhhB+l/6A7du3c95551FZWcng4CCnn346K1asoLGxkenTp1NRUUF7ezsNDQ3s2LGDEAINDQ1s27aNGTNmANDZ2cm8efNoampi586dzJo1i6amJmbOnMng4CBdXV3Mnz+fxsZGqqqqqKuro7m5mbq6Ovr6+ujp6RneXl1dTW1tLS0tLcyePZuenh56e3uHt0+bNo2amhpaW1upr6+no6ODvr6+4e01NTVUV1fT1tbG3LlzaWtro7+/f3j7WDE1NzcPN0cojMnMmDNnzqSNqbu7m5qamnF9T5MlpuT44/meJktMra2tuzlP5NzbmzE1NzdTX19f8rkHMGPGDPr7+5kyZQpmxuDg4PA1BKI7+f39/VRUVABRQb6qqmp49J+KigoGBgaoqKgghDDcZr+/vx8zG3V7ev/KykqGhoZ223/KlCnDIw0lTiGE3bannfe0fayYurq6aG9v3+17GgvJPgT33HNPSMZ4Tejo6GDq1KmTrjPN0NBQLqMi9fX1sWvXLmpra4tKPxnbv42Gu5YfFU/Iz7WUPgQ/O2exRL4meVpsHwIzOxM4OYRwfrx8DrAkhHBBQZqH4zRb4uXHiCoNHcCMEEKLmb0c+D/g8BBCe+FnlLsPgdI5nkbVXdUb3D0PJuqdZzkwr7LeaIxWBnzO9SEY6W7WjBkz6OzspLe3Nwej0enq6mL69Ol7/XPNbLhWXwyNjY0ynZDctfyoeIK7ZkEJnk8BhUNcHBCvGynNFjOrBOqAlhDdhdoFEEJ4IK4ovBD4Q4n6RaHyXYyEqruqN7h7HkzUO89yYF5lvdEYbxkQRCsEyWORQsys6Lvhe5O+vr5JOfpRmsl0Iu8Jdy0/Kp7grllQguf9wEIzO4So4L8ceEcqzc3AucAq4EzgjhBCMLMGYEcIYdDM/gZYCDw+Ef9iUPkuRkLVXdUb3D0PJuqdZzlQpaw3FpIVAiVGqrxMRlQ8wV2zQMUT3DULxusZ9wm4APgl0bCj3w0hrDWzy4E/hBBuBq4CvmdmG4AdRJUGgKXA5WbWDwwBHwgh7ChTKKOi8l2MhKq7qje4ex6oeoO2e8LkafA0DpR6c7e3t+850SRAxRPcNQtUPMFds6AUzxDCLSGEF4YQDg0hXBGvuzSuDBBC6A0hnBVCOCyEcEwI4fF4/f+GEA4PIRwVQnhZCOFnZQ1mFFS+i5FQdVf1BnfPA1Vv0HZPkHxCUFVVlbdC0TQ0NOStUBQqnuCuWaDiCVquF/+2mZa+4m9+/+r8l2ZoMzpKeVoqyjGquqt6g7vngao3aLsnSD4hSIZ3UmDHjsyfhJcFFU9w1yxQ8QQt14UzNJ5mKuVpqSjHqOqu6g3ungeq3qDtnlBUhcDMTjazdWa2wcwuHmH7VDP7Ubx9dTw1fbLtE/H6dWb2hnjdNDO7z8weMrO1ZvaZgvSHxMfYEB9zco0jOk5UhnVV8QR3zQIVT9ByrTQNV6U8LRXlGFXdVb3B3fNA1Ru03RP2WCEomKL+FGAx8HYzW5xKNjxFPfA1oinqidMtBw4HTga+FR9vF/C6EMKRwFHAyWZ2bHysLwJfi4/VGh97N5SmiFZ5jKTiCe6aBSqeoOX653aNa5VSnpaKcoyq7qre4O55oOoN2u4JxTwhmMgU9acC14cQdoUQngA2AMeEiM44fVX8CvE+r4uPQXzMt6aFVGb/BNi2bVveCkWh4gnumgUqnqDlelSdRvNGpTwtFeUYVd1VvcHd80DVG7TdE4q5fTWRKeoXAPem9l0Aw08eHgAOA74ZQlhtZnOBnSGEgXT6Qnbu3Mnxxx9ftints5xWvKenh23btmU2pX25YhocHGTTpk17bUr7icTU09NDa2trblPajyem3t5eent7J82U9qPF1NPTQ1dX16Sd0r4wpoGBAdrb2/f6uVdfPcQRMwfY0jOFqikwb+oQD+ys5OWzBugeNDZ1V/Di2gE2dldQWxmorx6itc949dw+OgaMrT1TeGHtII91VVBfPcSsqjC8/85+o6VvCps2bcrlGgHQ3NxcxM+BLuOdpGcyoequ6g3ungeq3qDtnmB7avc0wSnqLwPuDSF8P15/FXBrCOHGgn1nATcBHwIa4/SHxdsOjNMfUej0u9/9LhxxxG6rJi0tLS3U19fnrbFHVDzBXbNAxRPycz3pyj+Oe58Xzhjgr53FNxvKa5ShJE/HmtZ+b7Nq1aqwaNGish1P6RxPo+qu6g3ungeq3qDjPtY1vpgmQ+OZop7CKeqL2TeEsBO4k6iPQQswKz7GaJ8lNQ9BZ2fnnhNNAlQ8wV2zQMUTtFz3nzaUt0JRKOVpqSjHqOqu6g3ungeq3qDtnlBMhWB4ivp4xJ/lRFPSF5JMUQ8FU9TH65fHoxAdQjRF/X1m1hA/GcDMaoATgb/E+9wZH4P4mD9NCynNQzBv3ry8FYpCxRPcNQtUPEHL9cE2jU7FSnlaKsoxqrqreoO754GqN2i7J+yxQhC350+mqH8UuCGZot7M3hInuwqoj6eo/xhwcbzvWuAG4BHgNmBFCGEQ2B+408z+RFThuD2E8PP4WBcBH4uPVR8fezeU5iFI2udOdlQ8wV2zQMUTtFxfMlPjWqWUp6WiHKOqu6o3uHseqHqDtntCUbevQgi3ALek1l1a8L4XOGuUfa8Arkit+xMwYmPZeHr7Y4rxUiAaOGnyo+IJ7poFKp6g5ToQNFyV8rRUlGNUdVf1BnfPA1Vv0HZPkJypWGkegjlz5uStUBQqnuCuWaDiCVqu6zsr8lYoCqU8LRXlGFXdVb3B3fNA1Ru03RMkKwRK8xCoPEZS8QR3zQIVT9ByPcKbDE0alGNUdVf1BnfPA1Vv0HZPkKwQVFRo3HUDmDlzZt4KRaHiCe6aBSqeoOW6pUfjEquUp6WiHKOqu6o3uHseqHqDtnuCxq+VMCpDpKp4grtmgYonaLlWiVxhlfK0VJRjVHVX9QZ3zwNVb9B2TxD5udodpYzv6urKW6EoVDzBXbNAxRO0XOdN1ZiHQClPS0U5RlV3VW9w9zxQ9QZt9wTJCoHSPATz58/PW6EoVDzBXbNAxRO0XB/YqTEAglKelopyjKruqt7g7nmg6g3a7gmSFQKlTsWNjY15KxSFiie4axaoeIKW68tnaXQqVsrTUlGOUdVd1RvcPQ9UvUHbPUGyQqA03qvK0wwVT3DXLFDxBC3X7kGNa5VSnpaKcoyq7qre4O55oOoN2u4JkhUCpVGG6urq8lYoChVPcNcsUPEELddN3RrXKqU8LRXlGFXdVb3B3fNA1Ru03RMkKwQDAxqP4QGam5vzVigKFU9w1yxQ8QQt1xfXalyrlPK0VJRjVHVX9QZ3zwNVb9B2T5CsEPgTgvKj4gnumgUqnqDlutGfEEwalGNUdVf1BnfPA1Vv0HZPkKwQhBDyViiavr6+vBWKQsUT3DULVDxBy7W2UuNapZSnpaIco6q7qje4ex6oeoO2e4LGmHgphoY0xvYG6OnpyVuhKFQ8wV2zQMUTtFzrq8t3rVr/5SuLSrfw4+eP+9hKeVoqyjGquqt6g7vngao3aLsnSD4hUOrNrTI2rYonuGsWqHiClqvPQzB5UI5R1V3VG9w9D1S9Qds9QbJC4PMQlB8VT3DXLFDxBC1Xn4dg8qAco6q7qje4ex6oeoO2e4JkhWDKFB3t6urqvBWKQsUT3DULVDxBy7VjQGMeAqU8LRXlGFXdVb3B3fNA1Ru03RN0StYFKFUIamtr81YoChVPcNcsUPEELdetPRrXKqU8LRXlGFXdVb3B3fNA1Ru03RM0fq1SKM1D0NLSkrdCUah4grtmgYonaLm+sHYwb4WiUMrTUlGOUdVd1RvcPQ9UvUHbPUGyQlBZqdFRD2D27Nl5KxSFiie4axaoeIKW62NdGvMQKOVpqSjHqOqu6g3ungeq3qDtniBZIfBhR8uPiie4axaoeIKWazmHHc0SpTwtFeUYVd1VvcHd80DVG7TdE7xCkDG9vb15KxSFiie4axaoeIKW66wqjYnJlPK0VJRjVHVX9QZ3zwNVb9B2T5CsEPg8BOVHxRPcNQtUPEHL1echmDwox6jqruoN7p4Hqt6g7Z4gWSHweQjKj4onuGsWqHiClqvPQzB5UI5R1V3VG9w9D1S9Qds9QbJCoDTs6LRp0/JWKAoVT3DXLFDxBC3Xnf0a8xAo5WmpKMeo6q7qDe6eB6reoO2eoFOyLkCpQlBTU5O3QlGoeIK7ZoGKJ2i5tvRpXKuU8rRUlGNUdVf1BnfPA1Vv0HZP0Pi1SqE0D0Fra2veCkWh4gnumgUqnqDleuh0jXkIlPK0VJRjVHVX9QZ3zwNVb9B2T5CsECjNQ1BfX5+3QlGoeIK7ZoGKJ2i5/rVDYx4CpTwtFeUYVd1VvcHd80DVG7TdEyQrBErDjnZ0dOStUBQqnuCuWaDiCVqu+9doXKuU8rRUlGNUdVf1BnfPA1Vv0HZP8ApBxvT19eWtUBQqnuCuWaDiCVqutZUa8xAo5WmpKMeo6q7qDe6eB6reoO2eIFkh8HkIyo+KJ7hrFqh4gparz0MweVCOUdVd1RvcPQ9UvUHbPUGyQuDzEJQfFU9w1yxQ8QQtV5+HYPKgHKOqu6o3uHseqHqDtnuCZIXAhx0tPyqe4K5ZoOIJWq4+7OjkQTlGVXdVb3D3PFD1Bm33BI1fqxRmGpP9AFRXV+etUBQqnuCuWaDiCVquHQMa1yqlPC0V5RhV3VW9wd3zQNUbtN0TJCsEg4MaY3sDtLW15a1QFCqe4K5ZoOIJWq4H76dxrVLK01JRjlHVXdUb3D0PVL1B2z1BskKgNA/B3Llz81YoChVPcNcsUPEELddHOzSuVUp5WirKMaq6q3qDu+eBqjdouydIVgj8CUH5UfEEd80CFU/Qcj3InxBMGpRjVHVX9QZ3zwNVb9B2T5CsEISgMbY36IyIpOIJ7poFKp6g5bpfhca1SilPS0U5RlV3VW9w9zxQ9QZt9wTJCoHPQ1B+VDzBXbNAxRO0XH0egsmDcoyq7qre4O55oOoN2u4JRVUIzOxkM1tnZhvM7OIRtk81sx/F21eb2cEF2z4Rr19nZm+I1x1oZnea2SNmttbM/qkg/WVm9pSZPRi/3pj+PKWamMrYtCqe4K5ZoOIJWq7P5XkIJvK7EG9/gZl1mtk/lyw+DpTOmzSq7qre4O55oOoN2u4Je6wQmFkF8E3gFGAx8HYzW5xKdh7QGkI4DPga8MV438XAcuBw4GTgW/HxBoALQwiLgWOBFaljfi2EcFT8uiXtVFFRMc4w82P69Ol5KxSFiie4axaoeIKW67ZdGg9hx5unE/ldKOCrwK0lCZeA0nmTRtVd1RvcPQ9UvUHbPaGYX6tjgA0hhMdDCH3A9cCpqTSnAtfE728Ellk0WcCpwPUhhF0hhCeADcAxIYStIYQ1ACGEDuBRYMHEw5l8qFReVDzBXbNAxRO0XPuH8jYojhLydCK/C5jZW4EngLUlS48TpfMmjaq7qje4ex6oeoO2e0IxDVwXAJsLlrcAS0ZLE0IYMLM2oD5ef29q390K/vFj5JcCqwtWX2Bm7wL+QPQkobVwn+bmZo4//ngqKysZHBzk9NNPZ8WKFTQ2NjJ9+nQqKipob2+noaGBHTt2EEKgoaGBbdu2MWPGDAA6OzuZN28eTU1NmBlz5syhqamJmTNnMjg4SFdXF/Pnz6exsZGqqirq6upobm6mrq6Ovr4+enp6hrdXV1dTW1tLS0sLs2fPpqenh97eXubPn8/mzZvp6+ujpqaG1tZW6uvr6ejooK+vb3j/mpoaqquraWtrY+7cubS1tdHf3z+8fW/EtHXrVtrb24uKqbGxkWnTpuUW0+bN0elYzu8pq5haW1upqanJ5dwbT0ybN28ejm1vn3vjjamrq4uKioq9fu7VVw9xxMwBtvRMoWoKzJs6xAM7K3n5rAG6B41N3RW8uHaAjd0V1FYG6quHqJ4SOKBmiI4BY2vPFF5YO8hjXRXUVw8xqyoM77+z32jpm8IV/7eav3ZUsH/NELWVz2xv6ZvCCxp7mb1gFtsfa2L2gllUTatiyZQBeubNorJ7FzY4RH9tDd3d3eP+nnp6esY7elvJvwtm1gtcBJwIjNpcaPv27Zx33nllu87v3LmTqVOn5v6/Vsp5uXnzZoaGhibt9WO0mLq7uwEm1fXjuXhNTMf09NNP7/Z7PhnKGMXEtG3bNvbbb7/cyxilxLR582Z6e3snbbkpiWksbE8j9pjZmcDJIYTz4+VzgCUhhAsK0jwcp9kSLz9G9ONwGXBvCOH78fqrgFtDCDfGyzOA3wJXhBB+Eq+bBzQDAfgssH8I4b2FTvfcc09YvDj9dHpy0t3dzX777Ze3xh5R8QR3zQIVT8jP9aQr/zjufeqrh2jpK0+zoeN+84tnrTv7Zc/uyLbw4+eP+9hJnq5Zs+aBZcuWHb2n9BP8XbgYuC+EcIOZXQZ0hhD+Pf0Zq1atCosWLRp3LKOhdI6nUXVX9QZ3zwNVb9BxH+saX8wv1VPAgQXLB8TrRkxjZpVAHdAy1r5mVgX8L3BdUhkACCFsCyEMhhCGgP8mejS9GwMDGh31AHbs2JG3QlGoeIK7ZoGKJ2i5LpyhMQ9BCXk6kd+FJcCXzGwj8BHgEjO7gIxROm/SqLqreoO754GqN2i7JxTTZOh+YKGZHUJ0gV8OvCOV5mbgXGAVcCZwRwghmNnNwA/M7KvA84GFwH1xO9KrgEdDCF8tPJCZ7R9C2BovngY8XFpokwOVORNUPMFds0DFE7J1Xf/lK0fddtyaZ0aRWLXsTUUdr9I08rWEPC35dwF4VZKg4AnBN0ozLx6lczyNqruqN7h7Hqh6g7Z7wh4rBHHbzwuAXwIVwHdDCGvN7HLgDyGEm4kK998zsw3ADqIfB+J0NwCPEI0stCKEMGhmJwDnAH82swfjj7okHlHoS2Z2FFGToY3A+58lXakxtjdAQ0ND3gpFoeIJ7poFKp6g5frndo1r1XjzdCK/C3mhdN6kUXVX9QZ3zwNVb9B2TyiqcWsI4ZYQwgtDCIeGEK6I110aX/QJIfSGEM4KIRwWQjgmhPB4wb5XxPu9KIRwa7zu7hCChRD+Nj28aAjhnBDCS+Jtbyl4WjCM0jwE27Zty1uhKFQ8wV2zQMUTtFyPqtNo3lhKnk7kd6HgGJeN1H8gC5TOmzSq7qre4O55oOoN2u4JGoNkp1Aa3inp9T3ZUfEEd80CFU/Qct3aq3GJVcrTUlGOUdVd1RvcPQ9UvUHbPUHj18pxHMdxHMdxnEyQrBCMc7zsXOns7MxboShUPMFds0DFE7Rc95+mMTOZUp6WinKMqu6q3uDueaDqDdruCZIVgqqqqrwVimbevHl5KxSFiie4axaoeIKW64NtGp2KlfK0VJRjVHVX9QZ3zwNVb9B2T5CsECjNQ9DU1JS3QlGoeIK7ZoGKJ2i5vmSmxrVKKU9LRTlGVXdVb3D3PFD1Bm33BMkKgRLRlAuTHxVPcNcsUPEELdeBoOGqlKelohyjqruqN7h7Hqh6g7Z7gmSFQGkegjlz5uStUBQqnuCuWaDiCVqu6zs1RkRTytNSUY5R1V3VG9w9D1S9Qds9QbJCoDQPgcpjJBVPcNcsUPEELdcjvMnQpEE5RlV3VW9w9zxQ9QZt9wTJCoHSPAQzZ87MW6EoVDzBXbNAxRO0XLf0aFxilfK0VJRjVHVX9QZ3zwNVb9B2T9D4tRJGZYhUFU9w1yxQ8QQt1yqRK6xSnpaKcoyq7qre4O55oOoN2u4JIj9Xu6OU8V1dXXkrFIWKJ7hrFqh4gpbrvKka8xAo5WmpKMeo6q7qDe6eB6reoO2eIFkhUJqHYP78+XkrFIWKJ7hrFqh4gpbrAzs1BkBQytNSUY5R1V3VG9w9D1S9Qds9QbJCoNSpuLGxMW+FolDxBHfNAhVP0HJ9+SyNTsVKeVoqyjGquqt6g7vngao3aLsnSFYIlMZ7VXmaoeIJ7poFKp6g5do9qHGtUsrTUlGOUdVd1RvcPQ9UvUHbPUGyQqA0ylBdXV3eCkWh4gnumgUqnqDluqlb41qllKelohyjqruqN7h7Hqh6g7Z7gmSFYGBA4zE8QHNzc94KRaHiCe6aBSqeoOX64lqNa5VSnpaKcoyq7qre4O55oOoN2u4JkhUCf0JQflQ8wV2zQMUTtFw3+hOCSYNyjKruqt7g7nmg6g3a7gmSFYIQQt4KRdPX15e3QlGoeIK7ZoGKJ2i51lZqXKuU8rRUlGNUdVf1BnfPA1Vv0HZPkKwQDA1pjO0N0NPTk7dCUah4grtmgYonaLnWV2tcq5TytFSUY1R1V/UGd88DVW/Qdk+QrBAo9eZWGZtWxRPcNQtUPEHL1echmDwox6jqruoN7p4Hqt6g7Z4gWSHweQjKj4onuGsWqHiClqvPQzB5UI5R1V3VG9w9D1S9Qds9QbJCMGWKjnZ1dXXeCkWh4gnumgUqnqDl2jGgMQ+BUp6WinKMqu6q3uDueaDqDdruCTol6wKUKgS1tbV5KxSFiie4axaoeIKW69YejWuVUp6WinKMqu6q3uDueaDqDdruCRq/VimU5iFoaWnJW6EoVDzBXbNAxRO0XF9YO5i3QlEo5WmpKMeo6q7qDe6eB6reoO2eIFkhqKzU6KgHMHv27LwVikLFE9w1C1Q8Qcv1sS6NeQiU8rRUlGNUdVf1BnfPA1Vv0HZPkKwQ+LCj5UfFE9w1C1Q8QcvVhx2dPCjHqOqu6g3ungeq3qDtnuAVgozp7e3NW6EoVDzBXbNAxRO0XGdVaUxMppSnpaIco6q7qje4ex6oeoO2e4JkhcDnISg/Kp7grlmg4glarj4PweRBOUZVd1VvcPc8UPUGbfcEyQqBz0NQflQ8wV2zQMUTtFx9HoLJg3KMqu6q3uDueaDqDdruCZIVAqVhR6dNm5a3QlGoeIK7ZoGKJ2i57uzXmIdAKU9LRTlGVXdVb3D3PFD1Bm33BI3n2SmUKgQ1NTV5KxSFiie4axaoeIKW6/6/v5f9Gtvz1tgjSnlaKsoxqrqreoO754GqN2i7J+iUrAtQmoegtbU1b4WiUPEEd80CFU/Qcq0/cE7eCkWhlKelohyjqruqN7h7Hqh6g7Z7gmSFQGkegvr6+rwVikLFE9w1C1Q8Qcu1aWNz3gpFoZSnpaIco6q7qje4ex6oeoO2e4JkhUBp2NGOjo68FYpCxRPcNQtUPEHLdebzNKazV8rTUhktxvVfvnIvm4wf1e9H1RvcPQ9UvUHbPcErBBnT19eXt0JRqHiCu2aBiidouU7db2reCkWhlKelohyjqruqN7h7Hqh6g7Z7gmSFwOchKD8qnuCuWaDiCVquT619Om+FolDK01JRjlHVXdUb3D0PVL1B2z1BskLg8xCUHxVPcNcsUPEELdcFhz8/b4WiUMrTUlGOUdVd1RvcPQ9UvUHbPUGyQuDDjpYfFU9w1yxQ8QQt1+6d3XkrFIVSnpaKcoyq7qre4O55oOoN2u4JRZWszexkM1tnZhvM7OIRtk81sx/F21eb2cEF2z4Rr19nZm+I1x1oZnea2SNmttbM/qkg/Rwzu93M1sd/Z4/weaXEmgvV1dV5KxSFiie4axaoeIKW664ujXalSnlaKsoxqrqreoO754GqN2i7J+yxQmBmFcA3gVOAxcDbzWxxKtl5QGsI4TDga8AX430XA8uBw4GTgW/FxxsALgwhLAaOBVYUHPNi4DchhIXAb+Ll3RgcHBxvnLnR1taWt0JRqHiCu2aBiidouc5eMCtvhaJQytNSUY5R1V3VG9w9D1S9Qds9oZgnBMcAG0IIj4cQ+oDrgVNTaU4Fronf3wgss+g2/qnA9SGEXSGEJ4ANwDEhhK0hhDUAIYQO4FFgwQjHugZ4a1pIaR6CuXPn5q1QFCqe4K5ZoOIJWq7bH2vKW6EolPK0VJRjVHVX9QZ3zwNVb9B2TyimZFhEkU4AACAASURBVL0A2FywvAVYMlqaEMKAmbUB9fH6e1P7LijcMW5e9FJgdbxqXghha/y+EZiXFmpqauL444+nsrKSwcFBTj/9dFasWEFjYyPTp0+noqKC9vZ2Ghoa2LFjByEEGhoa2LZtGzNmzACgs7OTefPm0dTUhJkxZ84cmpqamDlzJoODg3R1dTF//nwaGxupqqqirq6O5uZm6urq6Ovro6enZ3h7dXU1tbW1tLS0MHv2bHp6eujt7WX+/Pk88cQTNDQ0UFNTQ2trK/X19XR0dNDX1ze8f01NDdXV1bS1tTF37lza2tro7+8f3r43Ytq+fTtTp04tKqbGxkamTZuWW0xPPPEECxYsKOv3lFVMbW1tHHroobmce+OJacuWLRxyyCG5nHvjjam3t5f9998/k3Ov84C5VHX1AtA/fRo1TW30zp0JQ4H9ZrUxf+E82hrbWFQ7wLypQzyws5KXzxqge9DY1F3Bi2sH2NhdQW1loL56iIZD6nneoQ3s6t5F+/YOGg6eS8vmHew3az9qaqfx1NqnWXD48+np6KV7Zzf1B86haWMzM59Xy9T9pg5v797Zza6uPmYvmMX2x5qYvWAWVdOqGJwyQM+8WVR278IGh+ivraG7u3vc31N/fz+zZmk8zSiVtrY2pk+fnrdGSai6q3qDu+eBqjdouydYCGHsBGZnAieHEM6Pl88BloQQLihI83CcZku8/BhRpeEy4N4Qwvfj9VcBt4YQboyXZwC/Ba4IIfwkXrczhDCr4NitIYTd+hHcdddd4cgjj5xQ4HuLTZs2cdBBB+WtsUdUPMFds0DFE7J1HWuSqu+veWYUiVXL3lTU8d7ZvpbH7984Ua1ROftlzx7qbuHHzx/3cZI8XbNmzQPLli07uhxuE2XVqlVh0aJFZTveaOfN+i9fWVKe7U2U/j8LUfUGd88DVW/QcR/rGl9Mk6GngAMLlg+I142YxswqgTqgZax9zawK+F/guqQyELPNzPaP0+wPbE8L+TwE5UfFE9w1C1Q8QcvV5yGYPCjHqOqu6g3ungeq3qDtnlBMheB+YKGZHWJm1USdhG9OpbkZODd+fyZwR4gePdwMLI9HIToEWAjcF/cvuAp4NITw1TGOdS7w07SQz0NQflQ8wV2zQMUTtFx9HoLJg3KMqu6q3uDueaDqDdruCXvsQxD3CbgA+CVQAXw3hLDWzC4H/hBCuJmocP89M9sA7CCqNBCnuwF4hGhkoRUhhEEzOwE4B/izmT0Yf9QlIYRbgC8AN5jZecAm4G1pp4qKiolFvRdRaVOm4gnumgUqnqDl2tnSmbdCUSjlaakox6jqruoN7p4Hqt6g7Z5Q1HA9cUH9ltS6Swve9wJnjbLvFcAVqXV3AyNOJhBCaAGWFeOlgErlRcUT3DULVDxBy3WwX2OIZKU8LRXlGFXdVb3B3fNA1Ru03RN0pvwtQGkegvb29rwVikLFE9w1C1Q8Qcu1bn5d3gpFoZSnpaIco6q7qje4ex6oeoO2e4JkhUCpU3FDQ0PeCkWh4gnumgUqnqDl2rh+W94KRaGUp6WiHKOqu6o3uHseqHqDtnuCZIVgYGAgb4Wi2bFjR94KRaHiCe6aBSqeoOXacHB93gpFoZSnpaIco6q7qje4ex6oeoO2e4JkhUCJPc3zMFlQ8QR3zQIVT9BytQqNS2wpeWpmJ5vZOjPbYGYXj7B9qpn9KN6+Op6EEjM7xswejF8PmdlpEw6gCJTOmzSq7qre4O55oOoN2u4JGr9WKSori+oLPSlQeYyk4gnumgUqnqDl2vjXZ02jMikZb56aWQXwTeAUYDHwdjNbnEp2HtAaQjgM+BrwxXj9w8DRIYSjgJOB/4rnr8kUpfMmjaq7qje4ex6oeoO2e4JkhUBpHoJt2zTaEKt4grtmgYonaLk+f5HGZDUl5OkxwIYQwuMhhD7geuDUVJpTgWvi9zcCy8zMQgjdIYSk3ec0YK/cWlM6b9Kouqt6g7vngao3aLsn6NxqL0BpeKcZM2bkrVAUKp7grlmg4glaru1NHXkrFEUJeboA2FywvAVYMlqaeD6bNqAeaDazJcB3gYOAcwoqCMNs376d8847j8rKSgYHBzn99NNZsWIFjY2NTJ8+nYqKCtrb22loaGDHjh2EEGhoaGDbtm3D8XR2djJv3jyamprYtWsX3d3dNDU1MXPmTAYHB+nq6mKwqpJNmzZRVVVFXV0dzc3N1NXV0dfXR09PD/Pnz6exsZHq6mpqa2tpaWlh9uzZ9PT00NvbO7x92rRp1NTU0NraSn19PR0dHfT19Q1vr6mpobq6mra2NubOnUtbWxv9/f3D28eKqaenh5aWlmfFZGbMmTPnWTElx8w7pqGhIVpbW8f1PU2WmHp6eujq6hrX9zRZYurv72fTpk1lOff2Zkw9PT3s2rUr8/+nLGLq6elh69atuV0jio1pLEyx3dPvfve7cMQRR+StURQtLS3U10/+joUqnuCuWaDiCdm6rv/ylaNu+/6aZ2aiXLXsTUUd7+8eu5fmjS0T9hqNs1/27CcQCz9+/riPk+TpmjVrHli2bNnRe0pvZmcCJ4cQzo+XzwGWhBAuKEjzcJxmS7z8WJymuSDNi4meIiyN57MZZtWqVWHRokXjjmU0Rjtv1n/5ypLybG+i9P9ZiKo3uHseqHqDjvtY13jJJkNK8xB0dmrMVKriCe6aBSqeoOU6s6E2b4WiKCFPnwIOLFg+IF43Ypq4j0AdsFvtKITwKNAJZH6HR+m8SaPqruoN7p4Hqt6g7Z4gWSFQmodg3rx5eSsUhYonuGsWqHiCluvTf2ncc6JJQAl5ej+w0MwOMbNqYDlwcyrNzcC58fszgTtCCCHepxLAzA4CFgEbS3UvFqXzJo2qu6o3uHseqHqDtnuCZIVAaR6CpqamvBWKQsUT3DULVDxBy3X+C5+Xt0JRjDdP4zb/FwC/BB4FbgghrDWzy83sLXGyq4B6M9sAfAxIhiY9AXjIzB4EbgL+sbAZUVYonTdpVN1VvcHd80DVG7TdEyQ7FSthZnkrFIWKJ7hrFqh4gpZrGBzKW6EoSsnTEMItwC2pdZcWvO8Fzhphv+8B3xu/5cRQOm/SqLqreoO754GqN2i7J0g+IVCah2DOnDl5KxSFiie4axaoeIKWa1OGHYrLiVKelopyjKruqt7g7nmg6g3a7gmSFQKleQhUHiP9/+y9fZwdV33f//5qn7XaXa1217u27FjGlqPI0BgDdih5IFFjbNLE1DWNSQCT2GnS2i1pUn6FkvBzIPQXQht+9Bdo0toEghMMpQlxgglQwHHqyDxYdhIbYiwbCVvyrlb7/PxwdX5/zMz66mofZu/u7Lkf6ft+ve5rd2bOnfv+njP3zD0zZ85R8QR3LQIVT9By7dur0a9UKU+rRTlGVXdVb3D3GKh6g7Z7hmSDQGkegrXGfa0VVDzBXYtAxRO0XMf6x2Ir5EIpT6tFOUZVd1VvcPcYqHqDtnuGZINACZUhUlU8wV2LQMUTtFzrGjQuXijlabUox6jqruoN7h4DVW/Qds+QbBAoZfzU1FRshVyoeIK7FoGKJ2i57ujSmFVZKU+rRTlGVXdVb3D3GKh6g7Z7hmSDQGkegr6+M2cSrUVUPMFdi0DFE7Rcjz1xPLZCLpTytFqUY1R1V/UGd4+Bqjdou2dINgiUHiru79eYmEjFE9y1CFQ8Qct19xUXxFbIhVKeVotyjKruqt7g7jFQ9QZt9wzJBoHSeK8qdzNUPMFdi0DFE7RcF2Y1Ll4o5Wm1KMeo6q7qDe4eA1Vv0HbPkGwQKI0y1NHREVshFyqe4K5FoOIJWq4jx0ZjK+RCKU+rRTlGVXdVb3D3GKh6g7Z7hmSDYHFxMbZCbk6ePBlbIRcqnuCuRaDiCVqu513aE1shF0p5Wi3KMaq6q3qDu8dA1Ru03TMkGwR+h2DzUfEEdy0CFU/QcvU7BLWDcoyq7qre4O4xUPUGbfcMyQZBCCG2Qm7m5+djK+RCxRPctQhUPEHLtam1MbZCLpTytFqUY1R1V/UGd4+Bqjdou2dINghOnToVWyE3MzMzsRVyoeIJ7loEKp6g5bp95/bYCrlQytNqUY5R1V3VG9w9BqreoO2eIdkgUHqaW2VsWhVPcNciUPEELVefh6B2qIzxqfffFclk/aiWj6o3uHsMVL1B2z1DskHg8xBsPiqe4K5FoOIJWq4+D0HtoByjqruqN7h7DFS9Qds9Q7JBsG2bjnZjo0YfYhVPcNciUPEELde56bnYCrlQytNqUY5R1V3VG9w9BqreoO2eofPLugylBkFbW1tshVyoeIK7FoGKJ2i5jp+YiK2QC6U8rRblGFXdVb3B3WOg6g3a7hk6v6zLUJqHYGhoKLZCLlQ8wV2LQMUTtFx79nTHVsiFUp5Wi3KMqu6q3uDuMVD1Bm33DMkGQX19fWyF3HR2dsZWyIWKJ7hrEah4gpbr0LPDsRVyoZSn1aIco6q7qje4ewxUvUHbPUOyQeDDjm4+Kp7grkWg4glarj7saO2gHKOqu6o3uHsMVL1B2z3DGwQFMzs7G1shFyqe4K5FoOIJWq4tbc2xFXKhlKfVohyjqruqN7h7DFS9Qds9Q7JB4PMQbD4qnuCuRaDiCVquPg9B7aAco6q7qje4ewxUvUHbPUOyQeDzEGw+Kp7grkWg4glarj4PQe2gHKOqu6o3uHsMVL1B2z1DskGgNOxoc7NGlwEVT3DXIlDxBC3XmQmN28hKeVotyjGquqt6g7vHQNUbtN0zdH5Zl6HUIGhpaYmtkAsVT3DXIlDxBC3X6dHp2Aq5UMrTalGOUdVd1RvcPQaq3qDtnpHrl7WZXWdmT5rZYTN7+zLbm8zsk+n2r5rZnrJt70jXP2lmrylb/xEzO2Fmj1fs604zO2Zmj6Wv11Z+ntI8BCMjI7EVcqHiCe5aBCqeoOXaddGu2Aq5UMrTalGOUdVd1RvcPQaq3qDtnrFmg8DM6oAPAdcD+4E3mNn+imS3AiMhhMuADwDvS9+7H7gZuAK4Dvhwuj+Aj6brluMDIYQr09f9lRuV5iHo6uqKrZALFU9w1yJQ8QQt18EjJ2Mr5EIpT6tFOUZVd1VvcPcYqHqDtntGnjsEVwOHQwjPhBDmgXuBGyrS3AB8LP3/08ABM7N0/b0hhLkQwneAw+n+CCE8CFQ1a4/SsKMTExOxFXKh4gnuWgQqnqDl2n6exnT2SnlaLcoxqrqreoO7x0DVG7TdM/Jcat8NPFu2/BxwzUppQgiLZjYGdKXrH6547+4cn3mHmb0Z+AbwqyGE0+7FDA0N8apXvYr6+npKpRI33ngjt99+O/39/bS2tlJXV8f4+Dg9PT0MDw8TQqCnp4eBgQF27NgBwOTkJL29vQwODmJm7Nq1i8HBQdrb2ymVSkxNTdHX10d/fz8NDQ10dHRw8uRJOjo6mJ+fZ2ZmZml7Y2MjbW1tDA0N0dnZyczMDLOzs/T19TE4OMi2bdtoaWlhZGSErq4uJiYmmJ+fX3p/S0sLjY2NjI2N0d3dzdjYGAsLC0vbtyKmkZGR05xWi6m/v5/m5uaoMTU3N29qORUV08jICJ2dnVGOvfXElH1+jGNvvTFNTU3R2tpayLE3eWE3DVPJg8ALrc20DI4x290OpwLbd47Rt7eXsf4x9rUt0tt0ikdG63nZzkWmS8bR6Tq+r22RI9N1tNUHuhpPsX1mOy96xR7mpucYPzFBz55uhp4dZvvO7bS0NXPsiePsvuICZiZmmR6dpuuiXQweOUn7eW00bW9a2j49Os3c1Dydu3dy4ulBOnfvpKG5gdK2RWZ6d1I/PYeVTrHQ1sL09PS6y2lmZkZqOOdqmJ+fj61QNaruqt7g7jFQ9QZt9wwLIayewOwm4LoQwm3p8puAa0IId5SleTxN81y6/DRJo+FO4OEQwj3p+ruBz4UQPp0u7wH+IoTw4rJ99QIngQC8Bzg/hPDz5U4PPfRQ2L+/stdSbTI3N0dTU1NsjTVR8QR3LQIVTyjW9an337XitnsOvTCs3MEDP5Frf68++EXmpos7UbzxqjPHvt77ttvWvZ8sTw8dOvTIgQMHXr4Zbhvl4MGDYd++fZu2v8rj5qn338Xet9229LeWUfp+lqPqDe4eA1Vv0HFfrY7P02XoGHBR2fKF6bpl05hZPdABDOV872mEEAZCCKUQwingf5B2MSrH5yHYfFQ8wV2LQMUTtFx9HoLaQTlGVXdVb3D3GKh6g7Z7Rp4GwdeBvWZ2iZk1kjwkfF9FmvuAW9L/bwK+HJJbD/cBN6ejEF0C7AW+ttqHmdn5ZYv/DHi8Mo0PO7r5qHiCuxaBiidoufqwo7WDcoyq7qre4O4xUPUGbfeMNZ8hSJ8JuAP4PFAHfCSE8ISZvRv4RgjhPuBu4ONmdpjkQeGb0/c+YWafAr4JLAK3hxBKAGb2CeDVQLeZPQf83yGEu4HfNrMrSboMHQF+sdIpeV5Zg8bGxtgKuVDxBHctAhVP0HKdm9LoV6qUp9WiHKOqu6o3uHsMVL1B2z0j1/id6dCf91ese1fZ/7PA61d473uB9y6z/g0rpH/TWj6lUmmtJDXD2NgYO3fujK2xJiqe4K5FoOIJWq6du3cycnw0tsaaKOVptSjHqOqu6g3uHgNVb9B2z9Dpe1OG0jwE3d3dsRVyoeIJ7loEKp6g5Xri6cHYCrlQytNqUY5R1V3VG9w9BqreoO2eIdkgULtDoICKJ7hrEah4gpZr526NK0ZKeVotyjGquqt6g7vHQNUbtN0zJBsEaw2VWkuojIik4gnuWgQqnqDl2tCsMba/Up5Wi3KMqu6q3uDuMVD1Bm33DJ2+N2UoTaDT13fmOOG1iIonuGsR1KLnSnMClBrqeWphcV37ijXO/LEnjkf53PVSi+W/2SjHqOqu6g3uHgNVb9B2z5C8Q6DUElMZm1bFE9y1CFQ8AWZ6NbrhgM9DUEsox6jqruoN7h4DVW/Qds+QbBDU1dXFVshNa2trbIVcqHiCuxaBiidA/fRcbIXcTA5NxlbIhVL5V4tyjKruqt7g7jFQ9QZt9wzJBoESKo0XFU9w1yJQ8QSw0qnYCrkpLWgMgKBU/tWiHKOqu6o3uHsMVL1B2z1DskGgNMrQ+Ph4bIVcqHiCuxaBiifAQpvOjJAdfR2xFXKhVP7VohyjqruqN7h7DFS9Qds9Q7JBoPRQcU9PT2yFXKh4grsWgYonQPNJnYq3/6mB2Aq5UCr/alGOUdVd1RvcPQaq3qDtniHZIFhcXN8IIzEZHh6OrZALFU9w1yJQ8QSY69wRWyE3PXu6YivkQqn8q0U5RlV3VW9w9xioeoO2e4Zkg0AJlTkTVDzBXYtAxROAbRbbIDdWp1HFSpV/lSjHqOqu6g3uHgNVb9B2z9A4W1VQX68zfYLKbSQVT3DXIlDxBLEuQ98+EVshF0rlXy3KMaq6q3qDu8dA1Ru03TMkGwRK8xAMDGj0IVbxBHctAhVPgJkejQd1AS7YpzFZjVL5V4tyjKruqt7g7jFQ9QZt9wzJBoHS8E47dmj0d1bxBHctAhVPgIap2dgKuRkfnIitkAul8q8W5RhV3VW9wd1joOoN2u4Zkg0Cx3Ecx3Ecx3E2B8kGgdI8BJOTGjOVqniCuxaBiifAQmtzbIXctPe0xVbIRTXlb2bXmdmTZnbYzN6+zPYmM/tkuv2rZrYnXf/jZvaImf19+vfHNhxADpSO8UpU3VW9wd1joOoN2u4Zkg0CpXkIent7YyvkQsUT3LUIVDwBWgbHYivk5vg/9MdWyMV6y9/M6oAPAdcD+4E3mNn+imS3AiMhhMuADwDvS9efBH4yhPAS4Bbg4xtQz43SMV6JqruqN7h7DFS9Qds9Q7JBoDQPweDgYGyFXKh4grsWgYonwGx3e2yF3PRdfl5shVxUUf5XA4dDCM+EEOaBe4EbKtLcAHws/f/TwAEzsxDCoyGE4+n6J4AWM2uqUj03Ssd4Jaruqt7g7jFQ9QZt9wyd8TtFMdMYM13FE9y1CFQ8ATilM95zKJ2KrZCLKsp/N/Bs2fJzwDUrpQkhLJrZGNBFcocg458Dh0IIc5UfcOLECW699Vbq6+splUrceOON3H777fT399Pa2kpdXR3j4+P09PQwPDxMCIGenh4GBgaWHvCbnJykt7eXwcFBxsfHmZ6eZnBwkPb2dmZ3tfHoJz5DS0M9R48epaGhgY6ODk6ePElHRwfz8/PMzMzQ19dHf38/jY2NtLW1MTQ0RGdnJzMzM8zOzi5tb25upqWlhZGREbq6upiYmGB+fn5pe0tLC42NjYyNjdHd3c3Y2BgLCwtL21eLaXR0lO3bt58Rk5mxa9eupZhKpRJTU1NL+4wd0+zsLCMjI+sqp1qJaXR0lF27dq2rnGolpsnJSY4ePbopx95WxjQ6Osp5551X+PepiJhGR0epr6+PVkfkjWk1THEyhYceeijs3195d7o2mZ6eXqrIaxkVT3DXIqhFz6fef9ey6xebG6mfnV/Xvva+7bYNfSbAPYde6P5z8MBP5NrfgUe+zPToTK601fDGq84c1jRvrOVk5X/o0KFHDhw48PK10pvZTcB1IYTb0uU3AdeEEO4oS/N4mua5dPnpNM3JdPkK4D7g2hDC05WfcfDgwbBv3751x7ISlcd4eVlXk2dbSS1+P/Og6g3uHgNVb9BxX62Ol+wypDQPgcptJBVPcNciUPEEsS5DezX6lVZR/seAi8qWL0zXLZvGzOqBDmAoXb4Q+FPgzcs1BopA6RivRNVd1RvcPQaq3qDtniHZIFCah2CtWzS1goonuGsRqHgCNEwUd8V9sxnr13gAuory/zqw18wuMbNG4GaSq/3l3Efy0DDATcCXQwjBzHYCnwXeHkJ4aAPa60LpGK9E1V3VG9w9BqreoO2eIdkgUEJliFQVT3DXIlDxBAh1OtVWXYPGxYv1ln8IYRG4A/g88C3gUyGEJ8zs3Wb2U2myu4EuMzsM/AqQDU16B3AZ8C4zeyx9Ff70tdIxXomqu6o3uHsMVL1B2z1D58xahlLGT01NxVbIhYonuGsRqHgCLG4vfECaTWNHl8bsldWUfwjh/hDC5SGES0MI703XvSuEcF/6/2wI4fUhhMtCCFeHEJ5J1/9mCKE1hHBl2evEpga0DErHeCWq7qre4O4xUPUGbfcMyQaB0jwEfX1nPvRXi6h4grsWgYonQMvAaGyF3Bx74vjaiWoApfKvFuUYVd1VvcHdY6DqDdruGZINAqWHivv7NSYmUvEEdy0CFU+Amd6dsRVys/uKC2Ir5EKp/KtFOUZVd1VvcPcYqHqDtnuGZINAacx0lbsZKp7grkWg4gmwbVGny+DCrMbFC6XyrxblGFXdVb3B3WOg6g3a7hmSDQKlUYY6OjpiK+RCxRPctQhUPAEaxqdjK+Rm5JhG9yal8q8W5RhV3VW9wd1joOoN2u4Zkg2CxcXF2Aq5OXny5NqJagAVT3DXIlDxBJjb1RZbITfnXdoTWyEXSuVfLcoxqrqreoO7x0DVG7TdMyQbBH6HYPNR8QR3LQIVT4BGv0Ow6SiVf7Uox6jqruoN7h4DVW/Qds+QbBCEEGIr5GZ+fj62Qi5UPMFdi0DFE6DUWB9bITdNrY2xFXKhVP7VohyjqruqN7h7DFS9Qds9Q7JBcOrUqdgKuZmZ0ZhVVcUT3LUIVDwBSs0aP7IBtu/cHlshF0rlXy3KMaq6q3qDu8dA1Ru03TMkGwRKT3OrjE2r4gnuWgQqnuDzEBSBUvlXi3KMqu6q3uDuMVD1Bm33DMkGgc9DsPmoeIK7FoGKJ/g8BEWgVP7VohyjqruqN7h7DFS9Qds9Q7JBsG2bjnZjo0b3BhVPcNciUPEE2DavM8rY3PRcbIVcKJV/tSjHqOqu6g3uHgNVb9B2z9D5ZV2GUoOgrU1jiEQVT3DXIlDxBGiY0umrOX5iIrZCLpTKv1qUY1R1V/UGd4+Bqjdou2fo/LIuQ2kegqGhodgKuVDxBHctAhVPgLlOnYq3Z093bIVcKJV/tSjHqOqu6g3uHgNVb9B2z5BsENTX6ww72NnZGVshFyqe4K5FoOIJ0Dg6FVshN0PPDsdWyIVS+VeLcoyq7qre4O4xUPUGbfeMXA0CM7vOzJ40s8Nm9vZltjeZ2SfT7V81sz1l296Rrn/SzF5Ttv4jZnbCzB6v2NcuM/uimT2V/j0jl33Y0c1HxRPctQhUPAFKLTp9NX3Y0dpBOUZVd1VvcPcYqHqDtnvGmg0CM6sDPgRcD+wH3mBm+yuS3QqMhBAuAz4AvC99737gZuAK4Drgw+n+AD6arqvk7cCXQgh7gS+ly6eh1CCYnZ2NrZALFU9w1yJQ8QQoNekMO9zS1hxbIRdK5V8tyjGquqt6g7vHQNUbtN0z8twhuBo4HEJ4JoQwD9wL3FCR5gbgY+n/nwYOmJml6+8NIcyFEL4DHE73RwjhQWC5++nl+/oY8LrKBD4Pweaj4gnuWgQqnuDzEBSBUvlXi3KMqu6q3uDuMVD1Bm33jDyd8XcDz5YtPwdcs1KaEMKimY0BXen6hyveu3uNz+sNITyf/t8P9FYmOHHiBL/wC79AfX09pVKJG2+8kdtvv53+/n5aW1upq6tjfHycnp4ehoeHCSHQ09PDwMAAO3bsAGBycpLe3l4GBwcxM3bt2sXg4CDt7e2USiWmpqbo6+ujv7+fhoYGOjo6OHnyJB0dHczPzzMzM7O0vbGxkba2NoaGhujs7GRmZobZ2Vn6+vp48skn6e3tpaWlhZGREbq6upiYmGB+fn7p/S0tLTQ2NjI2NkZ3dzdjY2MsLCwsbd+KmI4fP05ra2uumPr7+2lubo4W0+HDh7nooos2tZyKimlkZIS9e/dGOfbWE9N3v/tdLr300ijH3koxTV7YTePoFKWWRkpNDbQMjDLTu5OF7U20Hh9mfmcrTSMTLLS2cKqxfml73ew8dfOLzLdvp2l4goX27Rw9ejRXTJMXdtMwgEozvgAAIABJREFUlVzpWWhtpmVwjNnudjgV2L5zjL69vYz1j7GvbZHeplM8MlrPy3YuMl0yjk7X8X1tixyZrqOtPtDVeIrvufIiSgsl5qbnGD8xQc+eboaeHWb7zu20tDVz7Inj7L7iAmYmZpkenabrol0MHjlJ+3ltNG1vWto+PTrN3NQ8nbt3cuLpQTp376ShuYHStkVmendSPz2HlU6x0NbC9PT0ustpZmaG7m6NB6Crpb+/n4svvji2RlWouqt6g7vHQNUbtN0zLISwegKzm4DrQgi3pctvAq4JIdxRlubxNM1z6fLTJI2GO4GHQwj3pOvvBj4XQvh0urwH+IsQwovL9jUaQthZtjwSQjjtOYIHH3wwvOQlL6k25i1lYGCA3t4z2jQ1h4onuGsR1KLnU++/a9n1Mz0dtAyOrWtfe99224Y+E+CeQy9MPHPwwE/k2t+Nxx7h+X8obsKaN1515lWpvLGWk5X/oUOHHjlw4MDLN8Ntoxw8eDDs27dv0/ZXeYyXl3U1ebaV1OL3Mw+q3uDuMVD1Bh331er4PF2GjgEXlS1fmK5bNo2Z1QMdwFDO91YyYGbnp/s6HzhxhrTQPAQtLS2xFXKh4gnuWgQqngB1M/OxFXIzPTodWyEXSuVfLcoxqrqreoO7x0DVG7TdM/L8sv46sNfMLjGzRpKHhO+rSHMfcEv6/03Al0Ny6+E+4OZ0FKJLgL3A19b4vPJ93QL8WWUCpXkIRkZGYivkQsUT3LUIVDwB5ne2xlbITddFu2Ir5EKp/KtFOUZVd1VvcPcYqHqDtnvGmg2CEMIicAfweeBbwKdCCE+Y2bvN7KfSZHcDXWZ2GPgV0pGBQghPAJ8Cvgn8JXB7CKEEYGafAA4C32tmz5nZrem+fgv4cTN7Cvgn6fJpKM1D0NXVFVshFyqe4K5FoOIJ0DSiMfsvwOCRk7EVcqFU/tWiHKOqu6o3uHsMVL1B2z0j1y/rEML9wP0V695V9v8s8PoV3vte4L3LrH/DCumHgAOr+SgNOzoxMbH0QF8to+IJ7loEKp4AC60tNEzNxdbIRft5bUwMTsbWWBOl8q8W5RhV3VW9wd1joOoN2u4ZOp3xy1BqEMzPa/R3VvEEdy0CFU+AU406dwibtjfFVsiFUvlXi3KMqu6q3uDuMVD1Bm33DMkGgc9DsPmoeIK7FoGKJ/g8BEWgVP7VohyjqruqN7h7DFS9Qds9Q7JBsLCwEFshN/39xQ05uJmoeIK7FoGKJ8BM7861E9UIu6+4ILZCLpTKv1qUY1R1V/UGd4+Bqjdou2dINgh82NHNR8UT3LUIVDwB6mZ1bs36sKO1g3KMqu6q3uDuMVD1Bm33DJ1f1mWYWWyF3DQ2NsZWyIWKJ7hrEah4AtTN6ww7PDel0XhRKv9qUY5R1V3VG9w9BqreoO2eIdkgKJVKsRVyMza2vhlVY6HiCe5aBCqeAPPt22Mr5KZzt0b3JqXyrxblGFXdVb3B3WOg6g3a7hmSDQKleQi6u7tjK+RCxRPctQhUPAGahnXmITjx9GBshVwolX+1KMeo6q7qDe4eA1Vv0HbPkGwQ+B2CzUfFE9y1CFQ8ARb8DsGmo1T+1aIco6q7qje4ewxUvUHbPUOyQRBCiK2QG5URkVQ8wV2LQMUT4FR9XWyF3DQ0awyRrFT+1aIco6q7qje4ewxUvUHbPUOyQeDzEGw+Kp7grkWg4gk+D0ERKJV/tSjHqOqu6g3uHgNVb9B2z9DpjF+GUkusv7+fiy++OLbGmqh4wrnneu1dj64r/Rdue+m6P0MpT2d6d7LjuZNnrL/n0MrjQB/MmYevXGUf1bD7igt45utHNnWfRaBU/tWiHKOqu6o3uHsMVL1B2z1D8g5BXZ1Ol4HW1tbYCrlQ8QR3LQIVT4D66bnYCrmZHJqMrZALpfKvFuUYVd1VvcHdY6DqDdruGZINAiVUGi8qnuCuRaDiCWClU7EVclNa0BgAQan8q0U5RlV3VW9w9xioeoO2e4Zkg0BplKHx8fHYCrlQ8QR3LQIVT4CFNp0ZITv6OmIr5EKp/KtFOUZVd1VvcPcYqHqDtnuGZINA6aHinp6e2Aq5UPEEdy0CFU+A5pM6FW//UwOxFXKhVP7VohyjqruqN7h7DFS9Qds9Q7JBsLi4GFshN8PDw7EVcqHiCe5aBCqeAHOdO2Ir5KZnT1dshVwolX+1KMeo6q7qDe4eA1Vv0HbPkGwQKKEyZ4KKJ7hrEah4ArDNYhvkxuo0qlip8q8S5RhV3VW9wd1joOoN2u4ZGmerCurrdUZLVbmNpOIJ7loEKp4g1mXo2ydiK+RCqfyrRTlGVXdVb3D3GKh6g7Z7hmSDQGkegoEBjT7EKp7grkWg4gkw06PxoC7ABfs0JqtRKv9qUY5R1V3VG9w9BqreoO2eIdkgUBreaccOjf7OKp7grkWg4gnQMDUbWyE344MTsRVyoVT+1aIco6q7qje4ewxUvUHbPUOyQeA4juM4juM4zuYg2SBQmodgclJjplIVT3DXIlDxBFhobY6tkJv2nrbYCrlQKv9qUY5R1V3VG9w9BqreoO2eofN0bhlK8xD09vbGVsiFiie462by1PvvAqDU1MBTcys/m7P3bbdtldKatAyOrfs9r/zSZzfVIe/+jrdpNF5q/TjdDJRjVHVX9QZ3j4GqN2i7Z0jeIVCah2BwcDC2Qi5UPMFdi2C2uz22Qm6UXPsuPy+2Qi5UjtONoByjqruqN7h7DFS9Qds9Q7JBoISZxpjpKp7groVwSmgMZSHXUDoVWyEXMsfpBlCOUdVd1RvcPQaq3qDtniHZIFCah2DXrl2xFXKh4gnuWgRNIzr9H5VcB48MxVbIhcpxuhGUY1R1V/UGd4+Bqjdou2dINgiU5iFQuY2k4gnuWgRK3XCUXPv2avQrreY4NbPrzOxJMztsZm9fZnuTmX0y3f5VM9uTru8ys6+Y2aSZ/e6G5XOi8l1cDlV3VW9w9xioeoO2e4Zkg0BpHoL2do0fLyqe4K5F0DAxE1shN0quY/3rfwA6Bus9Ts2sDvgQcD2wH3iDme2vSHYrMBJCuAz4APC+dP0s8OvAv9+I83pR+S4uh6q7qje4ewxUvUHbPUOyQaCEyhCpKp7grkUQ6nSqAiXXugaNixdVHKdXA4dDCM+EEOaBe4EbKtLcAHws/f/TwAEzsxDCVAjh/5A0DLYMle/icqi6q3qDu8dA1Ru03TN0OuOXoZTxU1NTdHd3x9ZYExVPcNciWNzeBMMas+oque7o2sGJZ07G1liTKo7T3cCzZcvPAdeslCaEsGhmY0AXkCtDTpw4wa233kp9fT2lUokbb7yR22+/nf7+flpbW6mrq2N8fJyenh6Gh4cJIdDT08PAwMDSrKGTk5P09vYyODjI6Ogo27dvZ3BwkPb2dmZ3tbG4vYmWgVGOHj1KQ0MDHR0dnDx5ko6ODubn55mZmaGvr4/+/n4aGxtpa2tjaGiIzs5OZmZmmJ2dXdre3NxMS0sLIyMjdHV1MTExwfz8/NL2lpYWGhsbGRsbo7u7m7GxMRYWFpa2rxbT8ePHlx5aLI/JzNi1a9dSTKVSiampqaV9xo5penp63eVUKzEdP36clpaWdZVTrcQ0MDBw2v43cuxtZUwDAwO0tbUV/n0qIqbjx4+zsLAQrY7IG9NqWAg6I3ZkPPTQQ2H//sq707XJ3NwcTU1NsTXWRMUTzj3Xa+96dF3pv3DbS3OnXZqHoKGeuoWVh/ONMQ9B5lbJSq73HOovWmndNG1vZG56vrD9v/GqvjPWVVNW2XF66NChRw4cOPDytdKb2U3AdSGE29LlNwHXhBDuKEvzeJrmuXT56TTNyXT5LcDLy99TzsGDB8O+ffvWHctKVH4Xy4+vWppnYzmU6rxyVL3B3WOg6g067qvV8Tr33stQeqi4v7/2fqQsh4onuGsRzPTujK2QGyXX3VdcEFshF1Ucp8eAi8qWL0zXLZvGzOqBDiDasEsq38XlUHVX9QZ3j4GqN2i7Z0g2CJTGe1WZVVnFE9y1CLYt6nTDU3JdmNW4eFHFcfp1YK+ZXWJmjcDNwH0Vae4Dbkn/vwn4coh4S1rlu7gcqu6q3uDuMVD1Bm33DMlnCJRGGero6IitkAsVT3DXImgYn46tkBsl15Fjo7EVcrHe4zR9JuAO4PNAHfCREMITZvZu4BshhPuAu4GPm9lhYJik0QCAmR0B2oFGM3sdcG0I4ZubEswKqHwXl0PVXdUb3D0Gqt6g7Z4heYdgcXHlvs61xsmTtf9AIeh4grsWwdyuttgKuVFyPe/SntgKuajmOA0h3B9CuDyEcGkI4b3puneljQFCCLMhhNeHEC4LIVwdQnim7L17Qgi7Qgg7QggXFt0YAJ3v4nKouqt6g7vHQNUbtN0zJBsEfodg81HxBHctgkahq+5KrmfrHQJFlGNUdVf1BnePgao3aLtnSHYZUhoZaX6+uBFGNpPN8CxyNJxyailP14r5xe2LPD5++tes2riLpNRYW1XBtXc9yitXGDWob+959D91YouNqqOptTG2Qi5q6TtVFMoxqrqreoO7x0DVG7TdMyTvEJw6dSq2Qm5mZjRmVVXxBC3XrkaNY7XUrPHDFWD7zu2xFXKj4qr0naoW5RhV3VW9wd1joOoN2u4ZuRoEZnadmT1pZofN7O3LbG8ys0+m279qZnvKtr0jXf+kmb1mrX2a2UfN7Dtm9lj6urLy85Se5u7rO3Oc8FpExRO0XB8Zra0r7yvRMqDRtQXg2BPHYyvkRsVV6TtVLcoxqrqreoO7x0DVG7TdM9ZsEJhZHfAh4HpgP/AGM6ucFexWYCSEcBnwAeB96Xv3k4wscQVwHfBhM6vLsc+3hRCuTF+PVTr5PASbj4onaLm+bKfGA/A+tn8xqLgqfaeqRTlGVXdVb3D3GKh6g7Z7Rp47BFcDh0MIz4QQ5oF7gRsq0twAfCz9/9PAAUsmC7gBuDeEMBdC+A5wON1fnn2uLL1Np6dTY6NGVwwVT9BynVjUmDNj27xGwwVgbnoutkJuVFyVvlPVohyjqruqN7h7DFS9Qds9I09/ht3As2XLzwHXrJQmHZ96DOhK1z9c8d7d6f+r7fO9ZvYu4EvA20MIp51Vh4eHedWrXkV9fT2lUokbb7yR22+/nf7+flpbW6mrq2N8fJyenh6Gh4cJIdDT08PAwAA7duwAYHJykt7eXgYHBzEzdu3axeDgIO3t7ZRKJaampujr66O/v5+GhgY6Ojo4efIkHR0dzM/PMzMzs7S9sbGRtrY2hoaG6OzsZGZmhtnZWfr6+picnGRgYICWlhZGRkbo6upiYmKC+fn5pfe3tLTQ2NjI2NgY3d3djI2NsbCwsLR9K2JaXFzk6NGjuWLq7++nubn5jJh+pHueR0brednORYbmtzGxaOzZXuJbE/VcvL3E9rqwtH1gbhsjIyNVxTQ5OcnIyMimltNKMa1VTuUxD8xtY+EUXNhyisfH69m7o0Rn/Sk6Gk5xZcciz88mDdmjR4+uq5zOazrF97UtcmS6jrb6QFfjqaXPnFg0np/ZxuVtJZ6eqqOr8dRp5bhWTDPd7dTNL7Kwo4mFySYW2rdzqr6OloFRZnp3Uj89h5WSfW7l9+n8phIvesUehp4dZvvO7bS0NXPsiePpFfdAR187XRftYvDISdrPa6Npe9PS9unRaeam5uncvZMTTw/SuXsnDc0NS9snhyYpLZTo6Oug/6kBevZ0YXXb6P/2CS7Y18f44AQA7T1tHP+HfvouP49QOsXgkSH69vYy1j9GXUMdO7p2LO1zYXaBkWOjnHdpDyPHRmlqbWT7zu2M9o/xolfsYW56jvETE/Ts6V42ppmJWaZHp9cdU2nb4mnltNDWwvT09LrLqaGh4awYNm812tp0hqutRNVd1RvcPQaq3qDtnmFrjdhjZjcB14UQbkuX3wRcE0K4oyzN42ma59Llp0l+4N8JPBxCuCddfzfwufRty+7TzM4H+oFG4L8DT4cQ3l3u9MADD4Tv//7v31DgW8XRo0e5+OKLY2usyWZ4btUoQ7WUp2vF/CPd8/zVydOvHKw37iLz9an33wXA5IXd7Hhu5R+Ee99227ocNsq1dz3KK7/02WW3vegVe3jm60e21KdainZ941Vn9lutpqyy79ShQ4ceOXDgwMs3w22jHDx4MOzbt2/T9ldZb2THPmz98b1eaqnOWw+q3uDuMVD1Bh331er4PH1vjgEXlS1fmK5bNo2Z1QMdwNAq711xnyGE50PCHPAHJN2LTqO+XuNBTYDOzs7YCrlQ8QQt16enNObMaBydiq2Qm6Fnh2Mr5EbFVek7VS3KMaq6q3qDu8dA1Ru03TPyNAi+Duw1s0vMrJHkIeH7KtLcB9yS/n8T8OWQ3Hq4D7g5HYXoEmAv8LXV9pneISB9BuF1wOOVQj7s6Oaj4glarjLDjrbo9H9UGcoTdFyVvlPVohyjqruqN7h7DFS9Qds9Y81L7ekzAXcAnwfqgI+EEJ4ws3cD30inqb8b+LiZHQaGSX7gk6b7FPBNYBG4PYRQAlhun+lH/pGZ9QAGPAb8UqWTUoNgdnY2tkIuVDxBy3Vng8YkeqUmnaF8W9qaYyvkRsVV6TtVLcoxqrqreoO7x0DVG7TdM3L1vQkh3A/cX7HuXWX/zwKvX+G97wXem2ef6fofW8vH5yHYfFQ8QcvV5yHYfFTG9gcdV6XvVLUox6jqruoN7h4DVW/Qds/QGb+zDJ+HYPNR8QQtV5+HYPNRGdsfdFyVvlPVohyjqruqN7h7DFS9Qds9Q7JBoDQPQXOzRpcBFU/Qch1d0JiHoG5Op5E9M6Fza1bFVek7VS3KMaq6q3qDu8dA1Ru03TN0flmXodQgaGlpia2QCxVP0HIdmtc4Vutm5mMr5GZ6dDq2Qm5UXJW+U9VSHmP5kKMKqJaPqje4ewxUvUHbPUPj10oFi4sa3TAARkZGYivkQsUTtFwvbS3FVsjF/M7W2Aq56bpoV2yF3Ki4Kn2nqkU5RlV3VW9w9xioeoO2e4bGE48VKM1D0NXVFVshFyqeoOX67QmNeQiaRiZiK+Rm8IjOjLoqrkrfqWpRjlHVXdUb3D0Gqt5Qvft6Jx6F6id1XQvJOwRKw45OTGj80FLxBC3X81s0jtWFVp3bne3n6UwRr+Kq9J2qFuUYVd1VvcHdY6DqDdruGd4gKJj5eY2+2SqeoOXaVq8xD8GpRp27bk3bm2Ir5EbFVek7VS3KMaq6q3qDu8dA1Ru03TMkGwQ+D8Hmo+IJWq4+D8HmozK2P+i4Kn2nqkU5RlV3VW9w9xioeoO2e4bGr5UK1OYhuPjii2NrrMk3/+Rz7Hhu7f7Oe9922xbYnE7liCCTF3Yv6xrD7ZVf+uyq21/0ij38UfsVufa10sgnrzy0vvGNnxp5ZF3pIZmHYLXy3+pRWVaLefcVF/DM149sncwGUHFVqac2gnKMqu6q3uDuMVD1Bm33DMk7BD7s6OZTN6tzu0vJVWXYSc/TYlBxVamnNoJyjKruqt7g7jFQ9QZt9wydX9ZlmGlM9gTQ2NgYWyEXdfM6Q7kquc5NafzQ9jwtBhVXlXpqIyjHqOqu6g3uHgNVb9B2z5BsEJRKGmO7A4yNjcVWyMV8+/bYCrlRcu3cvTO2Qi48T4tBxVWlntoIyjGquqt6g7vHQNUbtN0zJBsESvMQdHd3x1bIRdOwzpBZSq4nnh6MrZALz9NiUHFVqac2gnKMqu6q3uDuMVD1Bm33DMkGgd8h2HwWhK4QK7mqXCH2PC0GFVeVemojKMeo6q7qDe4eA1Vv0HbPkGwQhKAxtjvojIh0ql5jRl3Qcm1o1hgi1/O0GFRcVeqpjaAco6q7qje4ewxUvUHbPUOn700ZG52HYL1TRW9kmmiVsWmVxqEv0nW9x8Yr19h+7Inj8Mp8w45uFvesc5hSgDc06FQFKmP7g46rSj21EZRjVHVX9QZ3j4GqN2i7Z0jeIVBqifX3r//HWQxmejW6NoCW6+4rLoitkAvP02JQcVWppzaCcoyq7qre4O4xUPUGbfcMyQZBXZ1O94bW1tbYCrmon56LrZAbJdfJocnYCrnwPC0GFVeVemojKMeo6q7qDe4eA1Vv0HbPkGwQKKHSeLHSqdgKuVFyLS1oPADveVoMKq4q9dRGUI5R1V3VG9w9BqreoO2eIdkgUBplaHx8PLZCLhbadGbZU3Lt6OuIrZALz9NiUHFVqac2gnKMqu6q3uDuMVD1Bm33DMkGwUYfKt5Kenp6YivkovmkzsGs5Nr/1EBshVx4nhaDiqtKPbURlGNUdVf1BnePgao3aLtnSDYIFhcXYyvkZnh4OLZCLuY6d8RWyI2Sa8+ertgKufA8LQYVV5V6aiMox6jqruoN7h4DVW/Qds+QbBAoITNnwjaLbZAfIVerE/mKeZ4WgoqrTD21AZRjVHVX9QZ3j4GqN2i7Z2icrSqor9cZM13lNpJSlxEl1/5vn4itkAvP02JQcVWppzaCcoyq7qre4O4xUPUGbfcMyQaB0jwEAwMafYhnejQefgQt1wv2aUxW4nlaDCquKvXURlCOUdVd1RvcPQaq3qDtniHZIFAa3mnHDo2+2Q1Ts7EVcqPkOj44EVshF56nxaDiqlJPbQTlGFXdVb3B3WOg6g3a7hmSDQLHcRzHcRzHcTYHyQaB0jwEk5MaM5UutDbHVsiNkmt7T1tshVx4nhaDiqtKPbURlGNUdVf1BnePgao3aLtnSDYIlOYh6O3tja2Qi5bBsdgKuVFyPf4P/bEVcuF5Wgwqrir11EZQjlHVXdUb3D0Gqt6g7Z4h2SBQmodgcHAwtkIuZrvbYyvkRsm17/LzYivkwvO0GFRcVeqpjaAco6q7qje4ewxUvUHbPUOyQaCEmcj47qeExtAVcg2lU7EV8uF5WggqrjL11AZQjlHVXdUb3D0Gqt6g7Z4h2SBQmodg165dsRVy0TSi0/9NyXXwyFBshVx4nhaDiqtKPbURlGNUdVf1BnePgao3aLtnSDYIlOYhULmNpNRlRMm1b69Gv0LP02JQcVWppzaCcoyq7qre4O4xUPUGbfcMyQaB0jwE7e0aP7QaJmZiK+RGyXWsX+NhXc/TYlBxVamnNoJyjKruqt7g7jFQ9QZt9wzJBoESKkOkhjqdQ0HJta5Bo/HqeVoMKq4q9dRGUI5R1V3VG9w9BqreoO2eofMroAyljJ+amoqtkIvF7U2xFXKj5LqjS2P2Qs/TYlBxVamnNoJyjKruqt7g7jFQ9QZt9wzJBoHSPAR9fX2xFXLRMjAaWyE3Sq7HnjgeWyEXnqfFoOKqUk9tBOUYVd1VvcHdY6DqDdruGbkaBGZ2nZk9aWaHzezty2xvMrNPptu/amZ7yra9I13/pJm9Zq19mtkl6T4Op/tsrPw8pYeK+/s1Jiaa6d0ZWyE3Sq67r7ggtkIuPE+LQcW1mnqqiPPCZnHtXY+e8frPn3ts6f97DvWf9rr2rkc3W2FTUTmPVKLqDe4eA1Vv0HbPWLNBYGZ1wIeA64H9wBvMbH9FsluBkRDCZcAHgPel790P3AxcAVwHfNjM6tbY5/uAD6T7Gkn3fRqjozpXMz/zmc/EVsjFZx/8SmyF3Ci5/vVXH4ytkAvP02JQcV1vPVXEeWFDAeTgG1/5XNEfURgq55FKVL3B3WOg6g3a7hl5BvS/GjgcQngGwMzuBW4AvlmW5gbgzvT/TwO/a8ksDTcA94YQ5oDvmNnhdH8st08z+xbwY8DPpGk+lu73v5ULKTUI/uRP/oS3vvWtsTXW5LN//QA//aKXxNbIhZLr3zzyEBf++L+KrbEmann6+ld8T2yNXKi4VlFPFXFeOLihINbg0Qc+x+UvuWHF7eu9S/CF2166UaXcqJxHKlH1BnePgao3vOBe63cbVyNPl6HdwLNly8+l65ZNE0JYBMaArlXeu9L6LmA03cdKn0UIOrOqLi4urp2oBgj1Oo+TKLnWN2lMoud5WgwqrlXUU0WcFwqlRecQPwOV80glqt7g7jFQ9QZt9wxb68e1md0EXBdCuC1dfhNwTQjhjrI0j6dpnkuXnwauIbk69HAI4Z50/d1Adt/2jH2Wpb8sXX8R8LkQwovLnf78z/989sSJE0tDDbW3tw/u2rXrZFU5UDDDw8PdtepWjoonuGsRqHiCuxZBmefFBw4c6FkrfRHnhRDCp8s/4/777594/vnnl37Gb7SeVymL5VB1V/UGd4+BqjdIua9Yx+e5fHUMuKhs+cJ03XJpnjOzeqADGFrjvcutHwJ2mll9ekVpuc/iJ3/yJ5tzeDuO4zjFUNR5YYnXvva1bZsp7DiO46xMnpuoXwf2pqP/NJI8DHZfRZr7gFvS/28CvhySWw/3ATeno01cAuwFvrbSPtP3fCXdB+k+/6z68BzHcZwCKOK84DiO40RizTsEIYRFM7sD+DxQB3wkhPCEmb0b+EYI4T7gbuDj6cNhwyQnB9J0nyJ50GwRuD2EUAJYbp/pR/4H4F4z+03g0XTfjuM4To1Q1HnBcRzHiUQIoaZeJLeSv0JysngCeGu6/k6S28qPpa/Xlr3nHcBh4EngNVvsewT4+9TpG+m6XcAXgafSv53pegP+a+r6d8BVW+j5vWV59xgwDvxyreQr8BHgBPB42bp15yPJFcmn0tctW+T5fuAfUpc/BXam6/cAM2V5+3tl73lZetwcTmOxLXJdd3mTDA35ZLrt7Vvk+ckyxyPAYzWSpyvVTzV1rK7iWZPHapGvoo/fTXI8gsB5JP18ibp6He53UmN14jLeEvXOOt1rOt+BZpI7l3+bev9Guv4S4KupwyeBxnR9U7p8ON2+Z614au0VXWCZQjg/O3iBNuDbJONc3wn8+2XS708LrCktqKeBui30PQJ0V6z77exgBd4OvC/9/7UkD1Ub8APAVyPlcR3QD1xcK/kK/DBwFadX1OvKx7RyfCb925n+37kFntcC9en/7yvz3FN7qXp0AAAgAElEQVSermI/X0vdLY3l+i3K03WVd/p6GngR0Jim2V+0Z8X2/wK8q0bydKX6qaaO1VU8a/JYLeq1FcfvJnkeQeQ8skK9UlPH/zrd76TG6sRlXCTqnXW613S+p3m3I/2/geRH/g8AnwJuTtf/HvCv0v//NemFFJK7oZ9cLZ6ij/VqXjU3EFsI4fkQwqH0/wngW6w+JN3SmNYhhO+QtMKuXiX9VnADyRwKpH9fV7b+D0PCwyQPUJ8fwe8A8HQI4egqabY0X0MID5J0K6h0WE8+vgb4YghhOIQwQnLF5LqiPUMIXwgvDJX7MMlDkiuSuraHEB4OSY3xh7wQW6Guq7BSeS+NNx9CmAey8ea3xDMdt/5fAJ9YbR9bmKcr1U81dayu5Fmrx2qBFH78FkhNnkdU6up1uK9EtDqxEpV6Z53uK1ET+Z7m3WS62JC+AslcWdmIaJV5npXFp4EDlfOu1NBv1GWpuQZBOelU9y8laZkB3GFmf2dmHzGzznRdlDGtywjAF8zsETP7l+m63hDC8+n//UBv+n9s14ybOf0HVi3mK6w/H2vB+ed5YWhdgEvM7FEz+ysz+6F03e7ULWOrPddT3rHz9IeAgRDCU2XraiJPK+qnmj1Wl6lHMxSO1Y0S+/jNi+J5pJyaPf5zIlMnqtQ7y7HB33Rb7m5mdWb2GEk3sy+SXN1faa6smpp3pRpqtkFgZjuA/wX8cghhnGS24kuBK4HnSboR1AI/GEK4CrgeuN3Mfrh8Y3pVLUQxW4Z0RJCfAv5nuqpW8/U0ai0fl8PM3knykOQfpaueB74nhPBS4FeAPzaz9lh+KRLlXcYbOL3xWhN5ukz9tEQtHasreYocq+cSUueR1VByTZGpE1XqneUQ+k23RAihFEK4kuRO6tXAvshKhVKTDQIzayA5cP4ohPAnACGEgbRwTgH/gxduueQa07ooQgjH0r8nSB7SuxoYyG7hpn9P1IJryvXAoRDCANRuvqasNx+jOZvZW4B/CvxsWjGT3iIcSv9/hOTqwuWpU3lXjS3zrKK8Y+ZpPXAjyYNaQG3k6XL1EzV4rK7gKXOsbhK1UI+tieB5pJKaO/7zolInqtQ7y7FJv+miHTMhhFGSB6NfSTpX1jIOS37VzLtSC9RcgyDtc3U38K0Qwu+UrS/vI/nPgMfT/6ONaW1mrWbWlv1P8sDe45w+/vYtvDCXwn3Amy3hB4Cxstt9W8VpV1xrMV/LWG8+fh641sw609uP16brCsXMrgP+L+CnQgjTZet7zKwu/f9FJHn4TOo6bmY/kB7vb2aL5tuoorzzjDdfFP8E+IeQznQL8fN0pfqJGjtWV6lHZY7VTSLm8ZsL0fNIJTV1/K8HhTpRpd5Zj3ut53taJ+5M/28Bfpzk+YevsPxcWfrzroQaeLK5/AX8IMltr7+jbDgq4OMkw7L9HUkGn1/2nneSXNF6ki0cAYPkafe/5YVhqd6Zru8CvkQyrNf/BnaFF55a/1Dq+vfAy7c4b1tJWqwdZetqIl9JGinPAwskfexurSYfSfpFH05fP7dFnodJ+gieNmQj8M/T4+Ix4BDwk2X7eTlJBfg08LsUM0Tmcq7rLu/0+/ftdNs7t8IzXf9R4Jcq0sbO05Xqp5o6VlfxrMljtchX0cfvJvipnUck6up1uNdcnbiMt0S9s073ms534B+RzIX1d2n9l4109yKSH/SHSbpeN6Xrm9Plw+n2F60VT629LJV1HMdxHMdxHOccpOa6DDmO4ziO4ziOs3V4g8BxHMdxHMdxzmG8QeA4juM4juM45zDeIHAcx3Ecx3GccxhvEDiO4ziO4zjOOYw3CBzHcRzHcRznHMYbBI7jOI7jOI5zDuMNAsdxHMdxHMc5h/EGgeM4juM4juOcw3iDwHEcx3Ecx3HOYbxB4DiO4ziO4zjnMN4gcBzHcRzHcZxzGG8QOI7jOI7jOM45jDcIHMdxHMdxHOccxhsEjuM4juM4jnMO4w0Cx3Ecx3EcxzmH8QaB4ziO4ziO45zDeIPAcRzHcRzHcc5hvEHgOI7jOI7jOOcw3iBwHMdxHMdxnHMYbxA4uTCzPWYWzOwHI3scMbNf24LPKTReM7vTzA5XrHu9mT1tZiUz++g69vUWM1vcdMlNpFaOH8dxNp9a+X6fLeeHjWJmD5jZXbE9HC28QXAOYGYfTSuvkP7YfM7M/tDMdsd2UyLNvzcus37DP8jNrA74CPAp4HuAt5Zte6OZPWhmY2Y2ZWaPm9lvxyg/M/s1Mzuy1Z+7Fmb2/5rZV81sutYbR45TS/j5YXMoy8OQ1kPfNLNfie1VS5jZO83sr81sPM2nC2M7OS/gDYJzh78Gzif5sfkzwEuB/xnVyCnnfGAHcH8I4VgIYQzAzO4G7gYeBK4H9gP/FugDfjWSay1SB/wx8OHYIo4jiJ8fNoc7SPLxCuCDwPvM7F/GVdo8zKxxg7toAu4D3rsJOs4m4w2Cc4f5EEJ/+mPzQeC/A680s3YAM2szs983s0EzmzOzb5jZtcvsZ4+ZfcnMZszsGTO7uXyjmX2vmX3WzCbT15+b2WVl29vN7A/MrD/9nGfN7Hcq9nF7enVlzsxOmNn/qnBoNLMPmtmwmQ2Y2QfMrL7s/Q1m9ltmdszM5tN9/UzFZ5xvZvea2WgaywNm9vLqsvZ0zKzTzO4xs++m+37SzH7VzGyF9G8Bnk0XH0yvnLzazP458PPALSGEXwsh/E0I4WgI4cshhDcD76nYz6vM7FB6deoRM3tFxfbLzOx/pTGPmNkXzOwlFWlelq6fTI+FPzGzi8s83wNcXHYl7M5028+kV+jHzOxkegxcvky4F5jZX6SOz6T7XC0vfyHdZ3PF+v+Q5u82gBDCvwkhfBB4fLX9OY6zLH5+OP0zqj0/jKX5+J0Qwu8Dfwe8pmLfq9bDec8fZvbTaT0/a2ZDZvY5M+usSPPraV4OW3LXZ0fF9pvN7LF0H0fM7HfMrLVs+wNmdreZvcfMnge+u1zQZvbjltxdurBi/U+ndX07QAjhXSGE9wNfzZGXzhbjDYJzEDO7ALgJKKUvSLqrvAZ4I3Al8BDwF2a2r+Ltv52mvZLkiuwfmdlL0/22AF8AmoEfSV87gL+0F64s/CZwFXADsBf4aeBbZW6/AbyP5ErvS4DrgEMVDv8GeB64Jv3/DuCWsu3/CfgF4JeBFwP3APeY2YH0Mwz4DLAP+KfA1cAA8EUz614j+/LQRPLD9HUkV/TfA/wG8JYV0n8ydYAkX84H/gZ4E3A4hHDvcm8KIYyULW4D/h+SrkZXASeAT2UnQjPrBf5Puv6HgB8AngQeMLOeNM1+4K+Ag8DLgR8jOT6+mP4g/yRJ2TyXOp4P/OeymLOy/fH0fZ+1M68o/Rbwh8A/Au4F7lqh4ZDxKaAxzZdy3gzcE0I4tcp7HcdZJ35+2Pj5wRIOAN8HzJetX7MeJsf5w8x+LvX+TJpfPwr8Jcmd0oybgF3Aq4Gb01j+Q9k+3gL8N+C/pJ/zZuCfAL9XEc6/AHqAAyR1+3J8iSTPf7Zi/S3AZ0II4yu8z6klQgj+OstfwEeBRWASmAZC+vrP6fbL0uXXVrzvEPCR9P89aZr3VKT5G+Dj6f+3pvvvLtveC8wAb06X/wz46AqerWnaf79KLEeA+yrWfQ74RPr/dmAO+NcVaf4U+HL6/4E0lv1l25tIKrR3VcT7g2VpAjCb5mP5axZYXKMMPgh8sWz5TpIf+6zyed+sjHWFfb8lfe9VZeuuSdd9b9nnPVzxPgOeBn657Di5tyJNU1qmr0uXfw04ksNpV/r5r6qI71fK0tQBE8AvrrGve4HPli2/vDy2ZfJi1bLwl7/89cILPz/A5p8fFtLlKeCasjRr1sMrxFV5/vgu8LurpH8A+NuKdf8NOFiRV79UkeaHU+/Osv18G9iW4zj6LeDxirJdBF6zTNpXp59zYezj318vvPwOwbnDV0mu2lxNcsXhIMmPO0iuDkDST72cB0n6QpZzsGL5obI0VwDfDCGczDaGEAZIroBkaT4M3GTJg7EfNLPrs24faZpmkqtIq/FYxfJxksoHkpNX4zKx/FWF51AI4ZtlnnMkeVQZbyXvJMnH8te7yhOY2TYze3t6K/akmU0CvwRcvMa+K1m2i9EKBOBvy5aPp3+zfHkF8LKyW/WTJD/G95BcicvS/LOKNEMkZbKXVTCzK83sT83sO2Y2wQu3litjXiq7EEKJ5EpZb7qP/1j+2Wb2Q2nSjwHXmtl56fKbga+FEJ5cNUccx8mLnx829/zwoySx/8cQQnn3mDXr4bXOH2k9eBFr58PfViwv5UN6N+Ji4HcqXD6Xpr2s7H2PhLI7sWb2sxX1dHZX4GPAFWZ2Vbr8syT1+/9ew9OpEerXTuKcJcyEELJhLh83s0uB/4/k1umWEUL4vJl9D8nt51eT3Pb8++x2bU7mK5YDW9f9baAsHwEwsxMVaX4VeAfw74BHSSr8fwf8xDo/q/xEuRan0h/YGSH9u63s75dIbp9XMlaW5uMkV3oqGVrpg81sO8nJ6f8AP0dyex3gCZKTbzmrld3vkXQRyjiW/v0CcBL4GTP7EMnt7ztX8nEcZ934+WFzyM4Ph83sdcC3zezRkDyXAfnq4c06f6yWD9nftwJfWea9z5X9P1Wx7T5OfwZgACCE8C0z+wbJBZtDvNCts4Qjgd8hOHe5E/g5Sx6UeiJd98MVaX6YMx/S/IGK5X9M0rWFdD/7y/tZpn0mv7d8PyGE4RDCJ0IIv0hSyf0IyVWob5Lccl3uYbW8HCa5JVwZy4+UOTwBdKV95jPPJpJuNpvxUOoPA38ZQvhICOHR9ASx6hX2FbgHuMwqHszLqHyAbA2+QdK4eC6EcLjiNViW5h8BTy+TJnteYZ7T+6lC0k+2B3hnCOGBEMK3gE7Wd4cjOy7KP3MmXV8C/ojkmYrrgQ6SbkSO4xTDnfj5YUPnh/ROyIeA/5o+lwD56uFVzx8hhBMkP9irzof0zsyzJN0uKz0OhxBmV3nvREXaibLNHwPekN4l+H6S58UcEbxBcI4SQngK+HPgvSGEp0mGmPuwmb3GzPaZ2QdJHrh6f8Vbb7VkRJnLzezdwCuBbBSIPwYGgU+a2VVm9jKSH27HSB5Ixczea2Y3WjLaxF6S24qTwHdDCJMkDzjdaclIEpeb2feb2TvWEdc08F+B91gy0dflZvYfSR5S+09psi8DXwP+2JKReV5MUnE1k/Sz3ChPAq82sx9NP/83SU4m6yKE8OnU62OWjPLwSjP7HjP7ETP7A+DX17G73yX5If9nZvZDlkys84NpefzjNM1/Ivlxf4+ZXW1ml6QxfNDMXpSm+Q7Ql7p0p3cHjpKcZP+NmV2aXs37IC/cpdgM/pDk4bnfAP4ihDBcvtGSkTuuJBk2MevCdKVVjKrhOM7a+Plh084Pv0vycPLNZctr1cN5zh+/AfyiJaMIfZ+ZXWFmd9j6BsV4J/BvLZkb4MVpnr/OzH5/nTGW8wmSi0F3A4dCCKc1oNLz15W80CVpf1pP79rAZzqbReyHGPxV/IvkobH/vcz6f0zyo+3VQDvw+yQV9hzJlYxry9LuSdO+ieRBo1mSH4c/U7HP7wXu54UHbv8CuKxs+6+TXGWZJLlF+lec/mCWkdzGfJLkavQA8D/Lth8Bfq3iM+8CHihbbiDp9nIs3cc3l/E8n+RkNEryoNpfAS9fJt7Kh8beuEw+voWyB1lJrmB/Chgn6WrzIZJ+uUfK0tzJGg8Vl227hWSc8HGS27ePp/Gdv9znp+suzMq2bN3FJFfaszI+SnIX4pKyNC8hebBvJM2XwyRDEO4qy9s/BobT/d+Zrr8JeCo9Lh4lueK2CLxltfjS/d+Z8zh+NN3HDctse4AXHoYsf706z7795a9z9YWfH4o+P/z3tG6sT5dXrYfJcf5I0/0syXMCc2m6zwI7020PAHdVpD9jQAiSkYwOkjzsPU7y/MW7yrafsZ8cx9Ofpnnx1hWOteXq6bfE/h74K2BpITmO4ziO4ziOcw7iXYYcx3Ecx3Ec5xzGGwSO4ziO4ziOcw7jDQLHcRzHcRzHOYfxBoHjOI7jOI7jnMNITkz2wAMPhKampnW9Z3Fxkfp6yXBzcbbHB2d/jGd7fHD2x6ge3/T09MkDBw70xPaA6ur5swX146goPF+Wx/NleTxfzmS1On5DOWVm15GMN15HMjTVb1VsbyIZv/dlJMNi/XQI4Ui67R3ArUAJ+LchhM+n63eSDBP2YpLhqH4+hHDadOhNTU3s27dvXa4jIyN0dq5nHictzvb44OyP8WyPD87+GNXjO3To0NHYDhnV1PNnC+rHUVF4viyP58vyeL6cyWp1fNVdhsysjmR83OtJZhF8Q/nMfim3AiMhhMuADwDvS9+7n2SijiuA60gmPMlmP/0gySx9+0hmuvtWtY7llEpn9+zZZ3t8cPbHeLbHB2d/jGd7fM7W4MfR8ni+LI/ny/J4vqyPjTxDcDXJxErPhBDmSSbxuKEizQ0kU1kDfBo4kE7hfQNwbwhhLoTwHZLJia42sw6SabvvBgghzIcQRjfguMTU1NRm7KZmOdvjg7M/xrM9Pjj7Yzzb43O2Bj+OlsfzZXk8X5bH82V9bKTL0G7g2bLl5zhzeu2lNCGERTMbA7rS9Q9XvHc3yYyAg8AfmNn3A4+QzHZ3WqmeOHGCW2+9lfr6ekqlEjfeeCO33347/f39tLa2UldXx/j4OD09PQwPDxNCoLOzk6NHj7Jjxw4AJicn6e3tZXBwEDNj165dDA4O0t7eTqlUYmpqir6+Pvr7+2loaKCjo4OTJ0/S0dHB/Pw8MzMzS9sbGxtpa2tjaGiIzs5OZmZmmJ2dXdre3NxMS0sLIyMjdHV1MTExwfz8/NL2lpYWGhsbGRsbo7u7m7GxMRYWFpa2rxRTT08PAwMD7Nixg+bmZo4ePXpWxVRZTgDT09NnVUzl5dTS0sLJkyfPqpgqy6lUKnH8+PGzKqbyciqVSoyOjsrG5NQGfX19sRVqEs+X5fF8WR7Pl/VR9UzFZnYTcF0I4bZ0+U3ANSGEO8rSPJ6meS5dfpqk0XAn8HAI4Z50/f/P3vtHx3XVh76frdGMNJJGv2Uplo0dEoNrN20gIU5amtxiSAOXNheTtOE2rNyHvXi0DlwoF0h4tylkkdcCb5XbtQrrleXwkhLuDWn6uDUvCQmLFHIBE4KdUGKCsROiWDYjjX6OfsxoRqP9/tBIGY+3ZR9p5pzR93w/a2Vl5uw9Z76f73xnfLbOOXvfCzzG4rLjPwJ+11r7tDHm74C0tfYvS9/70KFDtvzaUmst09PTnMtnZmaG5ubmVbmuB8r9jDG0tLSweEJGBgMDA2zZsiXoMKqGdD+Q77je/Y4cOXJ49+7dVwYdB7h/58PCeq+jaqF5caN5WaT8OFD6cd9KnOsYcKXf+LWcITgFbC55vqm4zdVn0BhTD7SxeHPxuV47CAxaa58ubn8YuONCgpmenqahoYFYLOZsb2xsPGebBMr9crkc09PTJBKJAKOqLNFoNOgQqop0P5DvKN2vlNVOKmGMibI4ccQbWfw36B+ttX/ta/A1TpjqyAuaFzeal0XKjwOlH/etxGqOAddyD8EzwDZjzMXGmBiLNwkfLOtzELit+Pgm4Em7OHQ7CNxijGkwxlwMbAN+bK1NAieNMa8vvmY38PMLCcZau+IHH4lEztkmgXK/WCx2zrMl65W2tragQ6gq0v1AvqN0vyXWMqkEcDPQYK29jMXBwv9ujNnqR9zrhbDUkVc0L240L4uUHwdKP+5bidUcA656QGCtnQduBx5ncSagh6y1R40xdxtj/qjY7V6gyxhzAvgLin/tt9YeBR5i8WD/W8B+a+3SBawfBL5mjPk34HLg/1xtjKXMz89XYjc1i3Q/gJGRkaBDqCrS/UC+o3S/EtYyqYQFmotnjeNADkj7E/b6IER15AnNixvNi5swHBdVkjWtQ2CtfRR4tGzbXSWPsyz+Ncj12nuAexzbnwMqfg2r9JGidD+Q/1cQ6X4g31G6XwlrmVTiYRYHC78GmoCPWGvHyt9gNZNHVOLG8Fq42b2xsZHBwUFRTpX4nLLZrOhJCVbrtLCwQDqdFuW0ms9p6br5fD5PXV0dxhjm5uaWf0MA6uvryefzy8dMhUKBaDS6PHiIRCLMz88TiUSw1rKwsEA0GiWfz2OMueD2+vp6FhYWzmivq6ujrq5uub1QKGCtPaPdGEOhULjg9pWcZmZmSKfTZ3xOK7Hqm4qDxHWzWTqdPkP2+gPPVvQ9n9j3horurxI88sgjXHLJJWzfvp18Pn/WdYTlOVnvDA8Ps2HDhqDDqBrS/UC+43r3u9Cbitc4qcTrgT8H/hPQAfwv4O3W2pdK3yPMNxWv9zqqFpoXN5qXRcJ+HFiO6xhwpd/4tdxDoATI/Pw8jz76KMeOHQNgYWEh4IiqTyaTCTqEqiLdD+Q7SvcrwcukEpRNKvEfWVx8Mm+tHQZ+QBXOCq9nQlRHntC8uNG8hJPy48C1ogOCCvPQQw/x1re+lWuvvZaPfOQjnDx5kiuvvJLR0VEWFhZ4xzvewZNPPskrr7zCrl27eP/738+uXbu47bbbmJ2dBeC5557jne98J7//+7/Pu9/9bpLJJAB/+Id/yJ133slb3vIW/u7v/o7HHnuMv/qrv+Laa69lcHAwSG1fkD6nsHQ/kO8o3a+EtUwq8QrwFgBjTDNwNfALX6JeJ4SojjyheXGjeaktgjoO/NWvfrWmuHVAUEGOHTvGN77xDR577DGeeuopIpEIP/jBD/jQhz7ERz/6Uf7+7/+e17/+9bzlLW8B4Pjx47zvfe/j6aefJpFIcO+995LP5/nEJz7Bfffdx7/+67/yp3/6p3zmM59Zfo98Ps+TTz7JRz/6Ud7+9rfz6U9/mqeeeopNmzYFpe0bS18IqUj3A/mO0v2WWMukEizOTtRijDnK4sDi/7HW/pu/BrVNWOrIK5oXN5qX2iHI48CLL754TbGv6aZi5UyeeuopfvrTn7J7924Astks3d3d3HHHHfzLv/wL9913H9/73veW+/f393P11VcD8Md//Md8+ctfZvfu3bzwwgvs2bMHWLw5pLe3d/k173rXu5zvLWkBsnMhfT5h6X4g31G6XymrnVTCWjvt2q68SpjqyAuaFzeal9ohyOPAtaIDggpireWWW27hrrvuOmP77Owsp0+fBhZXzltaKKL8IH7p+fbt23niiSec79HU1OTcHoZZhiQtsuZCuh/Id6y03/HPH/D8mm0f21fRGBT/kf49WS1S8nIh32sv32M/8lLpmKUS5HHgWtFLhirItddey8GDB0mlUgCMj49z8uRJPv3pT3PzzTdz55138uEPf3i5/+DgID/+8Y8BePjhh9m1axeXXnopo6Ojy9vz+TwvvPCC8/1aWlqYnp4GwjHf7ujoaNAhVBXpfiDfUbqf4g9aR240L240L7VDkMeBa0XsGYLy6aEKhULV/4q+fft2PvnJT/Lud797ee7Zz3zmMxw5coRvfetbRCIRvvnNb/K1r32N3/u932Pbtm3ce++9fPCDH+T1r38973vf+4jFYtx3333ccccdpNNp5ufn+cAHPsBv/MZvnPV+73rXu/jwhz/Ml7/8Ze69914uvfTSqvoFTUdHR9AhVBXpfiDfUbqf4g9aR240L240L24e+99+y/erJ4I8DrzvvvvWdB+B2AFBOQsLC74Uxp49e5av+1ri29/+9vLjf/zHfwTglVdeIRKJ8A//8A9n7eOyyy7jkUceOWv7N7/5zTOeX3311fzoRz8CFkeQ0slkMqLWVShHuh/Id5Tup/iD1pEbzYsbzYsbv477ygnqOHCthOaSIenz9Ev3g8WbcyQj3Q/kO0r3U/xB68iN5sWN5sVNGI6LKkloBgTlq/gGzWte8xp++MMfVmx/teZXDaTPtSzdD+Q7SvdT/EHryI3mxY3mxU2tHxdV+jhwrYRmQCD9khrpfiB/rmXpfiDfUbqf4g9aR240L240L27CcFxUSUIzIKirk60q3Q+gsbEx6BCqinQ/kO8o3U/xB60jN5oXN5oXN2E4LqokocmW9MKQ7gcQj8eDDqGqSPcD+Y7S/RR/0Dpyo3lxo3lxE4bjokoSmmxJn6dfuh8szucrGel+IN9Rup/iD1pHbjQvbjQvbsJwXFRJxE47Wr6qnrX2rBXhvOD3Cny//du/zZNPPklXV9cF9amvF/tRLrNSLiQg3Q/kO0r3U/xB68iN5sWN5sXNwN/945qO+8qp9ePAtRKaMwTSp58qFApBh1B1pqamgg6hqkj3A/mO0v0Uf9A6cqN5caN5cSP9uK/ShGZA4AevvPIKu3btYv/+/bzpTW/i/e9/P9/97ne54YYbuPLKKzl8+DDj4+PceuutvPnNb+Ztb3sbR48eBWBsbIw9e/ZwzTXX8KEPfQhr7fJ+H3roId761rdy7bXX8pGPfMR58F/aXyq5XC7oEKqKdD+Q7yjdT/EHrSM3mhc3mpfaIcjjwLUSmgGBXzeXvPTSS+zfv5+nn36a48eP8/DDD/PYY49x991384UvfIG/+Zu/4bLLLuP73/8+f/mXf8mf/dmfAfC5z32Oq6++mkOHDvHOd76TwcFBAI4dO8Y3vvENHnvsMZ566ikikQj/9E//dNb71vp8u5VA+lzL0v1AvqN0P8UftI7caF7caF7cBHVTcVDHgWtF/oXnRfxawnrLli3s2LEDgO3bt3PddddhjGHHjh288sornDx5kvvvvx+Aa6+9lrGxMdLpND/84Q+Xl7O+/vrraW9vB+Cpp57ipz/9Kbt37wYWVyTs7u4+633z+TwNDQ1V9wuSZDLJli1bgg6jakj3A/mO0v0Uf9A6cqN5caN5cePXcV85QR0HrpXQDAgqeWPJSsRiseXHdXV1y8/r6uqYn5/3/Jd8ay233HILd91114r9wjC9lvSp1aT7gXxH6X6KP2gduXLyQWgAACAASURBVNG8uNG8uPHruK+coI4D14r8o8ga45prrlk+1fP973+frq4uWltb+Z3f+R0efvhhAL797W8zMTEBLI4eDx48SCqVAhanFzt58uRZ+w2q8P2k9EsmEel+IN9Rup/iD1pHbjQvbjQv64tqHQeuFbFnCMqnh5qbm6uJS2o+8YlP8MEPfpA3v/nNxONxvvSlLwHw8Y9/nH379nHNNddw1VVXsWnTJmDxdNMnP/lJ3v3ud7OwsEA0GuVzn/scmzdvPmO/hUJB/NSjk5OTy6fQJCLdD+Q7SvdT/EHryI3mxY3mxc3WD99WE8d95VTrOHCtmPU4O82hQ4fs9u3bz9iWTqdpbW0952sKhUIg15L5hcvvfDlZb8zMzNDc3Bx0GFVDuh/Id6y0X/l6KhfCWubKPnLkyOHdu3dfueodVBDX73xYkP49WS1S8nIh32sv32M/8lLpmKtB+TGP9OO+8+E6BlzpNz40lwxJn6dfuh8s/hVEMtL9QL6jdD/FH7SO3Ghe3Ghe3IThuKiShGZAsB7PhHhBuh8szqQkGel+IN9Rup/iD1pHbjQvbjQvbsJwXFRJQjMgkD5Pv3Q/kD/XsnQ/kO8o3U/xB60jN5oXN5oXN2E4LqokYgYExpgVV+uTPoIu98vlcuJmHkomk0GHUFWk+4F8R+l+ij9oHbnRvLjRvCxSfhwo/bhvJVZzDChmWpqWlhamp6fJZrPO9mw2S2Njo89R+Ue5nzGGlpaWACOqPBJuJlsJ6X4g31G6n+IPWkduNC9uNC+LlB8HSj/uW4nVHAOKGRAYY0gkEudsLxQKombcKUe6HyB+tgDpfiDfUbqf4g9aR240L240L4uUHweG4biokoi5ZOh8pNPpoEOoKtL9QL6jdD+Q7yjdT/EHrSM3mhc3mhc3mhdvhGZA0NPTE3QIVUW6H8h3lO4H8h2l+yn+oHXkRvPiRvPiRvPijdAMCMbGxoIOoapI9wP5jtL9QL6jdD/FH7SO3Ghe3Ghe3GhevBGaAYH0+Wil+4F8R+l+IN9Rup/iD1pHbjQvbjQvbjQv3gjNgED6qSPpfiDfUbofyHeU7qf4g9aRG82LG82LG82LN0IzIBgaGgo6hKoi3Q/kO0r3A/mO0v1KMcbcYIw5Zow5YYy5w9HeYIz5erH9aWPM1uL2PzXGPFfy34Ix5nK/469lwlRHXtC8uNG8uNG8eCM0AwJpc/KXI90P5DtK9wP5jtL9ljDGRIAvAm8HdgDvMcbsKOu2Fxi31l4KfAH4LIC19mvW2suttZcD7wV+Za19zr/oa5+w1JFXNC9uNC9uNC/eCM2AQFEURakYVwEnrLUvWWtzwIPAjWV9bgTuLz5+GNhtzl468z3F1yqKoigBImZhsvMxPT1NV1dX0GFUDel+IN9Ruh/Id5TuV0I/cLLk+SCw61x9rLXzxphJoAsYKenzJ5w9kABgeHiYvXv3Ul9fT6FQYM+ePezfv59kMklzczORSIR0Ok1PTw9jY2NYa+np6WFoaGj5L4PT09P09vaSSqUwxtDZ2UkqlaK1tZVCocDMzAx9fX0kk0mi0ShtbW2MjIzQ1tZGLpcjk8kst8diMRKJBKOjo3R0dJDJZMhms8vtjY2NxONxxsfH6erqYmpqilwut9wej8eJxWJMTk7S3d3N5OQk+Xx+ub3UKZ/Pk8lkRDlV4nM6deoUc3Nz694p25lgvqmB+NAEmd526uYLRNOzzHUmiKVnKcTqGRgYuGCnmZkZotFoVZ3mOlrINzcST02S7W6FBUvD+DTZ7laiUxlspO6MmGuh9kZGRpienhb5G7Fap5Uw6/Eu7EOHDtnt27d7eo30Jayl+4F8R+l+IN+x0n7HP3/A82u2fWzfqt/vyJEjh3fv3n3l+foZY24CbrDW7is+fy+wy1p7e0mf54t9BovPXyz2GSk+3wUcsNZe5nqP1fzOS0H692S1+JmX6w8866n/E/vecMF9L+R77eV77EdeKh2zH+j36GxW+o0PzSVDqVQq6BCqinQ/kO8o3Q/kO0r3K+EUsLnk+abiNmcfY0w90AaMlrTfAvyPKsa4bglRHXlC8+JG8+JG8+KN0AwIzr50VRbS/UC+o3Q/kO8o3a+EZ4BtxpiLjTExFg/uD5b1OQjcVnx8E/CkLZ6SNsbUAX+M3j/gJER15AnNixvNixvNizdCcw9BZ2dn0CFUFel+IN9Ruh/Id5Tut0TxnoDbgceBCPAVa+1RY8zdwE+stQeBe4GvGmNOAGMsDhqWuBY4aa19ye/Y1wNhqSOvaF7caF7caF68EZozBNJPHUn3A/mO0v1AvqN0v1KstY9aa19nrb3EWntPcdtdxcEA1tqstfZma+2l1tqrSg/+rbXftdZeHVTstU6Y6sgLmhc3mhc3mhdvhGZAcL67q9c70v1AvqN0P5DvKN1P8QetIzeaFzeaFzeaF2+saUCw2pUqi213FrcfM8b8Qcn2l40xPyuuYPmTtcRXSqFQqNSuahLpfiDfUbofyHeU7qf4g9aRG82LG82LG82LN1Y9IFjLSpXFfrcAO4EbgC8V97fE7xdXsjzv9HcXyszMTKV2VZNI9wP5jtL9QL6jdD/FH7SO3Ghe3Ghe3GhevLGWMwRrWanyRuBBa+2ctfZXwIni/qpGX19fNXcfONL9QL6jdD+Q7yjdT/EHrSM3mhc3mhc3mhdvrGWWobWsVNkP/Kjstf3FxxZ4whhjgX+w1n65/I1Xs4JlLpejvr5e7Op0qVSKeDwuyqn8c5qYmOCSSy4R5VT6OWUyGbq7u0U5lX9Ox44do7u7W5RT6ef04osv8prXvKZiToVoPZnediLZHJHcPLnWJhrGpsi3NrFQH1le6bR+dg5TWCCfiDM7O7tqJ6U2SCaTbNmyJegwag7NixvNixvNizdWvVLxWlaqBD4F/Mha+0Bx+73AY9bah40x/dbaU8aYDcC3gQ9aa58qfe/VrGB5+vRpNm7cuCrX9YB0P5DvKN0P5DtW2q9WVyr2gzCvVCz9e7Ja/MzLelqp2I+8rMeVivV7dDbVWql4LStVnvO11tql/w8D36BClxK1tbVVYjc1i3Q/kO8o3Q/kO0r3U/xB68iN5sWN5sWN5sUbaxkQrGWlyoPALcVZiC4GtgE/NsY0G2MSAMaYZuB64Pk1xLjMyMhIJXZTs0j3A/mO0v1AvqN0P8UftI7caF7caF7caF68sep7CNayUmWx30PAz4F5YL+1tmCM6QW+UVxuuh7479bab63BbxnpI0XpfiDfUbofyHeU7qf4g9aRG82LG82LG82LN9ZyUzHW2keBR8u23VXyOAvcfI7X3gPcU7btJeC31xLTucjlctXYbc0g3Q/kO0r3A/mO0v0Uf9A6cqN5caN5caN58UZoVirOZDJBh1BVpPuBfEfpfiDfUbqf4g9aR240L240L240L94IzYBA+ny00v1AvqN0P5DvKN1P8QetIzeaFzeaFzeaF2+EZkCQTCaDDqGqSPcD+Y7S/UC+o3Q/xR+0jtxoXtxoXtxoXrwRmgFBLBYLOoSqIt0P5DtK9wP5jtL9FH/QOnKjeXGjeXGjefFGaAYEiUQi6BCqinQ/kO8o3Q/kO0r3U/xB68iN5sWN5sWN5sUboRkQjI6OBh1CVZHuB/IdpfuBfEfpfoo/aB250by40by40bx4IzQDgo6OjqBDqCrS/UC+o3Q/kO8o3U/xB60jN5oXN5oXN5oXb4RmQCB9+inpfiDfUbofyHeU7qf4g9aRG82LG82LG82LN0IzIMhms0GHUFWk+4F8R+l+IN9Rup/iD1pHbjQvbjQvbjQv3gjNgED6fLTS/UC+o3Q/kO8o3U/xB60jN5oXN5oXN5oXb4RmQCB9PlrpfiDfUbofyHeU7qf4g9aRG82LG82LG82LN0IzIGhsbAw6hKoi3Q/kO0r3A/mO0v0Uf9A6cqN5caN5caN58UZoBgTxeDzoEKqKdD+Q7yjdD+Q7SvdT/EHryI3mxY3mxY3mxRuhGRCMj48HHUJVke4H8h2l+4F8R+l+ij9oHbnRvLjRvLjRvHijPugA/KKrqyvoEKqKdD+Q7yjdD+Q7VtLv+gPPcs2RC78G9tY36g10UpD+PVktYcrL8c8fuOC++eYGjs/MOdu2fWxfpUJad4SpXipBaM4QTE1NBR1CVZHuB/IdpfuBfEfpfoo/aB250by4yTfrpTEutF68EZoBQS6XCzqEqiLdD+Q7SvcD+Y7S/RR/0Dpyo3lxsxALzcUentB68UZoBgTS56OV7gfyHaX7gXxH6X6KP2gdudG8uIkPTQQdQk2i9eKN0AwIpM9HK90P5DtK9wP5jtL9FH/QOnKjeXGT6W0POoSaROvFG6EZEEiffkq6H8h3lO4H8h2l+yn+oHXkRvPiJpLVS2NcaL14IzQDglgsFnQIVUW6H8h3lO4H8h2l+yn+oHXkRvPiJpKbDzqEmkTrxRuhGRBMTk4GHUJVke4H8h2l+4F8R+l+pRhjbjDGHDPGnDDG3OFobzDGfL3Y/rQxZmtJ228ZYw4ZY44aY35mjNElRUsIUx15QfPiJtfaFHQINYnWizdCMyDo7u4OOoSqIt0P5DtK9wP5jtL9ljDGRIAvAm8HdgDvMcbsKOu2Fxi31l4KfAH4bPG19cADwAestTuBfwfkfQp9XRCWOvKK5sVNw5hOr+lC68UboRkQSB8pSvcD+Y7S/UC+o3S/Eq4CTlhrX7LW5oAHgRvL+twI3F98/DCw2xhjgOuBf7PW/hTAWjtqrS34FPe6IER15AnNi5u8niFwovXijdBMXpvPy/4DlHQ/kO8o3Q/kO0r3K6EfOFnyfBDYda4+1tp5Y8wk0AW8DrDGmMeBHuBBa+3nyt9geHiYvXv3Ul9fT6FQYM+ePezfv59kMklzczORSIR0Ok1PTw9jY2NYa+np6WFoaIiWlhYApqen6e3tJZVKYYyhs7OTVCpFa2srhUKBmZkZ+vr6SCaTRKNR2traGBkZoa2tjVwuRyaTWW6PxWIkEglGR0fp6Oggk8mQzWaX2xsbG4nH44yPj9PV1cXU1BS5XG65PR6PE4vFmJycpLu7m8nJSfL5/HJ7qVM+n2dwcFCUUyU+p5GREQBfnK7rzvHCVD1bmgo0RSyHJ+q5on2eobk68guwKb7A8+l6trUUqDeWbDZ7wU7ZzgTzTQ3EhybI9LZTN18gmp5lrjNBLD1LIVZPoTH2antunuhMhrmOBLGJGQrxGIWG6HJ7vqmB+uksufZmGsanyDfHWYjVEx+aYGBgoCKf01xHC/nmRuKpSbLdrbBgaRifJtvdSnQqg43UMTAwUFO1t/RdkvgbsVqnlTDW2gv58a8pDh06ZLdv3+7pNXNzczQ0NFQpouCR7gfyHaX7gXzHSvpdf+BZrvnOIxfc/9Y3Ls65ve1j+1b9nkeOHDm8e/fuK8/XzxhzE3CDtXZf8fl7gV3W2ttL+jxf7DNYfP4ii4OG/wTsB94EzALfAf6rtfY7pe+xmt95KUj/nqwWP/Ny/YFnPfV/Yt8bLrjv8c8f8BrOihSi9UTy7huL1/J7UMqFxFyp96oU+j06m5V+40NzyZD0+Wil+4F8R+l+IN9Rul8Jp4DNJc83Fbc5+xTvG2gDRlk8m/CUtXbEWjsLPAq8seoRryNCVEee0Ly40XUI3Gi9eCM0A4Lm5uagQ6gq0v1AvqN0P5DvKN2vhGeAbcaYi40xMeAW4GBZn4PAbcXHNwFP2sVT0o8DlxljmooDheuAn/sU97ogRHXkCc2Lm/rZuaBDqEm0XrwRmnsIIpFI0CFUFel+IN9Ruh/Id5Tut0TxnoDbWTy4jwBfsdYeNcbcDfzEWnsQuBf4qjHmBDDG4qABa+24MeZvWRxUWOBRa+2FXxsVAsJSR17RvLgxhYWgQ6hJtF68EZozBOl0OugQqop0P5DvKN0P5DtK9yvFWvuotfZ11tpLrLX3FLfdVRwMYK3NWmtvttZeaq29ylr7UslrH7DW7rTW/qa19uNBOdQqYaojL2he3OQTuiKvC60Xb4RmQNDT0xN0CFVFuh/Id5TuB/Idpfsp/qB15Ebz4qZxRA98XWi9eCM0lwyNjY3R1CR3rl7pfiDfUbofyHeU7qf4Qy3WUTVn3blQajEvfvHAkXPfILvl8k0MPHdm+9KsY2EmzPWyGkJzhmA9Tq/qBel+IN9Ruh/Id5Tup/iD1pEbzYsbEwnNoZwntF68EZoqkn7qSLofyHeU7gfyHaX7Kf6gdeRG8+Im+cvhoEOoSbRevBGaAcHQ0FDQIVQV6X4g31G6H8h3lO6n+IPWkRvNi5uN2/XyIBdaL94IzYBgaUlnqUj3A/mO0v1AvqN0P8UftI7caF7cpFNTQYdQk2i9eCM0AwJFURRFURRFUc4mNAOC6enpoEOoKtL9QL6jdD+Q7yjdT/EHrSM3mhc3rT2JoEOoSbRevBGaAUFvb2/QIVQV6X4g31G6H8h3lO6n+IPWkRvNi5vTvzj3lKRhRuvFG6EZEKRSqaBDqCrS/UC+o3Q/kO8o3U/xB60jN5oXN32v2xB0CDWJ1os3QjMgMMYEHUJVke4H8h2l+4F8R+l+ij9oHbnRvLixhYWgQ6hJtF68EZoBQWdnZ9AhVBXpfiDfUbofyHeU7qf4g9aRG82Lm9TLo0GHUJNovXgjNAMC6aeOpPuBfEfpfiDfUbqf4g9aR240L276tum18i60XrwRmgFBa2tr0CFUFel+IN9Ruh/Id5Tup/iD1pEbzYubyeRk0CHUJFov3gjNgKBQKAQdQlWR7gfyHaX7gXxH6X6KP2gdudG8uIlEI0GHUJNovXhjTQMCY8wNxphjxpgTxpg7HO0NxpivF9ufNsZsLWm7s7j9mDHmD8peFzHGPGuM+f/WEl8pMzMzldpVTSLdD+Q7SvcD+Y7S/RR/0Dpyo3lx09KlK/K60HrxxqoHBMaYCPBF4O3ADuA9xpgdZd32AuPW2kuBLwCfLb52B3ALsBO4AfhScX9L/GfghdXG5qKvr6+Su6s5pPuBfEfpfiDfUbqf4g9aR240L25OHT0ddAg1idaLN9ZyhuAq4IS19iVrbQ54ELixrM+NwP3Fxw8Du83iPFA3Ag9aa+estb8CThT3hzFmE/DvgQNriO0skknZC3dI9wP5jtL9QL6jdD/FH7SO3Ghe3PTv3Bh0CDWJ1os36tfw2n7gZMnzQWDXufpYa+eNMZNAV3H7j8pe2198/N+AjwPnXIt7eHiYvXv3Ul9fT6FQYM+ePezfv59kMklzczORSIR0Ok1PTw9jY2NYawEYGBigpWXx1Nr09DS9vb2kUimMMXR2dpJKpWhtbaVQKDAzM0NfXx/JZJJoNEpbWxsjIyO0tbWRy+XIZDLL7bFYjEQiwejoKB0dHWQyGbLZ7HJ7Y2Mj8Xic8fFxurq6mJqaIpfLLbfH43FisRiTk5N0d3czOTlJPp9fbj+XU09PD0NDQ7S0tJDL5RgYGBDlVP45zczMMDs7K8qp9HPK5/OMjIyIcir/nKampjh9+rQop9LPaWpqiomJiYo4XdedwzTF6N+5kdmJWeZmcnT0tzP8YoqO/naijVFOHT1N/86NTI9OM9fWTD4RZ3Z2dtVOSm0QjUaDDqEm0by4yWfzQYdQk2i9eMMsHSx7fqExNwE3WGv3FZ+/F9hlrb29pM/zxT6Dxecvsjho+BTwI2vtA8Xt9wKPAVngHdbaPzfG/Dvgv1hr31n+3ocOHbLbt2/3FO/MzAzNzc2ePdcL0v1AvqN0P5DvWEm/6w88yzXfeeSC+9/6xsXT49s+tm/V73nkyJHDu3fvvnLVO6ggq/mdl0Itfk+uP/Csp/5P7HtDxWPwMy/V9D3+ee8XQDxw5Nx/7W7pbGZ67Mzr5Svxe1DKhcRcqfeqFLX4PQqalX7j13LJ0Clgc8nzTcVtzj7GmHqgDRhd4bW/C/yRMeZlFi9Beosx5oE1xLjMyMhIJXZTs0j3A/mO0v1AvqN0P8UftI7caF7cbLikJ+gQahKtF2+sZUDwDLDNGHOxMSbG4k3CB8v6HARuKz6+CXjSLp6SOAjcUpyF6GJgG/Bja+2d1tpN1tqtxf09aa29dQ0xLtPW1laJ3dQs0v1AvqN0P5DvKN1P8QetIzeaFzfjpyaCDqEm0XrxxqrvISjeE3A78DgQAb5irT1qjLkb+Im19iBwL/BVY8wJYIzFg3yK/R4Cfg7MA/uttVW9gDWXy1Vz94Ej3Q/kO0r3A/mO0v0Uf9A6cqN5cdPQHAs6hJpE68Uba7mpGGvto8CjZdvuKnmcBW4+x2vvAe5ZYd/fBb67lvhKyWQyldpVTSLdD+Q7SvcD+Y7S/RR/0Dpyo3lx09TeFHQINYnWizdCs1Kx9PlopfuBfEfpfiDfUbqf4g9aR240L250HQI3Wi/eCM2AQPp8tNL9QL6jdD+Q7yjdT/EHrSM3mhc3ug6BG60Xb4RmQBCLyb7GTrofyHeU7gfyHaX7Kf6gdeRG8+JmbnYu6BBqEq0Xb4RmQJBInHOdMxFI9wP5jtL9QL6jdD/FH7SO3Ghe3KSHp4IOoSbRevFGaAYEo6OjQYdQVaT7gXxH6X4g31G6n+IPWkduNC9uerZ2Bx1CTaL14o3QDAg6OjqCDqGqSPcD+Y7S/UC+o3Q/xR+0jtxoXtyMnhwLOoSaROvFG6EZEEiffkq6H8h3lO4H8h2l+yn+oHXkRvPiRqcddaP14o3QDAiy2WzQIVQV6X4g31G6H8h3lO5XijHmBmPMMWPMCWPMHY72BmPM14vtTxtjtha3bzXGZIwxzxX/+7/9jr3WCVMdeUHz4iaeaAw6hJpE68Uba1qYbD0hfT5a6X4g31G6H8h3lO63hDEmAnwReBswCDxjjDlorf15Sbe9wLi19lJjzC3AZ4E/Kba9aK293Neg1xFhqSOvaF7c6DoEbrRevBGaMwTS56OV7gfyHaX7gXxH6X4lXAWcsNa+ZK3NAQ8CN5b1uRG4v/j4YWC3Mcb4GOO6JUR15AnNixtdh8CN1os3QnOGoLFR9ik16X4g31G6H8h3lO5XQj9wsuT5ILDrXH2stfPGmEmgq9h2sTHmWSAN/Fdr7f8qf4Ph4WH27t1LfX09hUKBPXv2sH//fpLJJM3NzUQiEdLpND09PYyNjWGtpaenh6GhIVpaWgCYnp6mt7eXVCqFMYbOzk5SqRStra0UCgVmZmbo6+sjmUwSjUZpa2tjZGSEtrY2crkcmUxmuT0Wi5FIJBgdHaWjo4NMJkM2m11ub2xsJB6PMz4+TldXF1NTU+RyueX2eDxOLBZjcnKS7u5uJicnyefzy+2lTnV1dQwODtaU00UNBS6KL5CotxyeqOeK9nlGc3VMzRu2NhV4YaqeLU0FmiKL7QMDAxX/nGZmZjh9+rQvn9N13bmznK5on2doro78AmyKL/B8up5tLQXqjSWbzV6wU7YzwXxTA/GhCTK97dTNF4imZ5nrTBBLz1KI1VNojL3anpsn0TNNz9ZuRk+O0dTeRDzRyKmjp+nfuZGGlgba+lrp2txJ6uURWjckmN7URXxogoGBAU+1d67Paa6jhXxzI/HUJNnuVliwNIxPk+1uJTqVwUbqGBgYqKnvU6FQYGBgQORvxGqdVsJYay/kx7+mOHTokN2+fbun16TT6fMmYz0j3Q/kO0r3A/mOlfS7/sCzXPOdRy64/61vXDw9vu1j+1b9nkeOHDm8e/fuK8/XzxhzE3CDtXZf8fl7gV3W2ttL+jxf7DNYfP4ii4OGKaDFWjtqjLkC+J/ATmttuvQ9VvM7L4Va/J5cf+BZT/2f2PeGisfgZ16q6Xv88we8hsMDR8791+62vlYmk2d8fSrye1DKhcRcqfeqFLX4PQqalX7jQ3PJ0Pj4eNAhVBXpfiDfUbofyHeU7lfCKWBzyfNNxW3OPsaYeqANGLXWzllrRwGstYeBF4HXVT3idUSI6sgTmhc3XZs7gw6hJtF68UZoBgRdXV3n77SOke4H8h2l+4F8R+l+JTwDbDPGXGyMiQG3AAfL+hwEbis+vgl40lprjTE9xZuSMca8FtgGvORT3OuCENWRJzQvblIvjwQdQk2i9eKN0AwIpqZkL+0t3Q/kO0r3A/mO0v2WsNbOA7cDjwMvAA9Za48aY+42xvxRsdu9QJcx5gTwF8DS1KTXAv9mjHmOxZuNP2Ct1ZWVSghLHXlF8+KmdUMi6BBqEq0Xb4TmpuJcLhd0CFVFuh/Id5TuB/IdpfuVYq19FHi0bNtdJY+zwM2O1/0z8M9VD3AdE6Y68oLmxU1DU0PQIdQkWi/eCM0ZAunz0Ur3A/mO0v1AvqN0P8UftI7caF7c6DoEbrRevBGaAYH0+Wil+4F8R+l+IN9Rup/iD1pHbjQvbnQdAjdaL94IzYAgHo8HHUJVke4H8h2l+4F8R+l+ij9oHbnRvLiZnZgNOoSaROvFG6EZEMRisaBDqCrS/UC+o3Q/kO8o3U/xB60jN5oXN3Mzeq28C60Xb4RmQDA5ORl0CFVFuh/Id5TuB/Idpfsp/qB15Ebz4qajvz3oEGoSrRdvhGZA0N3dHXQIVUW6H8h3lO4H8h2l+yn+oHXkRvPiZvjFVNAh1CRaL94IzbSjk5OTNDc3Bx1G1ZDuB/IdpfuBfEfpfoo/aB25CTov13znkXO2HR8/7GMkZ9LR38702Exg7x8Exz9/4Lx9mv/0Hfo98kBoBgT5fD7oEKqKdD+Q7yjdD+Q7SvdT/EHryI3mxU20MRp0CIHzwJGzZxSKbTvJ90aGnP2f2PeGqsZz/YFnPfWvdjwXQmguGZI+H610P5DvKN0P5DtK91P8QevIjebFja5D4ObwRGj+5l0RQjMgkD4frXQ/kO8o3Q/kO0r3U/xB68iN5sWNrkPg5or2+aBDWFeEZkAg/Toy6X4g31G6H8h3lO6n+IPWkRvNi5vp0emgQ6hJhuZCc4hbEUKTrUgkEnQIVUW6H8h3lO4H8h2l+yn+oHXkFDn5TwAAIABJREFURvPippAvBB1CTZJfCDqC9UVoBgTpdDroEKqKdD+Q7yjdD+Q7SvdT/EHryI3mxU1bX1vQIdQkm+I6IvBCaAYEPT09QYdQVaT7gXxH6X4g31G6n+IPWkduNC9uksfdM+mEnefTelOxF0IzIBgbGws6hKoi3Q/kO0r3A/mO0v0Uf9A6cqN5cdOztSvoEGqSbS16KZUXQjMgsNYGHUJVke4H8h2l+4F8R+l+ij9oHbnRvLgxkdAcynmi3mi9eCE0VST9VKN0P5DvKN0P5DtK91P8QevIjebFTfKXw0GHUJP8TC8Z8kRoBgRDQ7KvsZPuB/IdpfuBfEfpfoo/aB250by42bhdF2xzcXmbrkPghdAMCFpaWoIOoapI9wP5jtL9QL6jdD/FH7SO3Ghe3KRTU0GHUJP8OhuaQ9yKoNlSFEVRFEVRlBATmgHB9LTslfyk+4F8R+l+IN9Rup/iD1pHbjQvblp7EkGHUJNc1KjrEHghNAOC3t7eoEOoKtL9QL6jdD+Q7yjdT/EHrSM3mhc3p3+RDDqEmuS5Sb2p2AuhGRCkUqmgQ6gq0v1AvqN0P5DvKN1P8QetIzeaFzd9r9sQdAg1yWWtelOxF0IzIDDGBB1CVZHuB/IdpfuBfEfpfoo/aB250by4sQW9NMbFvNV68UJoBgSdnZ1Bh1BVpPuBfEfpfiDfUbqf4g9aR240L25SL48GHUJNcnw6EnQI64rQDAikn2qU7gfyHaX7gXxH6X6KP2gdudG8uOnbpvdWuPhNvWTIE6EZELS2tgYdQlWR7gfyHaX7gXxH6X6KP2gdudG8uJlMTgYdQk0ymAnNIW5FCE22CoVC0CFUFel+IN9Ruh/Id5Tup/iD1pEbzYubSFQvjXERDc0RbmVYU7qMMTcYY44ZY04YY+5wtDcYY75ebH/aGLO1pO3O4vZjxpg/KG5rNMb82BjzU2PMUWPMp9cSXykzMzOV2lVNIt0P5DtK9wP5jtL9FH/QOnKjeXHT0qUrOLvobdCbrb2w6gGBMSYCfBF4O7ADeI8xZkdZt73AuLX2UuALwGeLr90B3ALsBG4AvlTc3xzwFmvtbwOXAzcYY65ebYyl9PX1VWI3NYt0P5DvKN0P5DtK91P8QevIjebFzamjp4MOoSY5PKHrEHhhLWcIrgJOWGtfstbmgAeBG8v63AjcX3z8MLDbLM4bdiPwoLV2zlr7K+AEcJVdZGkpwmjxP7uGGJdJJmUv3CHdD+Q7SvcD+Y7S/RR/0Dpyo3lx079zY9Ah1CRXtOtNxV5Yy4CgHzhZ8nywuM3Zx1o7D0wCXSu91hgTMcY8BwwD37bWPr2GGJeJRqOV2E3NIt0P5DtK9wP5jtL9SlnLJaPF9tcYY6aNMf/Fr5jXC2GqIy9oXtzks/mgQ6hJZgu6DoEXau58irW2AFxujGkHvmGM+U1r7fOlfYaHh9m7dy/19fUUCgX27NnD/v37SSaTNDc3E4lESKfT9PT0MDY2hrWW5uZmBgYGaGlZvNZuenqa3t5eUqkUxhg6OztJpVK0trZSKBSYmZmhr6+PZDJJNBqlra2NkZER2trayOVyZDKZ5fZYLEYikWB0dJSOjg4ymQzZbHa5vbGxkXg8zvj4OF1dXUxNTZHL5Zbb4/E4sViMyclJuru7mZycJJ/PL7efy6mnp4ehoaFlp4GBAXFOpZ9TPp9ndnZWlFPp5xSLxRgZGRHlVP45zc7Ocvr0aVFOpZ/T7OwsExMTFXG6rjuHaYrRv3MjsxOzzM3k6OhvZ/jFFB397UQbo5w6epr+nRuZHp1mrq2ZfCLO7Ozsqp0ulJJLRt/G4h90njHGHLTW/ryk2/Ilo8aYW1i8ZPRPStr/Fnjsgt80RLS1tQUdQk2ieXEzfmoi6BBqkoFZvdnaC8ba1V2RY4y5BviUtXbphuA7Aay1f13S5/Fin0PGmHogCfQAd5T2Le1X9h53AbPW2v+rdPuhQ4fs9u3bPcU7MDDAli1bvEmuI6T7gXxH6X4g37GSftcfeJZrvvPIBfe/9Y2L11dv+9i+Vb/nkSNHDu/evfvK8/Vby++/tdYaY/4D8LvADDBd/hsPq/udl0Itfk+uP/Csp/5P7HtDxWPwMy8u35W+j0vfv2rxwJFzXy712jdt5aVnXnbGs5bfg1KOf/7AeftU6r0uhPJ4XPmJ/cnb+N5IzPn6atRnKbXwfXGx0m/8Ws4QPANsM8ZcDJxi8Sbh/1jW5yBwG3AIuAl4sviPwUHgvxtj/hbYCGwDfmyM6QHy1toJY0ycxb8+fXYNMS4j/S8L0v1AvqN0P5DvuJKf138gahzXZZ+7ztXHWjtvjJkEuowxWeATLP6+n/NyodWcCa7EWZ5aOHPV2NjI4OBgTTld1FDgovgCiXrL4Yl6rmifZzRXx9S8YWtTgRem6tnSVKApstg+MDBQ8c8pm836dobxuu7cWU6vfdNWpkenKeQLtPW1kTw+RM/WLkykjkLMkulpIzqTBSDf3Eg8NUm2uxUWLA3j02S7W4lOZbCROuabGogPTZDpbaduvkA0PctcZ4JYepZCrJ5CY+zV9tw8iZ5perZ2M3pyjKb2JuKJxuUzhHWROtr6Wuna3Enq5RFaNySY3tRFfGiCgYGBipw1netoOa/TwMCAb9+nTHcrkdw8udYmGsam2HxZ/1lnTYcX4LruHM+n69nWUqDeWH6WrufytnlGR0er+n3aFC/QFVugPfrq92UibxjN1XFJc4FfTkXO+D5V6nM6n9NKrPoMAYAx5h3AfwMiwFestfcYY+4GfmKtPWiMaQS+CrwBGANusda+VHzt/wG8D5gHPmytfcwY81ss3oQcYfH+hoestXeXv+9q/nI0PDzMhg0bVqta80j3A/mO0v1AvuNKfqsZENTwGYKbgBustfuKz98L7LLW3l7S5/lin8Hi8xdZHDTcAfzYWvuQMeZT6BmCs6jF70kt/MXTz7yspzMEfds2kDw+7IwnzGcIpt71Bzyfdv/dW88QnM2a7iGw1j4KPFq27a6Sx1ng5nO89h7gnrJt/8bi4KHiZDKZauy2ZpDuB/IdpfuBfEfpfiWcAjaXPN9U3ObqM1i8ZKgNGGVxUHCTMeZzQDuwYIzJWmv/vvphrw9CVEee0Ly4aWpvCjqEmqQrpusQeKHmbiquFtLnL5buB/IdpfuBfEfpfiWs+pJR4PeWOpScIdDBQAkhqiNPaF7c6DoEbnQdAm+EZmFn6fMXS/cD+Y7S/UC+o3S/JYrTSN8OPA68wOLlnUeNMXcbY/6o2O1eFu8ZOAH8BcXJJJTzE5Y68ormxY2uQ+BG1yHwRmiGT7GY+05zKUj3A/mO0v1AvqN0v1LWcsloSZ9PVSW4dU6Y6sgLmhc3c7NzQYdQk0zN6zoEXgjNGYJEIhF0CFVFuh/Id5TuB/Idpfsp/qB15Ebz4iY9PBV0CDXJrzOhOcStCKHJ1tIUU1KR7gfyHaX7gXxH6X6KP2gdudG8uOnZ2h10CDXJ6xIXvtiiEqIBQUdHR9AhVBXpfiDfUbofyHeU7qf4g9aRG82Lm9GTY0GHUJO8OKMrFXshNAMC6dOVSfcD+Y7S/UC+o3Q/xR+0jtxoXtzotKNudNpRb4RmQJDNZoMOoapI9wP5jtL9QL6jdD/FH7SO3Ghe3MQTjUGHUJO0R1e/8G4YCc2AQPr8xdL9QL6jdD+Q7yjdT/EHrSM3mhc3ug6BG12HwBuhGRBIn79Yuh/Id5TuB/Idpfsp/qB15Ebz4kbXIXCj6xB4IzQDgsZG2afUpPuBfEfpfiDfUbqf4g9aR240L24yU3oplYuJvK5D4IXQDAji8XjQIVQV6X4g31G6H8h3lO6n+IPWkRvNi5vZidmgQ6hJRnOhOcStCKHJ1vj4eNAhVBXpfiDfUbofyHeU7qf4g9aRG82Lm67NnUGHUJNc0qzrEHghNAOCrq6uoEOoKtL9QL6jdD+Q7yjdT/EHrSM3mhc3qZdHgg6hJvnllK5D4IXQDAimpmQv7S3dD+Q7SvcD+Y7S/RR/0Dpyo3lx07ohEXQINclFcV2HwAuhGRDkcrmgQ6gq0v1AvqN0P5DvKN1P8QetIzeaFzcNTQ1Bh1CTJOp1HQIvhGZAIH3+Yul+IN9Ruh/Id5Tup/iD1pEbzYsbXYfAja5D4I3QZCuZTLJly5agw6ga0v1AvqN0P5DvKN1P8QetIzdrycv1B56tcDS1Q//Ojbz0zMtnbHvgyOKaDYcu0PuJfW+odFiBc0X7PN8biQUdxrohNGcIpE9XJt0P5DtK9wP5jtL9FH/QOnKjeXGj04660WlHvRGabMViskeJ0v1AvqN0P5DvKN1P8QetIzeaFzdzM3pvhYupeV2YzAuhGRBMTk4GHUJVke4H8h2l+4F8R+l+ij9oHbnRvLjp6G8POoSaZGuTrkPghdAMCLq7u4MOoapI9wP5jtL9QL6jdD/FH7SO3Ghe3Ay/mAo6hJrkhanQ3CZbEUIzIJD+lwXpfiDfUbofyHeU7qf4g9aRG82LGz1D4GaLniHwRGgGBPl8PugQqop0P5DvKN0P5DtK91P8QevIjebFTbQxGnQINUlTRNch8EJoBgTS5y+W7gfyHaX7gXxH6X6KP2gdudG8uNF1CNzoOgTeCM2AIJlMBh1CVZHuB/IdpfuBfEfpfoo/aB250by46d+5MegQapIr2ueDDmFdEZoBQXNzc9AhVBXpfiDfUbofyHeU7qf4g9aRG82Lm+nR6aBDqEmG5kJziFsRQpOtSCQSdAhVRbofyHeU7gfyHaX7Kf6gdeRG8+KmkNebZ13kF4KOYH0RmgFBOp0OOoSqIt0P5DtK9wP5jtL9FH/QOnKjeXHT1tcWdAg1yaa4jgi8EJoBQU9PT9AhVBXpfiDfUbofyHeU7qf4g9aRG82Lm+TxoaBDqEmeT+tNxV4IzYBgbGws6BCqinQ/kO8o3Q/kO0r3U/xB68iN5sVNz9auoEOoSba16KVUXgjN8Mla2fPRSvcD+Y7S/UC+o3Q/xR9qvY6u+c4j5+1zfPxwxd93pr+LzKlvnbV928f2rXnfF+JUq5jI+vnb7vHPH/DtvS5+6ReYw6+44yjWZyVq50JZqcaCiKec9VNFa0T6qUbpfiDfUbofyHeU7qf4g9aRm8YRvYfARfKXw0GHUJNoXrwRmgHB0JDsa+yk+4F8R+l+IN9Rul8pxpgbjDHHjDEnjDF3ONobjDFfL7Y/bYzZWtx+lTHmueJ/PzXGvMvv2GudMNWRFzI9evOsi43bdcE2F5oXb4RmQNDS0hJ0CFVFuh/Id5TuB/IdpfstYYyJAF8E3g7sAN5jjNlR1m0vMG6tvRT4AvDZ4vbngSuttZcDNwD/YIwJzeWrF0JY6sgr0Zls0CHUJOnUVNAh1CSaF2+EZkCgKIqiVIyrgBPW2pestTngQeDGsj43AvcXHz8M7DbGGGvtrLV2aQnRRqC2L5hXFEUJAaEZEExPy17JT7ofyHeU7gfyHaX7ldAPnCx5Pljc5uxTHABMAl0AxphdxpijwM+AD5QMEBRCVUeeyDc3Bh1CTdLakwg6hJpE8+KN0Jym7e3tDTqEqiLdD+Q7SvcD+Y7S/SqFtfZpYKcx5jeA+40xj1lrz7geZHh4mL1791JfX0+hUGDPnj3s37+fZDJJc3MzkUiEdDpNT08PY2NjWGvp6elhaGho+ZKb6elpent7SaVSGGPo7OwklUrR2tpKoVBgZmaGvr4+kskk0WiUtrY2RkZGaGtrI5fLkclklttjsRiJRILR0VE6OjrIZDJks9nl9sbGRuLxOOPj43R1dTE1NUUul1tuj8fjxGIxJicn6e7uZnJyknw+v9xe6tTW1sbg4GBNOV3UUOCi+AKJeotpitG/cyOzE7PMzeTo6G9n+MUUHf3tRBujnDp6mulN3dTPzmEKC+QTcRpH0sx1tECdoXEkTaanbfkSoHxzI/HUJNnuVliwNIxPk+1uJTqVwUbqmG9qID40wUJ9HbN9HUTTs8x1JoilZynE6hkYGDivU0v9Ale0zzORN4zm6rikucAvpyKenPp3bmR6dJpCvkBbXxvJ40P0bO3CROooxOyqnDK97dTNF85yKjTGXm3PzZPomaZnazejJ8doam8inmhcjmk+X6Ctr5WuzZ2kXh6hdUOChqYGTh09zXXdOUZzdUzNG7Y2FXhhqp4tTQWaIpbDE/Vc0T7P0Fwd4+PjK36f5jpazutU+jmcq/YK0fplp+hMhrmOBLGJGQrxGIWG6LJzZC5PJJMj195Mw/gU+eY4C7H6V9uzOSK5eXKtTTSMTbH5sv6zPqfZdIbXvmnrGZ9T8pfDbNzex1zr4uHvwMBAVb5Pm+IFumILtEdfzXPX9j5mJ2adn9P0pm4i2RwTExMX9Bux2t+9lTC1Pr2Zi0OHDtnt27d7es3JkyfZvHlzlSIKHul+IN9Ruh/Id1zJ7/oDz3ren5epEG994+INdGuZtu7IkSOHd+/efeX5+hljrgE+Za39g+LzOwGstX9d0ufxYp9DxXsEkkCPLftHxxjzJPBxa+1PSrev5ndeCrX4PSmt3wupy6V6rCQz/V00nxo9a/uF1Pz5vn9rnXa0Gr6lPHAkec62rVe8hpfPMb3mod3//oL2/8S+N6zYfiHThV7I51CtaUdd+VkpL5X4vVwJV72tVGPVjmeJlX7jQ3PJkDEm6BCqinQ/kO8o3Q/kO0r3K+EZYJsx5mJjTAy4BThY1ucgcFvx8U3Ak9ZaW3xNPYAxZguwHXjZn7DXByGqI28srL8/YPqBLSwEHUJNonnxRmguGers7Aw6hKoi3Q/kO0r3A/mO0v2WsNbOG2NuBx4HIsBXrLVHjTF3Az+x1h4E7gW+aow5AYyxOGgAeDNwhzEmDywAf26tHfHfonYJSx15pWFc761wkXr57LMmiubFK6E5Q5BKpYIOoapI9wP5jtL9QL6jdL9SrLWPWmtfZ629xFp7T3HbXcXBANbarLX2Zmvtpdbaq6y1LxW3f9Vau9Nae7m19o3W2v8ZpEctEqY68kK2e+VroMNK3za9d8mF5sUboRkQnO9mivWOdD+Q7yjdD+Q7SvdT/EHryE10KhN0CDXJZHIy6BBqEs2LN0IzICgUCkGHUFWk+4F8R+l+IN9Rup/iD1pHbmwkNIcsnohEI0GHUJNoXrwRmm/XzMxM0CFUFel+IN9Ruh/Id5Tup/iD1pGb+aaGoEOoSVq6dGVrF5oXb6xpQGCMucEYc8wYc8IYc4ejvcEY8/Vi+9PGmK0lbXcWtx8zxixNXbfZGPOvxpifG2OOGmP+81riK6Wvr7pTggWNdD+Q7yjdD+Q7SvdT/EHryE18aCLoEGqSU0dPBx1CTaJ58caqBwTGmAjwReDtwA7gPcaYHWXd9gLj1tpLgS8Any2+dgeLM07sBG4AvlTc3zzwUWvtDuBqYL9jn6simTz3HL4SkO4H8h2l+4F8R+l+ij9oHbnJ9LYHHUJN0r9zY9Ah1CSaF2+s5QzBVcAJa+1L1toc8CBwY1mfG4H7i48fBnabxQmWbwQetNbOWWt/BZwArrLW/tpaewTAWjsFvAD0ryHGZaLRaCV2U7NI9wP5jtL9QL6jdD/FH7SO3NTN670VLvLZfNAh1CSaF2+sZR2CfuBkyfNBYNe5+hTnrZ4Euorbf1T22jMO/IuXF70BeLr8jVezpH1zczMDAwOBL/++1iXtV1quulpLcAfpVPo55fN5ZmdnRTmVfk6xWIyRkRFRTuWf0+zsLKdPnxblVPo5zc7OMjEx4XS6qKHA6xIFXpyJnLWk/UTeMJqr45LmAr+cinBRfIFEvcU0xejfuZHZiVnmZnJ09Lcz/GKKjv52oo1RTh09Tf/OjUyPTjPX1kw+EWd2dnbVTkpt0NbWFnQINUk0PRt0CDXJ+Cm9lMqF5sUbNbkwmTGmBfhn4MPW2nR5+4YNG/jBD35w1uu2bNmy/LijowOApqYmYPFgubS9q6sL4Izl4Uvbu7u7z9rW3Ny84nsu/aNbOmVcafvS9qV+5e3t7e1nvc9KTqXtpX5SnODMz2lgYICmpiZRTqXtAwMDXHTRRaKcllhyikajbNy4UZRT6bZoNLr8vuWv+fVckl/PLc56MZh5dfaL743Elh8vbV/qd81sjpeeeXm5ffz04j9w02Ov3nS61N7QXk/D5AxNTU2rdnrllVdQgmdkZMT5/Qg7c50JorNzQYdRc2y4pOeM3wRlEc2LN9ZyydApYHPJ803Fbc4+xaXq24DRlV5rjImyOBj4mrX2/11DfGcg/S8u0v1AvqN0P5DvKN1P8QetIzcxPUPgRP8S7kbz4o21DAieAbYZYy42xsRYvEn4YFmfg8Btxcc3AU9aa21x+y3FWYguBrYBPy7eX3Av8IK19m/XENtZ5HK5Su6u5pDuB/IdpfuBfEfpfoo/aB25KcRq8qKGwGlojp2/UwjRvHhj1d+u4j0BtwOPAxHgK9bao8aYu4GfFJevvxf4qjHmBDDG4qCBYr+HgJ+zOLPQfmttwRjzZuC9wM+MMc8V3+qT1tpHVxvnEpmM7BUOpfuBfEfpfiDfUbqf4g9aR24KjXqA56Kpven8nUKI5sUbaxpuFw/UHy3bdlfJ4yxw8zleew9wT9m27wNmLTGdC+nzOkv3A/mO0v1AvqN0P8UftI7c6DoEbnS+fTeaF2+EZqVi6fM6S/cD+Y7S/UC+o3Q/xR+0jtzoOgRudL59N5oXb4RmQBCLyT7VKN0P5DtK9wP5jtL9FH/QOnJTl5sPOoSaZE5nXnKiefFGaAYEiUQi6BCqinQ/kO8o3Q/kO0r3U/xB68hNdEbvrXCRHp4KOoSaRPPijdAMCEZHR4MOoapI9wP5jtL9QL6jdD/FH7SO3Mx16EDJRc/W7qBDqEk0L94IzYBgaREiqUj3A/mO0v1AvqN0P8UftI7cxCZ0kSkXoyfHgg6hJtG8eCM0AwLp07hJ9wP5jtL9QL6jdD/FH7SO3BTiem+FC51e043mxRuhGRBks9mgQ6gq0v1AvqN0P5DvKN1P8QetIzeFhmjQIdQk8URj0CHUJJoXb4RmQCB9XmfpfiDfUbofyHeU7qf4g9aRG12HwI3Ot+9G8+KN0AwIpM/rLN0P5DtK9wP5jtL9FH/QOnKj6xC40fn23WhevLGmlYrXE42Nsk8dSfcD+Y7S/UC+o3Q/xR8k1NEDRyo/qLloFn79i7P3e+jAsxV/r2pTyfxkptZ+idn158nhNWXx3vrG6p7FqkR+VsrL0v7XY+1Ui9CcIYjH40GHUFWk+4F8R+l+IN9Rup/iD1pHbmYnZoMOoSbRvLjRvHgjNAOC8fHxoEOoKtL9QL6jdD+Q7yjdT/EHrSM3XZs7gw6hJtG8uNG8eCM0A4Kurq6gQ6gq0v1AvqN0P5DvKN1P8QetIzepl0eCDqEm0by40bx4IzQDgqkp2UtYS/cD+Y7S/UC+o3Q/xR+0jty0btCVil1oXtxoXrwRmgFBLpcLOoSqIt0P5DtK9wP5jtL9FH/QOnLT0NQQdAg1iebFjebFG6EZEEif11m6H8h3lO4H8h2l+yn+oHXkRueVd6N5caN58UZoBgTS53WW7gfyHaX7gXxH6X6KP2gdudF55d1oXtxoXrwRmgGB9GncpPuBfEfpfiDfUbqf4g9aR250Gkk3mhc3mhdvhGZAEIvFgg6hqkj3A/mO0v1AvqN0P8UftI7czM3ovRUuNC9uNC/eCM2AYHJyMugQqop0P5DvKN0P5DtK9yvFGHODMeaYMeaEMeYOR3uDMebrxfanjTFbi9vfZow5bIz5WfH/b/E79lonTHXkhY7+9qBDqEk0L240L94IzYCgu7s76BCqinQ/kO8o3Q/kO0r3W8IYEwG+CLwd2AG8xxizo6zbXmDcWnsp8AXgs8XtI8AfWmsvA24DvupP1OuHsNSRV4ZfTAUdQk2ieXGjefFGaAYE0v/iIt0P5DtK9wP5jtL9SrgKOGGtfclamwMeBG4s63MjcH/x8cPAbmOMsdY+a61dmv7jKBA3xuj8gCWEqI48oX/xdaN5caN58UZ90AH4RT6fDzqEqiLdD+Q7SvcD+Y7S/UroB06WPB8Edp2rj7V23hgzCXSxeIZgiXcDR6y1c+VvMDw8zN69e6mvr6dQKLBnzx72799PMpmkubmZSCRCOp2mp6eHsbExrLX09PQwNDRES0sLANPT0/T29pJKpTDG0NnZSSqVorW1lUKhwMzMDH19fSSTSaLRKG1tbYyMjNDW1kYulyOTySy3x2IxEokEo6OjdHR0kMlkyGazy+2NjY3E43HGx8fp6upiamqKXC633B6Px4nFYkxOTtLd3c3k5CT5fH65vdQpn88zODhYU04XNRS4KL5Aot5immL079zI7MQsczM5OvrbGX4xRUd/O9HGKKeOnqZ/50amR6cp5Au09bWRPD5Ez9YuTKSO5C+H2bi9j3RqcQG21p4Ep3+RpO91G7CFBVIvj9K3rZfJ5CSRaISWrhZOHT3Nhkt6ABg/NcGGS3oYPzVBQ3OM67pzHJ6o54r2eabmDb/O1PG6RIEXZyJ0xRZoj9rl9om8YTRXxyXNBX45FamYUyFmyfS0EZ3JApBvbiSemiTb3QoLlobxabLdrUSnMthIHa99U+PyPvPZ/FlOTe1Ny+1zs3Okh6fo2drN6MkxmtqbiCdefX2iu4V0aoquzZ2kXh6hdUOChqYGTh09zXXdOUZzdUzNG7Y2FXhhqp4tTQWaIq/mZGiujvwCbIov8Hy6nm0tBeqN5Wfpei5vm+fX2Tq6t3ad8TnN9LWc5TQwMHDe2itE68n0tlOXmyc6k2GuI0FsYoZCPEahIUp8aIJMbzsXzS7eFOxyutDPqbU3wWsbt65Ye9d153husp7LWueZt4bj0xF+s3WewUwd0TrobVhYztNswTAwG+E3EvP8/+zde5xddX3v/9cnc8skmZkkM0MC4VoIpGCPgkjEKlZHEamVitjGFi+wJPXDAAAgAElEQVSVHH/1F7Raa0V7pNTqOV56pJ6j9hwPKFT9FZEWTSsoKioHDKgEtESKBCQQYJK5JDOZyUxmZuf7+2OvGXf2d81k1lz2Wuu73s/HYz+y91pr7/39vNfKd893r8t+4mAdLfWO9sbDs9722jesnbamoeM7qBsdY//+/bPqI+ba783EnHMzLpBF27Ztcxs2bEj0nEOHDtHUFO6XUKHXB+HXGHp9EH6NM9V34XUPJH6987/3zVkve/k55WvXr3/f5sTvM2n79u33d3V1nXu05czsMuAi59zm6PGbgI3OuSsrlnkoWmZ39PixaJne6PFZwFbgQufcY9XvMZd+PhRZ/H9Suf0m2S4XUtOyRg4d9E8U3db1u/N+7fnWNPn/b7a+vH3hLi07XS6wMNmAn09cvbPpex795HWzer+FyGemXCYtVD6zMdM2thD992zM1McX5pCh0K/rHHp9EH6NodcH4dcYen0VngZOqHh8fDQtdhkzqwfagL7o8fHArcCb4wYDRVeg7SgRXVc+nnKJp1ySKcyAYPny5Wk3YVGFXh+EX2Po9UH4NYZeX4WfAOvN7BQzawQ2Uf62v9JWyicNA1wG3Omcc2a2EvgmcJVz7p6atThHCrQdJTLUN5R2EzJJucRTLskUZkBQV1eXdhMWVej1Qfg1hl4fhF9j6PVNcs5NAFcC3wYeBm52zu0wsw+b2Wujxa4H2s1sJ/DnwOSlSa8ETgOuNrMHo9sxNS4h04qyHSVVGi+l3YRMUi7xlEsyhRkQDA4Opt2ERRV6fRB+jaHXB+HXGHp9lZxztznnTnfOneqc+2g07Wrn3Nbo/qhz7g3OudOcc+c55x6Ppn/EObfcOfe8itveNGvJmiJtR0m0rW1LuwmZpFziKZdkCjMg6OzsTLsJiyr0+iD8GkOvD8KvMfT6pDa0HcXrfnRP2k3IJOUST7kkU5gBQX9/f9pNWFSh1wfh1xh6fRB+jaHXJ7Wh7She58ntaTchk5RLPOWSTGEGBHm8vGoSodcH4dcYen0Qfo2h1ye1oe0ontUV5k+WRJRLPOWSTGHSCn0XbOj1Qfg1hl4fhF9j6PVJbWg7itf9S51qEke5xFMuyRRmQLBnT9jHkoVeH4RfY+j1Qfg1hl6f1Ia2o3jHbUj2419FoVziKZdkCjMgmPxJ51CFXh+EX2Po9UH4NYZen9SGtqN4gz0H0m5CJimXeMolmcIMCERERERExFeYAcHQUNi/WBd6fRB+jaHXB+HXGHp9UhvajuK1drak3YRMUi7xlEsyhRkQrFmzJu0mLKrQ64Pwawy9Pgi/xtDrk9rQdhTvmf/oTrsJmaRc4imXZAozIOjp6Um7CYsq9Pog/BpDrw/CrzH0+qQ2tB3FW3v6MWk3IZOUSzzlkkxhBgRmlnYTFlXo9UH4NYZeH4RfY+j1SW1oO4rnSofTbkImKZd4yiWZwgwIVq9enXYTFlXo9UH4NYZeH4RfY+j1SW1oO4rX80Rf2k3IJOUST7kkU592A2qlp6eHk046Ke1mLJrQ64Pwawy9Pgi/xtDrk9rQdhRv7fo1PP6TJ7zp53/vm7VvTIZMlwvMLpttXb+7wC3KhplySaKWGT76yeuOusz6921ekPeqVpg9BK2trWk3YVGFXh+EX2Po9UH4NYZen9SGtqN4A90DaTchk5RLPOWSTGEGBKVSKe0mLKrQ64Pwawy9Pgi/xtDrk9rQdhSvrqEu7SZkknKJp1ySKcwhQ8PDw3R0dKTdjEUTen0Qfo2h1wfh13i0+op+aIPMTuj/T+ZqRfsK9j7em3YzMke5xFMuyRRmD8HatWvTbsKiCr0+CL/G0OuD8GsMvT6pDW1H8Z7e8UzaTcgk5RJPuSQzrwGBmV1kZo+Y2U4zuypmfpOZfTWaf5+ZnVwx7wPR9EfM7FUV079gZnvN7KH5tK1ad3fYP1ARen0Qfo2h1wfh1xh6fVIb2o7irTvruLSbkEnKJZ5ySWbOAwIzqwM+C7waOBN4o5mdWbXYFcA+59xpwLXAx6PnnglsAs4CLgI+F70ewA3RtAXV0NCw0C+ZKaHXB+HXGHp9EH6NodcntaHtKN746HjaTcgk5RJPuSQznz0E5wE7nXOPO+fGgJuAS6qWuQS4Mbp/C9Bl5V9cuQS4yTl3yDn3K2Bn9Ho45+4C+ufRrlhtbW0L/ZKZEnp9EH6NodcH4dcYen1SG9qO4u17en/aTcgk5RJPuSQzn5OK1wFPVTzeDWycbhnn3ISZDQDt0fR7q567brZvvHfvXq644grq6+splUpceumlbNmyhe7ubpYvX05dXR2Dg4N0dnbS39+Pc46xsTHq6+tZsWIFAENDQ6xZs4aenh7MjNWrV9PT00NrayulUonh4WHWrl1Ld3c3DQ0NtLW10dvbS1tbG2NjY4yMjEzNb2xspKWlhb6+PlatWsXIyAijo6NT85cuXUpzczP79u2jvb2dAwcOMDY2NjW/ubmZxsZGBgYG6OjoYGBggPHx8an509XU2dnJnj17WLFiBT09PTQ3NwdVU/V62r9/P6eeempQNVWup5GRETo6OoKqqXo9PfbYY3R0dARVU+V6euyxxzjxxBNjazq2qcRvvOBk+p7qZ9nKZTS3LOXpHc+w7qzjGDkwysH9B2k/YTU9T/TSekwLTcuapuYf3H+QQ8NjrFq3kr2P9bBq3UoaljZMzR/qG+JQ23LGW5o5ePDgnGuSbOjt7WX58uVpNyNzjjm1k6H+4bSbkTnKJZ5yScacc3N7otllwEXOuc3R4zcBG51zV1Ys81C0zO7o8WOUBw3XAPc6574cTb8euN05d0v0+GTg35xzz4l7723btrkNGzYkau/+/ftZuXJloufkSej1Qfg1hl4fhF/jTPVdeN0Di3qVocvPKZ+IOp8frdm+ffv9XV1d5y5Um+ZjLv18KLL4/+TC6x6Yup/W1bJWHbeSfc9k81vfyf9/s/Xl7Qt3nsh8c5nNj2pVr/O4emfT98zmh7dgYfKZTS5zqX0xXifJ9rNYffx8Dhl6Gjih4vHx0bTYZcysHmgD+mb53AU1Nja2mC+futDrg/BrDL0+CL/G0OuT2tB2FK9peWPaTcgk5RJPuSQznwHBT4D1ZnaKmTVSPkl4a9UyW4G3RPcvA+505V0SW4FN0VWITgHWAz+eR1uOamRkZDFfPnWh1wfh1xh6fRB+jaHXJ7Wh7SjespXL0m5CJimXeMolmTkPCJxzE8CVwLeBh4GbnXM7zOzDZvbaaLHrgXYz2wn8OXBV9NwdwM3AL4BvAVuccyUAM/snYBtwhpntNrMr5trGSqFf1zn0+iD8GkOvD8KvMfT6pDa0HcXTdeXjKZd4yiWZef0OgXPuNufc6c65U51zH42mXe2c2xrdH3XOvcE5d5pz7jzn3OMVz/1o9LwznHO3V0x/o3PuWOdcg3PueOfc9fNp46TQr+scen0Qfo2h1wfh1xh6fVIb2o7i6bry8ZRLPOWSTGF+qbixMexjyUKvD8KvMfT6IPwaQ69PakPbUbxDBw+l3YRMUi7xlEsyhRkQtLS0pN2ERRV6fRB+jaHXB+HXGHp9UhvajuIN7j2QdhMySbnEUy7JzOd3CHKlr69v6lrcIQq9Pgi/xtDrg/BrDL2+vKi8ROZs3LH57EVqydwk3Y6S1ptXnSd3cKBnKO1mxFrIy4gmleVc0qRckinMHoJVq1al3YRFFXp9EH6NodcH4dcYen1SG9qO4vU91Z92EzJJucRTLskUZkAQ+mXcQq8Pwq8x9Pog/BpDr09qQ9tRPF1GMp5yiadckinMgGB0dDTtJiyq0OuD8GsMvT4Iv8bQ66tkZheZ2SNmttPMroqZ32RmX43m3xf9Aj1m1m5m3zezITP7TK3bnQdF2o6SaG5ZmnYTMkm5xFMuyRRmQBD6dZ1Drw/CrzH0+iD8GkOvb5KZ1QGfBV4NnAm80czOrFrsCmCfc+404Frg49H0UeBDwF/UqLm5U5TtKCldVz6ecomnXJIpzIAg9Os6h14fhF9j6PVB+DWGXl+F84CdzrnHnXNjwE3AJVXLXALcGN2/BegyM3PODTvn7qY8MJAYBdqOEtF15eMpl3jKJZnCXGVo6dKZdx3l/aoUR6svBKHXGHp9EH6NoddXYR3wVMXj3cDG6ZZxzk2Y2QDQDvTO5g327t3LFVdcQX19PaVSiUsvvZQtW7bQ3d3N8uXLqaurY3BwkM7OTvr7+3HO0dnZyZ49ezh9xQQAxy49zIMD9fxW6wQTznh0qI7ntE6we2QJDUtgTdNh7t9fz65du2hoaKCtrY3e3l7a2toYGxtjZGSEtWvX0t3dTWNjIy0tLfT19bFq1SpGRkYYHR2dmr906VKam5vZt28f7e3tHDhwgLGxsan5zc3NNDY2MjAwQEdHBwMDA4yPj0/Nr6xpyZIl7N69+4iaJq86NDQ0xJo1a+jp6cHMWL16NS/tGPNqev7KCQ6WjF0H6/jNlgmeOFhHS72jvfHX8w9MGM+OLOH0lhKPDdfR3niYlQ1uav7+caNvbAmnLi/xywN1HNt8mJZ6hy1rZN1Zx3Fw/0EODY+xat1K9j7Ww6p1K2lY2sDTO55h3VnHMdQ3RGm8RNvaNrof3UPnye1Y3RK6f7mX4zasZbCnfFnI1s4WnvmPbtaefgyudJieJ/pYu34NA90D1DXUsaJ9BU/veIaWjhWc8Fvr2Pf0fo45tZN9T++naXkjy1Yum3rPQwcPMbj3AJ0nd9D3VD/LVi6juWXp1PyRA6Mc3H+Q9hNW0/NEL63HtNC0rGlqfq1rWnfWcYyPjs+rpqYVTbStbZ1zTftaJhg/DMc3H+ahwXrWryhRb45/H6zneW0TPDu6hI6T24+oaXjtCpr2DTHa0UrDgRFc3RJ27do1tT1P9/+p1FDPyJqVLBmboGF4hEOrWmjcP0ypuZFSUwPNe/YzsmYlxx5k3uuprqGO33jByTOup5d2jB21j5jc3mdaTy/tGDvq/6f2DWunrWno+A7qRseoG5tgrHUZTf0HGG9dxuH6uqlM6g8ewkqH2bVrV2y/N1Mf0dPTQ2tr64x9rjnnZtM3Z8q2bdvchg0bEj1ncHBwKoxHP3mdN/9olwzb1vW7RzzO2oCgsr5QhV5j6PVB+DXOVN+F1z3A+d/75qK99+XnlA8zWf++zXN+je3bt9/f1dV17tGWM7PLgIucc5ujx28CNjrnrqxY5qFomd3R48eiZXqjx28Fzq18TqW59POT8v4FT9L/J7W+7OhibsczaVvbykD3YCrvnWXzzaX675s41et8sr+pNJu+J+7vrzgLcRnX2eQyl9oX43Xi8pzOYvXxhTlkaN++fWk3YVGFXh+EX2Po9UH4NYZeX4WngRMqHh8fTYtdxszqgTagryaty7kCbUeJtJ+wOu0mZJJyiadckinMgKC9vT3tJiyq0OuD8GsMvT4Iv8bQ66vwE2C9mZ1iZo3AJmBr1TJbgbdE9y8D7nR53CWdggJtR4n0PDGro80KR7nEUy7JFGZAcOBA2D9hHXp9EH6NodcH4dcYen2TnHMTwJXAt4GHgZudczvM7MNm9tposeuBdjPbCfw5MHVpUjN7AvgU8FYz2x1zhaJCK8p2lFTrMS1pNyGTlEs85ZJMYU4qHhsbS7sJiyr0+iD8GkOvD8KvMfT6KjnnbgNuq5p2dcX9UeAN0zz35EVtXM4VaTtKomlZU9pNyCTlEk+5JFOYPQShX9c59Pog/BpDrw/CrzH0+qQ2tB3F03Xl4ymXeMolmcIMCEK/rnPo9UH4NYZeH4RfY+j1SW1oO4qn68rHUy7xlEsyhRkQNDc3p92ERRV6fRB+jaHXB+HXGHp9UhvajuId3H8w7SZkknKJp1ySKcyAoLGxMe0mLKrQ64Pwawy9Pgi/xtDrk9rQdhTv0LDOrYijXOIpl2QKMyAYGBhIuwmLKvT6IPwaQ68Pwq8x9PqkNrQdxVu1bmXaTcgk5RJPuSRTmAFBR0dH2k1YVKHXB+HXGHp9EH6NodcntaHtKN7ex3rSbkImKZd4yiWZwgwIQv/GJfT6IPwaQ68Pwq8x9PqkNrQdxdM3vvGUSzzlkkxhBgTj4+NpN2FRhV4fhF9j6PVB+DWGXp/UhrajeA1LG9JuQiYpl3jKJZnCDAhCv65z6PVB+DWGXh+EX2Po9UltaDuKp+vKx1Mu8ZRLMoUZEIR+XefQ64Pwawy9Pgi/xtDrk9rQdhRP15WPp1ziKZdkCjMgWL58edpNWFSh1wfh1xh6fRB+jaHXJ7Wh7SjeUN9Q2k3IJOUST7kkU5gBQV1dXdpNWFSh1wfh1xh6fRB+jaHXJ7Wh7SheabyUdhMySbnEUy7JFGZAMDg4mHYTFlXo9UH4NYZeH4RfY+j1SW1oO4rXtrYt7SZkknKJp1ySKcyAoLOzM+0mLKrQ64Pwawy9Pgi/xtDrk9rQdhSv+9E9aTchk5RLPOWSTH3aDaiV/v5+li1bNufnn/+9bx7x+NF998+4/Pr3bZ7ze83FfOvLg9BrDL0+CL/G0OuT2tB2FK/z5HZ2Pbg77WZkjnKJp1ySKcweAudc2k1YVKHXB+HXGHp9EH6NodcntaHtKJ7VFeZPlkSUSzzlkkxh0gp9F2zo9UH4NYZeH4RfY+j1SW1oO4rX/cu9aTchk5RLPOWSTGEGBHv2hH0sWej1Qfg1hl4fhF9j6PVJbWg7infcBv1gWxzlEk+5JFOYAcGKFSvSbsKiCr0+CL/G0OuD8GsMvT6pDW1H8QZ7DqTdhExSLvGUSzKFGRCIiIiIiIivMAOCoaGwf7Eu9Pog/BpDrw/CrzH0+qQ2tB3Fa+1sSbsJmaRc4imXZAozIFizZk3aTVhUodcH4dcYen0Qfo2h1ye1oe0o3jP/0Z12EzJJucRTLskUZkDQ09OTdhMWVej1Qfg1hl4fhF9j6PVJbWg7irf29GPSbkImKZd4yiWZwgwIzCztJiyq0OuD8GsMvT4Iv8bQ65Pa0HYUz5UOp92ETFIu8ZRLMoX5peLVq1cv6Ot9efvMu6K2XfdAoter/iXkpJatbObS32ibcZn5/nryhQlrArhj89nzes9Kk+vw0U9eNzXtaOth0rau313w9lSrbNdsVK+Phd5Gs2j16tWJc4La/PL3fNcfFGMdyuLTdhSv54m+tJuQScolnnJJpjB7CELfBbt2ffjHnIa+DkOvD8KvMfT6pDa0HcUrwufcXCiXeMolmcIMCFpbW9NuwqIa6B5IuwmLLvR1GHp9EH6NodcntaHtKF4RPufmQrnEUy7JFGZAUCqV0m7CoqprqEu7CYsu9HUYen0Qfo2h1ye1oe0oXhE+5+ZCucRTLskUZkAwPDycdhMW1Yr28H/ZMvR1GHp9EH6NodcntaHtKF4RPufmQrnEUy7JFGZAsHbt2rSbsKie3vFM2k1YdKGvw9Drg/BrDL0+qQ1tR/GK8Dk3F8olnnJJpjADgu7usH+gYt1Zx6XdhEUX+joMvT4Iv8bQ65Pa0HYUrwifc3OhXOIpl2TmNSAws4vM7BEz22lmV8XMbzKzr0bz7zOzkyvmfSCa/oiZvWq2rzlXX//61xfqpTLp/953V9pNWHShr8PQ64Pwawy9vkqL0f9LWZG2oySK8Dk3F8olnnJJZs4DAjOrAz4LvBo4E3ijmZ1ZtdgVwD7n3GnAtcDHo+eeCWwCzgIuAj5nZnWzfM05+Zd/+ZeFeJnM+tH996TdhEUX+joMvT4Iv8bQ65u0GP1/rdqeB0XZjpIqwufcXCiXeMolmfnsITgP2Omce9w5NwbcBFxStcwlwI3R/VuALiv/BOMlwE3OuUPOuV8BO6PXm81rzsnExMRCvExm1TeF/xtzoa/D0OuD8GsMvb4Ki9H/S6RA21EiRficmwvlEk+5JGPOubk90ewy4CLn3Obo8ZuAjc65KyuWeShaZnf0+DFgI3ANcK9z7svR9OuB26OnzfiaALfddtuBZ599dmow09ra2rN69eremdrb39/fcbRl8iz0+iD8GkOvD8KvMYD6Turq6uo82kKL0f87526pfI+59POhCGA7WhTKJZ5yiadcYk3bx+dy+HTxxRe3pN0GERFZPOrnRURqZz6HDD0NnFDx+PhoWuwyZlYPtAF9Mzx3Nq8pIiLpWoz+X0REUjKfAcFPgPVmdoqZNVI+SWxr1TJbgbdE9y8D7nTlY5S2Apuiq1CcAqwHfjzL1xQRkXQtRv8vIiIpmfOAwDk3AVwJfBt4GLjZObfDzD5sZq+NFrseaDezncCfA1dFz90B3Az8AvgWsMU5V5ruNefaxkmLdSnTWjOzJ8zs383sQTP7aTRttZl9x8wejf5dFU03M/sfUc0/N7Nz0m29z8y+YGZ7o2ONJ6clrsfM3hIt/6iZvSXuvdIyTY3XmNnT0Xp80MwurphX08vxzpeZnWBm3zezX5jZDjP7s2h6EOtxhvqCWYdzsRj9f61ryKKQtpH5SvL5UBRJ+9siMbOlZvZjM/tZlM3fRNNPsfJlj3da+TLIjWm3NbOcc0HfgDrgMeA3gEbgZ8CZabdrjrU8AXRUTfsEcFV0/yrg49H9iymfqG3AC4H70m5/TD0XAOcAD821HmA18Hj076ro/qq0aztKjdcAfxGz7JnR9tkEnBJtt3VZ3oaBY4FzovstwC+jOoJYjzPUF8w61C0bN20jXh6z/nwoyi1pf1ukW/SZsiK63wDcF33G3Axsiqb/L+Adabc1q7ci/FLxol3KNCMqL+13I/D7FdP/0ZXdC6w0s2PTaOB0nHN3Af1Vk5PW8yrgO865fufcPuA7lK9tngnT1Didml+Od76cc88657ZH9w9Q/rZ4HYGsxxnqm07u1qFkhraRCgk/HwphDv1tYUSfKUPRw4bo5oCXU77sMRQ0m9kqwoBgHfBUxePdzPyBnmUOuMPM7jezt0fT1jjnno3udwNrovt5rTtpPXmt88rokJkvVOzezXWNVv4l2rMpfzMT3Hqsqg8CXIeSKm0jRzddv1I4s+xvC8XKP3D7ILCX8pdKjwH7XfkQR9D/qRkVYUAQkhc7586h/OugW8zsgsqZrrxPbG4/LJFBodVT4R+AU4HnAc8C/z3d5syfma0A/hl4t3NusHJeCOsxpr7g1qFInoTQr8xV6P3tXLnyuajPo3zlsvOADSk3KVeKMCAI5hJ3zrmno3/3ArdS3uD3TB4KFP27N1o8r3UnrSd3dTrn9kQd12Hg//DrX2nNZY1m1kD5w+krzrl/iSYHsx7j6gttHUomaBs5uun6lcJI2N8WknNuP/B94HzKh6VO/uaW/k/NoAgDgiAuZWpmy82sZfI+cCHwEEde2u8twDei+1uBN0dXdXkhMFCxSzHLktbzbeBCM1sVHbZxYTQts6rO5Xgd5fUIObwcr5kZ5avJPOyc+1TFrCDW43T1hbQOJTO0jRzddP1KIcyhvy0MM+s0s5XR/WbglZTPsfg+5cseQ0GzmbW0z2quxY3ylU1+Sfl4sr9Kuz1zrOE3KF914mfAjsk6gHbge8CjwHeB1dF0Az4b1fzvwLlp1xBT0z9RPtxinPKxfVfMpR7gbZRP3twJ/Enadc2ixi9FNfycckd+bMXyfxXV+Ajw6qxvw8CLKe+e/jnwYHS7OJT1OEN9waxD3bJz0zZyRBaz/nwoyi1pf1ukG/CfgAeibB4Cro6m/wblL2V2Al8DmtJua1ZvFgUmIiIiIiIFVIRDhkREREREZBoaEIiIiIiIFJgGBCIiIiIiBaYBgYiIiIhIgWlAICIiIiJSYBoQiIiIiIgUmAYEIiIiIiIFpgGBiIiIiEiBaUAgIiIiIlJgGhCIiIiIiBSYBgQiIiIiIgWmAYGIiIiISIFpQCAiIiIiUmAaEIiIiIiIFJgGBCIiIiIiBaYBgYiIiIhIgWlAICIiIiJSYBoQiIiIiIgUmAYEIiIiIiIFpgGBiIiIiEiBaUAgNWVmJ5uZM7MXp9yOJ8zsv9TgfTJRr4jIQshKnxZqHx691+XTPc4CM7vGzHam3Q5ZWBoQyKyZ2Q1R5+TMrGRmu83sH81sXdpty5PpOngze6uZTaTRpjSY2V+Z2f81s8Eok+PTbpNIyNSHz5+Z3WVmX62adnaU6XTTL6htK4/OzOrN7L+a2QNmdsDMes3s22a2sYZteJ2Z3W5m3Vkc+BSNBgSS1P8FjgVOBP4IOBv4WqotklSYWeM8X6IJ2Ap8dAGaIyKzoz58fr4HvMzMrGJaF/DkNNOHgW01bN9RRX13E3A+8N+BFwK/A3QD3zWzU2vUlBXAj4E/rdH7yQw0IJCkxpxz3c65p51zdwGfB843s1YAM2sxs/9tZj1mdsjMfmpmF8a8zslm9j0zGzGzx81sU+VMMzvDzL5pZkPR7V/N7LSK+a1m9sXom4VDZvaUmX2q6jW2mNkvovl7zeyfq9rQaGafNrN+M9tjZteaWX3F8xvM7GNm9rSZjUWv9UdV73Gsmd1kZvujWn5gZufOLVqfmV1sZvdX1PA5M1teMf8GM/uumb0naudBM/uama1Osky03CYze9DMRq28O/5TVe/1AzO73sz+1syepfwBGNfmV0bfPh5fNf0Po/duBXDOXe2c+yRw38KkJSKzoD78yPdI2od/D+gEfqtiWhfwP4HGmOl3OefGo/f6IzO7z8wGrPyN/DfN7PQZ3stjZpdb+Rv9N1RMS9x3O+eGnXMvc8592Tm3wzn3EPA2YAK4uOK5S83sH6I27zOzf6A8mJipja1RX1+d9XFmNmFmrwBwzn3JOffXzrmvJ8lAFocGBDJnZnYccBlQim4AXwBeBVwOPA+4B/g3M9tQ9fRPRMs+D/j/gK+Y2dnR6zYDdwBLgZdGtxXAt+zX30p/BDgHuARYD/wh8HBF2/4G+DjwOcod9EXA9qo2vBN4FtgY3b8SeEvF/P8K/Gfg3cBzgC8DXzazrug9DPg6sAF4DXAesAf4jpl1HCW+ozKz/0T5G/S7gOdGbXsN8L+qFiX4OvUAACAASURBVD0PeFlU48WUM70+yTJm9lbgHyh/W3Qm8GbgFTHv9QeUPwy7gFdO0/TvUc71j6umvwX4unNucJrniUgNqQ+fUx9+H+Vv/SdfowF4CfAdyn119fTvVTy3qaLuV1LO/Js2y72tZvaXwGeA1zrnvhZNeysL13c3Ux7UDFdM+2/A66PXPT+at2WmdkZ9/NeBN1XNupzy+rpzpudLSpxzuuk2qxtwA+VvD4aAg4CLbn8XzT8tenxx1fO2A1+I7p8cLfO3Vcv8CPhSdP+K6PU7KuavAUaAN0ePvwHcME07l0fL/sUMtTwBbK2adjvwT9H9ZcAh4P+tWuZW4M7ofldUy5kV85sod3hXV9X74oplHDAa5Vh5GwUmKpb7EvDjqve/BDgMnFSxToaAtoplLoze47QEyzwB/GnVe10QLbMqevwD4JfAkllsKx8DHqpafxPAq2KW/Z3ofY5PexvXTbeQb+rDF6wPvw341+j+i4FewID3VE13wHNnqGF1tMxvV0xzwOVVj98MfBp4pvr1FrLvBq6LXm9FxXoYBf5z1XI/BXYe5bUuira1tRXT/h34b9Msf0TdutX+pj0EktR9lL8ROg/4W8rHRk5e6eHM6N+7qp5zF3BW1bTqYyrvqVjmLOAXzrneyZnOuT3AIxXLfA64zMweinYZv9rMllQ8fynlb6hm8mDV42cof2hB+YOxMaaWH1a1s88594uKdh6inFF1vdX+inKOlberq5Y5a5r3N36dNZSzGqh4fE/076yWMbNO4CTgUxW794cof7hCOYtJ9zvnDk8+MLM/rnyOmU3uFbgROMvMzoke/zGwF/guIpIm9eHz78O/C7w0OjypC/iBK/9V+/2q6T3AzyefZGbPM7NbzexXZnaAXx92edJR6vwI5fM9XuSc+1nF6825765mZh8Dfp/y3oehaPKplAdIP6pa/O6K551Y9RkwuWfiO5T7/D+KljuH8l6afzxKrZKS+qMvInKEEefc5OXGHrLyyUf/k/Ju2Zpxzn3bzE6kvGv7dyjvCv73yV3BszRW/bLU7jC6PRU5AmBme2v03tUma/4zyh9o1XZX3B+umreVI88B2APgnHvYzH5K+Zut7dG/X3bOlRCRNKkPn7/vUT5E5wWU//C/KZr+c2C8Yvqd0UABM1tGeYBzN/AnRH0lsIPywGUm36V8SNUmyntfJ82n7yZql1He+/BGoMs59/O45WbwDOUB5qRBAOdcycy+Qrnv/1T070+ccw/7LyFZoD0EMl/XAH8SnYS1I5pWfYm1C4CHqqa9sOrxi4DJb2l2UP7meuoYTjNbA5xR+TrOuX7n3D855/4f4HcpH6d6ZvQ6o5QPi5mrnZR3N1fX8tKKNuwA2s1s6pt4M2uifDxrdb1zsWOa93f8OmuA37TohMDIi6J/fzGbZaJv7p4CznDO7Yy5jU7XQOfcgaplD1TMvhF4Y/TN0HPRN0MiWXQN6sOT9uE/p3yY0O9RzuHOqJ7DlPdATE6v3CP6m5SP4f8r59wPoj+MV1He43s0d1I+9+u/mNmHJifOp++Oaq2jfB7IG4Dfqdz7EHmM8qDrRVXTf7uiDRNV71n5xdaNwHOjc0veiD4Dsi3tY5Z0y8+N8vGn342Zfivw7ej+zZSPQXwV5RO1Pk25Q9kQzT+Z8h+0T1PelXg68GHKx8WfEy3TDOyi/C3MOcDzKX/7sRNojJb5KHAp5Q+Y9ZS/4TpAdJw85V2sQ5RPfjqd8h+kH6ho8xPAf6mq4zrKu34nH38C6KPcWZ4OfDBqZ1c03yh/O/4g5Q7yOcBXgX1Ex84y/TkE3rGSwFs58hyC/0T5GMxroywvoryL+UtV62TyBK7nUP7w+yXwjYTLvClaT38VLXMG5d3H/7timR8A1yXYXtqj13yA8u7q6vknUv5maXOUyYXR49Vpb+u66RbiDfXhC9KHR9O/GvWrT1dNf2c03QGnVEzvoDzI+RzlQ3G6gJ9E7XlrxXJx5xBcHt3/7ei1P1wxf059N+UjRL4W5fMSYG3FbUXFcp+mvDfjtdFrfyJqw4znEFQ8fzvlz4BDQHvVvNX8+pBZF62f5wEnpv1/pYi31BugW35uTP9h8qLoP/PvAK3A/6Z87OQhyicfXVix7GTn+qaokxoFfgX8UdVrnkH5xK3JE27/jegE2Gj+hyh/gzMEDFD+Vqbyj26jvBv1kaiz3AN8rWL+Exz9w6SB8u7Zp6PX+EVMO4+lvLt4P+WT4H4InBtTb+IBQTTtYuD+KMseyleTWF69ToC/oHwi3EHgnys73tksEy33+5SPCz4YdfgPEp1YF83/AQkGBNFzbo3q/bNpticXc3tr2tu6brqFeFMfvjB9eDT97dH0L1dNf040/bGYnC8DHo0ye4Dy3ooJZjkgiB5vjNr6sYppifvuirribtdULNccbQ8D0e3zlK88NNsBwZ9Fr3lrzLy3TvP+N6T9f6WIN4tWiojkkJndQPnqPK+YzzIiIiJSXDqHQERERESkwDQgEBEREREpMB0yJCIiIiJSYNpDICIiIiJSYLn8YbIf/OAHrqmpKe1mLKiJiQnq63O5OlKhvJJRXskUNa+DBw/2dnV1dabdDph9P1/UdTUTZeJTJj5l4gs9k5n6+FxW3dTUxIYNG9JuxoLat28fq1atSrsZuaG8klFeyRQ1r+3bt+9Kuw2TZtvPF3VdzUSZ+JSJT5n4Qs9kpj5ehwxlRKlUSrsJuaK8klFeySiv/NC68ikTnzLxKRNfkTPRgCAjhoeH025CriivZJRXMsorP7SufMrEp0x8ysRX5Ew0IMiItWvXpt2EXFFeySivZJRXfmhd+ZSJT5n4lImvyJnk8hyCOM45hoaGyOtlVIeHh1m+fPmCvZ6ZsWLFCsxswV4zS7q7uznppJPSbkZuKK9klFc2xfXzC9135sVMfby2X58y8SkTX5EzCWZAMDQ0RFNTE42NjWk3ZU6WLl26oG0fGxtjaGiIlpaWBXvNLGloaEi7CbmivJJRXtkU188vdN+ZFzP18dp+fcrEp0x8Rc4kmEOGnHO5/lCoq6tb0NdrbGzM7d6S2Whra0u7CbmivJJRXtkU188vdN+ZFzP18dp+fcrEp0x8Rc4kmAFB3k1MTKTdhFzp7e1Nuwm5orySUV75ob7Tp+3Xp0x8ysRX5Ew0IMiIon7LNVdFHsXPhfJKRnnlh/pOn7ZfnzLxKRNfkTMJ5hyCahde98CCvt4dm89e0NerNpfDe775zW9y6qmnBvcjbbMxNjaWdhNyRXklo7zyIW/9fFJz7eO1/fqUiU+Z+IqcifYQZMThw4cTLT8xMcFtt93GI488skgtyraRkZG0m5AryisZ5SVpm08fr+3Xp0x8ysRX5Ew0IFhgN998M694xSu44IILeM973sNTTz3FueeeS19fH4cPH+biiy/mzjvv5Mknn2Tjxo28/e1vn/r34MGDADz44IO85jWv4WUvexmvf/3r6e7uBuD3fu/3+MAHPsDLX/5yPv3pT3P77bfz13/911xwwQX86le/SrPsmivytYLnQnklo7xkOnPt49/ylrfUrI/X9utTJj5l4ityJhoQLKBHHnmEW2+9ldtvv5277rqLuro67rnnHt71rnfx3ve+l8985jOcccYZvPzlLwfg0Ucf5W1vexv33Xcfy5cv5/rrr2d8fJz3v//93HDDDXz/+9/nj//4j/nIRz4y9R7j4+PceeedvPe97+XVr341f/M3f8Ndd93FKaecklbZqZj8AJXZUV7JKC+JM58+vqWlpWZ9vLZfnzLxKRNfkTMJ9hyCNNx111387Gc/o6urC4DR0VE6Ojq46qqr+MY3vsENN9zAD3/4w6nl161bxwtf+EIALrvsMr7whS/Q1dXFww8/zKWXXgpAqVRizZo1U8953eteV8OKsivPl5hNg/JKRnlJnPn08X/wB3/A5z//+Zr08dp+fcrEp0x8Rc5EA4IF5Jxj06ZNXH311UdMP3jwIM888wxQ/lXNyR+SqfyFySVLlkw93rBhA3fccUfseyxbtmwxmp47of7g2mJRXskoL4kznz6+8vFi9/Hafn3KxKdMfEXORAOCBXTBBRdw+eWX8453vIPOzk727dvH0NAQn/nMZ3jDG97ACSecwLvf/W5uuukmAHbv3s2Pf/xjzjvvPG655RY2btzIaaedRl9f39T08fFxdu7cyW/+5m9677dixQqGhoZqXWYm9PX1sWLFirSbkRvKK5mFzivp1XCydrUbKctLH6//7z5l4lMmvixlUvm5UYvPhGAHBGl8oG7YsIEPfvCDvP71r+fw4cM0NDTwkY98hO3bt/Otb32Luro6/vVf/5WvfOUrvOQlL2H9+vVcf/31vPOd7+T000/nbW97G42Njdxwww1cddVVDA4OMjExwZ/+6Z/Gfli87nWv493vfjef//znueGGGwp1HsGqVavSbkKuKK9klFc+3LH5bEqlUs1+i2A+ffwZZ5xRsz5e269PmfiUia/Imdhcrn+ftm3btrnq6zIPDg7S2tqaUouSe/LJJ9m0aRM/+tGPgPKJZA0NDQv6HnnLJIk9e/YccdytzEx5JbPQeeVlD8H27dvv7+rqOjeVN68y235+MfrOhVDdxy+G6fp4/X/3KROfMvFlKZPF2EMwUx+vqwxlRNLfISi60dHRtJuQK8orGeWVH+o7fdp+fcrEp0x8Rc5EA4KUnHjiiUd8c5TFb7iyrMjXCp4L5ZWM8sqPrPad1X18LWn79SkTnzLxFTkTDQgyYnx8PO0m5EqRrxU8F8orGeWVH+o7fdp+fcrEp0x8Rc5EA4KMWLJEqyKJpUuXpt2EXFFeySiv/FDf6dP261MmPmXiK3Im6kkzQh9qyTQ3N6fdhFxRXskor/xQ3+nT9utTJj5l4ityJupJM2JiYiLtJuTKvn370m5CriivZJRXfqjv9Gn79SkTnzLxFTmTYH+H4NFPXregr7f+fZsX9PWq1dcfuSqe+9zncuedd9Le3j7tc2azTKiKWPN8KK9klFc+PPrJ63DOeb8IPFeL3c9XWsw+XtuvT5n4lImvyJloD0FGlEqltJuQKwcOHEi7CbmivJJRXmVmdpGZPWJmO83sqpj5TWb21Wj+fWZ2cjS93cy+b2ZDZvaZiuWXmdk3zew/zGyHmX1svm3UZUd92n59ysSnTHxFzkQDggX05JNPsnHjRrZs2cILXvAC3v72t/ODH/yAiy66iHPPPZf777+fffv2cfnll/PiF7+YV77ylezYsQMo/1z2pZdeyvnnn8+73vUuKn8w7uabb+YVr3gFF1xwAe95z3s0eADGxsbSbkKuKK9klBeYWR3wWeDVwJnAG83szKrFrgD2OedOA64FPh5NHwU+BPxFzEv/nXNuA3A28Ntm9urFaP9imE8f39/fX7M+XtuvT5n4lImvyJloQLDAHn/8cbZs2cJ9993Ho48+yi233MLtt9/Ohz/8Ya699lo+9rGP8Vu/9VvcfffdfOhDH+Id73gHAH//93/PC1/4QrZt28ZrXvMadu/eDcAjjzzCrbfeyu23385dd91FXV0dX/va19IsMROKfK3guVBeySgvAM4DdjrnHnfOjQE3AZdULXMJcGN0/xagy8zMOTfsnLub8sBginPuoHPu+9H9MWA7cPx8Glnrk4rn2sd/4hOfqFkfr+3Xp0x8ysRX5EyCPYcgLSeddBJnnln+Em3Dhg289KUvxcw488wzefLJJ3nqqae48cby5+cFF1xAf38/g4OD/OhHP+JLX/oSABdeeCErV64E4K677uJnP/sZXV1dQPlX9Do6OlKoLFu6u7s56aST0m5GbiivZJQXAOuApyoe7wY2TreMc27CzAaAdqD3aC9uZiuB3wM+HTd/7969XHHFFdTX11Mqlbj00kv5kz/5Ew4dOsSSJUswM0ql0hHnECxZsoTDhw9PPXbOTU2bzfxSqcTExAR1dXU45zh8+DANDQ2Mj49Pvd+JJ57IGWecQalUYv369bzkJS9hbGyM9evXs2vXLp588km++MUvMjY2xsaNG+nv76e3t5d77rmHL37xixw6dIiuri5WrlzJoUOH+OEPf8iDDz7Iy1/+cqDcx7e3tzM2NjbVhkOHDlFXVzfVxoaGBiYmJjh48CD19fX09PTQ2tpKqVRieHiYUqlEXV0dDQ0NtLW10dvbS1tbG2NjY4yMjLB27Vq6u7tpbGykpaWFvr4+Vq1axcjICKOjo1Pzly5dSnNzM/v27aO9vZ0DBw4wNjY2Nb+5uZnGxkYGBgbo6OhgYGCA8fHxqfnLly+nrq6OwcFBOjs76e/vxzlHZ2cne/bsYcWKFQAMDQ2xZs0aenp6MDNWr17t1TT5mnOtaTKTkGqa73qazCSkmua7nkZHR2loaMhETS9YNc6yOsf9++vZtWvXgqynmWhAsMAaGxun7i9ZsmTq8ZIlS5iYmEj8q5rOOTZt2sTVV1+9oO3MuyJfGmwulFcyymtxmVk98E/A/3DOPR63zDHHHMM999xzxLTBwUGampqmHtfV1XH48OEj9hJM/uFcqXLaTPPr6upi50++Z11dHU1NTVPLNTQ0sHTpUpqammhqapr6Y72uru6Iz4LGxkbMjPr6+iPaP3n/jW98Y2wfb2YsWbLkiOdMXoCisbGRZcuWsWzZsiMGrx0dHezdu5djjjlmatry5cu91658zuQfEpV/MFTOn5w+uVz1/MkvsCrfp3L+qlWrAFi2bFns/MkTOU844YTY+ZNfglVOS1pTdSYh1FQ9P2lN1ZmEUFP1/KQ1VWeSZk0/2dcQO38+6+lXv/qV1/ZJs9rXOtcTy6J5H4imP2Jmr4qmLTWzH5vZz6ITy/6mYvlTotfYGb1mY/X75dn5558/tTv47rvvpr29ndbWVs4//3xuueUWAL7zne+wf/9+oLwXYevWrfT09ADlS2I99dRT8S9eIJUftnJ0yisZ5QXA08AJFY+Pj6bFLhP9kd8G9M3itT8PPOqc+/sFaGemTNfHv+hFL6pZH6/t16dMfMrEV+RMjrqHoOLEsldS3mX8EzPb6pz7RcViUyeWmdkmyieW/WF0Atom4CzgOOC7ZnY6cAh4uXNuyMwagLvN7Hbn3L3Rc691zt1kZv8reu1/SFpYLS8fl8T73/9+3vnOd/LiF7+Y5uZmPve5zwHwnve8hy1btnD++edz3nnncfzx5cNqN2zYwAc/+EFe//rXT+2+/sQnPnHEyK+IBgYGpkbRcnTKKxnlBcBPgPVmdgrlP/w3AX9UtcxW4C3ANuAy4E5XebZsDDP7COWBw7w76fXv28yhQ4eO+AY9bdP18X/5l3/J5s2ba9LHa/v1KROfMvEVORM7St+NmZ0PXOOcm/x2/wMAzrn/VrHMt6NltkXfEnUDncBVlctWLlfx3GXA3cA7gB8DPcDa6HjUI9570rZt29yGDRuOaOfg4OBRj4/Ksslj+RZS3jOZyfDwcOxuO4mnvJJZ6LwuvO6BRMvfsfnsBXvvJLZv335/V1fXuZOPzexi4O+BOuALzrmPmtmHgZ8657aa2VLgS5SvGNQPbJo8BMjMngBagUZgP3AhMEj5nIP/oPzFEMBnnHPeD8fMtp9fjL4zL6br4/X/3adMfMrEl6VMKj83FuozobqPrzSbcwjmc2LZOuDequeug6k9D/cDpwGfdc7dZ2YdwH7n3ET18pVme7LZ5HwoH3c5Pj4ee2IWlI8NnelkstnOr6+v5/Dhw0fMX7JkydQ5BJNtcs4dMX/yZLbp5s+lpomJCXbt2pWJk2MW+sSs8fFxVq5cGVRNi7mennzySU4++eSgalrM9dTf309jY+OC1XTOynGeHVnC6S0lHhuuo73xMCsbyieLPX/lBPvHjb6xJZy6vMQvD9Tx7LPPprKeqjnnbgNuq5p2dcX9UeAN3hPL806Omw4szK+IRYo8IJjOwMBAZv6oyQpl4lMmviJnMps9BJcBFznnNkeP3wRsdM5dWbHMQ9Eyu6PHj1EeNFwD3Ouc+3I0/XrgdufcLRXPXQncCryT8p6Fe6NrWmNmJ0TLP6eyTSHuIViM3d55z2Qmu3bt0lVgElBeySx0XnndQ5Cm2fbzWTtkqJam6+P1/92nTHzKxJelTGq9h2A2JxXP58Syoz7XObcf+D5wUfScldFrTPdeQUp69aGiK/K1gudCeSWjvPJDfadP269PmfiUia/ImcxmQDB1Yll0xZ9NlE8kqzR5YhkceWLZVmBTdBWiU4D1wI/NrDPaM4CZNVM+Yfk/oud8P3oNotf8xmwKMbNc/8Lc+Pj4gr7e2NjY1LW2Q9Td3Z12E3JFeSWjvLIprp9f6L4zL2bq47X9+pSJT5n4ipzJUc8hiM4JuBL4Nr8+sWxH5YllwPXAl8xsJ9GJZdFzd5jZzcAvgAlgi3OuZGbHAjdG5xEsAW52zv1b9JbvB26KrkTxQPTaR7VixQqGhoYYHR09+sIZNDo6ytKlSxfs9czsiGvchqaox/jNlfJKRnllU1w/v9B9Z17M1Mdr+/UpE58y8RU5k1n9MNk8Tyz7KPDRqmk/p3xVirjlHwfOm027KpkZLS0tSZ+WGaVSKdjj/ReDTiJMRnklo7yyKa6fV9/p0/brUyY+ZeIrciaz+mEyWXyDg4NpNyFXlFcyyisZ5ZUfWlc+ZeJTJj5l4ityJhoQZERnZ2faTcgV5ZWM8kpGeeWH1pVPmfiUiU+Z+IqciQYEGdHf3592E3JFeSWjvJJRXvmhdeVTJj5l4lMmviJnogFBRhzt9yDkSMorGeWVjPLKD60rnzLxKROfMvEVORMNCDKiyLup5kJ5JaO8klFe+aF15VMmPmXiUya+Imcyq6sMyeLbs2dPZn4dLw+UVzLKK5ks5fXoJ69LtPz6921epJZkU5bWVVYoE58y8SkTX5Ez0R6CjAj5NwMWg/JKRnklo7zyQ+vKp0x8ysSnTHxFzkQDAhERERGRAtOAICOGhobSbkKuKK9klFcyyis/tK58ysSnTHzKxFfkTDQgyIg1a9ak3YRcUV7JKK9klFd+aF35lIlPmfiUia/ImWhAkBE9PT1pNyFXlFcyyisZ5ZUfWlc+ZeJTJj5l4ityJhoQZISZpd2EXFFeySivZJRXfmhd+ZSJT5n4lImvyJloQJARq1evTrsJuaK8klFeySiv/NC68ikTnzLxKRNfkTPRgCAjirybai6UVzLKKxnllR9aVz5l4lMmPmXiK3ImGhBkRGtra9pNyBXllYzySkZ55YfWlU+Z+JSJT5n4ipyJBgQZUSqV0m5CriivZJRXMsorP7SufMrEp0x8ysRX5Ew0IMiI4eHhtJuQK8orGeWVjPLKD60rnzLxKROfMvEVORMNCDJi7dq1aTchV5RXMsorGeWVH1pXPmXiUyY+ZeIrciYaEGREd3d32k3IFeWVjPJKRnnlh9aVT5n4lIlPmfiKnIkGBBnR0NCQdhNyRXklo7ySUV75oXXlUyY+ZeJTJr4iZ6IBQUa0tbWl3YRcUV7JKK9klFd+aF35lIlPmfiUiS+rmVx43QOL/h4aEGREb29v2k3IFeWVjPJKRnnlh9aVT5n4lIlPmfiKnIkGBBmR1VFpVimvZJRXMsorP7SufMrEp0x8ysRX5Ew0IMiIsbGxtJuQK8orGeWVjPLKD60rnzLxKROfMvEVORMNCDJiZGQk7SbkivJKRnklo7zyQ+vKp0x8ysSnTHxFzkQDgowo8rVv50J5JaO8klFe+aF15VMmPmXiUya+ImeiAUFGFPnat3OhvJJRXskor/zQuvIpE58y8SkTX5Ez0YAgIxobG9NuQq4or2SUVzLKKz+0rnzKxKdMfMrEV+RMNCDIiJaWlrSbkCvKKxnllYzyyg+tK58y8SkTnzLxFTkTDQgyoq+vL+0m5IrySkZ5JaO88kPryqdMfMrEp0x8Rc5EA4KMWLVqVdpNyBXllYzySkZ55YfWlU+Z+JSJT5n4ipyJBgQZUeRLXc2F8kpGeSWjvPJD68qnTHzKxKdMfEXORAOCjBgdHU27CbmivJJRXskor/zQuvIpE58y8SkTX5Ez0YAgI4p87du5UF7JKK9klFd+aF35lIlPmfiUia/ImWhAkBFFvvbtXCivZJRXMsorP7SufMrEp0x8ysRX5Ew0IMiIpUuXpt2EXFFeySivZJRXfmhd+ZSJT5n4lImvyJloQJARzc3NaTchV5RXMsorGeVVZmYXmdkjZrbTzK6Kmd9kZl+N5t9nZidH09vN7PtmNmRmn6l6zvPN7N+j5/wPM7P5tFHryqdMfMrEp0x8Rc5EA4KM2LdvX9pNyBXllYzySkZ5gZnVAZ8FXg2cCbzRzM6sWuwKYJ9z7jTgWuDj0fRR4EPAX8S89D8A/xlYH90umk87ta58ysSnTHzKxFfkTDQgyIj29va0m5AryisZ5ZWM8gLgPGCnc+5x59wYcBNwSdUylwA3RvdvAbrMzJxzw865uykPDKaY2bFAq3PuXuecA/4R+P35NFLryqdMfMrEp0x8Rc6kPu0GSNmBAwdYsWJF2s3IDeWVjPJKRnkBsA54quLxbmDjdMs45ybMbABoB3pneM3dVa+5Lm7BvXv3csUVV1BfX0+pVOLSSy9ly5YtdHd3s3z5curq6hgcHARg//79OOfo7Oxkz549U+tuaGiINWvW0NPTg5mxevVqenp6aG1tpVQqMTw8zNq1a+nu7qahoYG2tjZ6e3tpa2tjbGyMkZGRqfmNjY20tLTQ19fHqlWrGBkZYXR0dGr+0qVLaW5uZt++fbS3t3PgwAHGxsam5jc3N9PY2MjAwAAdHR0MDAwwPj4+Nb+yps7OTvr7++dc05IlS+jr6wuqpvmup8lMQqppvutpMpOQaprveiqVSvT19WWiphesGmdZneP+/fU8f+UEvb29815PM7HylzQzM7OLgE8DdcB1zrmPVc1vovxNz/OBPuAPnXNPRPM+QHm3cgl4l3Pu22Z2QrT8GsABn3fOjjlWlQAAIABJREFUfTpa/hrKu5N7opf/oHPutsr327Ztm9uwYcNR250nu3bt4qSTTkq7GbmhvJJRXsksdF4XXvdAouXv2Hz21P1HP3ldoueuf9/mRMtX2r59+/1dXV3nApjZZcBFzrnN0eM3ARudc1dOLm9mD0XL7I4ePxYt0xs9fitw7uRzzOxc4GPOuVdEj18CvN8595rqtsy2n9e27VMmPmXiUya+LGVS/blR+bkwV5V9fLWj7iGoOI70lZS/zfmJmW11zv2iYrGp40jNbBPl40j/MDredBNwFnAc8F0zOx2YAN7rnNtuZi3A/Wb2nYrXvNY593dzKzefinzt27lQXskor2SUFwBPAydUPD4+mha3zG4zqwfaKH8pNNNrHn+U10xE68qnTHzKxKdMfEXOZDbnEMz5ONJo+k3OuUPOuV8BO4HznHPPOue2AzjnDgAPM81u46Io8rVv50J5JaO8klFeAPwEWG9mp5hZI+Uvd7ZWLbMVeEt0/zLgTjfDbmfn3LPAoJm9MPqMeDPwjfk0UuvKp0x8ysSnTHxFzmQ25xDM5zjSdcC9Vc894g//6DJ1ZwP3VUy+0szeDPyU8p6EI077nu2xpXk6Fs45x65du4I/ZnGhajp8+DC9vb1B1bSY62l4eJihoaGgalrM9VQqldi1a9eC1XTOynGeHVnC6S0lHhuuo73xMCsbfn1s6P5xo29sCacuL/HLA3U8++yzUzUNHd9B3egYdWMTjLUuo6n/AOOtyzhcX0fznv2MrFlJ/cFDWOkw4y3NHDx4cM7rqVLUl18JfJvy4aJfcM7tMLMPAz91zm0Frge+ZGY7gX7Kg4bJvv0JoBVoNLPfBy6M9gL/v8ANQDNwe3SbsyJfJnA6ysSnTHzKxFfkTI56DsF8jiMFrgHudc59OZp+PXC7c+6W6PEK4IfAR51z/xJNW0P5hDQH/C1wrHPubZVtCvEcgv3797Ny5cq0m5EbyisZ5ZXMQueVx3MI0jbbfl7btk+Z+JSJT5n4spRJrc8hmM0hQ0mOI6XqONJpn2tmDcA/A1+ZHAwAOOf2OOdKzrnDwP+hfMhS8AYGBtJuQq4or2SUVzLKKz+0rnzKxKdMfMrEV+RMZjMgmM9xpFuBTdGvWZ5C+UdofhwdO3o98LBz7lOVLxRdp3rS64CHkhaVRx0dHWk3IVeUVzLKKxnllR9aVz5l4lMmPmXiK3ImRx0QOOcmgMnjSB8Gbp48jtTMXhstdj3QHh1H+ufAVdFzdwA3A78AvgVscc6VgN8G3gS83MwejG4XR6/1iehn7X8OvAx4z0IVm2VFHpXOhfJKRnklo7zyQ+vKp0x8ysSnTHxFzmRWP0wW/Q7AbVXTrq64Pwq8YZrnfhT4aNW0uwGbZvk3zaZNoRkfH0+7CbmivJJRXskor/zQuvIpE58y8SkTX5Ezmc0hQ1IDRb727Vwor2SUVzLKKz+0rnzKxKdMfMrEV+RMNCDIiCJf+3YulFcyyisZ5ZUfWlc+ZeJTJj5l4ityJhoQZMTy5cvTbkKuKK9klFcyyis/tK58ysSnTHzKxFfkTDQgyIi6urq0m5AryisZ5ZWM8soPrSufMvEpE58y8RU5Ew0IMmJwcDDtJuSK8kpGeSWjvPJD68qnTHzKxKdMfEXORAOCjOjs7Ey7CbmivJJRXskor/zQuvIpE58y8SkTX5Ez0YAgI/r7+9NuQq4or2SUVzLKKz+0rnzKxKdMfMrEV+RMNCDIiPIPO8tsKa9klFcyyis/tK58ysSnTHzKxFfkTDQgyIgi76aaC+WVjPJKRnnlh9aVT5n4lIlPmfiKnIkGBBmxZ8+etJuQK8orGeWVjPLKD60rnzLxKROfMvEVORMNCDJixYoVaTchV5RXMsorGeWVH1pXPmXiUyY+ZeIrciYaEIiIiIiIFJgGBBkxNDSUdhNyRXklo7ySUV75oXXlUyY+ZeJTJr4iZ6IBQUasWbMm7SbkivJKRnklo7zyQ+vKp0x8ysSnTHxFzkQDgozo6elJuwm5orySUV7JKK/80LryKROfMvEpE1+RM9GAICPMLO0m5IrySkZ5JaO88kPryqdMfMrEp0x8Rc6kPu0GSNnq1avTbkKuKK9klFcyyis/tK58ysSnTHzKxJeFTC687oFU3ld7CDKiyLup5kJ5JaO8klFe+aF15VMmPmXiUya+ImeiAUFGtLa2pt2EXFFeySivZJRXfmhd+ZSJT5n4lImvyJloQJARpVIp7SbkivJKRnklo7zyQ+vKp0x8ysSnTHxFzkQDgowYHh5Ouwm5orySUV7JKK/80LryKROfMvEpE1+RM9GAICPWrl2bdhNyRXklo7ySUV75oXXlUyY+ZeJTJr4iZ6IBQUZ0d3en3YRcUV7JKK9klFd+aF35lIlPmfiUia/ImWhAkBENDQ1pNyFXlFcyyisZ5ZUfWlc+ZeJTJj5l4ityJhoQZERbW1vaTcgV5ZWM8kpGeeWH1pVPmfiUiU+Z+IqciQYEGdHb25t2E3JFeSWjvJJRXvmhdeVTJj5l4lMmviJnogFBRhR5VDoXyisZ5ZWM8soPrSufMvEpE58y8RU5Ew0IMmJsbCztJuSK8kpGeSWjvPJD68qnTHzKxKdMfEXORAOCjBgZGUm7CbmivJJRXskor/zQuvIpE58y8SkTX5Ez0YAgI4p87du5UF7JKK9klFd+aF35lIlPmfiUia/ImWhAkBFFvvbtXCivZJRXMsorP7SufMrEp0x8ysRX5Ew0IMiIxsbGtJuQK8orGeWVjPLKD60rnzLxKROfMvEVORMNCDKipaUl7SbkivJKRnklo7zyQ+vKp0x8ysSnTHxFzkQDgozo6+tLuwm5orySUV7JKK/80LryKROfMvEpE1+RM9GAICNWrVqVdhNyRXklo7ySUV75oXXlUyY+ZeJTJr4iZ6IBQUYU+VJXc6G8klFeySiv/NC68ikTnzLxKRNfkTPRgCAjRkdH025CriivZJRXMsqrzMwuMrNHzGynmV0VM7/JzL4azb/PzE6umPeBaPojZvaqiunvMbMdZvaQmf2TmS2dTxu1rnzKxKdMfMrEV+RMNCDIiCJf+3YulFcyyisZ5QVmVgd8Fng1cCbwRjM7s2qxK4B9zrnTgGuBj0fPPRPYBJwFXAR8zszqzGwd8C7gXOfcc4C6aLk507ryKROfMvEpE1+RM9GAICOKfO3buVBeySivZJQXAOcBO51zjzvnxoCbgEuqlrkEuDG6fwvQZWYWTb/JOXfIOfcrYGf0egD1QLOZ1QPLgGfm00itK58y8SkTnzLxFTmT+rQbIGVLl85rr3nhKK9klFcyyguAdcBTFY93AxunW8Y5N2FmA0B7NP3equeuc85tM7O/A54ERoA7nHN3xL353r17ueKKK6ivr6dUKnHppZeyZcsWuru7Wb58OXV1dQwODrJkyRJ2796Nc47Ozk727NnDihUrABgaGmLNmjX09PRgZqxevZqenh5aW1splUoMDw+zdu1auru7aWhooK2tjd7eXtra2hgbG2NkZGRqfmNjIy0tLfT19bFq1SpGRkYYHR2dmr906VKam5vZt28f7e3tHDhwgLGxsan5zc3NNDY2MjAwQEdHBwMDA4yPj0/Nr6yps7OT/v7+OddUX1/Prl27gqppvutpMpOQaprveprMJKSa5ruelixZwq5du1Kt6aUdYzx8oJ6TlpVYVue4f389z185QW9v77zX00zMOTfjAlA+jhT4NOXdu9c55z5WNb8J+Efg+UAf8IfOuSeieR+gvFu5BLzLOfdtMzshWn4N4IDPO+c+HS2/GvgqcDLwBPAHzrl9le+3bds2t2HDhqO2O08GBwePurLk15RXMsormYXO68LrHki0/B2bz566/+gnr0v03PXv25xo+Urbt2+/v6ur61wAM7sMuMg5tzl6/CZgo3PuysnlzeyhaJnd0ePHKA8argHudc59OZp+PXA78D3gn+H/b+/eg+QqzzuP/x71dM+05n5jRghWwrYwJZyNETaYTcrxRgnIJGUSCseQglCJtFupiIqzSdhAUuulvKFix7t2shV7qxJBYpvEmCXeRGXA2MF2nOwKDBLERhAscZlCoBnN/doz3dN69o8+MzT9zKXfnss577y/TxXFTM+Z1tvf90z3vNOnT+NjAMYA/G8ADy9sV67a+3nu2xabWGxisYmVhCbLPV6UPy7Uqvw+vtKqhwxtxHGkAOYB/I6q7gXwAQCHy67zLgBPqOoelB48zAvZtqLR0dHVN6JF7OWGvdywFwDgDQAXl31+UXTZkttEhwC1ovRHoeW+92cAvKqqg6paAPA1AP9uLYPkXFlsYrGJxSZWyE2qeQ3Buh9HqqpnVfUEAKjqJIAXUXqKufK6vgjgF2q7aX7p7OyMewheYS837OWGvQAATwPYIyKXiEgGpT/uHK3Y5iiA26OPbwLwbS097XwUwM3RWYguAbAHwPdROlToAyKyPXqM2I/S/X/NOFcWm1hsYrGJFXKTal5DsO7HkZZ/Y3SauisAPBVd1KOqZ6OP+1E6rOhtqj221Kdj4aampjA8PLzlj1lcr9s0Pz+P2dnZLXWbNnKeXn/9dezatWtL3aaNnKfR0VGk0+l1u0372go4m9uGS5uLeHk6hc7MebSl3zo2dKwgGM5vwzsbi/jRZApnz55dvE1TF3UhNZtHKj+PfMt21I9MotCyHefrUsgOjCHX04a6mTlI8TwKzVnMzMzUPE/lovvyOwA8jtLhover6kkR+SSAZ1T1KID7AHxZRE4DGEF0xqBou4cAvIDSM8KHVbUI4CkReRjAiejyZwH8eeV9vIvJycnF20clbGKxicUmVshNVn0NwUYcR6qqD0efNwH4RwD3qurXosvGVLWt7LpHVfVtbx23FV9D0NfXh127dsU9DG+wlxv2crPevXx8DUHcqr2f575tsYnFJhabWEloktjXEGBjjiOFiKRRenHZXy8sBiIDIrIj2mYHgHNVjNF7IZ/7thbs5Ya93LCXPzhXFptYbGKxiRVyk2oWBOt+HGl07Oh9AF5U1c+ucF23A/h71xvlo5DPfVsL9nLDXm7Yyx+cK4tNLDax2MQKucmqryHYiONIReQnAdwG4Ici8lz0T/2+qj4K4FMAHhKRgwD6APzSet7gpMpms3EPwSvs5Ya93LCXPzhXFptYbGKxiRVyk6remCz6Rf3Riss+UfbxLICPLvO99wK4t+KyfwYgy2w/jNKZJ4KSyWTiHoJX2MsNe7lhL39wriw2sdjEYhMr5CbVHDJEm2B8fDzuIXiFvdywlxv28gfnymITi00sNrFCbsIFQUJ0dXXFPQSvsJcb9nLDXv7gXFlsYrGJxSZWyE24IEiIkFeltWAvN+zlhr38wbmy2MRiE4tNrJCbcEGQEIVCIe4heIW93LCXG/byB+fKYhOLTSw2sUJuwgVBQoR87ttasJcb9nLDXv7gXFlsYrGJxSZWyE24IEiIkM99Wwv2csNebtjLH5wri00sNrHYxAq5CRcECdHY2Bj3ELzCXm7Yyw17+YNzZbGJxSYWm1ghN+GCICFSqVTcQ/AKe7lhLzfs5Q/OlcUmFptYbGKF3IQLgoSYmJiIewheYS837OWGvfzBubLYxGITi02skJtwQZAQ3d3dcQ/BK+zlhr3csJc/OFcWm1hsYrGJFXKTurgHQCUjIyPYvn173MPwBnu5YS83G93rmiceWfHrp0aPb9i/vdVw37bYxGITi02skJvwGYKEUNW4h+AV9nLDXm7Yyx+cK4tNLDax2MQKuQkXBAkR8tNUtWAvN+zlhr38wbmy2MRiE4tNrJCbcEGQEAMDA3EPwSvs5Ya93LCXPzhXFptYbGKxiRVyEy4IEqKpqSnuIXiFvdywlxv28gfnymITi00sNrFCbsIFARERERFRwLggSIipqam4h+AV9nLDXm7Yyx+cK4tNLDax2MQKuQkXBAnR09MT9xC8wl5u2MsNe/mDc2WxicUmFptYITfhgiAhBgcH4x6CV9jLDXu5YS9/cK4sNrHYxGITK+QmXBAkhIjEPQSvsJcb9nLDXv7gXFlsYrGJxSZWyE24IEiIjo6OuIfgFfZyw15u2MsfnCuLTSw2sdjECrlJXdwDoJLBwUHs2rUr7mF4g73csJebuHs9cKLf+Xtu3de7ASNJvrjnKonYxGITi02skJvwGYKEaGlpiXsIXmEvN+zlhr38wbmy2MRiE4tNrJCbcEGQEMViMe4heIW93LCXG/byB+fKYhOLTSw2sUJuwgVBQkxPT8c9BK+wlxv2csNe/uBcWWxisYnFJlbITbggSIje3jCP/60Ve7lhLzfs5Q/OlcUmFptYbGKF3IQLgoTo73d/EWHI2MsNe7lhL39wriw2sdjEYhMr5CZcECREOp2OewheYS837OWGvfzBubLYxGITi02skJtwQZAQra2tcQ/BK+zlhr3csJc/OFcWm1hsYrGJFXITLggSYmhoKO4heIW93LCXG/byB+fKYhOLTSw2sUJuwgVBQoS8Kq0Fe7lhLzfs5Q/OlcUmFptYbGKF3IQLgoTI5/NxD8Er7OWGvdywlz84VxabWGxisYkVchMuCBIil8vFPQSvsJcb9nLDXv7gXFlsYrGJxSZWyE24IEiIkM99Wwv2csNebtjLH5wri00sNrHYxAq5CRcECRHyuW9rwV5u2MsNe/mDc2WxicUmFptYITfhgiAhMplM3EPwCnu5YS837OUPzpXFJhabWGxihdyEC4KEaG5ujnsIXmEvN+zlhr38wbmy2MRiE4tNrJCbcEGQEMPDw3EPwSvs5Ya93LBXiYgcEJGXROS0iNy1xNfrReSr0defEpHdZV+7O7r8JRG5ruzyNhF5WET+VUReFJFr1jJGzpXFJhabWGxihdyEC4KEaG9vj3sIXmEvN+zlhr0AEUkB+DyADwPYC+AWEdlbsdlBAKOq+i4AnwPw6eh79wK4GcDlAA4A+EJ0fQDwpwC+oaqXAfhxAC+uZZycK4tNLDax2MQKuQkXBAkR8qmuasFebtjLDXsBAK4CcFpVX1HVPIAHAdxQsc0NAL4YffwwgP0iItHlD6rqnKq+CuA0gKtEpBXABwHcBwCqmlfVsbUMknNlsYnFJhabWCE3qatmIxE5gNJfdVIAjqjqpyq+Xg/gSwCuBDAM4GOq+lr0tbtR+itSEcBvqurj0eX3A/h5AOdU9T1l13UPgP8AYDC66PdV9dEab583Zmdn4x6CV9jLDXu5YS8AwE4Ar5d9fgbA1ctto6rzIjIOoDO6/MmK790JIIfSfftfisiPAzgO4OOqOl35j587dw4HDx5EXV0disUibrzxRhw+fBj9/f1obGxEKpXCxMQECoUCCoUCVBXd3d0YGBhAU1MTAGBqago9PT0YHByEiKCjowODg4NoaWlBsVjE9PQ0ent70d/fj3Q6jdbWVgwNDaG1tRX5fB65XG7x65lMBs3NzRgeHkZ7eztyuRxmZ2cXv97Q0IBsNovR0VF0dnZicnIS+Xx+8evZbBaZTAbj4+Po6urC+Pg4CoXC4tfLb1N3dzdGRkZqvk3FYhF9fX1b6jatdZ4Wmmyl27TWeVpospVu01rnaXZ2FrOzs7Hepp/qyuPFyTrs2l7E9pTi+Fgdrmybx9DQ0JrnaSWiqitvUHqa90cAfja6U38awC2q+kLZNr8B4N+q6q+LyM0AflFVPxY9bfwVlP7SdCGAfwBwqaoWReSDAKYAfGmJBcGUqv735cZ07Ngxveyyy1Yct2/m5uZQX18f9zC8wV5u2MvNeve69sizb/v8miceWbfrXnDrvtL5s/fceajm6zhx4sTx/fv3vw8AROQmAAdU9VD0+W0ArlbVOxa2F5Hno23ORJ+/jNKi4R4AT6rqA9Hl9wF4DMBrKC0UfkJVnxKRPwUwoar/pXIs1d7Pc9+22MRiE4tNrCQ0qXy8WPDNQ1es+brL7+MrVXPI0Lo/bQwAqvo9ACPOt2aLCvnct7VgLzfs5Ya9AABvALi47POLosuW3EZE6gC0ovQs8XLfewbAGVV9Krr8YQD71jJIzpXFJhabWGxihdykmkOGNuJp49XcISK/AuAZAL+jqqPlX6z2qWSfnvo6f/48+vr6tvxTlOt1m4rFIoaGhrbUbdrIeZqensbU1NSWuk0bOU/z8/Po6+tbt9u0r62As7ltuLS5iJenU9hxWS+yzQ144+Sb2Hn5hchNzmJmbAadF3dg8LUhtFzQjPrt9Ytfnxmbwdx0Hu0723Du5UG072xDuiG9+PWp4SnMtTai0JzFzMxMzfNU4WkAe0TkEpR+mb8ZwC9XbHMUwO0AjgG4CcC3VVVF5CiAvxGRz6L07PAeAN+Pnh1+XUTeraovAdgP4AWsQUNDw1q+fUtiE4tNLDaxQm5SzSFD6/60sao+HH2+G8DXKw4Z6gEwBEAB/DcAO1T118rHtBUPGZqYmFj1+C56C3u5YS83693Lx0OGAEBErgfwJyi9fux+Vb1XRD4J4BlVPSoiDQC+DOAKlJ7xvVlVX4m+9w8A/BqAeQC/paqPRZe/F8ARABkArwD41co/+gDV389z37bYxGITi02sJDSJ65Chap4hcHna+EyVTxsvS1UHFj4Wkb8A8PUqxui90dHR2HdCn7CXG/Zyw14l0QkdHq247BNlH88C+Ogy33svgHuXuPw5AEs+INWCc2WxicUmFptYITep5jUEi08bi0gGpaeNj1Zss/C0MVD2tHF0+c3Rm9dcguhp45X+MRHZUfbpLwJ4vooxeq+zszPuIXiFvdywlxv28gfnymITi00sNrFCbrLqgkBV5wHcAeBxlN5A5iFVPSkinxSRj0Sb3QegU0ROA/htAHdF33sSwEMoHSP6DQCHVbUIACLyFZSOO323iJwRkYPRdf2xiPxQRH4A4N8D+E/rdFsTbXJyMu4heIW93LCXG/byB+fKYhOLTSw2sUJuUtX7EGzQ08a3LLP9bdWMaavJ5/NxD8Er7OWGvdywlz84VxabWGxisYkVchO+U3FC9Pb2xj0Er7CXG/Zyw17+4FxZbGKxicUmVshNuCBIiJDPfVsL9nLDXm7Yyx+cK4tNLDax2MQKuQkXBAmRzWbjHoJX2MsNe7lhL39wriw2sdjEYhMr5CZcECREJpOJewheYS837OWGvfzBubLYxGITi02skJtwQZAQ4+PjcQ/BK+zlhr3csJc/OFcWm1hsYrGJFXITLggSoqurK+4heIW93LCXG/byB+fKYhOLTSw2sUJuwgVBQoS8Kq0Fe7lhLzfs5Q/OlcUmFptYbGKF3IQLgoQoFApxD8Er7OWGvdywlz84VxabWGxisYm1WU2uPfKs+bzyss3GBUFChHzu21qwlxv2csNe/uBcWWxisYnFJlbITbggSIiQz31bC/Zyw15u2MsfnCuLTSw2sdjECrkJFwQJ0djYGPcQvMJebtjLDXv5g3NlsYnFJhabWCE34YIgIVKpVNxD8Ap7uWEvN+zlD86VxSYWm1hsYoXcpC7uAVDJxMQE2tvbY/v3T33miNP2e+48tEEjqU7cvXzDXm7Yyx+cK4tNLDax2MQKuQmfIUiI7u7uuIfgFfZyw15u2MsfnCuLTSw2sdjECrkJFwQJMTIyEvcQvMJebtjLDXv5g3NlsYnFJhabWCE34YIgIVQ17iF4hb3csJcb9vIH58piE4tNLDaxQm7CBUFChPw0VS3Yyw17uWEvf3CuLDax2MRiEyvkJlwQJMTAwEDcQ/AKe7lhLzfs5Q/OlcUmFptYbGKF3IQLgoRoamqKewheYS837OWGvfzBubLYxGITi02skJvwtKNERERERJts4ZTv15wovUPyqdHjix+bbUePA9i4077zGYKEmJqainsIXmEvN+zlhr38wbmy2MRiE4tNrJCbcEGQED09PXEPwSvs5Ya93LCXPzhXFptYbGKxiRVyEy4IEmJwcDDuIXiFvdywlxv28gfnymITi00sNrFCbsIFQUKISNxD8Ap7uWEvN+zlD86VxSYWm1hsYoXchAuChOjo6Ih7CF5hLzfs5Ya9/MG5stjEYhOLTayQm3BBkBAhP01VC/Zyw15u2MsfnCuLTSw2sdjECrkJFwQJ0dLSEvcQvMJebtjLDXv5g3NlsYnFJhabWCE34YIgIYrFYtxD8Ap7uWEvN+zlD86VxSYWm1hsYoXchAuChJieno57CF5hLzfs5Ya9/MG5stjEYhOLTayQm3BBkBC9vb1xD8Er7OWGvdywlz84VxabWGxisYkVcpO6uAdAJf39/di1a1fcw/AGe7lhLzfs5Q/OlcUmFptYbGKttcmpzxypartrTvTj1Ojxmv+djcBnCBIinU7HPQSvsJcb9nLDXv7gXFlsYrGJxSZWyE24IEiI1tbWuIfgFfZyw15u2MsfnCuLTSw2sdjECrkJFwQJMTQ0FPcQvMJebtjLDXv5g3NlsYnFJhabWCE34YIgIUJeldaCvdywlxv28gfnymITi00sNrFCbsIFQULk8/m4h+AV9nLDXm7Yyx+cK4tNLDax2MQKuQkXBAmRy+XiHoJX2MsNe7lhL39wriw2sdjEYhMr5CZcECREyOe+rQV7uWEvN+zlD86VxSYWm1hsYoXchO9DkBA8H7Ab9lpZ5bmQpy7qQtOZpV8stefOQ5sxJK9w/yoRkQMA/hRACsARVf1UxdfrAXwJwJUAhgF8TFVfi752N4CDAIoAflNVHy/7vhSAZwC8oao/v5Yxcq4sNrHYxGITK+QmVT1DICIHROQlETktInct8fV6Eflq9PWnRGR32dfuji5/SUSuK7v8fhE5JyLPV1xXh4h8S0RORf9vr/3m+SOTycQ9BK+wl5tt+fm4h+AV7l+Lv7R/HsCHAewFcIuI7K3Y7CCAUVV9F4DPAfh09L17AdwM4HIABwB8Ibq+BR8H8OJ6jJNzZbGJxSYWm1ghN1l1QbCBDwp/FV1W6S4AT6jqHgBPRJ9vec28cJEtAAAf+UlEQVTNzXEPwSvs5SY9He5xkbXg/gUAuArAaVV9RVXzAB4EcEPFNjcA+GL08cMA9ouIRJc/qKpzqvoqgNPR9UFELgLwcwCqe0vPVXCuLDax2MRiEyvkJtUcMrT4oAAAIrLwoPBC2TY3ALgn+vhhAH9W+aAA4FURWXhQOKaq3yt/JqHiuj4UffxFAN8F8HtV3yJPDQ8Po6mpKe5heIO93My1NyM9PRf3MLzB/QsAsBPA62WfnwFw9XLbqOq8iIwD6Iwuf7Lie3dGH/8JgP8MYMVH3nPnzuHgwYOoq6tDsVjEjTfeiMOHD6O/vx+NjY1IpVKYmJhAoVBAQ0MDVBXd3d0YGBhYnLupqSn09PRgcHAQIoKOjg4MDg6ipaUFxWIR09PT6O3tRX9/P9LpNFpbWzE0NITW1lbk83nkcrnFr2cyGTQ3N2N4eBjt7e3I5XKYnZ1d/HpDQwOy2SxGR0fR2dmJyclJ5PP5xa9ns1lkMhmMj4+jq6sL4+PjKBQKi18vv03d3d0YGRmp+TYVi0UMDw9vqdu01nlaaLKVbtNa52mhyVa6TWudp9nZWaTT6ZpvU6GxHnPtzciMTaOYzaBYn0Z2YAy5njak5gpI5fLItzWi+fUpzFzQhvOZOmQHxvCO9+/GzNgM8i3b8Y7378a5lwfRvrMN6YY03jj5JnZefiFmW9OQ4nn09fXVPE8rEVVdeQORmwAcUNVD0ee3AbhaVe8o2+b5aJsz0ecvo/TAcQ+AJ1X1gejy+wA8pqoPR5/vBvB1VX1P2XWNqWpb9LGg9MxDW/mYjh07ppdddtmK4/bNxMTEqpO1kSqPOV9N3Medx90r6SrnM9+URWZq6WcJ4p7LJFrv/evaI8++7fNrnnhk3a57wa37Si+GW8t8njhx4vj+/fvfB2zMfT+AWQDXq+pviMiHAPzucq8hqPZ+nvcFFptYbGKxibXWJtX+LvXAif7F++yFz4HS/fjCx5XW+z6+UqJfVKyqKiJmxVLtX458WulOT09jdHQ0tr9I5LpaUGzILK5kt+XnkZ7OLbvSHRgYiPWvLMViEfl8fkv8RWJD/hqWrnvbXySmd3ZAzgyh0Jhd/ItErqcNqdk8xsbGvLhNmzlPY2NjGB0dXbfbtK+tgLO5bbi0uYiXp1PYcVkvss0Ni3/5yU3OYmZsBp0Xd2DwtSG0XNCM+u31i1+fGZvB3HQe7TvblvzL0dTwFOZaG1FozmJmZqbmearwBoCLyz6/KLpsqW3OiEgdgFaUXly83Pd+BMBHROR6AA0AWkTkAVW9tdrHhUq5XI6/1FRgE4tNLDaxQm5SzTME1wC4R1Wviz6/GwBU9Y/Ktnk82uZY9KDQD6Ab0fH/C9uWbxd9vhv2GYKXAHxIVc+KyA4A31XVd5ePaSs+Q9DX1xfrK9t9e4Yg7l5Jx7MMrc1671+ePkNQB+BHAPaj9Mv80wB+WVVPLmwvIocB/Jiq/rqI3AzgRlX9JRG5HMDfoHSI6IUovR5sj6oWy773Q1iHZwh4X2CxicUmFptYa23i8zME1Zxl6GkAe0TkEhHJoPQi4aMV2xwFcHv08U0Avq2llcZRADdHZyG6BMAeAN9f5d8rv67bAfx9FWP0Xsjnvq0Fe7nJDozFPQSvcP8qvSYAwB0AHkfpjEAPqepJEfmkiHwk2uw+AJ3R68N+G2/9EegkgIdQeq3ZNwAcLl8MrCfOlcUmFptYbGKF3GTVBcFGPSiIyFcAHAPwbhE5IyIHo+v6FICfFZFTAH4m+nzL6+9fekVIS2MvN7mettU3okXcv0pU9VFVvVRV36mq90aXfUJVj0Yfz6rqR1X1Xap61cLJJ6Kv3Rt937tV9bElrvu7a30PAoBztRQ2sdjEYhMr5CZVvYZAVR8F8GjFZZ8o+3gWwEeX+d57Ady7xOW3LLP9MEpPUQeloaEh7iF4hb3cpOYKcQ/BK9y//MG5stjEYhOLTayQm1T1xmS08bLZbNxD8Ap7uUnl8nEPwSvcv/zBubLYxGITi02skJtwQZAQo6OjcQ/BK+zlJt/WGPcQvML9yx+cK4tNLDax2MQKuQkXBAnR2dkZ9xC8wl5u6kcn4x6CV7h/+YNzZbGJxSYWm1ghN+GCICEmJ/kLmwv2clNoDPdp0Fpw//IH58piE4tNLDaxJicnce2RZxdPFV3+cbnlLn/gRP+ypw2tZttqv3cjcEGQEPk8j/F2wV5uzmcS/R6EicP9yx+cK4tNLDax2MQKuQkXBAkR8rlva8Febvg+BG64f/mDc2WxicUmFptYITfhgiAhQj73bS3Yyw3fh8AN9y9/cK4sNrHYxGITK+QmXBAkRMinuqoFe7lJzYb7NGgtuH/5g3NlsYnFJhabWCE34YIgITKZTNxD8Ap7uUnl5+Megle4f/mDc2WxicUmFptYITfhgiAhxsfH4x6CV9jLTb5le9xD8Ar3L39wriw2sdjEYhMr5CZcECREV1dX3EPwCnu5qR/h6eVccP/yB+fKYhOLTSw2sUJuwgVBQoS8Kq0Fe7kp8BkCJ9y//MG5stjEYhOLTayQm3BBkBCFQiHuIXiFvdycr0vFPQSvcP/yB+fKYhOLTSw2sUJuwgVBQoR87ttasJcbvg+BG+5f/uBcWWxisYnFJlbITbggSIiQz31bC/Zyw/chcMP9yx+cK4tNLDax2MQKuUld3AOgksbGxriH4JVae536zJGqt91z56Ga/o0kqpuZi3sIXuHPoz84VxabWGxisYlVajIS9zBiwWcIEiKV4jHeLtjLjRTPxz0Er3D/8gfnymITi00sNrFCbsIFQUJMTEzEPQSvsJebQnO4775YC+5f/uBcWWxisYnFJlbITbggSIju7u64h+AV9nLTMBTunVwtuH/5g3NlsYnFJhabWCE34YIgIUZGwjxmrVbs5WauvSnuIXiF+5c/OFcWm1hsYrGJFXKTIF9UfO2RZ522/+ahKzZoJG9R1Q3/N7aSjez1wInSWQaOOewnm7GPrMk2iXsEXuHPoz84VxabWGxisYkVchM+Q5AQIT9NVQv2csNDhtxw//IH58piE4tNLDaxQm7CBUFCDAwMxD0Er7CXm1x3a9xD8Ar3L39wriw2sdjEYhMr5CZcECREUxOP8XbBXm7S07NxD8Er3L/8wbmy2MRiE4tNrJCbcEFARERERBQwLggSYmpqKu4heIW93BQaG+Iegle4f/mDc2WxicUmFptYITfhgiAhenp64h6CV9jLTXZwPO4heIX7lz84VxabWGxisYkVchMuCBJicHAw7iF4hb3czHa1xD0Er3D/8gfnymITi00sNrFCbsIFQUKI8DzxLtjL0flwz61cC+5f/uBcWWxisYnFJlbITbggSIiOjo64h+AV9nJTPxrucZG14P7lD86VxSYWm1hsYoXchAuChAj5aapasJcbHjLkhvuXPzhXFptYbGKxiRVyEy4IEqKlhb+wuWAvN+nJXNxD8Ar3L39wriw2sdjEYhMr5CZcECREsViMewheYS83muKPugvuX/7gXFlsYrGJxSZWyE34W0JCTE9Pxz0Er7CXm/nt9XEPwSvcv/zBubLYxGITi02skJtwQZAQvb29cQ/BK+zlJjswFvcQvML9yx+cK4tNLDax2MQKuQkXBAnR398f9xC8wl5ucj1tcQ/BK9y//MG5stjEYhOLTayQm3BBkBDpdDruIXiFvdxsmw/3uMhacP/yB+fKYhOLTSw2sUJuwgVBQrS2tsY9BK+wl5v0xEzcQ/AK9y9/cK4sNrHYxGITK+QmXBAkxNDQUNxD8Ap7uZnraI57CF7h/uUPzpXFJhabWGxihdyEC4KECHlVWgv2cpPhMwROuH+ViMgBEXlJRE6LyF1LfL1eRL4aff0pEdld9rW7o8tfEpHrossuFpHviMgLInJSRD6+1jFyriw2sdjEYhMr5CZVLQjW+0FhpesUkb8SkVdF5Lnov/eu7Sb6IZ/Pxz0Er7CXm2KmLu4heIX7FyAiKQCfB/BhAHsB3CIieys2OwhgVFXfBeBzAD4dfe9eADcDuBzAAQBfiK5vHsDvqOpeAB8AcHiJ63TCubLYxGITi02skJus+ltC2YPCzwI4A+BpETmqqi+Ubbb4oCAiN6P0oPCxigeFCwH8g4hcGn3PStd5p6o+vA63b9Od+syRqrfdc+ehxY9zufV9J1mXcSRNNWOfuqgL42c29qm9a554pOptT40ef9t8Jk2xIRPLv+u6H7o03Mjrdv15XG0s15zw8swVVwE4raqvAICIPAjgBgDl9/03ALgn+vhhAH8mIhJd/qCqzgF4VUROA7hKVY8BOAsAqjopIi8C2FlxnU7W+75zK2ATi00sNrFCblLNMwSLDwqqmgew8KBQ7gYAX4w+fhjA/soHBVV9FcDp6Pqquc6ghHzu21rwvPpu2MsNfx4BlH5Rf73s8zPRZUtuo6rzAMYBdFbzvdEzyVcAeGotg+RcWWxisYnFJlbITao5jmCpO/arl9tGVedFpPxB4cmK7114UFjpOu8VkU8AeALAXdFfmRadO3cOBw8eRF1dHYrFIm688UYcPnwY/f39aGxsRCqVwsTEBLq7uzEyMgJVRXd3NwYGBtDU1IRLm+axo+E8nhuvw4+1zGNeBaemUnhPyzzO5LYhvQ3oqT+P42N1uLJtHm+++SZaW1sxNDSE1tZW5PN55HI59Pb2or+/H5lMBs3NzRgeHka+KYtiNoNifRrZgTHketqQmisglcsj39aI+tFJFBqzOJ+pw9zcHPr7+5HNZjE6OoqGhgZ0dXVhfHwchUJh8fqruU0AMDU1hZ6eHgwODmJ6RwfqR6cw29WC9GQOmtqG+e31i2PaNl9EemIGcx3NyEzMoJipQ7Eh89bX8/NIT+cw196MzNi0uU0DAwOL4+7s7MTk5CTy+fzimLPZLDKZDMbHx51v09RFXUhPzwIACo0NyA6OY7arBTivi7dpviGNhpGpdb1NC/P0jvfvxuBrQ2i5oBn12+vxxsk3sfPyCzEzNoO56Tzad7bh3MuDaN/ZhnRDGm+cfBNTF3VhaGjIeZ5EBB0dHRgcHERLSwuKxSKmp6cXO6XT6ar3vfb2duRyOczOzqKYrnvbbZr6N91o7htY3PcWb/NsHmNjYzXNUzW3aa610Wnf6+vrW/Y2LYypoaEB2WwWUxd1ve3nqfw2pfLzyLdsR/3IJAot23G+LrX481bNbRocHEQ2m616nmZ621fc93bOCSbOTaJ7dxeGXx/B9rbtyDY3LO5buclZzIzNoPPiDud9b+flF2JqeApzrY0oNGcxMzNT8763WUSkCcDfAvgtVZ1Yaptq7+cLhQIaGhpi+1mr3C834j7R9TYVi0WkUqktdZvWfJ8YNdlKt2mt87TQZCvdprXO0+zsLH6qK48zuW0YGhrCT3XlcXysDn19fW+7Tbu2F9Fcp+jr63v7bepuQvfuLuSzsuLvgs2vTy3ezxe3zeMd79+96v38bGsaUjyPvr6+mudpxftlVV3tjvsmAAdU9VD0+W0ArlbVO8q2eT7a5kz0+cso/YJ/D4AnVfWB6PL7ADwWfduS1ykiOwD0A8gA+HMAL6vqJ8vHdOzYMb3ssstWHPdKrj3yrNP23zx0RdXbLhw68EAVhwgc2/9zix/vayvgxNj6nf92qcNdbt23fivf5Q6/WI+21RwKMnNBG7afq+6v3tXMxVrduq/X6ZCUjdwHAdtwpV61HupUzW2o3A9X2weTcsjQ2bNnsWPHjiW/ttTtdjm8bKMstF3LoWsnTpw4vn///vcBgIhcA+AeVV14QfDdAKCqf7SwvYg8Hm1zTETqULrv7gZwV/m2FdulAXwdwOOq+tnlxlLt/fxKcxUqNrHYxGIT6+zZs7j9kdLvDN88dMXi/X3lY/Byl//XW/4QwOqPdeW/l9y6r7eq31PW+z6+UjWHDL0B4OKyzy+KLltym+hBoRXA8Arfu+x1qupZLZkD8JcoHV605Z3N8YRPLtLT4R7nVwv2ctPczNO0AngawB4RuUREMii9HuxoxTZHAdwefXwTgG9r6a9MRwHcHJ1w4hIAewB8PzqU9D4AL660GHDBubLYxGITi02skJtU81vouj8orHSd0TMEiB44fgHA82u5gb64tJnvJOtirj3cH9pasJeb4eHhuIcQu+g1AXcAeBzAiwAeUtWTIvJJEflItNl9ADqjFw3/Nt56ZuAkgIdQerHwNwAcVtUigJ8AcBuAny47k9z1axkn58piE4tNLDaxQm6y6msIotcELDwopADcv/CgAOAZVT2K0oPCl6MHhRGUfsFHtN3Cg8I83npQwFLXGf2Tfy0i3QAEwHMAfn39bm5yvTydinsIXsmMTcc9BK+wl5v29va4h5AIqvoogEcrLvtE2cezAD66zPfeC+Deisv+GaX79nXDubLYxGITi02sUpORuIcRi6pOTr7eDwrLXWd0+U9XM6atpjNzHmdyXBRUq5jNAFM8DKZa7OUml8ut+gIsSgbOlcUmFptYbGKVn3a0mtfJlW9T+XqCytcFLPdagc14nWM1eOB6QrSlV35xN71dsX79XoAdAvZyMzs7G/cQqEqcK4tNLDax2MQKuQkXBAlxfIzvJOuC59V3w15uQj4XtW84VxabWGxisYkVchMuCBLiyrb5uIfglVxPW9xD8Ap7uenvT8ZTuLQ6zpXFJhabWGxihdyEC4KEGCus6+vstrzUXCHuIXiFvdw0NDTEPQSqEufKYhOLTSw2sUJuwgVBQgznORUuUrl83EPwCnu5yWazcQ+BqsS5stjEYhOLTayQm/C30IR4ZyPfh8BFvq0x7iF4hb3cjI6Oxj0EqhLnymITi00sNrFCbsIFQUL8aJKnHHVRPzoZ9xC8wl5uOjs74x4CVYlzZbGJxSYWm1ghN+GCICF2ZM/HPQSvFBrDfVqvFuzlZnKSCyhfcK4sNrHYxGITK+QmXBAkRHMd34fAxfkMT9Pqgr3c5PN8zYUvOFcWm1hsYrGJFXITLggSgu9D4Ibn1XfDXm5CPhe1bzhXFptYbGKxiRVyE/4WmhBXts3jH4cycQ/DG7meNjSdGYp7GN5gLzf9/f3YtWtX3MOgKnCuLDax2MRiE6v8fQiueeKRxY9PjR5/23bXnLDvV1C5jW/4DEFC8LSjblKz4T6tVwv2chPyqed8w7my2MRiE4tNrJCb8LfQhJic5xuTuUjl+c7OLtjLTSbDZ+t8wbmy2MRiE4tNrJCbcEGQELu3830IXORbtsc9BK+wl5vx8fG4h0BV4lxZbGKxicUmVshNuCBIiBcn+XIOF/Uj4Z4arBbs5aarqyvuIVCVOFcWm1hsYrGJFXITLggSYhefIXBS4F+8nbCXm5D/SuQbzpXFJhabWGxihdyEC4KE2J7i+xC4OF/Hd3Z2wV5uCoVC3EOgKnGuLDax2MRiEyvkJlwQJATfh8ANz6vvhr3chHwuat9wriw2sdjEYhMr5Cb8LTQhqnkfgvJz4obO9/PqO8/loSvW9O+t1OvUZ444XdeeOw+taSwrcR3LRuH5uf3BubLYxGITi02s8vchCA0XBAkxMJe8J2seWOKNNxYcO/Lsuvwb1y5xPUu94UelC8bmce6V5CwIHjjR79TkGsfrX6rTitd/oh+37nvrLx11M3Orfs9K811uveZ+oyx3O1zGfVnzPP71WyPrNSTaQI2NjXEPIXHYxGITi02sUpMw7/uT91tooArn4x6BX4oFvgjbhRS5g7ngz6M/Uim+PqYSm1hsYrGJFXITLggS4qIsfwNx0drbGvcQvFJoDvfdF2vBn0d/TExMxD2ExGETi00sNrFCbsIFQUI8P8Gjt1z0nxqIewheaRgK906uFvx59Ed3d3fcQ0gcNrHYxGITK+QmXBAkxJ4mHgLjont3Z9xD8Mpce1PcQ/AKfx79MTIS5vG+K2ETi00sNrFCbsIFQULUCd+HwIWkuOs62SZxj8Ar/Hn0hyrnqhKbWGxisYkVchP+VpUQP+QhCk76f3Qu7iF4hYcMueHPoz9Cfop/OWxisYnFJlbITbggSIj3ts7HPQSvXHhZuG8eUotcN1+E7YI/j/4YGODriSqxicUmFptYITfhgiAhzs5yKlxMDE7GPQSvpKdn4x6CV/jz6I+mJr4+phKbWGxisYkVchM+6hERERERBYwLgoTY0cDznrto6W6OewheKTQ2xD0Er/Dn0R9TU1NxDyFx2MRiE4tNrJCbcEGQEM+N80WMLt781/64h+CV7OB43EPwCn8e/dHT0xP3EBKHTSw2sdjECrkJFwQJ8WMtfBGji95LL4h7CF6Z7WqJewhe4c+jPwYHB+MeQuKwicUmFptYITfhgiAh5pXniXehRR7S4eR8uOdWrgV/Hv0hwrmqxCYWm1hsYoXchAuChDg1lYp7CF4ZfG047iF4pX403OMia8GfR390dHTEPYTEYROLTSw2sUJuwgVBQryHhyg46d0T7nF+teAhQ2748+iPkJ/iXw6bWGxisYkVchMuCBLiTI5T4WK8ny+SdZGezMU9BK/w59EfLS1c7FZiE4tNLDaxQm7CR72ESHMmnKTSPKTDhaa4g7ngz6M/isVi3ENIHDax2MRiEyvkJnzYS4ieer5I1kVTZ7jvJliL+e31cQ/BK/x59Mf09HTcQ0gcNrHYxGITK+QmPNl2Qhwf41S4eOPkm3EPwSvZgbG4h+AV/jz6o7e311x26jNHnK9nz52H1mM4ibBUk9CxiRVak2ruF4rpOlzz1JlNGE3y8BmChLiyjS9idLHz8gvjHoJXcj1tcQ/BK/x59Ed/P9+ksBKbWGxisYkV8mNlVQsCETkgIi+JyGkRuWuJr9eLyFejrz8lIrvLvnZ3dPlLInLdatcpIpdE13E6us7M2m6iH575zmNxD8Er//TU9+Ieglce+d534h6CV/jzWLKZ9/21+ru/+7u1XsWWwyYWm1hsYoX8WLnqgkBEUgA+D+DDAPYCuEVE9lZsdhDAqKq+C8DnAHw6+t69AG4GcDmAAwC+ICKpVa7z0wA+F13XaHTdW96z3+UvIC7+3/H/G/cQvPLIP3037iF4hT+Psdz31+RrX/vaWr59S2ITi00sNrFCfqys5hmCqwCcVtVXVDUP4EEAN1RscwOAL0YfPwxgv5Te7u0GAA+q6pyqvgrgdHR9S15n9D0/HV0Houv8hdpvnj+yPHjLSV09j/F2oXXcwVzw5xHAJt73r2WQ8/M8vKsSm1hsYrGJFfJjpajqyhuI3ATggKoeij6/DcDVqnpH2TbPR9uciT5/GcDVAO4B8KSqPhBdfh+AhT+9mess2/5d0eUXA3hMVd9TPqZHH3108uzZs4uz1tLSMtjR0TFUU4GEGBkZ6fL9Nmwm9nLDXm4C7rVr//793cDm3veXX+eCau/nA56rZbGJxSYWm1gBNFm8j6/k5Z9Zr7/++ua4x0BERBuH9/NERJunmudG3gBwcdnnF0WXLbmNiNQBaAUwvML3Lnf5MIC26DqW+7eIiGjjbeZ9PxERxaiaBcHTAPZEZ//JoPRCsaMV2xwFcHv08U0Avq2lY5GOArg5OhPFJQD2APj+ctcZfc93outAdJ1/X/vNIyKiGm3aff8m3BYiIlrBqocMqeq8iNwB4HEAKQD3q+pJEfkkgGdU9SiA+wB8WUROAxhB6U4e0XYPAXgBwDyAw6paBIClrjP6J38PwIMi8ocAno2um4iINlEM9/1ERBQXVeV/m/AfgNcA/BDAcyg9mAJAB4BvATgV/b89ulwA/E+UzszxAwD74h7/JvS5H8A5AM+XXebcB6W/Vp6K/rs97tu1yb3uQenwi+ei/64v+9rdUa+XAFxXdvmB6LLTAO6K+3ZtYK+LUXr28QUAJwF8nPuY//+Fsv8ucbv5eKJ83KiyR9CPC7zvd2gV9wBC+S+6A++quOyPF37YANwF4NPRx9ejdEYOAfABAE/FPf5N6PNBAPsq7sic+kQ/4K9E/2+PPm6P+7ZtYq97APzuEtvuBfAvAOoBXALgZZT+OpuKPn4HgEy0zd64b9sG9dqxcMcOoBnAj6Iu3Mc8/S+k/XeJ287HE+XjRpU9gn5c4H1/9f+Fe8LVZCg/h3f5ey7cAOBLWvIkSi+03hHHADeLqn4PpUMOyrn2uQ7At1R1RFVHUVr1H9j40W++ZXotZ9POCZ9UqnpWVU9EH08CeBHATnAf81kw+2+Vgns84ePG2/FxweJ9f/W4INg8CuCbInJcRP5jdFmPqp6NPu4H0BN9vBPA62Xfeya6LDSufdgNuENEfiAi94tIe3QZe5URkd0ArgDwFLiP+SzkueDjyfL4M23xcQG8718NFwSb5ydVdR+ADwM4LCIfLP+ilp6TWvld4gLGPlX5XwDeCeC9AM4C+B/xDid5RKQJwN8C+C1VnSj/Gvcx8ggfT6rADgD4uACA9/3V4IJgk6jqG9H/zwH4Pyg9LTew8NRt9P9z0eY8V3eJa5+gu6nqgKoWVfU8gL9AaR8D2AsAICJplB4Q/lpVvxZdzH3MX8HOBR9PVsSf6TJ8XOB9f7W4INgEItIoIs0LHwO4FsDzePs5vMvfc+EogF+Rkg8AGC97aiskrn0eB3CtiLRHT4teG10WhIrjgn8RpX0M4DnhISKC0ikyX1TVz5Z9ifuYv4LZf8vx8WRV/JkuE/rjAu/7HWz2q5hD/A+lV+v/S/TfSQB/EF3eCeAJlE5h9Q8AOqLLBcDnUXql/w8BvC/u27AJjb6C0tOZBZSOzTtYSx8Av4bSi6NOA/jVuG/XJvf6ctTjByjdqe0o2/4Pol4vAfhw2eXXo3TWhZcX9sut+B+An0TpKeEfoOz0e9zH/P4vlP234jbz8eStFnzcWL1H0I8LvO+v/j+JbiQREREREQWIhwwREREREQWMCwIiIiIiooBxQUBEREREFDAuCIiIiIiIAsYFARERERFRwLggICIiIiIKGBcEREREREQB+//gvPFGVLaJQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_index = 0\n",
    "fig_title = \"Expert vs Model's returns\"\n",
    "density = True # If true, than the histogram's integral sums up to 1\n",
    "\n",
    "for ax in grid_iterator(n_rows=3, n_cols=2, axis_size=5, fig_title=fig_title):\n",
    "    env_name = AVAILABLE_ENVS[env_index]\n",
    "    env_index+=1\n",
    "    \n",
    "    ax.hist(returns[env_name]['expert'], label='expert', density=density, bins=25)\n",
    "    ax.hist(returns[env_name]['model'], label='model', density=density, bins=25, alpha=0.5)\n",
    "    ax.set_aspect('auto')\n",
    "    ax.set_title(env_name)\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With dropout and batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_index = 0\n",
    "fig_title = \"Expert vs Model's returns\"\n",
    "density = True # If true, than the histogram's integral sums up to 1\n",
    "\n",
    "for ax in grid_iterator(n_rows=3, n_cols=2, axis_size=5, fig_title=fig_title):\n",
    "    env_name = AVAILABLE_ENVS[env_index]\n",
    "    env_index+=1\n",
    "    \n",
    "    ax.hist(returns[env_name]['expert'], label='expert', density=density, bins=25)\n",
    "    ax.hist(returns[env_name]['model'], label='model', density=density, bins=25, alpha=0.5)\n",
    "    ax.set_aspect('auto')\n",
    "    ax.set_title(env_name)\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolAnt-v1\n",
      "loading dataset RoboschoolAnt-v1\n",
      "loading dataset RoboschoolHumanoid-v1\n",
      "loading dataset RoboschoolHumanoid-v1\n",
      "loading dataset RoboschoolHalfCheetah-v1\n",
      "loading dataset RoboschoolHalfCheetah-v1\n",
      "loading dataset RoboschoolReacher-v1\n",
      "loading dataset RoboschoolReacher-v1\n",
      "loading dataset RoboschoolHopper-v1\n",
      "loading dataset RoboschoolHopper-v1\n",
      "loading dataset RoboschoolWalker2d-v1\n",
      "loading dataset RoboschoolWalker2d-v1\n"
     ]
    }
   ],
   "source": [
    "from hw1.manage_datasets import load_dataset\n",
    "\n",
    "envs_stats = []\n",
    "for env_name in AVAILABLE_ENVS:\n",
    "    expert_data = load_dataset(dataset_name=env_name, dataset_dir=EXPERT_DATA_DIR)\n",
    "    dataset_size = len(expert_data['observations'])\n",
    "    expert_returns = expert_data['returns']\n",
    "    model_returns = load_dataset(dataset_name=env_name, dataset_dir=SUPERVISED_MODELD_DATA_DIR)['returns']\n",
    "    \n",
    "    env_stats = {\n",
    "        'env_name': env_name,\n",
    "        'dataset_size': dataset_size,\n",
    "        'expert_mean': expert_returns.mean(),\n",
    "        'expert_std': expert_returns.std(),\n",
    "        'model_mean': model_returns.mean(),\n",
    "        'model_std': model_returns.std(),\n",
    "    }\n",
    "    envs_stats.append(env_stats)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['env_name', 'dataset_size','expert_mean', 'model_mean', 'expert_std', 'model_std']\n",
    "df2 = pd.DataFrame(envs_stats)[cols]\n",
    "df2['model_to_expert'] = df2['model_mean'] / df2['expert_mean']\n",
    "df2.sort_values(['dataset_size', 'model_to_expert'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_name</th>\n",
       "      <th>dataset_size</th>\n",
       "      <th>expert_mean</th>\n",
       "      <th>model_mean</th>\n",
       "      <th>expert_std</th>\n",
       "      <th>model_std</th>\n",
       "      <th>model_to_expert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RoboschoolAnt-v1</td>\n",
       "      <td>50000</td>\n",
       "      <td>1818.829300</td>\n",
       "      <td>1844.283954</td>\n",
       "      <td>381.867818</td>\n",
       "      <td>307.360874</td>\n",
       "      <td>1.013995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RoboschoolWalker2d-v1</td>\n",
       "      <td>50000</td>\n",
       "      <td>2205.412558</td>\n",
       "      <td>2146.176260</td>\n",
       "      <td>81.940065</td>\n",
       "      <td>309.945304</td>\n",
       "      <td>0.973140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RoboschoolHumanoid-v1</td>\n",
       "      <td>44444</td>\n",
       "      <td>2848.910280</td>\n",
       "      <td>54.546204</td>\n",
       "      <td>1033.996305</td>\n",
       "      <td>14.689183</td>\n",
       "      <td>0.019146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RoboschoolHalfCheetah-v1</td>\n",
       "      <td>42602</td>\n",
       "      <td>2271.298439</td>\n",
       "      <td>2243.406738</td>\n",
       "      <td>909.003381</td>\n",
       "      <td>947.148682</td>\n",
       "      <td>0.987720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RoboschoolHopper-v1</td>\n",
       "      <td>35778</td>\n",
       "      <td>1541.857022</td>\n",
       "      <td>1581.175253</td>\n",
       "      <td>687.020552</td>\n",
       "      <td>634.960057</td>\n",
       "      <td>1.025501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RoboschoolReacher-v1</td>\n",
       "      <td>7500</td>\n",
       "      <td>18.612237</td>\n",
       "      <td>20.090711</td>\n",
       "      <td>10.257760</td>\n",
       "      <td>8.078745</td>\n",
       "      <td>1.079436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   env_name  dataset_size  expert_mean   model_mean   expert_std   model_std  model_to_expert\n",
       "0          RoboschoolAnt-v1         50000  1818.829300  1844.283954   381.867818  307.360874         1.013995\n",
       "5     RoboschoolWalker2d-v1         50000  2205.412558  2146.176260    81.940065  309.945304         0.973140\n",
       "1     RoboschoolHumanoid-v1         44444  2848.910280    54.546204  1033.996305   14.689183         0.019146\n",
       "2  RoboschoolHalfCheetah-v1         42602  2271.298439  2243.406738   909.003381  947.148682         0.987720\n",
       "4       RoboschoolHopper-v1         35778  1541.857022  1581.175253   687.020552  634.960057         1.025501\n",
       "3      RoboschoolReacher-v1          7500    18.612237    20.090711    10.257760    8.078745         1.079436"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing RoboschoolAnt-v1 and RoboschoolHumanoid-v1\n",
    "1. Dataset size: train dataset was about the same size, 45K for the RoboschoolAnt-v1 (90% of 50K) vs 40K for the RoboschoolHumanoid-v1. \n",
    "2. Model architecture: the same model arcitecture was used for both tasks: 3 Fully Connected layers with 100 neurons each. L2 regularization of 1e-04 was used with no dropout nor Batch Normalization. \n",
    "3. Optimizer, Epochs and Learning rate: both models were trained for 100 epochs with Adam optimizer with initial learning rate of 1e-03. The learning rate was halved after every five cosecutive epochs with no Validation MSE improvement.\n",
    "4. Performance: for the RoboschoolAnt-v1, the model performance outperformed the expert by ~1.3%. For the RoboschoolHumanoid-v1 task the model achived less than %2 (~1.9%) of the expert mean reward. For the RoboschoolAnt-v1 task, the return std was also decreased (expert std of ~382, vs model's std of ~307)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model performance vs number of epochs for RoboschoolAnt-v1\n",
    "The RoboschoolAnt-v1 model significantly outperformed RoboschoolHumanoid-v1 model's performance against the expert. It would be interesting to see the the amount of training data needed in order to reach these performance. Another objective is to validate that the perfomance gap between the two tasks was not couse by the fact that RoboschoolHumanoid-v1 was train on a smaller dataset (45K for RoboschoolAnt-v1 vs 40K for RoboschoolHumanoid-v1).\n",
    "\n",
    "Note - we will plot the performance in terms of validation loss instead of model_mean/expert_mean in order to avoid running the full 50 trajectories on all training set sizes. In addition, we will report the model_mean/expert_mean specifically for the specific case of training over 40K examples, in order to assure that the performance difference with RoboschoolHumanoid-v1 was not cause by the training set size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolAnt-v1\n",
      "Domain name: RoboschoolAnt-v1\n",
      "(45000, 28) (5000, 28) (45000, 8) (5000, 8)\n",
      "Training a FC ANN for env RoboschoolAnt-v1 over a training set size 10000 \n",
      "model_name='model_RoboschoolAnt-v1_training_set_size_10000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolAnt-v1_training_set_size_10000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "Train on 10000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 1s 99us/step - loss: 0.6922 - mean_squared_error: 0.6680 - val_loss: 0.4279 - val_mean_squared_error: 0.4028\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.3670 - mean_squared_error: 0.3410 - val_loss: 0.3179 - val_mean_squared_error: 0.2910\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.2843 - mean_squared_error: 0.2566 - val_loss: 0.2561 - val_mean_squared_error: 0.2277\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 0.2420 - mean_squared_error: 0.2131 - val_loss: 0.2361 - val_mean_squared_error: 0.2067\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.2164 - mean_squared_error: 0.1866 - val_loss: 0.2129 - val_mean_squared_error: 0.1827\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.2017 - mean_squared_error: 0.1713 - val_loss: 0.2004 - val_mean_squared_error: 0.1697\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.1898 - mean_squared_error: 0.1588 - val_loss: 0.1934 - val_mean_squared_error: 0.1622\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.1812 - mean_squared_error: 0.1499 - val_loss: 0.1874 - val_mean_squared_error: 0.1560\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.1723 - mean_squared_error: 0.1407 - val_loss: 0.1778 - val_mean_squared_error: 0.1460\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.1657 - mean_squared_error: 0.1339 - val_loss: 0.1767 - val_mean_squared_error: 0.1447\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 0.1603 - mean_squared_error: 0.1283 - val_loss: 0.1684 - val_mean_squared_error: 0.1363\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.1559 - mean_squared_error: 0.1237 - val_loss: 0.1664 - val_mean_squared_error: 0.1341\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.1514 - mean_squared_error: 0.1191 - val_loss: 0.1656 - val_mean_squared_error: 0.1332\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.1478 - mean_squared_error: 0.1154 - val_loss: 0.1632 - val_mean_squared_error: 0.1307\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 1s 50us/step - loss: 0.1440 - mean_squared_error: 0.1115 - val_loss: 0.1550 - val_mean_squared_error: 0.1225\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 1s 55us/step - loss: 0.1416 - mean_squared_error: 0.1090 - val_loss: 0.1543 - val_mean_squared_error: 0.1218\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 1s 52us/step - loss: 0.1389 - mean_squared_error: 0.1063 - val_loss: 0.1519 - val_mean_squared_error: 0.1193\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 1s 57us/step - loss: 0.1367 - mean_squared_error: 0.1040 - val_loss: 0.1472 - val_mean_squared_error: 0.1145\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.1348 - mean_squared_error: 0.1022 - val_loss: 0.1452 - val_mean_squared_error: 0.1126\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 1s 51us/step - loss: 0.1306 - mean_squared_error: 0.0980 - val_loss: 0.1466 - val_mean_squared_error: 0.1140\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.1310 - mean_squared_error: 0.0984 - val_loss: 0.1441 - val_mean_squared_error: 0.1115\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.1279 - mean_squared_error: 0.0952 - val_loss: 0.1395 - val_mean_squared_error: 0.1069\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 1s 51us/step - loss: 0.1264 - mean_squared_error: 0.0938 - val_loss: 0.1409 - val_mean_squared_error: 0.1083\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.1247 - mean_squared_error: 0.0922 - val_loss: 0.1379 - val_mean_squared_error: 0.1054\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.1221 - mean_squared_error: 0.0896 - val_loss: 0.1405 - val_mean_squared_error: 0.1080\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 1s 51us/step - loss: 0.1215 - mean_squared_error: 0.0891 - val_loss: 0.1350 - val_mean_squared_error: 0.1026\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.1198 - mean_squared_error: 0.0874 - val_loss: 0.1380 - val_mean_squared_error: 0.1056\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.1181 - mean_squared_error: 0.0858 - val_loss: 0.1328 - val_mean_squared_error: 0.1005\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.1162 - mean_squared_error: 0.0840 - val_loss: 0.1348 - val_mean_squared_error: 0.1025\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.1158 - mean_squared_error: 0.0836 - val_loss: 0.1356 - val_mean_squared_error: 0.1035\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.1149 - mean_squared_error: 0.0828 - val_loss: 0.1338 - val_mean_squared_error: 0.1017\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.1139 - mean_squared_error: 0.0818 - val_loss: 0.1316 - val_mean_squared_error: 0.0996\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.1121 - mean_squared_error: 0.0802 - val_loss: 0.1327 - val_mean_squared_error: 0.1008\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.1112 - mean_squared_error: 0.0793 - val_loss: 0.1300 - val_mean_squared_error: 0.0982\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 1s 50us/step - loss: 0.1102 - mean_squared_error: 0.0784 - val_loss: 0.1256 - val_mean_squared_error: 0.0939\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.1090 - mean_squared_error: 0.0773 - val_loss: 0.1255 - val_mean_squared_error: 0.0938\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.1091 - mean_squared_error: 0.0774 - val_loss: 0.1285 - val_mean_squared_error: 0.0969\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 1s 51us/step - loss: 0.1075 - mean_squared_error: 0.0760 - val_loss: 0.1225 - val_mean_squared_error: 0.0910\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.1071 - mean_squared_error: 0.0756 - val_loss: 0.1268 - val_mean_squared_error: 0.0954\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.1057 - mean_squared_error: 0.0744 - val_loss: 0.1226 - val_mean_squared_error: 0.0913\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.1050 - mean_squared_error: 0.0737 - val_loss: 0.1224 - val_mean_squared_error: 0.0911\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.1050 - mean_squared_error: 0.0738 - val_loss: 0.1236 - val_mean_squared_error: 0.0925\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.1048 - mean_squared_error: 0.0737 - val_loss: 0.1254 - val_mean_squared_error: 0.0943\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0979 - mean_squared_error: 0.0668 - val_loss: 0.1167 - val_mean_squared_error: 0.0857\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0966 - mean_squared_error: 0.0655 - val_loss: 0.1160 - val_mean_squared_error: 0.0850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.0964 - mean_squared_error: 0.0654 - val_loss: 0.1168 - val_mean_squared_error: 0.0858\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.0956 - mean_squared_error: 0.0647 - val_loss: 0.1164 - val_mean_squared_error: 0.0855\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0960 - mean_squared_error: 0.0651 - val_loss: 0.1151 - val_mean_squared_error: 0.0842\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0956 - mean_squared_error: 0.0647 - val_loss: 0.1164 - val_mean_squared_error: 0.0855\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.0949 - mean_squared_error: 0.0641 - val_loss: 0.1143 - val_mean_squared_error: 0.0835\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.0943 - mean_squared_error: 0.0635 - val_loss: 0.1158 - val_mean_squared_error: 0.0851\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0948 - mean_squared_error: 0.0641 - val_loss: 0.1155 - val_mean_squared_error: 0.0848\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.0942 - mean_squared_error: 0.0636 - val_loss: 0.1148 - val_mean_squared_error: 0.0842\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0945 - mean_squared_error: 0.0639 - val_loss: 0.1139 - val_mean_squared_error: 0.0833\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0929 - mean_squared_error: 0.0624 - val_loss: 0.1122 - val_mean_squared_error: 0.0817\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0934 - mean_squared_error: 0.0629 - val_loss: 0.1144 - val_mean_squared_error: 0.0839\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.0925 - mean_squared_error: 0.0620 - val_loss: 0.1137 - val_mean_squared_error: 0.0833\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.0921 - mean_squared_error: 0.0617 - val_loss: 0.1125 - val_mean_squared_error: 0.0822\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0917 - mean_squared_error: 0.0614 - val_loss: 0.1147 - val_mean_squared_error: 0.0844\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0920 - mean_squared_error: 0.0617 - val_loss: 0.1126 - val_mean_squared_error: 0.0823\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.0886 - mean_squared_error: 0.0583 - val_loss: 0.1094 - val_mean_squared_error: 0.0792\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.0883 - mean_squared_error: 0.0581 - val_loss: 0.1102 - val_mean_squared_error: 0.0800\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 1s 52us/step - loss: 0.0879 - mean_squared_error: 0.0577 - val_loss: 0.1099 - val_mean_squared_error: 0.0797\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 1s 53us/step - loss: 0.0877 - mean_squared_error: 0.0575 - val_loss: 0.1103 - val_mean_squared_error: 0.0801\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 1s 54us/step - loss: 0.0875 - mean_squared_error: 0.0574 - val_loss: 0.1105 - val_mean_squared_error: 0.0804\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0873 - mean_squared_error: 0.0572 - val_loss: 0.1089 - val_mean_squared_error: 0.0788\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.0871 - mean_squared_error: 0.0570 - val_loss: 0.1102 - val_mean_squared_error: 0.0801\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.0872 - mean_squared_error: 0.0572 - val_loss: 0.1094 - val_mean_squared_error: 0.0794\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.0869 - mean_squared_error: 0.0569 - val_loss: 0.1095 - val_mean_squared_error: 0.0795\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.0868 - mean_squared_error: 0.0568 - val_loss: 0.1092 - val_mean_squared_error: 0.0793\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0864 - mean_squared_error: 0.0564 - val_loss: 0.1085 - val_mean_squared_error: 0.0786\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.0863 - mean_squared_error: 0.0564 - val_loss: 0.1082 - val_mean_squared_error: 0.0783\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.0863 - mean_squared_error: 0.05 - 0s 46us/step - loss: 0.0862 - mean_squared_error: 0.0563 - val_loss: 0.1071 - val_mean_squared_error: 0.0773\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.0859 - mean_squared_error: 0.0560 - val_loss: 0.1084 - val_mean_squared_error: 0.0785\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.0859 - mean_squared_error: 0.0561 - val_loss: 0.1080 - val_mean_squared_error: 0.0782\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0856 - mean_squared_error: 0.0558 - val_loss: 0.1079 - val_mean_squared_error: 0.0782\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.0856 - mean_squared_error: 0.0558 - val_loss: 0.1080 - val_mean_squared_error: 0.0783\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.0854 - mean_squared_error: 0.0556 - val_loss: 0.1077 - val_mean_squared_error: 0.0779\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0838 - mean_squared_error: 0.0541 - val_loss: 0.1061 - val_mean_squared_error: 0.0764\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.0835 - mean_squared_error: 0.0538 - val_loss: 0.1066 - val_mean_squared_error: 0.0769\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.0834 - mean_squared_error: 0.0537 - val_loss: 0.1063 - val_mean_squared_error: 0.0767\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0833 - mean_squared_error: 0.0536 - val_loss: 0.1063 - val_mean_squared_error: 0.0766\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.0832 - mean_squared_error: 0.0535 - val_loss: 0.1063 - val_mean_squared_error: 0.0766\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 0.0832 - mean_squared_error: 0.0536 - val_loss: 0.1065 - val_mean_squared_error: 0.0768\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.0823 - mean_squared_error: 0.0527 - val_loss: 0.1057 - val_mean_squared_error: 0.0760\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0821 - mean_squared_error: 0.0525 - val_loss: 0.1054 - val_mean_squared_error: 0.0758\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0821 - mean_squared_error: 0.0525 - val_loss: 0.1054 - val_mean_squared_error: 0.0757\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0820 - mean_squared_error: 0.0524 - val_loss: 0.1054 - val_mean_squared_error: 0.0758\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.0820 - mean_squared_error: 0.0524 - val_loss: 0.1056 - val_mean_squared_error: 0.0760\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0820 - mean_squared_error: 0.0524 - val_loss: 0.1053 - val_mean_squared_error: 0.0757\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.0819 - mean_squared_error: 0.0524 - val_loss: 0.1055 - val_mean_squared_error: 0.0759\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.0815 - mean_squared_error: 0.0519 - val_loss: 0.1049 - val_mean_squared_error: 0.0753\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0814 - mean_squared_error: 0.0519 - val_loss: 0.1049 - val_mean_squared_error: 0.0753\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.0814 - mean_squared_error: 0.0518 - val_loss: 0.1048 - val_mean_squared_error: 0.0753\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.0814 - mean_squared_error: 0.0518 - val_loss: 0.1049 - val_mean_squared_error: 0.0753\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.0814 - mean_squared_error: 0.0518 - val_loss: 0.1048 - val_mean_squared_error: 0.0752\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.0813 - mean_squared_error: 0.0518 - val_loss: 0.1050 - val_mean_squared_error: 0.0754\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.0811 - mean_squared_error: 0.0515 - val_loss: 0.1047 - val_mean_squared_error: 0.0752\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.0811 - mean_squared_error: 0.0515 - val_loss: 0.1047 - val_mean_squared_error: 0.0752\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.0810 - mean_squared_error: 0.0515 - val_loss: 0.1047 - val_mean_squared_error: 0.0751\n",
      "hw1/models/model_RoboschoolAnt-v1_training_set_size_10000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolAnt-v1\n",
      "{'model_path': 'hw1/models/model_RoboschoolAnt-v1_training_set_size_10000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'train_mse': 0.07178900007456282, 'model_name': 'model_RoboschoolAnt-v1_training_set_size_10000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'dataset_name': 'RoboschoolAnt-v1', 'test_mse': 0.07513460437322089}\n",
      "Training a FC ANN for env RoboschoolAnt-v1 over a training set size 20000 \n",
      "model_name='model_RoboschoolAnt-v1_training_set_size_20000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolAnt-v1_training_set_size_20000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.5228 - mean_squared_error: 0.4981 - val_loss: 0.3090 - val_mean_squared_error: 0.2828\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.2672 - mean_squared_error: 0.2398 - val_loss: 0.2298 - val_mean_squared_error: 0.2014\n",
      "Epoch 3/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.2144 - mean_squared_error: 0.1853 - val_loss: 0.1986 - val_mean_squared_error: 0.1689\n",
      "Epoch 4/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.1880 - mean_squared_error: 0.1578 - val_loss: 0.1779 - val_mean_squared_error: 0.1474\n",
      "Epoch 5/100\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.1731 - mean_squared_error: 0.1423 - val_loss: 0.1676 - val_mean_squared_error: 0.1366\n",
      "Epoch 6/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.1626 - mean_squared_error: 0.1315 - val_loss: 0.1664 - val_mean_squared_error: 0.1352\n",
      "Epoch 7/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.1547 - mean_squared_error: 0.1233 - val_loss: 0.1546 - val_mean_squared_error: 0.1232\n",
      "Epoch 8/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.1488 - mean_squared_error: 0.1174 - val_loss: 0.1504 - val_mean_squared_error: 0.1189\n",
      "Epoch 9/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.1435 - mean_squared_error: 0.1120 - val_loss: 0.1455 - val_mean_squared_error: 0.1141\n",
      "Epoch 10/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.1388 - mean_squared_error: 0.1073 - val_loss: 0.1445 - val_mean_squared_error: 0.1131\n",
      "Epoch 11/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.1353 - mean_squared_error: 0.1039 - val_loss: 0.1369 - val_mean_squared_error: 0.1056\n",
      "Epoch 12/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.1319 - mean_squared_error: 0.1006 - val_loss: 0.1321 - val_mean_squared_error: 0.1008\n",
      "Epoch 13/100\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.1282 - mean_squared_error: 0.0970 - val_loss: 0.1321 - val_mean_squared_error: 0.1010\n",
      "Epoch 14/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.1253 - mean_squared_error: 0.0942 - val_loss: 0.1309 - val_mean_squared_error: 0.0998\n",
      "Epoch 15/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.1233 - mean_squared_error: 0.0923 - val_loss: 0.1275 - val_mean_squared_error: 0.0966\n",
      "Epoch 16/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.1209 - mean_squared_error: 0.0901 - val_loss: 0.1377 - val_mean_squared_error: 0.1069\n",
      "Epoch 17/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.1187 - mean_squared_error: 0.0880 - val_loss: 0.1254 - val_mean_squared_error: 0.0948\n",
      "Epoch 18/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.1170 - mean_squared_error: 0.0865 - val_loss: 0.1275 - val_mean_squared_error: 0.0971\n",
      "Epoch 19/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.1150 - mean_squared_error: 0.0846 - val_loss: 0.1232 - val_mean_squared_error: 0.0929\n",
      "Epoch 20/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.1130 - mean_squared_error: 0.0827 - val_loss: 0.1211 - val_mean_squared_error: 0.0909\n",
      "Epoch 21/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.1114 - mean_squared_error: 0.0813 - val_loss: 0.1188 - val_mean_squared_error: 0.0888\n",
      "Epoch 22/100\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.1101 - mean_squared_error: 0.0801 - val_loss: 0.1143 - val_mean_squared_error: 0.0845\n",
      "Epoch 23/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.1083 - mean_squared_error: 0.0785 - val_loss: 0.1154 - val_mean_squared_error: 0.0857\n",
      "Epoch 24/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.1070 - mean_squared_error: 0.0774 - val_loss: 0.1158 - val_mean_squared_error: 0.0863\n",
      "Epoch 25/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.1064 - mean_squared_error: 0.0770 - val_loss: 0.1132 - val_mean_squared_error: 0.0838\n",
      "Epoch 26/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.1047 - mean_squared_error: 0.0754 - val_loss: 0.1108 - val_mean_squared_error: 0.0816\n",
      "Epoch 27/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.1034 - mean_squared_error: 0.0743 - val_loss: 0.1113 - val_mean_squared_error: 0.0822\n",
      "Epoch 28/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.1024 - mean_squared_error: 0.0734 - val_loss: 0.1135 - val_mean_squared_error: 0.0845\n",
      "Epoch 29/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.1015 - mean_squared_error: 0.0727 - val_loss: 0.1131 - val_mean_squared_error: 0.0843\n",
      "Epoch 30/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.1004 - mean_squared_error: 0.0717 - val_loss: 0.1100 - val_mean_squared_error: 0.0813\n",
      "Epoch 31/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0999 - mean_squared_error: 0.0713 - val_loss: 0.1086 - val_mean_squared_error: 0.0800\n",
      "Epoch 32/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0985 - mean_squared_error: 0.0701 - val_loss: 0.1114 - val_mean_squared_error: 0.0830\n",
      "Epoch 33/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.0980 - mean_squared_error: 0.0697 - val_loss: 0.1051 - val_mean_squared_error: 0.0768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0971 - mean_squared_error: 0.0689 - val_loss: 0.1069 - val_mean_squared_error: 0.0788\n",
      "Epoch 35/100\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0958 - mean_squared_error: 0.0677 - val_loss: 0.1072 - val_mean_squared_error: 0.0792\n",
      "Epoch 36/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0950 - mean_squared_error: 0.0670 - val_loss: 0.1039 - val_mean_squared_error: 0.0760\n",
      "Epoch 37/100\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0953 - mean_squared_error: 0.0675 - val_loss: 0.1032 - val_mean_squared_error: 0.0754\n",
      "Epoch 38/100\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0934 - mean_squared_error: 0.0657 - val_loss: 0.1047 - val_mean_squared_error: 0.0770\n",
      "Epoch 39/100\n",
      "20000/20000 [==============================] - ETA: 0s - loss: 0.0935 - mean_squared_error: 0.06 - 1s 36us/step - loss: 0.0936 - mean_squared_error: 0.0660 - val_loss: 0.1039 - val_mean_squared_error: 0.0763\n",
      "Epoch 40/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0924 - mean_squared_error: 0.0649 - val_loss: 0.1018 - val_mean_squared_error: 0.0743\n",
      "Epoch 41/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0919 - mean_squared_error: 0.0646 - val_loss: 0.1016 - val_mean_squared_error: 0.0744\n",
      "Epoch 42/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0908 - mean_squared_error: 0.0635 - val_loss: 0.1015 - val_mean_squared_error: 0.0743\n",
      "Epoch 43/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0908 - mean_squared_error: 0.0637 - val_loss: 0.1018 - val_mean_squared_error: 0.0747\n",
      "Epoch 44/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0897 - mean_squared_error: 0.0627 - val_loss: 0.0998 - val_mean_squared_error: 0.0729\n",
      "Epoch 45/100\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0895 - mean_squared_error: 0.0626 - val_loss: 0.0985 - val_mean_squared_error: 0.0716\n",
      "Epoch 46/100\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0890 - mean_squared_error: 0.0622 - val_loss: 0.0982 - val_mean_squared_error: 0.0714\n",
      "Epoch 47/100\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0881 - mean_squared_error: 0.0614 - val_loss: 0.1044 - val_mean_squared_error: 0.0778\n",
      "Epoch 48/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0875 - mean_squared_error: 0.0609 - val_loss: 0.0979 - val_mean_squared_error: 0.0713\n",
      "Epoch 49/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0877 - mean_squared_error: 0.0612 - val_loss: 0.1004 - val_mean_squared_error: 0.0739\n",
      "Epoch 50/100\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0864 - mean_squared_error: 0.0600 - val_loss: 0.0974 - val_mean_squared_error: 0.0710\n",
      "Epoch 51/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0862 - mean_squared_error: 0.0599 - val_loss: 0.0980 - val_mean_squared_error: 0.0718\n",
      "Epoch 52/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0860 - mean_squared_error: 0.0598 - val_loss: 0.0966 - val_mean_squared_error: 0.0705\n",
      "Epoch 53/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.0852 - mean_squared_error: 0.0591 - val_loss: 0.0952 - val_mean_squared_error: 0.0691\n",
      "Epoch 54/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0846 - mean_squared_error: 0.0586 - val_loss: 0.0953 - val_mean_squared_error: 0.0693\n",
      "Epoch 55/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.0839 - mean_squared_error: 0.0580 - val_loss: 0.0956 - val_mean_squared_error: 0.0698\n",
      "Epoch 56/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0840 - mean_squared_error: 0.0582 - val_loss: 0.0953 - val_mean_squared_error: 0.0695\n",
      "Epoch 57/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0837 - mean_squared_error: 0.0579 - val_loss: 0.0949 - val_mean_squared_error: 0.0692\n",
      "Epoch 58/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.0839 - mean_squared_error: 0.0582 - val_loss: 0.0955 - val_mean_squared_error: 0.0699\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 59/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0773 - mean_squared_error: 0.0517 - val_loss: 0.0893 - val_mean_squared_error: 0.0637\n",
      "Epoch 60/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0769 - mean_squared_error: 0.0514 - val_loss: 0.0929 - val_mean_squared_error: 0.0674\n",
      "Epoch 61/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0766 - mean_squared_error: 0.0512 - val_loss: 0.0893 - val_mean_squared_error: 0.0638\n",
      "Epoch 62/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0766 - mean_squared_error: 0.0512 - val_loss: 0.0901 - val_mean_squared_error: 0.0648\n",
      "Epoch 63/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0764 - mean_squared_error: 0.0511 - val_loss: 0.0894 - val_mean_squared_error: 0.0640\n",
      "Epoch 64/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0761 - mean_squared_error: 0.0508 - val_loss: 0.0886 - val_mean_squared_error: 0.0634\n",
      "Epoch 65/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0758 - mean_squared_error: 0.0506 - val_loss: 0.0883 - val_mean_squared_error: 0.0631\n",
      "Epoch 66/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0755 - mean_squared_error: 0.0503 - val_loss: 0.0875 - val_mean_squared_error: 0.0623\n",
      "Epoch 67/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0756 - mean_squared_error: 0.0505 - val_loss: 0.0881 - val_mean_squared_error: 0.0630\n",
      "Epoch 68/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.0755 - mean_squared_error: 0.0504 - val_loss: 0.0886 - val_mean_squared_error: 0.0636\n",
      "Epoch 69/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0749 - mean_squared_error: 0.0499 - val_loss: 0.0891 - val_mean_squared_error: 0.0642\n",
      "Epoch 70/100\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0748 - mean_squared_error: 0.0499 - val_loss: 0.0873 - val_mean_squared_error: 0.0624\n",
      "Epoch 71/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0747 - mean_squared_error: 0.0498 - val_loss: 0.0866 - val_mean_squared_error: 0.0617\n",
      "Epoch 72/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0743 - mean_squared_error: 0.0495 - val_loss: 0.0877 - val_mean_squared_error: 0.0630\n",
      "Epoch 73/100\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.0739 - mean_squared_error: 0.0492 - val_loss: 0.0867 - val_mean_squared_error: 0.0620\n",
      "Epoch 74/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.0740 - mean_squared_error: 0.0494 - val_loss: 0.0864 - val_mean_squared_error: 0.0617\n",
      "Epoch 75/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0735 - mean_squared_error: 0.0489 - val_loss: 0.0867 - val_mean_squared_error: 0.0621\n",
      "Epoch 76/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0734 - mean_squared_error: 0.0489 - val_loss: 0.0865 - val_mean_squared_error: 0.0620\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 77/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0702 - mean_squared_error: 0.0457 - val_loss: 0.0842 - val_mean_squared_error: 0.0597\n",
      "Epoch 78/100\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0701 - mean_squared_error: 0.0456 - val_loss: 0.0845 - val_mean_squared_error: 0.0600\n",
      "Epoch 79/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0700 - mean_squared_error: 0.0456 - val_loss: 0.0842 - val_mean_squared_error: 0.0598\n",
      "Epoch 80/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0700 - mean_squared_error: 0.0456 - val_loss: 0.0845 - val_mean_squared_error: 0.0601\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0700 - mean_squared_error: 0.0456 - val_loss: 0.0833 - val_mean_squared_error: 0.0589\n",
      "Epoch 82/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0698 - mean_squared_error: 0.0455 - val_loss: 0.0851 - val_mean_squared_error: 0.0608\n",
      "Epoch 83/100\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.0696 - mean_squared_error: 0.0453 - val_loss: 0.0830 - val_mean_squared_error: 0.0587\n",
      "Epoch 84/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0696 - mean_squared_error: 0.0453 - val_loss: 0.0831 - val_mean_squared_error: 0.0589\n",
      "Epoch 85/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0693 - mean_squared_error: 0.0450 - val_loss: 0.0838 - val_mean_squared_error: 0.0595\n",
      "Epoch 86/100\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.0694 - mean_squared_error: 0.0452 - val_loss: 0.0837 - val_mean_squared_error: 0.0595\n",
      "Epoch 87/100\n",
      "20000/20000 [==============================] - 1s 40us/step - loss: 0.0693 - mean_squared_error: 0.0451 - val_loss: 0.0831 - val_mean_squared_error: 0.0590\n",
      "Epoch 88/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0691 - mean_squared_error: 0.0450 - val_loss: 0.0829 - val_mean_squared_error: 0.0588\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 89/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0675 - mean_squared_error: 0.0434 - val_loss: 0.0817 - val_mean_squared_error: 0.0576\n",
      "Epoch 90/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0673 - mean_squared_error: 0.0433 - val_loss: 0.0814 - val_mean_squared_error: 0.0574\n",
      "Epoch 91/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.0673 - mean_squared_error: 0.0432 - val_loss: 0.0816 - val_mean_squared_error: 0.0575\n",
      "Epoch 92/100\n",
      "20000/20000 [==============================] - 1s 40us/step - loss: 0.0673 - mean_squared_error: 0.0433 - val_loss: 0.0814 - val_mean_squared_error: 0.0573\n",
      "Epoch 93/100\n",
      "20000/20000 [==============================] - 1s 40us/step - loss: 0.0672 - mean_squared_error: 0.0432 - val_loss: 0.0811 - val_mean_squared_error: 0.0571\n",
      "Epoch 94/100\n",
      "20000/20000 [==============================] - 1s 40us/step - loss: 0.0671 - mean_squared_error: 0.0431 - val_loss: 0.0813 - val_mean_squared_error: 0.0573\n",
      "Epoch 95/100\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.0670 - mean_squared_error: 0.0430 - val_loss: 0.0812 - val_mean_squared_error: 0.0572\n",
      "Epoch 96/100\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.0670 - mean_squared_error: 0.0431 - val_loss: 0.0817 - val_mean_squared_error: 0.0577\n",
      "Epoch 97/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.0669 - mean_squared_error: 0.0429 - val_loss: 0.0812 - val_mean_squared_error: 0.0573\n",
      "Epoch 98/100\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.0668 - mean_squared_error: 0.0429 - val_loss: 0.0814 - val_mean_squared_error: 0.0575\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 99/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.0660 - mean_squared_error: 0.0420 - val_loss: 0.0807 - val_mean_squared_error: 0.0568\n",
      "Epoch 100/100\n",
      "20000/20000 [==============================] - 1s 39us/step - loss: 0.0659 - mean_squared_error: 0.0420 - val_loss: 0.0805 - val_mean_squared_error: 0.0566\n",
      "hw1/models/model_RoboschoolAnt-v1_training_set_size_20000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolAnt-v1\n",
      "{'model_path': 'hw1/models/model_RoboschoolAnt-v1_training_set_size_20000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'train_mse': 0.05111074326336414, 'model_name': 'model_RoboschoolAnt-v1_training_set_size_20000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'dataset_name': 'RoboschoolAnt-v1', 'test_mse': 0.056568306112516495}\n",
      "Training a FC ANN for env RoboschoolAnt-v1 over a training set size 30000 \n",
      "model_name='model_RoboschoolAnt-v1_training_set_size_30000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolAnt-v1_training_set_size_30000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "Train on 30000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 2s 58us/step - loss: 0.4402 - mean_squared_error: 0.4135 - val_loss: 0.2606 - val_mean_squared_error: 0.2316\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 1s 43us/step - loss: 0.2244 - mean_squared_error: 0.1943 - val_loss: 0.2020 - val_mean_squared_error: 0.1710\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.1842 - mean_squared_error: 0.1526 - val_loss: 0.1750 - val_mean_squared_error: 0.1431\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 2s 71us/step - loss: 0.1657 - mean_squared_error: 0.1335 - val_loss: 0.1638 - val_mean_squared_error: 0.1315\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 1s 43us/step - loss: 0.1535 - mean_squared_error: 0.1210 - val_loss: 0.1544 - val_mean_squared_error: 0.1219\n",
      "Epoch 6/100\n",
      "30000/30000 [==============================] - 1s 44us/step - loss: 0.1441 - mean_squared_error: 0.1115 - val_loss: 0.1418 - val_mean_squared_error: 0.1093\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 1s 48us/step - loss: 0.1368 - mean_squared_error: 0.1043 - val_loss: 0.1372 - val_mean_squared_error: 0.1048\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 1s 49us/step - loss: 0.1314 - mean_squared_error: 0.0991 - val_loss: 0.1356 - val_mean_squared_error: 0.1033\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.1267 - mean_squared_error: 0.0944 - val_loss: 0.1277 - val_mean_squared_error: 0.0956\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.1232 - mean_squared_error: 0.0912 - val_loss: 0.1263 - val_mean_squared_error: 0.0944\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 1s 39us/step - loss: 0.1191 - mean_squared_error: 0.0873 - val_loss: 0.1236 - val_mean_squared_error: 0.0919\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.1166 - mean_squared_error: 0.0851 - val_loss: 0.1185 - val_mean_squared_error: 0.0871\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 1s 42us/step - loss: 0.1144 - mean_squared_error: 0.0831 - val_loss: 0.1155 - val_mean_squared_error: 0.0844\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.1117 - mean_squared_error: 0.0807 - val_loss: 0.1145 - val_mean_squared_error: 0.0836\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.1091 - mean_squared_error: 0.0783 - val_loss: 0.1119 - val_mean_squared_error: 0.0813\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.1078 - mean_squared_error: 0.0773 - val_loss: 0.1189 - val_mean_squared_error: 0.0885\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.1061 - mean_squared_error: 0.0759 - val_loss: 0.1081 - val_mean_squared_error: 0.0779\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 1s 46us/step - loss: 0.1031 - mean_squared_error: 0.0731 - val_loss: 0.1074 - val_mean_squared_error: 0.0776\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 1s 47us/step - loss: 0.1023 - mean_squared_error: 0.0725 - val_loss: 0.1077 - val_mean_squared_error: 0.0781\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.1011 - mean_squared_error: 0.0716 - val_loss: 0.1040 - val_mean_squared_error: 0.0746\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 1s 39us/step - loss: 0.0994 - mean_squared_error: 0.0701 - val_loss: 0.1033 - val_mean_squared_error: 0.0741\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 2s 56us/step - loss: 0.0982 - mean_squared_error: 0.0691 - val_loss: 0.1034 - val_mean_squared_error: 0.0745\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 1s 50us/step - loss: 0.0970 - mean_squared_error: 0.0682 - val_loss: 0.1003 - val_mean_squared_error: 0.0716\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.0959 - mean_squared_error: 0.0673 - val_loss: 0.1015 - val_mean_squared_error: 0.0730\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.0951 - mean_squared_error: 0.0667 - val_loss: 0.1022 - val_mean_squared_error: 0.0739\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.0940 - mean_squared_error: 0.0658 - val_loss: 0.0997 - val_mean_squared_error: 0.0716\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 1s 42us/step - loss: 0.0929 - mean_squared_error: 0.0649 - val_loss: 0.0999 - val_mean_squared_error: 0.0720\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 1s 42us/step - loss: 0.0922 - mean_squared_error: 0.0644 - val_loss: 0.0993 - val_mean_squared_error: 0.0716\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 1s 43us/step - loss: 0.0854 - mean_squared_error: 0.0577 - val_loss: 0.0920 - val_mean_squared_error: 0.0645\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 1s 43us/step - loss: 0.0850 - mean_squared_error: 0.0575 - val_loss: 0.0920 - val_mean_squared_error: 0.0645\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 1s 42us/step - loss: 0.0846 - mean_squared_error: 0.0573 - val_loss: 0.0911 - val_mean_squared_error: 0.0638\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 1s 37us/step - loss: 0.0840 - mean_squared_error: 0.0568 - val_loss: 0.0904 - val_mean_squared_error: 0.0632\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 1s 43us/step - loss: 0.0837 - mean_squared_error: 0.0566 - val_loss: 0.0898 - val_mean_squared_error: 0.0627\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 1s 49us/step - loss: 0.0831 - mean_squared_error: 0.0561 - val_loss: 0.0917 - val_mean_squared_error: 0.0648\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 1s 45us/step - loss: 0.0827 - mean_squared_error: 0.0558 - val_loss: 0.0903 - val_mean_squared_error: 0.0634\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 1s 48us/step - loss: 0.0822 - mean_squared_error: 0.0554 - val_loss: 0.0906 - val_mean_squared_error: 0.0639\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 2s 64us/step - loss: 0.0818 - mean_squared_error: 0.0552 - val_loss: 0.0888 - val_mean_squared_error: 0.0622\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 1s 47us/step - loss: 0.0815 - mean_squared_error: 0.0549 - val_loss: 0.0882 - val_mean_squared_error: 0.0617\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 1s 48us/step - loss: 0.0810 - mean_squared_error: 0.0545 - val_loss: 0.0890 - val_mean_squared_error: 0.0626\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.0808 - mean_squared_error: 0.0545 - val_loss: 0.0865 - val_mean_squared_error: 0.0603\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 1s 45us/step - loss: 0.0799 - mean_squared_error: 0.0537 - val_loss: 0.0878 - val_mean_squared_error: 0.0616\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 1s 47us/step - loss: 0.0797 - mean_squared_error: 0.0536 - val_loss: 0.0870 - val_mean_squared_error: 0.0610\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 1s 44us/step - loss: 0.0794 - mean_squared_error: 0.0534 - val_loss: 0.0892 - val_mean_squared_error: 0.0633\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 1s 49us/step - loss: 0.0790 - mean_squared_error: 0.0531 - val_loss: 0.0854 - val_mean_squared_error: 0.0596\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 1s 45us/step - loss: 0.0788 - mean_squared_error: 0.0530 - val_loss: 0.0871 - val_mean_squared_error: 0.0614\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.0784 - mean_squared_error: 0.0528 - val_loss: 0.0858 - val_mean_squared_error: 0.0602\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 1s 42us/step - loss: 0.0781 - mean_squared_error: 0.0526 - val_loss: 0.0858 - val_mean_squared_error: 0.0602\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 1s 46us/step - loss: 0.0775 - mean_squared_error: 0.0521 - val_loss: 0.0854 - val_mean_squared_error: 0.0599\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.0775 - mean_squared_error: 0.0521 - val_loss: 0.0849 - val_mean_squared_error: 0.0596\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.0740 - mean_squared_error: 0.0487 - val_loss: 0.0825 - val_mean_squared_error: 0.0573\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.0738 - mean_squared_error: 0.0486 - val_loss: 0.0827 - val_mean_squared_error: 0.0575\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.0736 - mean_squared_error: 0.0484 - val_loss: 0.0816 - val_mean_squared_error: 0.0565\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 1s 37us/step - loss: 0.0735 - mean_squared_error: 0.0484 - val_loss: 0.0827 - val_mean_squared_error: 0.0576\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 1s 38us/step - loss: 0.0732 - mean_squared_error: 0.0482 - val_loss: 0.0825 - val_mean_squared_error: 0.0575\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.0730 - mean_squared_error: 0.0480 - val_loss: 0.0814 - val_mean_squared_error: 0.0564\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.0729 - mean_squared_error: 0.0480 - val_loss: 0.0810 - val_mean_squared_error: 0.0561\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 1s 44us/step - loss: 0.0728 - mean_squared_error: 0.0479 - val_loss: 0.0810 - val_mean_squared_error: 0.0561\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 2s 52us/step - loss: 0.0727 - mean_squared_error: 0.0478 - val_loss: 0.0807 - val_mean_squared_error: 0.0559\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 1s 38us/step - loss: 0.0723 - mean_squared_error: 0.0475 - val_loss: 0.0801 - val_mean_squared_error: 0.0553\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 1s 37us/step - loss: 0.0723 - mean_squared_error: 0.0475 - val_loss: 0.0813 - val_mean_squared_error: 0.0566\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 1s 36us/step - loss: 0.0720 - mean_squared_error: 0.0474 - val_loss: 0.0799 - val_mean_squared_error: 0.0553\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 1s 37us/step - loss: 0.0721 - mean_squared_error: 0.0475 - val_loss: 0.0806 - val_mean_squared_error: 0.0560\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.0717 - mean_squared_error: 0.0471 - val_loss: 0.0801 - val_mean_squared_error: 0.0555\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 1s 47us/step - loss: 0.0715 - mean_squared_error: 0.0470 - val_loss: 0.0799 - val_mean_squared_error: 0.0554\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 1s 36us/step - loss: 0.0698 - mean_squared_error: 0.0453 - val_loss: 0.0788 - val_mean_squared_error: 0.0543\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.0696 - mean_squared_error: 0.0452 - val_loss: 0.0794 - val_mean_squared_error: 0.0550\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 1s 39us/step - loss: 0.0696 - mean_squared_error: 0.0452 - val_loss: 0.0789 - val_mean_squared_error: 0.0545\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 1s 37us/step - loss: 0.0694 - mean_squared_error: 0.0450 - val_loss: 0.0785 - val_mean_squared_error: 0.0541\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 1s 37us/step - loss: 0.0695 - mean_squared_error: 0.0451 - val_loss: 0.0783 - val_mean_squared_error: 0.0540\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 1s 36us/step - loss: 0.0693 - mean_squared_error: 0.0450 - val_loss: 0.0789 - val_mean_squared_error: 0.0545\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.0693 - mean_squared_error: 0.0450 - val_loss: 0.0782 - val_mean_squared_error: 0.0539\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 1s 39us/step - loss: 0.0691 - mean_squared_error: 0.0449 - val_loss: 0.0782 - val_mean_squared_error: 0.0540\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 1s 35us/step - loss: 0.0690 - mean_squared_error: 0.0448 - val_loss: 0.0780 - val_mean_squared_error: 0.0538\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 1s 36us/step - loss: 0.0690 - mean_squared_error: 0.0448 - val_loss: 0.0788 - val_mean_squared_error: 0.0546\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 1s 36us/step - loss: 0.0689 - mean_squared_error: 0.0447 - val_loss: 0.0781 - val_mean_squared_error: 0.0539\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 1s 35us/step - loss: 0.0688 - mean_squared_error: 0.0447 - val_loss: 0.0776 - val_mean_squared_error: 0.0534\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 1s 37us/step - loss: 0.0687 - mean_squared_error: 0.0445 - val_loss: 0.0778 - val_mean_squared_error: 0.0537\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 1s 35us/step - loss: 0.0686 - mean_squared_error: 0.0445 - val_loss: 0.0774 - val_mean_squared_error: 0.0533\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 1s 36us/step - loss: 0.0686 - mean_squared_error: 0.0445 - val_loss: 0.0779 - val_mean_squared_error: 0.0538\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 1s 34us/step - loss: 0.0684 - mean_squared_error: 0.0444 - val_loss: 0.0775 - val_mean_squared_error: 0.0534\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 1s 39us/step - loss: 0.0684 - mean_squared_error: 0.0444 - val_loss: 0.0777 - val_mean_squared_error: 0.0537\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 1s 42us/step - loss: 0.0683 - mean_squared_error: 0.0443 - val_loss: 0.0774 - val_mean_squared_error: 0.0535\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.0682 - mean_squared_error: 0.0443 - val_loss: 0.0780 - val_mean_squared_error: 0.0541\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 84/100\n",
      "30000/30000 [==============================] - 1s 38us/step - loss: 0.0673 - mean_squared_error: 0.0433 - val_loss: 0.0765 - val_mean_squared_error: 0.0525\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 1s 37us/step - loss: 0.0672 - mean_squared_error: 0.0433 - val_loss: 0.0766 - val_mean_squared_error: 0.0526\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.0671 - mean_squared_error: 0.0432 - val_loss: 0.0765 - val_mean_squared_error: 0.0526\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 1s 36us/step - loss: 0.0671 - mean_squared_error: 0.0432 - val_loss: 0.0767 - val_mean_squared_error: 0.0528\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.0670 - mean_squared_error: 0.0432 - val_loss: 0.0764 - val_mean_squared_error: 0.0526\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 1s 38us/step - loss: 0.0670 - mean_squared_error: 0.0431 - val_loss: 0.0764 - val_mean_squared_error: 0.0526\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 1s 37us/step - loss: 0.0665 - mean_squared_error: 0.0427 - val_loss: 0.0764 - val_mean_squared_error: 0.0525\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 1s 38us/step - loss: 0.0665 - mean_squared_error: 0.0426 - val_loss: 0.0760 - val_mean_squared_error: 0.0522\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 1s 48us/step - loss: 0.0665 - mean_squared_error: 0.0426 - val_loss: 0.0761 - val_mean_squared_error: 0.0523\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 1s 46us/step - loss: 0.0664 - mean_squared_error: 0.0426 - val_loss: 0.0762 - val_mean_squared_error: 0.0524\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 1s 40us/step - loss: 0.0664 - mean_squared_error: 0.0426 - val_loss: 0.0761 - val_mean_squared_error: 0.0523\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 1s 43us/step - loss: 0.0664 - mean_squared_error: 0.0426 - val_loss: 0.0761 - val_mean_squared_error: 0.0523\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 1s 38us/step - loss: 0.0663 - mean_squared_error: 0.0425 - val_loss: 0.0759 - val_mean_squared_error: 0.0521\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.0661 - mean_squared_error: 0.0423 - val_loss: 0.0760 - val_mean_squared_error: 0.0522\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.0661 - mean_squared_error: 0.0423 - val_loss: 0.0759 - val_mean_squared_error: 0.0520\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 1s 43us/step - loss: 0.0661 - mean_squared_error: 0.0423 - val_loss: 0.0758 - val_mean_squared_error: 0.0520\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 1s 41us/step - loss: 0.0660 - mean_squared_error: 0.0422 - val_loss: 0.0759 - val_mean_squared_error: 0.0521\n",
      "hw1/models/model_RoboschoolAnt-v1_training_set_size_30000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolAnt-v1\n",
      "{'model_path': 'hw1/models/model_RoboschoolAnt-v1_training_set_size_30000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'train_mse': 0.04610444645938512, 'model_name': 'model_RoboschoolAnt-v1_training_set_size_30000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'dataset_name': 'RoboschoolAnt-v1', 'test_mse': 0.05207300935301427}\n",
      "Training a FC ANN for env RoboschoolAnt-v1 over a training set size 40000 \n",
      "model_name='model_RoboschoolAnt-v1_training_set_size_40000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "model_path='hw1/models/model_RoboschoolAnt-v1_training_set_size_40000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm'\n",
      "Train on 40000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.4050 - mean_squared_error: 0.3780 - val_loss: 0.2344 - val_mean_squared_error: 0.2049\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.2052 - mean_squared_error: 0.1746 - val_loss: 0.1852 - val_mean_squared_error: 0.1539\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.1722 - mean_squared_error: 0.1404 - val_loss: 0.1596 - val_mean_squared_error: 0.1275\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 0.1545 - mean_squared_error: 0.1223 - val_loss: 0.1527 - val_mean_squared_error: 0.1204\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 2s 51us/step - loss: 0.1433 - mean_squared_error: 0.1111 - val_loss: 0.1404 - val_mean_squared_error: 0.1081\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 2s 46us/step - loss: 0.1357 - mean_squared_error: 0.1036 - val_loss: 0.1306 - val_mean_squared_error: 0.0985\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 0.1294 - mean_squared_error: 0.0975 - val_loss: 0.1261 - val_mean_squared_error: 0.0943\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 0.1237 - mean_squared_error: 0.0920 - val_loss: 0.1213 - val_mean_squared_error: 0.0898\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 0.1198 - mean_squared_error: 0.0885 - val_loss: 0.1193 - val_mean_squared_error: 0.0882\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 42us/step - loss: 0.1163 - mean_squared_error: 0.0854 - val_loss: 0.1185 - val_mean_squared_error: 0.0877\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 0.1128 - mean_squared_error: 0.0822 - val_loss: 0.1126 - val_mean_squared_error: 0.0822\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 0.1101 - mean_squared_error: 0.0799 - val_loss: 0.1119 - val_mean_squared_error: 0.0818\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 0.1077 - mean_squared_error: 0.0778 - val_loss: 0.1108 - val_mean_squared_error: 0.0811\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 0.1049 - mean_squared_error: 0.0754 - val_loss: 0.1113 - val_mean_squared_error: 0.0819\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 0.1035 - mean_squared_error: 0.0743 - val_loss: 0.1060 - val_mean_squared_error: 0.0770\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 0.1012 - mean_squared_error: 0.0723 - val_loss: 0.1078 - val_mean_squared_error: 0.0791\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0998 - mean_squared_error: 0.0712 - val_loss: 0.1041 - val_mean_squared_error: 0.0757\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 0.0982 - mean_squared_error: 0.0699 - val_loss: 0.1021 - val_mean_squared_error: 0.0739\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0969 - mean_squared_error: 0.0689 - val_loss: 0.0974 - val_mean_squared_error: 0.0695\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0951 - mean_squared_error: 0.0673 - val_loss: 0.0995 - val_mean_squared_error: 0.0718\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0938 - mean_squared_error: 0.0662 - val_loss: 0.0968 - val_mean_squared_error: 0.0694\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0930 - mean_squared_error: 0.0657 - val_loss: 0.0970 - val_mean_squared_error: 0.0698\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0918 - mean_squared_error: 0.0648 - val_loss: 0.0934 - val_mean_squared_error: 0.0665\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0904 - mean_squared_error: 0.0635 - val_loss: 0.0925 - val_mean_squared_error: 0.0658\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0899 - mean_squared_error: 0.0633 - val_loss: 0.0906 - val_mean_squared_error: 0.0641\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0889 - mean_squared_error: 0.0625 - val_loss: 0.0908 - val_mean_squared_error: 0.0645\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0882 - mean_squared_error: 0.0620 - val_loss: 0.0917 - val_mean_squared_error: 0.0656\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0871 - mean_squared_error: 0.0611 - val_loss: 0.0908 - val_mean_squared_error: 0.0649\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0863 - mean_squared_error: 0.0604 - val_loss: 0.0897 - val_mean_squared_error: 0.0640\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0858 - mean_squared_error: 0.0601 - val_loss: 0.0909 - val_mean_squared_error: 0.0653\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 0.0794 - mean_squared_error: 0.0539 - val_loss: 0.0827 - val_mean_squared_error: 0.0573\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 0.0788 - mean_squared_error: 0.0534 - val_loss: 0.0830 - val_mean_squared_error: 0.0577\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 0.0786 - mean_squared_error: 0.0534 - val_loss: 0.0849 - val_mean_squared_error: 0.0597\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0780 - mean_squared_error: 0.0529 - val_loss: 0.0822 - val_mean_squared_error: 0.0572\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0775 - mean_squared_error: 0.0525 - val_loss: 0.0842 - val_mean_squared_error: 0.0592\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0772 - mean_squared_error: 0.0523 - val_loss: 0.0820 - val_mean_squared_error: 0.0572\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0768 - mean_squared_error: 0.0521 - val_loss: 0.0815 - val_mean_squared_error: 0.0568\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0764 - mean_squared_error: 0.0518 - val_loss: 0.0814 - val_mean_squared_error: 0.0568\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0763 - mean_squared_error: 0.0518 - val_loss: 0.0807 - val_mean_squared_error: 0.0563\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0756 - mean_squared_error: 0.0512 - val_loss: 0.0807 - val_mean_squared_error: 0.0564\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0752 - mean_squared_error: 0.0509 - val_loss: 0.0816 - val_mean_squared_error: 0.0574\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0749 - mean_squared_error: 0.0508 - val_loss: 0.0800 - val_mean_squared_error: 0.0559\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 0.0746 - mean_squared_error: 0.0505 - val_loss: 0.0807 - val_mean_squared_error: 0.0568\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 0.0742 - mean_squared_error: 0.0503 - val_loss: 0.0791 - val_mean_squared_error: 0.0553\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 0.0740 - mean_squared_error: 0.0502 - val_loss: 0.0787 - val_mean_squared_error: 0.0550\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0738 - mean_squared_error: 0.0501 - val_loss: 0.0793 - val_mean_squared_error: 0.0556\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0733 - mean_squared_error: 0.0497 - val_loss: 0.0787 - val_mean_squared_error: 0.0552\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0730 - mean_squared_error: 0.0495 - val_loss: 0.0783 - val_mean_squared_error: 0.0548\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0729 - mean_squared_error: 0.0495 - val_loss: 0.0782 - val_mean_squared_error: 0.0548\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 0.0724 - mean_squared_error: 0.0491 - val_loss: 0.0783 - val_mean_squared_error: 0.0551\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 0.0722 - mean_squared_error: 0.0490 - val_loss: 0.0775 - val_mean_squared_error: 0.0544\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0719 - mean_squared_error: 0.0488 - val_loss: 0.0768 - val_mean_squared_error: 0.0537\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0718 - mean_squared_error: 0.0488 - val_loss: 0.0767 - val_mean_squared_error: 0.0537\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 0.0716 - mean_squared_error: 0.0487 - val_loss: 0.0763 - val_mean_squared_error: 0.0534\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0713 - mean_squared_error: 0.0484 - val_loss: 0.0762 - val_mean_squared_error: 0.0534\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0710 - mean_squared_error: 0.0482 - val_loss: 0.0782 - val_mean_squared_error: 0.0554\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0708 - mean_squared_error: 0.0481 - val_loss: 0.0767 - val_mean_squared_error: 0.0541\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0706 - mean_squared_error: 0.0480 - val_loss: 0.0750 - val_mean_squared_error: 0.0524\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0702 - mean_squared_error: 0.0477 - val_loss: 0.0755 - val_mean_squared_error: 0.0530\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0701 - mean_squared_error: 0.0477 - val_loss: 0.0761 - val_mean_squared_error: 0.0536\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0697 - mean_squared_error: 0.0473 - val_loss: 0.0747 - val_mean_squared_error: 0.0523\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0698 - mean_squared_error: 0.0475 - val_loss: 0.0749 - val_mean_squared_error: 0.0526\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0696 - mean_squared_error: 0.0473 - val_loss: 0.0753 - val_mean_squared_error: 0.0531\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0661 - mean_squared_error: 0.0439 - val_loss: 0.0719 - val_mean_squared_error: 0.0497\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 0.0660 - mean_squared_error: 0.0438 - val_loss: 0.0728 - val_mean_squared_error: 0.0506\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0658 - mean_squared_error: 0.0437 - val_loss: 0.0720 - val_mean_squared_error: 0.0499\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0658 - mean_squared_error: 0.0437 - val_loss: 0.0715 - val_mean_squared_error: 0.0495\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0656 - mean_squared_error: 0.0436 - val_loss: 0.0717 - val_mean_squared_error: 0.0497\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 0.0655 - mean_squared_error: 0.0435 - val_loss: 0.0714 - val_mean_squared_error: 0.0494\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 0.0654 - mean_squared_error: 0.0434 - val_loss: 0.0721 - val_mean_squared_error: 0.0502\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 0.0652 - mean_squared_error: 0.0434 - val_loss: 0.0714 - val_mean_squared_error: 0.0496\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 0.0651 - mean_squared_error: 0.0433 - val_loss: 0.0712 - val_mean_squared_error: 0.0494\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 2s 43us/step - loss: 0.0650 - mean_squared_error: 0.0432 - val_loss: 0.0709 - val_mean_squared_error: 0.0492\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0649 - mean_squared_error: 0.0431 - val_loss: 0.0716 - val_mean_squared_error: 0.0498\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0646 - mean_squared_error: 0.0429 - val_loss: 0.0711 - val_mean_squared_error: 0.0494\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 0.0647 - mean_squared_error: 0.0430 - val_loss: 0.0707 - val_mean_squared_error: 0.0491\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0643 - mean_squared_error: 0.0427 - val_loss: 0.0710 - val_mean_squared_error: 0.0494\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0644 - mean_squared_error: 0.0429 - val_loss: 0.0711 - val_mean_squared_error: 0.0496\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0626 - mean_squared_error: 0.0411 - val_loss: 0.0695 - val_mean_squared_error: 0.0480\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0626 - mean_squared_error: 0.0411 - val_loss: 0.0689 - val_mean_squared_error: 0.0474\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0624 - mean_squared_error: 0.0409 - val_loss: 0.0693 - val_mean_squared_error: 0.0478\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 0.0623 - mean_squared_error: 0.0408 - val_loss: 0.0690 - val_mean_squared_error: 0.0475\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 2s 50us/step - loss: 0.0623 - mean_squared_error: 0.0408 - val_loss: 0.0690 - val_mean_squared_error: 0.0476\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 2s 45us/step - loss: 0.0622 - mean_squared_error: 0.0408 - val_loss: 0.0687 - val_mean_squared_error: 0.0473\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 2s 46us/step - loss: 0.0622 - mean_squared_error: 0.0408 - val_loss: 0.0692 - val_mean_squared_error: 0.0478\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 0.0621 - mean_squared_error: 0.0407 - val_loss: 0.0689 - val_mean_squared_error: 0.0475\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 0.0620 - mean_squared_error: 0.0407 - val_loss: 0.0688 - val_mean_squared_error: 0.0475\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0620 - mean_squared_error: 0.0406 - val_loss: 0.0683 - val_mean_squared_error: 0.0470\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0619 - mean_squared_error: 0.0406 - val_loss: 0.0689 - val_mean_squared_error: 0.0476\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 0.0618 - mean_squared_error: 0.0406 - val_loss: 0.0688 - val_mean_squared_error: 0.0475\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 0.0618 - mean_squared_error: 0.0406 - val_loss: 0.0694 - val_mean_squared_error: 0.0482\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0617 - mean_squared_error: 0.0404 - val_loss: 0.0686 - val_mean_squared_error: 0.0474\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0617 - mean_squared_error: 0.0405 - val_loss: 0.0688 - val_mean_squared_error: 0.0476\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0607 - mean_squared_error: 0.0395 - val_loss: 0.0679 - val_mean_squared_error: 0.0467\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 0.0607 - mean_squared_error: 0.0395 - val_loss: 0.0679 - val_mean_squared_error: 0.0468\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 0.0606 - mean_squared_error: 0.0395 - val_loss: 0.0678 - val_mean_squared_error: 0.0466\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0606 - mean_squared_error: 0.0394 - val_loss: 0.0679 - val_mean_squared_error: 0.0467\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0605 - mean_squared_error: 0.0394 - val_loss: 0.0677 - val_mean_squared_error: 0.0466\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 0.0605 - mean_squared_error: 0.0394 - val_loss: 0.0677 - val_mean_squared_error: 0.0466\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 0.0605 - mean_squared_error: 0.0394 - val_loss: 0.0676 - val_mean_squared_error: 0.0465\n",
      "hw1/models/model_RoboschoolAnt-v1_training_set_size_40000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5\n",
      "Done training model for RoboschoolAnt-v1\n",
      "{'model_path': 'hw1/models/model_RoboschoolAnt-v1_training_set_size_40000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'train_mse': 0.04007870833210467, 'model_name': 'model_RoboschoolAnt-v1_training_set_size_40000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm', 'dataset_name': 'RoboschoolAnt-v1', 'test_mse': 0.04650886960807739}\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import Callback, LambdaCallback, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from hw1.manage_datasets import get_datasets\n",
    "from keras_helpers.model_helper import create_model, get_model_name, calc_mse\n",
    "from keras_helpers.keras_train_stats import KerasTrainStats\n",
    "\n",
    "\n",
    "\n",
    "ANT_SAVED_MODELS_DIR = 'hw1/ant_models'\n",
    "MODEL_FILE_NAME = \"base.hdf5\"\n",
    "create_dir_if_not_exists(SAVED_MODELS_DIR)\n",
    "\n",
    "model_mse = []\n",
    "env_name = 'RoboschoolAnt-v1'\n",
    "# Load the datasets once\n",
    "X_train, X_test, y_train, y_test = get_datasets(dataset_name=env_name, dataset_dir=EXPERT_DATA_DIR)\n",
    "\n",
    "for train_size in range(10000, 50000, 10000):  # [10000, 20000, 30000, 40000]\n",
    "    print(\"Training a FC ANN for env %s over a training set size %d \" % (env_name, train_size))\n",
    "    \n",
    "    # Define the model params   \n",
    "    config_dict = dict(\n",
    "        input_dim=len(X_train[1, :]),\n",
    "        output_dim=len(y_train[1, :]),\n",
    "        units=100,\n",
    "        layers = 3,\n",
    "        l2_reg = 1e-04,\n",
    "        optimizer_cls=keras.optimizers.Adam,\n",
    "        lr = 1e-03,\n",
    "        dropout=None,\n",
    "        use_batchnorm=False)\n",
    "    \n",
    "    # Create the model\n",
    "    model = create_model(**config_dict)\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = config_dict['optimizer_cls'](lr=config_dict['lr'])\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    \n",
    "    # Set a unique name/directory for the model\n",
    "    base_name = \"%s_training_set_size_%d\" % (env_name, train_size)\n",
    "    model_name = get_model_name(base_name=base_name, **config_dict)\n",
    "    model_path = os.path.join(SAVED_MODELS_DIR, model_name)\n",
    "    print(\"model_name='%s'\" % model_name)\n",
    "    print(\"model_path='%s'\" % model_path)\n",
    "    create_dir_if_not_exists(model_path)\n",
    "    model_filename = os.path.join(model_path, MODEL_FILE_NAME)\n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_mean_squared_error', factor=0.5, patience=5, verbose=1)\n",
    "    tf_board = TensorBoard()\n",
    "\n",
    "    # Define a train_stats object\n",
    "    train_stats = KerasTrainStats(model_name=model_name, history_dir=model_path)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "\n",
    "    _ = model.fit([X_train[0:train_size]], y_train[0:train_size],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[train_stats.print_callback, reduce_lr, tf_board],\n",
    "        validation_data=([X_test], y_test)\n",
    "        )\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(model_filename)\n",
    "    print(model_filename)\n",
    "    \n",
    "    # Calculate the MSE for each \n",
    "    res = calc_mse(model, env_name, X_train, X_test, y_train, y_test)\n",
    "    res['model_name'] = model_name\n",
    "    res['model_path'] = model_path\n",
    "    model_mse.append(res)\n",
    "    print(\"Done training model for %s\" % env_name)\n",
    "    #print(\"KerasTrainStats(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='%s MSE')\" % dataset_name)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the test MSE error for each of the models\n",
    "roboschool_ant_df = pd.DataFrame(model_mse)\n",
    "test_mse = roboschool_ant_df['test_mse'].tolist()\n",
    "\n",
    "# Add the test MSE error we previously got for the training set size of 45K\n",
    "test_mse_45k = 0.046053225442220666\n",
    "test_mse.append(test_mse_45k)\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(20,10))\n",
    "scatter(x=[1e+4, 2e+4, 3e+4, 4e+4, 45000], y=test_mse)\n",
    "_ = plt.title(\"Test MSE vs training set size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant improvement in terms of MSE when increasing the dataset size upto 40K. On the contrary, there seems to be a very subtle performance improvement between 40K and 45K (0.0465 MSE vs 0.04605 respectively). We will also calculate the 40K model mean return vs the expert return. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the trajectories using the 40K model and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env description: Supervised model policy for module RoboschoolAnt-v1 with a smaller training set of 40K examples\n",
      "mean return 1906.4720582679638\n",
      "std of return 338.23867998992245\n",
      "CPU times: user 2min 56s, sys: 1min 13s, total: 4min 10s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "ant_40k_model_filename = 'hw1/models/model_RoboschoolAnt-v1_training_set_size_40000_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5'\n",
    "policy = SupervisedModelPolicy(env_name, model_filename=ant_40k_model_filename)\n",
    "env = gym.make(env_name)\n",
    "description = \"Supervised model policy for module %s with a smaller training set of 40K examples\" % env_name\n",
    "%time supervised_modeled_data = run_policy(env=env, policy=policy, num_rollouts=50, \\\n",
    "                                           description=description, verbose=False)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1906.4720582679638, 338.23867998992245)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns = supervised_modeled_data['returns']\n",
    "returns.mean(), returns.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models returns were even better than the expert and the model trained over 45K examples. \n",
    "\n",
    "\n",
    "Maybe this means that the expert model is overfitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAgger\n",
    "We will run the DAgger algorithm on the RoboschoolHumanoid-v1 task for which our model had the worst returns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo code\n",
    "\n",
    "Initial ANN model (we already did this part)\n",
    "1. Generate trajectories from an expert policy and build a dataset $D=$ {$o_1, a_1...,o_n, a_n$}\n",
    "2. Train a function approximator (ANN) $\\pi_\\theta(o_t|a_t)$ over $D$\n",
    "\n",
    "Improving the model with expert data:  \n",
    "Loop:\n",
    "1. Generate k trajectories using $\\pi_\\theta(o_t|a_t)$: for each observasion ($o_t$) in each trajectory, \"ask\" the expert policy for the appropriate action for each observation and use it as a label for a new dataset $D_\\pi$\n",
    "2. Aggregate: $D\\leftarrow D \\cup D_\\pi$\n",
    "3. Train a function approximator (ANN) $\\pi_\\theta(o_t|a_t)$ over $D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAgagger():\n",
    "    def __init__(self, env_name, dest_model_dir, model_filename=None, update_epoch_num=5, \n",
    "                 saved_iterations=5, batch_size=64, dataset_dir=EXPERT_DATA_DIR):\n",
    "        \"\"\"\n",
    "        saved_iterations: int or None - save model after nuber of iterations \n",
    "        \"\"\"\n",
    "        # Create the environment and the policy object\n",
    "        self.env_name = env_name\n",
    "        self.env = gym.make(env_name)\n",
    "        self.policy = SupervisedModelPolicy(env_name, model_filename=model_filename)\n",
    "        # Set a reference to the policy model\n",
    "        self._model = self.policy.model\n",
    "        \n",
    "        # Load train/test set\n",
    "        X_train, X_test, y_train, y_test = get_datasets(dataset_name=env_name, dataset_dir=dataset_dir)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.update_epoch_num = update_epoch_num\n",
    "        self._num_epdates = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.saved_iterations = saved_iterations\n",
    "        \n",
    "        self.dest_model_dir = dest_model_dir\n",
    "        create_dir_if_not_exists(dest_model_dir)\n",
    "        \n",
    "        self._steps_data = []\n",
    "        self.calc_step_data()\n",
    "        \n",
    "    \n",
    "    def get_steps_data(self):\n",
    "        return pd.DataFrame(self._steps_data)\n",
    "        \n",
    "    \n",
    "    def _update_datasets(self, X_new, y_new, aggregate=True):\n",
    "        \"\"\"Add the additional trajectories dataset to the training set\"\"\"\n",
    "        # Concatenate the previous training set with the new samples\n",
    "        if aggregate:\n",
    "            self.X_train = np.concatenate((self.X_train, X_new), axis=0)\n",
    "            self.y_train = np.concatenate((self.y_train, y_new), axis=0)\n",
    "        \n",
    "        # Replace the entire training set with the new samples\n",
    "        else:\n",
    "            self.X_train = X_new\n",
    "            self.y_train = y_new\n",
    "    \n",
    "    def update_policy(self, X_new, y_new, update_epoch_num=None, batch_size=None, aggregate=True):\n",
    "        # Update the saved datasets\n",
    "        self._update_datasets(X_new, y_new, aggregate=aggregate)\n",
    "        \n",
    "        # Run update_epoch_num iterations\n",
    "        if update_epoch_num is None:\n",
    "            update_epoch_num = self.update_epoch_num\n",
    "        \n",
    "        # TODO: add batch_size as a parameter\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        \n",
    "        # Train additional 'epochs' number of epochs on the new dataset\n",
    "        _ = self._model.fit([self.X_train], self.y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=update_epoch_num,\n",
    "                validation_data=([self.X_test], self.y_test)\n",
    "            )\n",
    "        \n",
    "#         # Calculate the MSE for each \n",
    "#         res = calc_mse(model, env_name, self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "#         res['model_name'] = model_name\n",
    "#         res['model_path'] = model_path\n",
    "#         model_mse.append(res)\n",
    "#         print(\"Done training model for %s\" % env_name)\n",
    "#         #print(\"KerasTrainStats(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='%s MSE')\" % dataset_name)\n",
    "#         print(res)\n",
    "        \n",
    "    \n",
    "    def create_trajectories(self, k, max_timesteps=None):\n",
    "        # Run k trajectories using the current policy\n",
    "        description = \"Runnig DAgger iteration %d on env %s\" % (self._num_epdates, env_name)\n",
    "        model_data = run_policy(env=self.env, policy=self.policy, num_rollouts=k, description=description, \n",
    "                                render=False, verbose=False, max_timesteps=max_timesteps)\n",
    "        \n",
    "        X_new = model_data['observations']\n",
    "        y_new = model_data['actions']\n",
    "        returns = model_data['returns']\n",
    "        return X_new, y_new, returns\n",
    "    \n",
    "    \n",
    "    def step(self, k, update_epoch_num=None, max_timesteps=None, aggregate=True):\n",
    "        # Generate trajectories using corrent policy\n",
    "        X_new, y_new, returns = self.create_trajectories(k=k, max_timesteps=max_timesteps)\n",
    "        # Update policy\n",
    "        self.update_policy(X_new, y_new, update_epoch_num=update_epoch_num, aggregate=aggregate)\n",
    "        \n",
    "        # Increase the internal update count\n",
    "        self._num_epdates +=1\n",
    "        \n",
    "        # Save the model\n",
    "        saved_iterations = self.saved_iterations\n",
    "        if saved_iterations and not self._num_epdates % saved_iterations:\n",
    "            model_name = \"%s_DAgger_update_%d.hdf5\" % (env_name, self._num_epdates)\n",
    "            model_path = os.path.join(self.dest_model_dir, model_name)\n",
    "            model.save(model_path)\n",
    "            print(\"Saving model %s after update number %d\" % (model_name, self._num_epdates))\n",
    "            \n",
    "        self.calc_step_data()\n",
    "\n",
    "    def calc_step_data(self):\n",
    "        # Update the steps statistics\n",
    "        step_data = calc_mse(self._model, self.env_name, self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        step_data['iteration'] = self._num_epdates\n",
    "        self._steps_data.append(step_data)\n",
    "        print(\"step_data: %s\" % step_data)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-1d0f96c9652b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdest_model_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hw1/models/DAgger/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0menv_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDAgagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_model_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_epoch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_model_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdest_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-149-1b25781ab5a5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_name, dest_model_dir, model_filename, update_epoch_num, saved_iterations, batch_size, dataset_dir)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSupervisedModelPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Set a reference to the policy model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-35f0f8c6edcd>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_name, model_filename)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mmodel_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_to_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    818\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[1;32m    819\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m   \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2878\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2879\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2880\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    480\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_model_filename = 'hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5'\n",
    "env_name = 'RoboschoolHumanoid-v1'\n",
    "\n",
    "dest_model_dir = 'hw1/models/DAgger/%s' % env_name\n",
    "\n",
    "dagger = DAgagger(env_name=env_name, model_filename=initial_model_filename, update_epoch_num=25, saved_iterations=5, batch_size=64, dest_model_dir=dest_model_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env description: Runnig DAgger iteration 0 on env RoboschoolHumanoid-v1\n",
      "mean return 52.27372984527294\n",
      "std of return 19.566098813105157\n",
      "Train on 42056 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "42056/42056 [==============================] - 4s 94us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "42056/42056 [==============================] - 2s 54us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "42056/42056 [==============================] - 2s 51us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "42056/42056 [==============================] - 2s 53us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "42056/42056 [==============================] - 2s 49us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "42056/42056 [==============================] - 2s 54us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "42056/42056 [==============================] - 2s 52us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "42056/42056 [==============================] - 2s 50us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "42056/42056 [==============================] - 2s 49us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "42056/42056 [==============================] - 2s 49us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "42056/42056 [==============================] - 2s 49us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "42056/42056 [==============================] - 2s 49us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "42056/42056 [==============================] - 2s 49us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "42056/42056 [==============================] - 2s 48us/sample - loss: 0.0196 - mean_squared_error: 0.0118 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.011790019281903893, 'iteration': 1, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013618511818293233}\n",
      "Env description: Runnig DAgger iteration 1 on env RoboschoolHumanoid-v1\n",
      "mean return 54.83941136163187\n",
      "std of return 15.144382791214843\n",
      "Train on 44139 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "44139/44139 [==============================] - 2s 50us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "44139/44139 [==============================] - 2s 49us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "44139/44139 [==============================] - 2s 50us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "44139/44139 [==============================] - 2s 52us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "44139/44139 [==============================] - 2s 50us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "44139/44139 [==============================] - 2s 49us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "44139/44139 [==============================] - 2s 48us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "44139/44139 [==============================] - 2s 50us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "44139/44139 [==============================] - 2s 52us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "44139/44139 [==============================] - 2s 50us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "44139/44139 [==============================] - 2s 53us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "44139/44139 [==============================] - 3s 58us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "44139/44139 [==============================] - 2s 56us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "44139/44139 [==============================] - 2s 50us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "44139/44139 [==============================] - 2s 56us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "44139/44139 [==============================] - 2s 48us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "44139/44139 [==============================] - 2s 51us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "44139/44139 [==============================] - 2s 48us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "44139/44139 [==============================] - 2s 49us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "44139/44139 [==============================] - 2s 49us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44139/44139 [==============================] - 2s 47us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "44139/44139 [==============================] - 2s 49us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "44139/44139 [==============================] - 2s 50us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "44139/44139 [==============================] - 2s 55us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "44139/44139 [==============================] - 2s 48us/sample - loss: 0.0191 - mean_squared_error: 0.0112 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.011234887736525761, 'iteration': 2, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013618507683586018}\n",
      "Env description: Runnig DAgger iteration 2 on env RoboschoolHumanoid-v1\n",
      "mean return 58.486514840041785\n",
      "std of return 16.587300302304836\n",
      "Train on 46267 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "46267/46267 [==============================] - 4s 81us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "46267/46267 [==============================] - 2s 53us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "46267/46267 [==============================] - 2s 49us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "46267/46267 [==============================] - 2s 50us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "46267/46267 [==============================] - 2s 51us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "46267/46267 [==============================] - 2s 50us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "46267/46267 [==============================] - 2s 47us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "46267/46267 [==============================] - 2s 50us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "46267/46267 [==============================] - 2s 49us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "46267/46267 [==============================] - 2s 50us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "46267/46267 [==============================] - 2s 48us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "46267/46267 [==============================] - 3s 55us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "46267/46267 [==============================] - 2s 52us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "46267/46267 [==============================] - 2s 50us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "46267/46267 [==============================] - 3s 60us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "46267/46267 [==============================] - 2s 53us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "46267/46267 [==============================] - 2s 49us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "46267/46267 [==============================] - 2s 49us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "46267/46267 [==============================] - 2s 48us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "46267/46267 [==============================] - 2s 48us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "46267/46267 [==============================] - 2s 49us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "46267/46267 [==============================] - 2s 50us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "46267/46267 [==============================] - 2s 48us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "46267/46267 [==============================] - 2s 53us/sample - loss: 0.0186 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "46267/46267 [==============================] - 2s 48us/sample - loss: 0.0185 - mean_squared_error: 0.0107 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.010721166142417554, 'iteration': 3, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013620116992236107}\n",
      "Env description: Runnig DAgger iteration 3 on env RoboschoolHumanoid-v1\n",
      "mean return 52.96799575537064\n",
      "std of return 14.654583749553149\n",
      "Train on 48343 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "48343/48343 [==============================] - 2s 49us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "48343/48343 [==============================] - 2s 50us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "48343/48343 [==============================] - 2s 47us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "48343/48343 [==============================] - 2s 48us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "48343/48343 [==============================] - 2s 48us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "48343/48343 [==============================] - 2s 48us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "48343/48343 [==============================] - 2s 47us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "48343/48343 [==============================] - 2s 48us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "48343/48343 [==============================] - 2s 48us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "48343/48343 [==============================] - 2s 48us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "48343/48343 [==============================] - 2s 49us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "48343/48343 [==============================] - 2s 51us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "48343/48343 [==============================] - 2s 49us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "48343/48343 [==============================] - 2s 49us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48343/48343 [==============================] - 2s 47us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "48343/48343 [==============================] - 3s 52us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "48343/48343 [==============================] - 2s 47us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "48343/48343 [==============================] - 4s 82us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "48343/48343 [==============================] - 2s 47us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "48343/48343 [==============================] - 2s 44us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "48343/48343 [==============================] - 2s 44us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "48343/48343 [==============================] - 2s 45us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "48343/48343 [==============================] - 2s 43us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "48343/48343 [==============================] - 2s 44us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "48343/48343 [==============================] - 2s 44us/sample - loss: 0.0181 - mean_squared_error: 0.0103 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.01026533425025045, 'iteration': 4, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013624178840773672}\n",
      "Env description: Runnig DAgger iteration 4 on env RoboschoolHumanoid-v1\n",
      "mean return 55.295062990323856\n",
      "std of return 12.405262259471101\n",
      "Train on 50425 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "50425/50425 [==============================] - 3s 63us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "50425/50425 [==============================] - 3s 60us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "50425/50425 [==============================] - 3s 65us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "50425/50425 [==============================] - 3s 55us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "50425/50425 [==============================] - 3s 57us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "50425/50425 [==============================] - 3s 59us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "50425/50425 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "50425/50425 [==============================] - 3s 58us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "50425/50425 [==============================] - 3s 55us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "50425/50425 [==============================] - 3s 50us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "50425/50425 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "50425/50425 [==============================] - 3s 56us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "50425/50425 [==============================] - 3s 55us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "50425/50425 [==============================] - 3s 51us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "50425/50425 [==============================] - 3s 51us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "50425/50425 [==============================] - 3s 50us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "50425/50425 [==============================] - 3s 50us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "50425/50425 [==============================] - 3s 50us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "50425/50425 [==============================] - 3s 50us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "50425/50425 [==============================] - 3s 51us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "50425/50425 [==============================] - 3s 50us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "50425/50425 [==============================] - 3s 50us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "50425/50425 [==============================] - 3s 55us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "50425/50425 [==============================] - 3s 55us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "50425/50425 [==============================] - 3s 51us/sample - loss: 0.0177 - mean_squared_error: 0.0098 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_5.hdf5 after update number 5\n",
      "step_data: {'train_mse': 0.009847241764600724, 'iteration': 5, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013630785007976397}\n",
      "Env description: Runnig DAgger iteration 5 on env RoboschoolHumanoid-v1\n",
      "mean return 52.289148335259014\n",
      "std of return 15.762046015833683\n",
      "Train on 52487 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "52487/52487 [==============================] - 3s 49us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "52487/52487 [==============================] - 3s 49us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "52487/52487 [==============================] - 3s 49us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "52487/52487 [==============================] - 3s 50us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "52487/52487 [==============================] - 3s 50us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "52487/52487 [==============================] - 3s 49us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "52487/52487 [==============================] - 3s 52us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "52487/52487 [==============================] - 3s 49us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52487/52487 [==============================] - 3s 48us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "52487/52487 [==============================] - 2s 47us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "52487/52487 [==============================] - 3s 48us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "52487/52487 [==============================] - 2s 46us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "52487/52487 [==============================] - 2s 47us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "52487/52487 [==============================] - 3s 49us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "52487/52487 [==============================] - 2s 47us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "52487/52487 [==============================] - 2s 47us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "52487/52487 [==============================] - 2s 45us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "52487/52487 [==============================] - 2s 46us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "52487/52487 [==============================] - 2s 47us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "52487/52487 [==============================] - 2s 46us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "52487/52487 [==============================] - 2s 47us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "52487/52487 [==============================] - 2s 46us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "52487/52487 [==============================] - 2s 46us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "52487/52487 [==============================] - 2s 45us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "52487/52487 [==============================] - 2s 45us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.009467365156240205, 'iteration': 6, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013638019366437795}\n",
      "Env description: Runnig DAgger iteration 6 on env RoboschoolHumanoid-v1\n",
      "mean return 53.85360983089206\n",
      "std of return 13.99913542269025\n",
      "Train on 54536 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "54536/54536 [==============================] - 3s 46us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "54536/54536 [==============================] - 3s 46us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "54536/54536 [==============================] - 2s 45us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "54536/54536 [==============================] - 3s 46us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "54536/54536 [==============================] - 3s 46us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "54536/54536 [==============================] - 3s 47us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "54536/54536 [==============================] - 3s 47us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "54536/54536 [==============================] - 2s 45us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "54536/54536 [==============================] - 3s 52us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "54536/54536 [==============================] - 3s 49us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "54536/54536 [==============================] - 3s 47us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "54536/54536 [==============================] - 3s 47us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "54536/54536 [==============================] - 2s 45us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "54536/54536 [==============================] - 3s 46us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "54536/54536 [==============================] - 3s 46us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "54536/54536 [==============================] - 2s 45us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "54536/54536 [==============================] - 3s 46us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "54536/54536 [==============================] - 3s 46us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "54536/54536 [==============================] - 3s 47us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "54536/54536 [==============================] - 3s 46us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "54536/54536 [==============================] - 3s 46us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "54536/54536 [==============================] - 3s 47us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "54536/54536 [==============================] - 3s 47us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "54536/54536 [==============================] - 2s 46us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "54536/54536 [==============================] - 3s 47us/sample - loss: 0.0169 - mean_squared_error: 0.0091 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.009119551756808057, 'iteration': 7, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013647205759410449}\n",
      "Env description: Runnig DAgger iteration 7 on env RoboschoolHumanoid-v1\n",
      "mean return 53.89850576806555\n",
      "std of return 17.777808816697178\n",
      "Train on 56563 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "56563/56563 [==============================] - 3s 45us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "56563/56563 [==============================] - 3s 45us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56563/56563 [==============================] - 3s 46us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "56563/56563 [==============================] - 3s 46us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "56563/56563 [==============================] - 3s 46us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "56563/56563 [==============================] - 3s 46us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "56563/56563 [==============================] - 3s 46us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "56563/56563 [==============================] - 3s 45us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "56563/56563 [==============================] - 2s 44us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "56563/56563 [==============================] - 2s 44us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "56563/56563 [==============================] - 2s 44us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "56563/56563 [==============================] - 3s 45us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "56563/56563 [==============================] - 3s 44us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "56563/56563 [==============================] - 3s 46us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "56563/56563 [==============================] - 3s 47us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "56563/56563 [==============================] - 3s 46us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "56563/56563 [==============================] - 3s 45us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "56563/56563 [==============================] - 3s 44us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "56563/56563 [==============================] - 3s 47us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "56563/56563 [==============================] - 3s 45us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "56563/56563 [==============================] - 3s 46us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "56563/56563 [==============================] - 3s 46us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "56563/56563 [==============================] - 3s 45us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "56563/56563 [==============================] - 3s 46us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "56563/56563 [==============================] - 3s 46us/sample - loss: 0.0166 - mean_squared_error: 0.0088 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "step_data: {'train_mse': 0.008801480422916466, 'iteration': 8, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013656674000661034}\n",
      "Env description: Runnig DAgger iteration 8 on env RoboschoolHumanoid-v1\n",
      "mean return 53.4391518790046\n",
      "std of return 22.831023232964743\n",
      "Train on 58552 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "58552/58552 [==============================] - 3s 44us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "58552/58552 [==============================] - 3s 44us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "58552/58552 [==============================] - 3s 44us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 6/25\n",
      "58552/58552 [==============================] - 3s 51us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/25\n",
      "58552/58552 [==============================] - 3s 51us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 8/25\n",
      "58552/58552 [==============================] - 3s 50us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "58552/58552 [==============================] - 3s 53us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "58552/58552 [==============================] - 3s 45us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "58552/58552 [==============================] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.00 - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "58552/58552 [==============================] - 3s 45us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "58552/58552 [==============================] - 3s 45us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "58552/58552 [==============================] - 3s 45us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58552/58552 [==============================] - 3s 47us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "58552/58552 [==============================] - 3s 46us/sample - loss: 0.0163 - mean_squared_error: 0.0085 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "step_data: {'train_mse': 0.008512026680249609, 'iteration': 9, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013669350538778104}\n",
      "Env description: Runnig DAgger iteration 9 on env RoboschoolHumanoid-v1\n",
      "mean return 56.214977592988745\n",
      "std of return 10.167281780813811\n",
      "Train on 60686 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "60686/60686 [==============================] - 3s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "60686/60686 [==============================] - 3s 45us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "60686/60686 [==============================] - 3s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "60686/60686 [==============================] - 3s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/25\n",
      "60686/60686 [==============================] - 3s 47us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 6/25\n",
      "60686/60686 [==============================] - 3s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/25\n",
      "60686/60686 [==============================] - 3s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 8/25\n",
      "60686/60686 [==============================] - 3s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "60686/60686 [==============================] - 3s 45us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "60686/60686 [==============================] - 3s 45us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "60686/60686 [==============================] - 3s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "60686/60686 [==============================] - 3s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "60686/60686 [==============================] - 3s 44us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "60686/60686 [==============================] - 3s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "60686/60686 [==============================] - 3s 45us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "60686/60686 [==============================] - 3s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "60686/60686 [==============================] - 3s 47us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "60686/60686 [==============================] - 3s 45us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "60686/60686 [==============================] - 3s 45us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "60686/60686 [==============================] - 3s 45us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "60686/60686 [==============================] - 3s 45us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "60686/60686 [==============================] - 3s 45us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "60686/60686 [==============================] - 3s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "60686/60686 [==============================] - 3s 45us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "60686/60686 [==============================] - 3s 48us/sample - loss: 0.0160 - mean_squared_error: 0.0082 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_10.hdf5 after update number 10\n",
      "step_data: {'train_mse': 0.008223131358345665, 'iteration': 10, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013682041106995571}\n",
      "Env description: Runnig DAgger iteration 10 on env RoboschoolHumanoid-v1\n",
      "mean return 55.0835456418994\n",
      "std of return 12.519084159154096\n",
      "Train on 62724 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "62724/62724 [==============================] - 3s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "62724/62724 [==============================] - 3s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "62724/62724 [==============================] - 3s 47us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "62724/62724 [==============================] - 3s 46us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/25\n",
      "62724/62724 [==============================] - 3s 46us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 6/25\n",
      "62724/62724 [==============================] - 3s 46us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/25\n",
      "62724/62724 [==============================] - 3s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 8/25\n",
      "62724/62724 [==============================] - 3s 46us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "62724/62724 [==============================] - 3s 46us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "62724/62724 [==============================] - 3s 46us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "62724/62724 [==============================] - 3s 46us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "62724/62724 [==============================] - 3s 46us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "62724/62724 [==============================] - 3s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "62724/62724 [==============================] - 3s 44us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "62724/62724 [==============================] - 3s 44us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "62724/62724 [==============================] - 3s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "62724/62724 [==============================] - 3s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62724/62724 [==============================] - 3s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "62724/62724 [==============================] - 3s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "62724/62724 [==============================] - 3s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "62724/62724 [==============================] - 3s 46us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "62724/62724 [==============================] - 3s 46us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "62724/62724 [==============================] - 3s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "62724/62724 [==============================] - 3s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "62724/62724 [==============================] - 3s 46us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "step_data: {'train_mse': 0.00796681117223558, 'iteration': 11, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013695149209289081}\n",
      "Env description: Runnig DAgger iteration 11 on env RoboschoolHumanoid-v1\n",
      "mean return 49.26477397467057\n",
      "std of return 12.987717749579273\n",
      "Train on 64659 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "64659/64659 [==============================] - 3s 47us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "64659/64659 [==============================] - 3s 46us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "64659/64659 [==============================] - 3s 46us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "64659/64659 [==============================] - 3s 45us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/25\n",
      "64659/64659 [==============================] - 3s 46us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 6/25\n",
      "64659/64659 [==============================] - 3s 46us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/25\n",
      "64659/64659 [==============================] - 3s 45us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 8/25\n",
      "64659/64659 [==============================] - 3s 44us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "64659/64659 [==============================] - 3s 44us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "64659/64659 [==============================] - 3s 44us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "64659/64659 [==============================] - 3s 44us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "64659/64659 [==============================] - 3s 46us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "64659/64659 [==============================] - 3s 46us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "64659/64659 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "64659/64659 [==============================] - 3s 47us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "64659/64659 [==============================] - 3s 46us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "64659/64659 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "64659/64659 [==============================] - 3s 47us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "64659/64659 [==============================] - 3s 46us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "64659/64659 [==============================] - 3s 46us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "64659/64659 [==============================] - 3s 46us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "64659/64659 [==============================] - 4s 65us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "64659/64659 [==============================] - 3s 45us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "64659/64659 [==============================] - 3s 45us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "64659/64659 [==============================] - 3s 46us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "step_data: {'train_mse': 0.007740663914046399, 'iteration': 12, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013711425092851245}\n",
      "Env description: Runnig DAgger iteration 12 on env RoboschoolHumanoid-v1\n",
      "mean return 56.274717512356936\n",
      "std of return 13.794518826519734\n",
      "Train on 66796 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "66796/66796 [==============================] - 3s 45us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "66796/66796 [==============================] - 3s 45us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "66796/66796 [==============================] - 3s 48us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "66796/66796 [==============================] - 3s 47us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/25\n",
      "66796/66796 [==============================] - 3s 46us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 6/25\n",
      "66796/66796 [==============================] - 3s 46us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/25\n",
      "66796/66796 [==============================] - 3s 45us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 8/25\n",
      "66796/66796 [==============================] - 3s 50us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "66796/66796 [==============================] - 3s 47us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "66796/66796 [==============================] - 3s 46us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "66796/66796 [==============================] - 3s 46us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66796/66796 [==============================] - 3s 46us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.01370.0\n",
      "Epoch 13/25\n",
      "66796/66796 [==============================] - 3s 45us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "66796/66796 [==============================] - 3s 46us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "66796/66796 [==============================] - 3s 46us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "66796/66796 [==============================] - 3s 45us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "66796/66796 [==============================] - 3s 45us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "66796/66796 [==============================] - 3s 45us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "66796/66796 [==============================] - 3s 45us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "66796/66796 [==============================] - 3s 45us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "66796/66796 [==============================] - 3s 45us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "66796/66796 [==============================] - 3s 46us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "66796/66796 [==============================] - 4s 61us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "66796/66796 [==============================] - 3s 45us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "66796/66796 [==============================] - 3s 44us/sample - loss: 0.0152 - mean_squared_error: 0.0075 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "step_data: {'train_mse': 0.007504527138114325, 'iteration': 13, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013729382020478067}\n",
      "Env description: Runnig DAgger iteration 13 on env RoboschoolHumanoid-v1\n",
      "mean return 54.32990035962244\n",
      "std of return 10.905415953384212\n",
      "Train on 68798 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "68798/68798 [==============================] - 3s 43us/sample - loss: 0.0150 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "68798/68798 [==============================] - 3s 43us/sample - loss: 0.0150 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "68798/68798 [==============================] - 3s 44us/sample - loss: 0.0150 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "68798/68798 [==============================] - 3s 44us/sample - loss: 0.0150 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/25\n",
      "68798/68798 [==============================] - 3s 44us/sample - loss: 0.0150 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 6/25\n",
      "68798/68798 [==============================] - 3s 43us/sample - loss: 0.0150 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/25\n",
      "68798/68798 [==============================] - 3s 45us/sample - loss: 0.0150 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 8/25\n",
      "68798/68798 [==============================] - 3s 45us/sample - loss: 0.0150 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "68798/68798 [==============================] - 3s 45us/sample - loss: 0.0150 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "68798/68798 [==============================] - 3s 45us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "68798/68798 [==============================] - 3s 44us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "68798/68798 [==============================] - 3s 44us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "68798/68798 [==============================] - 3s 45us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "68798/68798 [==============================] - 3s 45us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "68798/68798 [==============================] - 3s 45us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "68798/68798 [==============================] - 3s 45us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "68798/68798 [==============================] - 3s 44us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "68798/68798 [==============================] - 3s 45us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "68798/68798 [==============================] - 3s 44us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "68798/68798 [==============================] - 3s 44us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "68798/68798 [==============================] - 3s 43us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "68798/68798 [==============================] - 3s 44us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "68798/68798 [==============================] - 3s 45us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "68798/68798 [==============================] - 3s 45us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "68798/68798 [==============================] - 3s 44us/sample - loss: 0.0149 - mean_squared_error: 0.0073 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "step_data: {'train_mse': 0.00729889772782718, 'iteration': 14, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013747453100586046}\n",
      "Env description: Runnig DAgger iteration 14 on env RoboschoolHumanoid-v1\n",
      "mean return 54.34508506179252\n",
      "std of return 14.454109233706903\n",
      "Train on 70809 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "70809/70809 [==============================] - 3s 44us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 5/25\n",
      "70809/70809 [==============================] - 3s 48us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70809/70809 [==============================] - 3s 44us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 7/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 8/25\n",
      "70809/70809 [==============================] - 3s 43us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 9/25\n",
      "70809/70809 [==============================] - 3s 43us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 10/25\n",
      "70809/70809 [==============================] - 3s 44us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 11/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 12/25\n",
      "70809/70809 [==============================] - 3s 46us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 13/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 14/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 15/25\n",
      "70809/70809 [==============================] - 3s 44us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 16/25\n",
      "70809/70809 [==============================] - 3s 44us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 17/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 18/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 19/25\n",
      "70809/70809 [==============================] - 134s 2ms/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 20/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 21/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 22/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 23/25\n",
      "70809/70809 [==============================] - 3s 45us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 24/25\n",
      "70809/70809 [==============================] - 3s 44us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 25/25\n",
      "70809/70809 [==============================] - 3s 44us/sample - loss: 0.0147 - mean_squared_error: 0.0071 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_15.hdf5 after update number 15\n",
      "step_data: {'train_mse': 0.007105328963939707, 'iteration': 15, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013768667999673622}\n",
      "Env description: Runnig DAgger iteration 15 on env RoboschoolHumanoid-v1\n",
      "mean return 51.40462490631755\n",
      "std of return 15.747556171681476\n",
      "Train on 72830 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "72830/72830 [==============================] - 3s 42us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 2/25\n",
      "72830/72830 [==============================] - 3s 42us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 3/25\n",
      "72830/72830 [==============================] - 3s 43us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 4/25\n",
      "72830/72830 [==============================] - 3s 45us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 5/25\n",
      "72830/72830 [==============================] - 3s 45us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 6/25\n",
      "72830/72830 [==============================] - 3s 46us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 7/25\n",
      "72830/72830 [==============================] - 3s 44us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 8/25\n",
      "72830/72830 [==============================] - 3s 43us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 9/25\n",
      "72830/72830 [==============================] - 3s 44us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 10/25\n",
      "72830/72830 [==============================] - 3s 44us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 11/25\n",
      "72830/72830 [==============================] - 3s 42us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 12/25\n",
      "72830/72830 [==============================] - 3s 43us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 13/25\n",
      "72830/72830 [==============================] - 3s 44us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 14/25\n",
      "72830/72830 [==============================] - 3s 44us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 15/25\n",
      "72830/72830 [==============================] - 3s 44us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 16/25\n",
      "72830/72830 [==============================] - 3s 44us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 17/25\n",
      "72830/72830 [==============================] - 3s 43us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 18/25\n",
      "72830/72830 [==============================] - 3s 47us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 19/25\n",
      "72830/72830 [==============================] - 3s 46us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 20/25\n",
      "72830/72830 [==============================] - 3s 44us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 21/25\n",
      "72830/72830 [==============================] - 3s 43us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 22/25\n",
      "72830/72830 [==============================] - 3s 43us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 23/25\n",
      "72830/72830 [==============================] - 3s 46us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 24/25\n",
      "72830/72830 [==============================] - 3s 45us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 25/25\n",
      "72830/72830 [==============================] - 3s 43us/sample - loss: 0.0145 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "step_data: {'train_mse': 0.0069211509789144894, 'iteration': 16, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013786651920571673}\n",
      "Env description: Runnig DAgger iteration 16 on env RoboschoolHumanoid-v1\n",
      "mean return 54.39497084668113\n",
      "std of return 12.832290088616825\n",
      "Train on 74875 samples, validate on 4445 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74875/74875 [==============================] - 3s 43us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 2/25\n",
      "74875/74875 [==============================] - 3s 43us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 3/25\n",
      "74875/74875 [==============================] - 3s 43us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 4/25\n",
      "74875/74875 [==============================] - 3s 45us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 5/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 6/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 7/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 8/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 9/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138A: 1s - ETA: 0s - loss: 0.0143 - mean_squar\n",
      "Epoch 10/25\n",
      "74875/74875 [==============================] - 3s 43us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 11/25\n",
      "74875/74875 [==============================] - 3s 45us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 12/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 13/25\n",
      "74875/74875 [==============================] - 3s 45us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 14/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 15/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 16/25\n",
      "74875/74875 [==============================] - 3s 45us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 17/25\n",
      "74875/74875 [==============================] - 3s 45us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 18/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 19/25\n",
      "74875/74875 [==============================] - 3s 46us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 20/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 21/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 22/25\n",
      "74875/74875 [==============================] - 3s 45us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 23/25\n",
      "74875/74875 [==============================] - 3s 43us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 24/25\n",
      "74875/74875 [==============================] - 3s 43us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 25/25\n",
      "74875/74875 [==============================] - 3s 44us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "step_data: {'train_mse': 0.006746211379731713, 'iteration': 17, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013809277161108743}\n",
      "Env description: Runnig DAgger iteration 17 on env RoboschoolHumanoid-v1\n",
      "mean return 56.04218998239681\n",
      "std of return 17.46634964026817\n",
      "Train on 76994 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "76994/76994 [==============================] - 4s 46us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 2/25\n",
      "76994/76994 [==============================] - 3s 45us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 3/25\n",
      "76994/76994 [==============================] - 3s 45us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 4/25\n",
      "76994/76994 [==============================] - 3s 45us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 5/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 6/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 7/25\n",
      "76994/76994 [==============================] - 3s 43us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 8/25\n",
      "76994/76994 [==============================] - 3s 43us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 9/25\n",
      "76994/76994 [==============================] - 3s 43us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 10/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 11/25\n",
      "76994/76994 [==============================] - 3s 43us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 12/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 13/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 14/25\n",
      "76994/76994 [==============================] - 3s 43us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 15/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 16/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 17/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 18/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 19/25\n",
      "76994/76994 [==============================] - 3s 43us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 20/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 21/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76994/76994 [==============================] - 3s 43us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 23/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 24/25\n",
      "76994/76994 [==============================] - 3s 45us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 25/25\n",
      "76994/76994 [==============================] - 3s 44us/sample - loss: 0.0141 - mean_squared_error: 0.0066 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "step_data: {'train_mse': 0.006574817118709176, 'iteration': 18, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013830599356457206}\n",
      "Env description: Runnig DAgger iteration 18 on env RoboschoolHumanoid-v1\n",
      "mean return 59.39240267009579\n",
      "std of return 14.107377623804242\n",
      "Train on 79207 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "79207/79207 [==============================] - 4s 45us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 2/25\n",
      "79207/79207 [==============================] - 4s 45us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 3/25\n",
      "79207/79207 [==============================] - 4s 45us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 4/25\n",
      "79207/79207 [==============================] - 4s 45us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 5/25\n",
      "79207/79207 [==============================] - 3s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 6/25\n",
      "79207/79207 [==============================] - 4s 56us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 7/25\n",
      "79207/79207 [==============================] - 3s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 8/25\n",
      "79207/79207 [==============================] - 4s 45us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 9/25\n",
      "79207/79207 [==============================] - 3s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 10/25\n",
      "79207/79207 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.00 - 3s 43us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 11/25\n",
      "79207/79207 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.00 - 3s 43us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 12/25\n",
      "79207/79207 [==============================] - 3s 43us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 13/25\n",
      "79207/79207 [==============================] - 3s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 14/25\n",
      "79207/79207 [==============================] - 3s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 15/25\n",
      "79207/79207 [==============================] - 3s 43us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 16/25\n",
      "79207/79207 [==============================] - 3s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 17/25\n",
      "79207/79207 [==============================] - 3s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 18/25\n",
      "79207/79207 [==============================] - 3s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 19/25\n",
      "79207/79207 [==============================] - 3s 43us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 20/25\n",
      "79207/79207 [==============================] - 4s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 21/25\n",
      "79207/79207 [==============================] - 4s 45us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 22/25\n",
      "79207/79207 [==============================] - 4s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 23/25\n",
      "79207/79207 [==============================] - 3s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 24/25\n",
      "79207/79207 [==============================] - 3s 43us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 25/25\n",
      "79207/79207 [==============================] - 3s 44us/sample - loss: 0.0139 - mean_squared_error: 0.0064 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "step_data: {'train_mse': 0.006405707902958509, 'iteration': 19, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013854975573495005}\n",
      "Env description: Runnig DAgger iteration 19 on env RoboschoolHumanoid-v1\n",
      "mean return 50.75938872754876\n",
      "std of return 19.164363420672412\n",
      "Train on 81237 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "81237/81237 [==============================] - 4s 44us/sample - loss: 0.0138 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 2/25\n",
      "81237/81237 [==============================] - 4s 43us/sample - loss: 0.0138 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 3/25\n",
      "81237/81237 [==============================] - 4s 43us/sample - loss: 0.0138 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 4/25\n",
      "81237/81237 [==============================] - 4s 44us/sample - loss: 0.0138 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 5/25\n",
      "81237/81237 [==============================] - 3s 43us/sample - loss: 0.0138 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 6/25\n",
      "81237/81237 [==============================] - 4s 44us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 7/25\n",
      "81237/81237 [==============================] - 4s 44us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 8/25\n",
      "81237/81237 [==============================] - 4s 45us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 9/25\n",
      "81237/81237 [==============================] - 4s 44us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 10/25\n",
      "81237/81237 [==============================] - 4s 43us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 11/25\n",
      "81237/81237 [==============================] - 4s 43us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 12/25\n",
      "81237/81237 [==============================] - 4s 46us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 13/25\n",
      "81237/81237 [==============================] - 4s 44us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 14/25\n",
      "81237/81237 [==============================] - 4s 44us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 15/25\n",
      "81237/81237 [==============================] - 4s 46us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n",
      "81237/81237 [==============================] - 3s 43us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 17/25\n",
      "81237/81237 [==============================] - 4s 45us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 18/25\n",
      "81237/81237 [==============================] - 4s 50us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 19/25\n",
      "81237/81237 [==============================] - 3s 43us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 20/25\n",
      "81237/81237 [==============================] - 4s 44us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 21/25\n",
      "81237/81237 [==============================] - 4s 44us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 22/25\n",
      "81237/81237 [==============================] - 4s 44us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 23/25\n",
      "81237/81237 [==============================] - 3s 43us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 24/25\n",
      "81237/81237 [==============================] - 3s 43us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 25/25\n",
      "81237/81237 [==============================] - 4s 43us/sample - loss: 0.0138 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_20.hdf5 after update number 20\n",
      "step_data: {'train_mse': 0.0062605652604597415, 'iteration': 20, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013880857847977043}\n",
      "Env description: Runnig DAgger iteration 20 on env RoboschoolHumanoid-v1\n",
      "mean return 56.941365586018584\n",
      "std of return 14.754163232831143\n",
      "Train on 83344 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 2/25\n",
      "83344/83344 [==============================] - 4s 45us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 3/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 4/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 5/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 6/25\n",
      "83344/83344 [==============================] - 4s 43us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 7/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 8/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 9/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 10/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 11/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 12/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 13/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 14/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 15/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 16/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 17/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 18/25\n",
      "83344/83344 [==============================] - 4s 43us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 19/25\n",
      "83344/83344 [==============================] - 4s 45us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 20/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 21/25\n",
      "83344/83344 [==============================] - 4s 47us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 22/25\n",
      "83344/83344 [==============================] - 4s 43us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 23/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 24/25\n",
      "83344/83344 [==============================] - 4s 43us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 25/25\n",
      "83344/83344 [==============================] - 4s 44us/sample - loss: 0.0136 - mean_squared_error: 0.0061 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "step_data: {'train_mse': 0.006117671536573228, 'iteration': 21, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013906217662333456}\n",
      "Env description: Runnig DAgger iteration 21 on env RoboschoolHumanoid-v1\n",
      "mean return 54.81616999642082\n",
      "std of return 11.603307843334605\n",
      "Train on 85389 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 2/25\n",
      "85389/85389 [==============================] - 4s 45us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 3/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 4/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 5/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 6/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 7/25\n",
      "85389/85389 [==============================] - 4s 43us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 8/25\n",
      "85389/85389 [==============================] - 5s 55us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 9/25\n",
      "85389/85389 [==============================] - 4s 48us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85389/85389 [==============================] - 4s 48us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 11/25\n",
      "85389/85389 [==============================] - 4s 48us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 12/25\n",
      "85389/85389 [==============================] - 4s 47us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 13/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 14/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 15/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 16/25\n",
      "85389/85389 [==============================] - 4s 43us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 17/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 18/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 19/25\n",
      "85389/85389 [==============================] - 4s 43us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 20/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 21/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 22/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 23/25\n",
      "85389/85389 [==============================] - 4s 43us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 24/25\n",
      "85389/85389 [==============================] - 4s 43us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 25/25\n",
      "85389/85389 [==============================] - 4s 44us/sample - loss: 0.0134 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "step_data: {'train_mse': 0.00598647083163988, 'iteration': 22, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013931646577346335}\n",
      "Env description: Runnig DAgger iteration 22 on env RoboschoolHumanoid-v1\n",
      "mean return 51.57066324698881\n",
      "std of return 16.966715561994654\n",
      "Train on 87469 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "87469/87469 [==============================] - 4s 45us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 2/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 3/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 4/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 5/25\n",
      "87469/87469 [==============================] - 4s 46us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 6/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 7/25\n",
      "87469/87469 [==============================] - 4s 47us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 8/25\n",
      "87469/87469 [==============================] - 4s 46us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 9/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 10/25\n",
      "87469/87469 [==============================] - 4s 43us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 11/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 12/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 13/25\n",
      "87469/87469 [==============================] - 4s 43us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 14/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 15/25\n",
      "87469/87469 [==============================] - 4s 43us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 16/25\n",
      "87469/87469 [==============================] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.00 - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 17/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 18/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 19/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 20/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 21/25\n",
      "87469/87469 [==============================] - 4s 43us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 22/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 23/25\n",
      "87469/87469 [==============================] - 4s 43us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 24/25\n",
      "87469/87469 [==============================] - 4s 44us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 25/25\n",
      "87469/87469 [==============================] - 4s 43us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "step_data: {'train_mse': 0.0058594235167732794, 'iteration': 23, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013958457809775669}\n",
      "Env description: Runnig DAgger iteration 23 on env RoboschoolHumanoid-v1\n",
      "mean return 55.51237053318705\n",
      "std of return 12.878760272576336\n",
      "Train on 89577 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 2/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 3/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 5/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 6/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 7/25\n",
      "89577/89577 [==============================] - 4s 43us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 8/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 9/25\n",
      "89577/89577 [==============================] - 4s 43us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 10/25\n",
      "89577/89577 [==============================] - 4s 46us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 11/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 12/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 13/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 14/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 15/25\n",
      "89577/89577 [==============================] - 4s 46us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 16/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 17/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 18/25\n",
      "89577/89577 [==============================] - 4s 46us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 19/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 20/25\n",
      "89577/89577 [==============================] - 4s 43us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 21/25\n",
      "89577/89577 [==============================] - 4s 46us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 22/25\n",
      "89577/89577 [==============================] - 4s 43us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 23/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 24/25\n",
      "89577/89577 [==============================] - 5s 52us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 25/25\n",
      "89577/89577 [==============================] - 4s 44us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "step_data: {'train_mse': 0.00573738843742503, 'iteration': 24, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013987630227162364}\n",
      "Env description: Runnig DAgger iteration 24 on env RoboschoolHumanoid-v1\n",
      "mean return 57.710697149824725\n",
      "std of return 15.176825762292557\n",
      "Train on 91708 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 2/25\n",
      "91708/91708 [==============================] - 4s 46us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 3/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 4/25\n",
      "91708/91708 [==============================] - 4s 44us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 5/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 6/25\n",
      "91708/91708 [==============================] - 4s 44us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 7/25\n",
      "91708/91708 [==============================] - 4s 44us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 8/25\n",
      "91708/91708 [==============================] - 4s 44us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 9/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 10/25\n",
      "91708/91708 [==============================] - 4s 44us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 11/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 12/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 13/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 14/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 15/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 16/25\n",
      "91708/91708 [==============================] - 4s 44us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 17/25\n",
      "91708/91708 [==============================] - 4s 44us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 18/25\n",
      "91708/91708 [==============================] - 4s 44us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 19/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 20/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 21/25\n",
      "91708/91708 [==============================] - 4s 47us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 22/25\n",
      "91708/91708 [==============================] - 4s 44us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 23/25\n",
      "91708/91708 [==============================] - 4s 44us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 24/25\n",
      "91708/91708 [==============================] - 4s 43us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91708/91708 [==============================] - 4s 44us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_25.hdf5 after update number 25\n",
      "step_data: {'train_mse': 0.005620164406375038, 'iteration': 25, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014016993705507345}\n",
      "Env description: Runnig DAgger iteration 25 on env RoboschoolHumanoid-v1\n",
      "mean return 55.93657150553995\n",
      "std of return 9.709267828559478\n",
      "Train on 93792 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 2/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 3/25\n",
      "93792/93792 [==============================] - 4s 45us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 4/25\n",
      "93792/93792 [==============================] - 4s 43us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 5/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 6/25\n",
      "93792/93792 [==============================] - 4s 43us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 7/25\n",
      "93792/93792 [==============================] - 4s 43us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 8/25\n",
      "93792/93792 [==============================] - 4s 43us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 9/25\n",
      "93792/93792 [==============================] - 4s 43us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 10/25\n",
      "93792/93792 [==============================] - 4s 43us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 11/25\n",
      "93792/93792 [==============================] - 4s 43us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 12/25\n",
      "93792/93792 [==============================] - 4s 43us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 13/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 14/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 15/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 16/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 17/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 18/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 19/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 20/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 21/25\n",
      "93792/93792 [==============================] - 4s 43us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 22/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 23/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 24/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 25/25\n",
      "93792/93792 [==============================] - 4s 44us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "step_data: {'train_mse': 0.005511172188470284, 'iteration': 26, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014046032168396215}\n",
      "Env description: Runnig DAgger iteration 26 on env RoboschoolHumanoid-v1\n",
      "mean return 53.94302676691666\n",
      "std of return 11.54402456350926\n",
      "Train on 95796 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 2/25\n",
      "95796/95796 [==============================] - 4s 44us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 3/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 4/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 5/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 6/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 7/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 8/25\n",
      "95796/95796 [==============================] - 4s 44us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 9/25\n",
      "95796/95796 [==============================] - 4s 44us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 10/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 11/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 12/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 13/25\n",
      "95796/95796 [==============================] - 4s 44us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 14/25\n",
      "95796/95796 [==============================] - 4s 44us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 15/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 16/25\n",
      "95796/95796 [==============================] - 4s 44us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 17/25\n",
      "95796/95796 [==============================] - 4s 44us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 18/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 20/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 21/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 22/25\n",
      "95796/95796 [==============================] - 4s 43us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 23/25\n",
      "95796/95796 [==============================] - 4s 44us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 24/25\n",
      "95796/95796 [==============================] - 4s 44us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 25/25\n",
      "95796/95796 [==============================] - 4s 45us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "step_data: {'train_mse': 0.005412305714768839, 'iteration': 27, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014077991590400773}\n",
      "Env description: Runnig DAgger iteration 27 on env RoboschoolHumanoid-v1\n",
      "mean return 55.82075237650838\n",
      "std of return 21.311393000068175\n",
      "Train on 97882 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "97882/97882 [==============================] - 4s 44us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 2/25\n",
      "97882/97882 [==============================] - 4s 45us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 3/25\n",
      "97882/97882 [==============================] - 4s 44us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 4/25\n",
      "97882/97882 [==============================] - 4s 45us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 5/25\n",
      "97882/97882 [==============================] - 4s 44us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 6/25\n",
      "97882/97882 [==============================] - 4s 43us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 7/25\n",
      "97882/97882 [==============================] - 4s 45us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 8/25\n",
      "97882/97882 [==============================] - 4s 44us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 9/25\n",
      "97882/97882 [==============================] - 4s 43us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 10/25\n",
      "97882/97882 [==============================] - 4s 43us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 11/25\n",
      "97882/97882 [==============================] - 4s 43us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 12/25\n",
      "97882/97882 [==============================] - 4s 46us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 13/25\n",
      "97882/97882 [==============================] - 4s 44us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 14/25\n",
      "97882/97882 [==============================] - 4s 44us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 15/25\n",
      "97882/97882 [==============================] - 4s 43us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 16/25\n",
      "97882/97882 [==============================] - 4s 44us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 17/25\n",
      "97882/97882 [==============================] - 4s 43us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 18/25\n",
      "97882/97882 [==============================] - 4s 44us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 19/25\n",
      "97882/97882 [==============================] - 4s 44us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 20/25\n",
      "97882/97882 [==============================] - 4s 44us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 21/25\n",
      "97882/97882 [==============================] - 4s 43us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 22/25\n",
      "97882/97882 [==============================] - 4s 43us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 23/25\n",
      "97882/97882 [==============================] - 4s 43us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 24/25\n",
      "97882/97882 [==============================] - 4s 44us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 25/25\n",
      "97882/97882 [==============================] - 4s 43us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "step_data: {'train_mse': 0.0053126344765030645, 'iteration': 28, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014109139274937437}\n",
      "Env description: Runnig DAgger iteration 28 on env RoboschoolHumanoid-v1\n",
      "mean return 53.97372800246194\n",
      "std of return 13.502176039419886\n",
      "Train on 99966 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "99966/99966 [==============================] - 4s 44us/sample - loss: 0.0125 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 2/25\n",
      "99966/99966 [==============================] - 4s 43us/sample - loss: 0.0125 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 3/25\n",
      "99966/99966 [==============================] - 4s 45us/sample - loss: 0.0125 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 4/25\n",
      "99966/99966 [==============================] - 4s 44us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 5/25\n",
      "99966/99966 [==============================] - 4s 43us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 6/25\n",
      "99966/99966 [==============================] - 4s 43us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 7/25\n",
      "99966/99966 [==============================] - 4s 43us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 8/25\n",
      "99966/99966 [==============================] - 4s 44us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 9/25\n",
      "99966/99966 [==============================] - 4s 42us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 10/25\n",
      "99966/99966 [==============================] - 4s 42us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 11/25\n",
      "99966/99966 [==============================] - 4s 44us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 12/25\n",
      "99966/99966 [==============================] - 4s 43us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99966/99966 [==============================] - 4s 44us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 14/25\n",
      "99966/99966 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.00 - 4s 44us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 15/25\n",
      "99966/99966 [==============================] - 4s 43us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 16/25\n",
      "99966/99966 [==============================] - 4s 43us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 17/25\n",
      "99966/99966 [==============================] - 4s 43us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 18/25\n",
      "99966/99966 [==============================] - 4s 43us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 19/25\n",
      "99966/99966 [==============================] - 5s 54us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 20/25\n",
      "99966/99966 [==============================] - 5s 50us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 21/25\n",
      "99966/99966 [==============================] - 5s 52us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 22/25\n",
      "99966/99966 [==============================] - 6s 57us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 23/25\n",
      "99966/99966 [==============================] - 5s 52us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 24/25\n",
      "99966/99966 [==============================] - 6s 56us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 25/25\n",
      "99966/99966 [==============================] - 5s 52us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "step_data: {'train_mse': 0.005217806374021614, 'iteration': 29, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014139245898171393}\n",
      "Env description: Runnig DAgger iteration 29 on env RoboschoolHumanoid-v1\n",
      "mean return 52.599505243591445\n",
      "std of return 16.321811513905494\n",
      "Train on 102005 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "102005/102005 [==============================] - 5s 48us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 2/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 3/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 4/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 5/25\n",
      "102005/102005 [==============================] - 5s 46us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 6/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 7/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 8/25\n",
      "102005/102005 [==============================] - 5s 46us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 9/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 10/25\n",
      "102005/102005 [==============================] - 5s 48us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 11/25\n",
      "102005/102005 [==============================] - 5s 46us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 12/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 13/25\n",
      "102005/102005 [==============================] - 5s 48us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 14/25\n",
      "102005/102005 [==============================] - 5s 46us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 15/25\n",
      "102005/102005 [==============================] - 5s 49us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 16/25\n",
      "102005/102005 [==============================] - 5s 46us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 17/25\n",
      "102005/102005 [==============================] - 5s 48us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 18/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 19/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 20/25\n",
      "102005/102005 [==============================] - 5s 46us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 21/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 22/25\n",
      "102005/102005 [==============================] - 5s 46us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 23/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 24/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 25/25\n",
      "102005/102005 [==============================] - 5s 47us/sample - loss: 0.0123 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_30.hdf5 after update number 30\n",
      "step_data: {'train_mse': 0.00512989080976927, 'iteration': 30, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014170635441517688}\n",
      "Env description: Runnig DAgger iteration 30 on env RoboschoolHumanoid-v1\n",
      "mean return 55.38196653151251\n",
      "std of return 18.417624170266937\n",
      "Train on 104088 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 2/25\n",
      "104088/104088 [==============================] - 5s 47us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 3/25\n",
      "104088/104088 [==============================] - 6s 56us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 4/25\n",
      "104088/104088 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 5/25\n",
      "104088/104088 [==============================] - 5s 47us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 7/25\n",
      "104088/104088 [==============================] - 5s 45us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 8/25\n",
      "104088/104088 [==============================] - 5s 45us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 9/25\n",
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 10/25\n",
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 11/25\n",
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 12/25\n",
      "104088/104088 [==============================] - 5s 45us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 13/25\n",
      "104088/104088 [==============================] - 5s 48us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 14/25\n",
      "104088/104088 [==============================] - 5s 45us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 15/25\n",
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 16/25\n",
      "104088/104088 [==============================] - 5s 45us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 17/25\n",
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 18/25\n",
      "104088/104088 [==============================] - 5s 47us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 19/25\n",
      "104088/104088 [==============================] - 5s 45us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 20/25\n",
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 21/25\n",
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 22/25\n",
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 23/25\n",
      "104088/104088 [==============================] - 5s 45us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 24/25\n",
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 25/25\n",
      "104088/104088 [==============================] - 5s 46us/sample - loss: 0.0122 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "step_data: {'train_mse': 0.00504346212650003, 'iteration': 31, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014203322568508283}\n",
      "Env description: Runnig DAgger iteration 31 on env RoboschoolHumanoid-v1\n",
      "mean return 55.80260277675734\n",
      "std of return 14.399480198744858\n",
      "Train on 106228 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "106228/106228 [==============================] - 5s 45us/sample - loss: 0.0121 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 2/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 3/25\n",
      "106228/106228 [==============================] - 5s 45us/sample - loss: 0.0121 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 4/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 5/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 6/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 7/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 8/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 9/25\n",
      "106228/106228 [==============================] - 5s 45us/sample - loss: 0.0121 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 10/25\n",
      "106228/106228 [==============================] - 5s 45us/sample - loss: 0.0121 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 11/25\n",
      "106228/106228 [==============================] - 5s 47us/sample - loss: 0.0121 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 12/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 13/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 14/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 15/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 16/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 17/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 18/25\n",
      "106228/106228 [==============================] - 5s 47us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 19/25\n",
      "106228/106228 [==============================] - 5s 49us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 20/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 21/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 22/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 23/25\n",
      "106228/106228 [==============================] - 5s 47us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 24/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 25/25\n",
      "106228/106228 [==============================] - 5s 46us/sample - loss: 0.0121 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "step_data: {'train_mse': 0.004958039264057273, 'iteration': 32, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014236139428915178}\n",
      "Env description: Runnig DAgger iteration 32 on env RoboschoolHumanoid-v1\n",
      "mean return 55.502951152554964\n",
      "std of return 16.10881010218652\n",
      "Train on 108289 samples, validate on 4445 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108289/108289 [==============================] - 5s 45us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 2/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 3/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 4/25\n",
      "108289/108289 [==============================] - 5s 45us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 5/25\n",
      "108289/108289 [==============================] - 5s 45us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 6/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 7/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 8/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 9/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 10/25\n",
      "108289/108289 [==============================] - 5s 45us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 11/25\n",
      "108289/108289 [==============================] - 5s 45us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 12/25\n",
      "108289/108289 [==============================] - 5s 45us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 13/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 14/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 15/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 16/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 17/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 18/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 19/25\n",
      "108289/108289 [==============================] - 5s 48us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 20/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 21/25\n",
      "108289/108289 [==============================] - 5s 47us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 22/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 23/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 24/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 25/25\n",
      "108289/108289 [==============================] - 5s 46us/sample - loss: 0.0120 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "step_data: {'train_mse': 0.004879737509713564, 'iteration': 33, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014269053342227346}\n",
      "Env description: Runnig DAgger iteration 33 on env RoboschoolHumanoid-v1\n",
      "mean return 51.46118167513718\n",
      "std of return 18.459881448775096\n",
      "Train on 110312 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "110312/110312 [==============================] - 5s 45us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 2/25\n",
      "110312/110312 [==============================] - 5s 46us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 3/25\n",
      "110312/110312 [==============================] - 5s 46us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 4/25\n",
      "110312/110312 [==============================] - 5s 46us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 5/25\n",
      "110312/110312 [==============================] - 5s 45us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 6/25\n",
      "110312/110312 [==============================] - 5s 46us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 7/25\n",
      "110312/110312 [==============================] - 5s 46us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 8/25\n",
      "110312/110312 [==============================] - 5s 46us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 9/25\n",
      "110312/110312 [==============================] - 5s 46us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 10/25\n",
      "110312/110312 [==============================] - 5s 46us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 11/25\n",
      "110312/110312 [==============================] - 5s 46us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 12/25\n",
      "110312/110312 [==============================] - 5s 46us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 13/25\n",
      "110312/110312 [==============================] - 5s 44us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 14/25\n",
      "110312/110312 [==============================] - 5s 43us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 15/25\n",
      "110312/110312 [==============================] - 5s 43us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 16/25\n",
      "110312/110312 [==============================] - 5s 42us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 17/25\n",
      "110312/110312 [==============================] - 5s 45us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 18/25\n",
      "110312/110312 [==============================] - 5s 43us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 19/25\n",
      "110312/110312 [==============================] - 5s 43us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 20/25\n",
      "110312/110312 [==============================] - 5s 44us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110312/110312 [==============================] - 5s 44us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 22/25\n",
      "110312/110312 [==============================] - 5s 45us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 23/25\n",
      "110312/110312 [==============================] - 5s 43us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 24/25\n",
      "110312/110312 [==============================] - 5s 43us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 25/25\n",
      "110312/110312 [==============================] - 5s 43us/sample - loss: 0.0119 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "step_data: {'train_mse': 0.00480617411171436, 'iteration': 34, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.01430429668318721}\n",
      "Env description: Runnig DAgger iteration 34 on env RoboschoolHumanoid-v1\n",
      "mean return 54.96551954352908\n",
      "std of return 15.414347810784433\n",
      "Train on 112411 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 2/25\n",
      "112411/112411 [==============================] - 5s 44us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 3/25\n",
      "112411/112411 [==============================] - 5s 44us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 4/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 5/25\n",
      "112411/112411 [==============================] - 5s 44us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 6/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 7/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 8/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 9/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 10/25\n",
      "112411/112411 [==============================] - 5s 44us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 11/25\n",
      "112411/112411 [==============================] - 5s 44us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 12/25\n",
      "112411/112411 [==============================] - 5s 44us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 13/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 14/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 15/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 16/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 17/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 18/25\n",
      "112411/112411 [==============================] - 5s 42us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 19/25\n",
      "112411/112411 [==============================] - 5s 44us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 20/25\n",
      "112411/112411 [==============================] - 5s 45us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 21/25\n",
      "112411/112411 [==============================] - 5s 44us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 22/25\n",
      "112411/112411 [==============================] - 5s 44us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 23/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 24/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 25/25\n",
      "112411/112411 [==============================] - 5s 43us/sample - loss: 0.0118 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_35.hdf5 after update number 35\n",
      "step_data: {'train_mse': 0.004732561749917054, 'iteration': 35, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014339288535294798}\n",
      "Env description: Runnig DAgger iteration 35 on env RoboschoolHumanoid-v1\n",
      "mean return 52.35135139091922\n",
      "std of return 16.514664449339723\n",
      "Train on 114386 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 2/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 3/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 4/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 5/25\n",
      "114386/114386 [==============================] - 5s 44us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 6/25\n",
      "114386/114386 [==============================] - 5s 44us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 7/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 8/25\n",
      "114386/114386 [==============================] - 5s 44us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 9/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 10/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 11/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 12/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 13/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 15/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 16/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 17/25\n",
      "114386/114386 [==============================] - 5s 44us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 18/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 19/25\n",
      "114386/114386 [==============================] - 5s 44us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 20/25\n",
      "114386/114386 [==============================] - 5s 44us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 21/25\n",
      "114386/114386 [==============================] - 5s 44us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 22/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 23/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 24/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 25/25\n",
      "114386/114386 [==============================] - 5s 43us/sample - loss: 0.0117 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "step_data: {'train_mse': 0.004666954986125402, 'iteration': 36, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014375289750906888}\n",
      "Env description: Runnig DAgger iteration 36 on env RoboschoolHumanoid-v1\n",
      "mean return 53.69077568515608\n",
      "std of return 15.010641393045566\n",
      "Train on 116417 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "116417/116417 [==============================] - 5s 44us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 2/25\n",
      "116417/116417 [==============================] - 5s 44us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 3/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 4/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 6/25\n",
      "116417/116417 [==============================] - 5s 42us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 7/25\n",
      "116417/116417 [==============================] - 5s 44us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 8/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 9/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 10/25\n",
      "116417/116417 [==============================] - 5s 45us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 11/25\n",
      "116417/116417 [==============================] - 5s 44us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 12/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 13/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 14/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 15/25\n",
      "116417/116417 [==============================] - 6s 52us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 16/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 17/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 18/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 19/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 20/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 21/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 22/25\n",
      "116417/116417 [==============================] - 5s 44us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 23/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 24/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 25/25\n",
      "116417/116417 [==============================] - 5s 43us/sample - loss: 0.0116 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "step_data: {'train_mse': 0.004601484997275403, 'iteration': 37, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014409947514730499}\n",
      "Env description: Runnig DAgger iteration 37 on env RoboschoolHumanoid-v1\n",
      "mean return 54.79589705668335\n",
      "std of return 13.708221731549548\n",
      "Train on 118489 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 2/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 3/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 4/25\n",
      "118489/118489 [==============================] - 5s 44us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/25\n",
      "118489/118489 [==============================] - 5s 45us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 6/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 7/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118489/118489 [==============================] - 5s 44us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 9/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144s - loss: 0.0115 - mean_squared_error: 0.\n",
      "Epoch 10/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 11/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 12/25\n",
      "118489/118489 [==============================] - 5s 42us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 13/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 14/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 15/25\n",
      "118489/118489 [==============================] - 5s 46us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 16/25\n",
      "118489/118489 [==============================] - 5s 44us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 17/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 18/25\n",
      "118489/118489 [==============================] - 5s 42us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 19/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 20/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 21/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 22/25\n",
      "118489/118489 [==============================] - 5s 44us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 23/25\n",
      "118489/118489 [==============================] - 5s 44us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 24/25\n",
      "118489/118489 [==============================] - 5s 42us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 25/25\n",
      "118489/118489 [==============================] - 5s 43us/sample - loss: 0.0115 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "step_data: {'train_mse': 0.004536508443976106, 'iteration': 38, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014442469949318115}\n",
      "Env description: Runnig DAgger iteration 38 on env RoboschoolHumanoid-v1\n",
      "mean return 52.46421955002832\n",
      "std of return 22.11199450579662\n",
      "Train on 120480 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "120480/120480 [==============================] - 5s 42us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 2/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 3/25\n",
      "120480/120480 [==============================] - 5s 42us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 4/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 6/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 7/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 8/25\n",
      "120480/120480 [==============================] - 5s 44us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 9/25\n",
      "120480/120480 [==============================] - 5s 44us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 10/25\n",
      "120480/120480 [==============================] - 5s 44us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 12/25\n",
      "120480/120480 [==============================] - 5s 44us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 13/25\n",
      "120480/120480 [==============================] - 5s 44us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 14/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 15/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 16/25\n",
      "120480/120480 [==============================] - 5s 44us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 17/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 18/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 19/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 20/25\n",
      "120480/120480 [==============================] - 5s 44us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 21/25\n",
      "120480/120480 [==============================] - 5s 44us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 22/25\n",
      "120480/120480 [==============================] - 5s 43us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 23/25\n",
      "120480/120480 [==============================] - 5s 44us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 24/25\n",
      "120480/120480 [==============================] - 5s 45us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 25/25\n",
      "120480/120480 [==============================] - 5s 44us/sample - loss: 0.0114 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "step_data: {'train_mse': 0.004477426926901677, 'iteration': 39, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014478038513169625}\n",
      "Env description: Runnig DAgger iteration 39 on env RoboschoolHumanoid-v1\n",
      "mean return 55.429857169652315\n",
      "std of return 14.802484574679461\n",
      "Train on 122575 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "122575/122575 [==============================] - 5s 44us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "122575/122575 [==============================] - 5s 44us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 3/25\n",
      "122575/122575 [==============================] - 5s 44us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 4/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 5/25\n",
      "122575/122575 [==============================] - 5s 44us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 6/25\n",
      "122575/122575 [==============================] - 5s 44us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 7/25\n",
      "122575/122575 [==============================] - 5s 44us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 8/25\n",
      "122575/122575 [==============================] - 5s 44us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 9/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 10/25\n",
      "122575/122575 [==============================] - 5s 44us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 12/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 13/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 14/25\n",
      "122575/122575 [==============================] - 5s 44us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 15/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 16/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 17/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 18/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 19/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 20/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 21/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 22/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 23/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 24/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 25/25\n",
      "122575/122575 [==============================] - 5s 43us/sample - loss: 0.0113 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_40.hdf5 after update number 40\n",
      "step_data: {'train_mse': 0.004416322558109811, 'iteration': 40, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.01451501540967498}\n",
      "Env description: Runnig DAgger iteration 40 on env RoboschoolHumanoid-v1\n",
      "mean return 54.55408126593839\n",
      "std of return 10.114814898846197\n",
      "Train on 124575 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "124575/124575 [==============================] - 5s 44us/sample - loss: 0.0112 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 2/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 3/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 4/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 5/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 6/25\n",
      "124575/124575 [==============================] - 5s 42us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 7/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 8/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 9/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 10/25\n",
      "124575/124575 [==============================] - 5s 44us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/25\n",
      "124575/124575 [==============================] - 5s 44us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 12/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 13/25\n",
      "124575/124575 [==============================] - 5s 44us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 14/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 15/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 16/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 17/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 18/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 19/25\n",
      "124575/124575 [==============================] - 5s 44us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 20/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 21/25\n",
      "124575/124575 [==============================] - 5s 44us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124575/124575 [==============================] - 5s 44us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 23/25\n",
      "124575/124575 [==============================] - 5s 44us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 24/25\n",
      "124575/124575 [==============================] - 5s 43us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 25/25\n",
      "124575/124575 [==============================] - 6s 45us/sample - loss: 0.0112 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "step_data: {'train_mse': 0.0043613774018127025, 'iteration': 41, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014550593350258476}\n",
      "Env description: Runnig DAgger iteration 41 on env RoboschoolHumanoid-v1\n",
      "mean return 56.18720020341512\n",
      "std of return 14.823793669325728\n",
      "Train on 126612 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "126612/126612 [==============================] - 5s 42us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 2/25\n",
      "126612/126612 [==============================] - 6s 44us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 3/25\n",
      "126612/126612 [==============================] - 5s 43us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 4/25\n",
      "126612/126612 [==============================] - 7s 52us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 5/25\n",
      "126612/126612 [==============================] - 6s 49us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 6/25\n",
      "126612/126612 [==============================] - 6s 47us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 7/25\n",
      "126612/126612 [==============================] - 6s 44us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 8/25\n",
      "126612/126612 [==============================] - 5s 43us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 9/25\n",
      "126612/126612 [==============================] - 5s 43us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 10/25\n",
      "126612/126612 [==============================] - 6s 44us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 11/25\n",
      "126612/126612 [==============================] - 5s 43us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 12/25\n",
      "126612/126612 [==============================] - 5s 43us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 13/25\n",
      "126612/126612 [==============================] - 6s 45us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 14/25\n",
      "126612/126612 [==============================] - 6s 45us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 15/25\n",
      "126612/126612 [==============================] - 6s 45us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 16/25\n",
      "126612/126612 [==============================] - 6s 44us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 17/25\n",
      "126612/126612 [==============================] - 5s 43us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 18/25\n",
      "126612/126612 [==============================] - 6s 44us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 19/25\n",
      "126612/126612 [==============================] - 6s 44us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 20/25\n",
      "126612/126612 [==============================] - 6s 45us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 21/25\n",
      "126612/126612 [==============================] - 5s 42us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 22/25\n",
      "126612/126612 [==============================] - 5s 43us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 23/25\n",
      "126612/126612 [==============================] - 5s 43us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 24/25\n",
      "126612/126612 [==============================] - 5s 43us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 25/25\n",
      "126612/126612 [==============================] - 6s 45us/sample - loss: 0.0111 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "step_data: {'train_mse': 0.0043063189188657, 'iteration': 42, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014586634827197437}\n",
      "Env description: Runnig DAgger iteration 42 on env RoboschoolHumanoid-v1\n",
      "mean return 56.11029636690604\n",
      "std of return 11.563817040007045\n",
      "Train on 128701 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 2/25\n",
      "128701/128701 [==============================] - 5s 42us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 3/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 4/25\n",
      "128701/128701 [==============================] - 5s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 5/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 6/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 7/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 8/25\n",
      "128701/128701 [==============================] - 6s 44us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 9/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 10/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 11/25\n",
      "128701/128701 [==============================] - 6s 44us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 12/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 13/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 14/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 15/25\n",
      "128701/128701 [==============================] - 5s 42us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 17/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 18/25\n",
      "128701/128701 [==============================] - 6s 44us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 19/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 20/25\n",
      "128701/128701 [==============================] - 6s 46us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 21/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 22/25\n",
      "128701/128701 [==============================] - 6s 44us/sample - loss: 0.0110 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 23/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 24/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 25/25\n",
      "128701/128701 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0043 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "step_data: {'train_mse': 0.004251707982495252, 'iteration': 43, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014624003106727046}\n",
      "Env description: Runnig DAgger iteration 43 on env RoboschoolHumanoid-v1\n",
      "mean return 52.39188103430555\n",
      "std of return 18.553848572206867\n",
      "Train on 130782 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 2/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 3/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 4/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 5/25\n",
      "130782/130782 [==============================] - 6s 46us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 6/25\n",
      "130782/130782 [==============================] - 6s 44us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 7/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0110 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 8/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 9/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 10/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 11/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 12/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 13/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 14/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 15/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 16/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 17/25\n",
      "130782/130782 [==============================] - 6s 44us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 18/25\n",
      "130782/130782 [==============================] - 6s 42us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 19/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 20/25\n",
      "130782/130782 [==============================] - 6s 44us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 21/25\n",
      "130782/130782 [==============================] - 6s 45us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 22/25\n",
      "130782/130782 [==============================] - 6s 44us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 23/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 24/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 25/25\n",
      "130782/130782 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "step_data: {'train_mse': 0.004199295956718328, 'iteration': 44, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014658530032493192}\n",
      "Env description: Runnig DAgger iteration 44 on env RoboschoolHumanoid-v1\n",
      "mean return 56.98318065399951\n",
      "std of return 17.450415027815588\n",
      "Train on 132854 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 2/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 3/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 4/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 5/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 6/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 7/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 8/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 9/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 11/25\n",
      "132854/132854 [==============================] - 6s 42us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 12/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 13/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 14/25\n",
      "132854/132854 [==============================] - 6s 47us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 15/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 16/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 17/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 18/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 19/25\n",
      "132854/132854 [==============================] - 7s 49us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 20/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 21/25\n",
      "132854/132854 [==============================] - 6s 45us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 22/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 23/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 24/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 25/25\n",
      "132854/132854 [==============================] - 6s 43us/sample - loss: 0.0109 - mean_squared_error: 0.0042 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_45.hdf5 after update number 45\n",
      "step_data: {'train_mse': 0.004149234495606426, 'iteration': 45, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014696628125315088}\n",
      "Env description: Runnig DAgger iteration 45 on env RoboschoolHumanoid-v1\n",
      "mean return 50.21540332974625\n",
      "std of return 20.06315461278429\n",
      "Train on 134843 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "134843/134843 [==============================] - 6s 44us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 2/25\n",
      "134843/134843 [==============================] - 7s 51us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 3/25\n",
      "134843/134843 [==============================] - 6s 45us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 4/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 5/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 6/25\n",
      "134843/134843 [==============================] - 6s 45us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 7/25\n",
      "134843/134843 [==============================] - 6s 45us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 8/25\n",
      "134843/134843 [==============================] - 6s 45us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 9/25\n",
      "134843/134843 [==============================] - 6s 45us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 10/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 11/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 12/25\n",
      "134843/134843 [==============================] - 6s 47us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 13/25\n",
      "134843/134843 [==============================] - 6s 45us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 14/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 15/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 16/25\n",
      "134843/134843 [==============================] - 6s 47us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 17/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 18/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 19/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 20/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 21/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 22/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 23/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 24/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 25/25\n",
      "134843/134843 [==============================] - 6s 46us/sample - loss: 0.0108 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "step_data: {'train_mse': 0.004102925541535808, 'iteration': 46, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014734824373754873}\n",
      "Env description: Runnig DAgger iteration 46 on env RoboschoolHumanoid-v1\n",
      "mean return 49.63283824250953\n",
      "std of return 22.746681574009337\n",
      "Train on 136874 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "136874/136874 [==============================] - 6s 46us/sample - loss: 0.0107 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 2/25\n",
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 4/25\n",
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 5/25\n",
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 6/25\n",
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 7/25\n",
      "136874/136874 [==============================] - 6s 46us/sample - loss: 0.0107 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 8/25\n",
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 9/25\n",
      "136874/136874 [==============================] - 6s 47us/sample - loss: 0.0107 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 10/25\n",
      "136874/136874 [==============================] - 6s 46us/sample - loss: 0.0107 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 11/25\n",
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 12/25\n",
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 13/25\n",
      "136874/136874 [==============================] - 6s 46us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 14/25\n",
      "136874/136874 [==============================] - 6s 46us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 15/25\n",
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 16/25\n",
      "136874/136874 [==============================] - 6s 46us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 17/25\n",
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 18/25\n",
      "136874/136874 [==============================] - 6s 46us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 19/25\n",
      "136874/136874 [==============================] - 7s 51us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 20/25\n",
      "136874/136874 [==============================] - 7s 51us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 21/25\n",
      "136874/136874 [==============================] - 6s 46us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 22/25\n",
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 23/25\n",
      "136874/136874 [==============================] - 6s 46us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 24/25\n",
      "136874/136874 [==============================] - 6s 46us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 25/25\n",
      "136874/136874 [==============================] - 6s 45us/sample - loss: 0.0107 - mean_squared_error: 0.0041 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "step_data: {'train_mse': 0.004057130402111587, 'iteration': 47, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014770879436530653}\n",
      "Env description: Runnig DAgger iteration 47 on env RoboschoolHumanoid-v1\n",
      "mean return 54.51408247051116\n",
      "std of return 18.75743712387399\n",
      "Train on 139029 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 2/25\n",
      "139029/139029 [==============================] - 6s 47us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 3/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 4/25\n",
      "139029/139029 [==============================] - 6s 46us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 5/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 6/25\n",
      "139029/139029 [==============================] - 6s 44us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 7/25\n",
      "139029/139029 [==============================] - 6s 46us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 8/25\n",
      "139029/139029 [==============================] - 6s 44us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 9/25\n",
      "139029/139029 [==============================] - 6s 44us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 10/25\n",
      "139029/139029 [==============================] - 6s 46us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 11/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 12/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 13/25\n",
      "139029/139029 [==============================] - 6s 44us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 14/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 15/25\n",
      "139029/139029 [==============================] - 6s 46us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 16/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 17/25\n",
      "139029/139029 [==============================] - 6s 46us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 18/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 19/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 20/25\n",
      "139029/139029 [==============================] - 6s 46us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 21/25\n",
      "139029/139029 [==============================] - 6s 46us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 22/25\n",
      "139029/139029 [==============================] - 6s 46us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 23/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 25/25\n",
      "139029/139029 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "step_data: {'train_mse': 0.004008850775633631, 'iteration': 48, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.01480772702958448}\n",
      "Env description: Runnig DAgger iteration 48 on env RoboschoolHumanoid-v1\n",
      "mean return 54.50681265802427\n",
      "std of return 15.184829901749737\n",
      "Train on 141071 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "141071/141071 [==============================] - 7s 47us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 2/25\n",
      "141071/141071 [==============================] - 7s 52us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 3/25\n",
      "141071/141071 [==============================] - 6s 46us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 4/25\n",
      "141071/141071 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 5/25\n",
      "141071/141071 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 6/25\n",
      "141071/141071 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 7/25\n",
      "141071/141071 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 8/25\n",
      "141071/141071 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 9/25\n",
      "141071/141071 [==============================] - 6s 44us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 10/25\n",
      "141071/141071 [==============================] - 6s 46us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 11/25\n",
      "141071/141071 [==============================] - 6s 46us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 12/25\n",
      "141071/141071 [==============================] - 6s 45us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 13/25\n",
      "141071/141071 [==============================] - 7s 49us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 14/25\n",
      "141071/141071 [==============================] - 6s 42us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 15/25\n",
      "141071/141071 [==============================] - 6s 43us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 16/25\n",
      "141071/141071 [==============================] - 6s 43us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 17/25\n",
      "141071/141071 [==============================] - 6s 43us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 18/25\n",
      "141071/141071 [==============================] - 6s 43us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 19/25\n",
      "141071/141071 [==============================] - 6s 43us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 20/25\n",
      "141071/141071 [==============================] - 6s 43us/sample - loss: 0.0106 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 21/25\n",
      "141071/141071 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 22/25\n",
      "141071/141071 [==============================] - 6s 44us/sample - loss: 0.0105 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 23/25\n",
      "141071/141071 [==============================] - 6s 45us/sample - loss: 0.0105 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 24/25\n",
      "141071/141071 [==============================] - 6s 44us/sample - loss: 0.0105 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 25/25\n",
      "141071/141071 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0040 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "step_data: {'train_mse': 0.003965531111707154, 'iteration': 49, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.01484405440663232}\n",
      "Env description: Runnig DAgger iteration 49 on env RoboschoolHumanoid-v1\n",
      "mean return 57.12600019445747\n",
      "std of return 16.003542725434357\n",
      "Train on 143209 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "143209/143209 [==============================] - 6s 44us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 2/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 3/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 4/25\n",
      "143209/143209 [==============================] - 7s 46us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 5/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 6/25\n",
      "143209/143209 [==============================] - 6s 44us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 7/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 8/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 9/25\n",
      "143209/143209 [==============================] - 6s 44us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 10/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 11/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 12/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 13/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 14/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 15/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 16/25\n",
      "143209/143209 [==============================] - 6s 44us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 17/25\n",
      "143209/143209 [==============================] - 6s 42us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 19/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 20/25\n",
      "143209/143209 [==============================] - 6s 45us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 21/25\n",
      "143209/143209 [==============================] - 6s 44us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 22/25\n",
      "143209/143209 [==============================] - 6s 44us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 23/25\n",
      "143209/143209 [==============================] - 6s 44us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 24/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Epoch 25/25\n",
      "143209/143209 [==============================] - 6s 43us/sample - loss: 0.0105 - mean_squared_error: 0.0039 - val_loss: 0.0214 - val_mean_squared_error: 0.0149\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_50.hdf5 after update number 50\n",
      "step_data: {'train_mse': 0.003921014247216358, 'iteration': 50, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014881756585328372}\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    dagger.step(k=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to reduce max_timesteps, to learn the beggining of each trajectory before it goes to \"unknown zone\" (it is not really a human expert) and increase k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolHumanoid-v1\n",
      "Domain name: RoboschoolHumanoid-v1\n",
      "(39999, 44) (4445, 44) (39999, 17) (4445, 17)\n",
      "step_data: {'train_mse': 0.012396673013696149, 'iteration': 0, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013617273586400507}\n",
      "Env description: Runnig DAgger iteration 0 on env RoboschoolHumanoid-v1\n",
      "mean return 2.266280763415486\n",
      "std of return 1.6225819861129134\n",
      "Train on 42499 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "42499/42499 [==============================] - 6s 140us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "42499/42499 [==============================] - 7s 161us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "42499/42499 [==============================] - 4s 88us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "42499/42499 [==============================] - 3s 69us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "42499/42499 [==============================] - 4s 88us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "42499/42499 [==============================] - 3s 72us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "42499/42499 [==============================] - 2s 58us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "42499/42499 [==============================] - 2s 57us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "42499/42499 [==============================] - 3s 62us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "42499/42499 [==============================] - 2s 53us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "42499/42499 [==============================] - 2s 54us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "42499/42499 [==============================] - 2s 54us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "42499/42499 [==============================] - 2s 53us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "42499/42499 [==============================] - 2s 57us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "42499/42499 [==============================] - 2s 57us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "42499/42499 [==============================] - 2s 54us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "42499/42499 [==============================] - 2s 55us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "42499/42499 [==============================] - 2s 55us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "42499/42499 [==============================] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.01 - 3s 62us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "42499/42499 [==============================] - 2s 56us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "42499/42499 [==============================] - 2s 52us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "42499/42499 [==============================] - 2s 52us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "42499/42499 [==============================] - 2s 55us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "42499/42499 [==============================] - 2s 56us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "42499/42499 [==============================] - 2s 58us/sample - loss: 0.0195 - mean_squared_error: 0.0117 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.011667117904281786, 'iteration': 1, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013617577755431789}\n",
      "Env description: Runnig DAgger iteration 1 on env RoboschoolHumanoid-v1\n",
      "mean return 2.22908905799895\n",
      "std of return 1.7094785553358451\n",
      "Train on 44999 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "44999/44999 [==============================] - 2s 52us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "44999/44999 [==============================] - 2s 54us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "44999/44999 [==============================] - 2s 54us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "44999/44999 [==============================] - 2s 51us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "44999/44999 [==============================] - 2s 54us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "44999/44999 [==============================] - 2s 54us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "44999/44999 [==============================] - 3s 58us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "44999/44999 [==============================] - 3s 58us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "44999/44999 [==============================] - 2s 54us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "44999/44999 [==============================] - 3s 57us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "44999/44999 [==============================] - 3s 57us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "44999/44999 [==============================] - 2s 54us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "44999/44999 [==============================] - 3s 58us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "44999/44999 [==============================] - 3s 64us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "44999/44999 [==============================] - 3s 57us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "44999/44999 [==============================] - 3s 57us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "44999/44999 [==============================] - 2s 52us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "44999/44999 [==============================] - 2s 53us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44999/44999 [==============================] - 2s 53us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "44999/44999 [==============================] - 2s 52us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "44999/44999 [==============================] - 2s 52us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "44999/44999 [==============================] - 3s 64us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "44999/44999 [==============================] - 2s 55us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "44999/44999 [==============================] - 3s 64us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "44999/44999 [==============================] - 3s 58us/sample - loss: 0.0189 - mean_squared_error: 0.0110 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.011021129816360647, 'iteration': 2, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013618413019778649}\n",
      "Env description: Runnig DAgger iteration 2 on env RoboschoolHumanoid-v1\n",
      "mean return 2.1952634148740233\n",
      "std of return 1.5053650879888405\n",
      "Train on 47499 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "47499/47499 [==============================] - 3s 54us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "47499/47499 [==============================] - 2s 51us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "47499/47499 [==============================] - 3s 57us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "47499/47499 [==============================] - 3s 53us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "47499/47499 [==============================] - 3s 54us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "47499/47499 [==============================] - 3s 54us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "47499/47499 [==============================] - 3s 55us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "47499/47499 [==============================] - 3s 57us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "47499/47499 [==============================] - 3s 54us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "47499/47499 [==============================] - 3s 58us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "47499/47499 [==============================] - 3s 62us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "47499/47499 [==============================] - 3s 56us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "47499/47499 [==============================] - 3s 55us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "47499/47499 [==============================] - 3s 55us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "47499/47499 [==============================] - 3s 54us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "47499/47499 [==============================] - 3s 55us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "47499/47499 [==============================] - 3s 53us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "47499/47499 [==============================] - 3s 54us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "47499/47499 [==============================] - 3s 55us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "47499/47499 [==============================] - 3s 55us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "47499/47499 [==============================] - 3s 55us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "47499/47499 [==============================] - 3s 56us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "47499/47499 [==============================] - 3s 54us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "47499/47499 [==============================] - 3s 54us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "47499/47499 [==============================] - 4s 76us/sample - loss: 0.0183 - mean_squared_error: 0.0104 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.010445503468390122, 'iteration': 3, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013622739735854818}\n",
      "Env description: Runnig DAgger iteration 3 on env RoboschoolHumanoid-v1\n",
      "mean return 2.119533265224649\n",
      "std of return 1.89335755778704\n",
      "Train on 49999 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "49999/49999 [==============================] - 4s 71us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "49999/49999 [==============================] - 4s 77us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "49999/49999 [==============================] - 4s 87us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "49999/49999 [==============================] - 3s 58us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "49999/49999 [==============================] - 3s 62us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "49999/49999 [==============================] - 3s 57us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "49999/49999 [==============================] - 3s 54us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "49999/49999 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "49999/49999 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "49999/49999 [==============================] - 3s 54us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "49999/49999 [==============================] - 3s 54us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "49999/49999 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49999/49999 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "49999/49999 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "49999/49999 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "49999/49999 [==============================] - 3s 55us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "49999/49999 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "49999/49999 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "49999/49999 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "49999/49999 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "49999/49999 [==============================] - 3s 54us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "49999/49999 [==============================] - 3s 54us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "49999/49999 [==============================] - 3s 54us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "49999/49999 [==============================] - 3s 53us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "49999/49999 [==============================] - 3s 55us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.009928985148186574, 'iteration': 4, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013628102684622438}\n",
      "Env description: Runnig DAgger iteration 4 on env RoboschoolHumanoid-v1\n",
      "mean return 2.123647915740954\n",
      "std of return 1.8838172061915381\n",
      "Train on 52499 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "52499/52499 [==============================] - 3s 56us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "52499/52499 [==============================] - 3s 57us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "52499/52499 [==============================] - 3s 58us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "52499/52499 [==============================] - 3s 65us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "52499/52499 [==============================] - 3s 59us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "52499/52499 [==============================] - 3s 61us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "52499/52499 [==============================] - 3s 55us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "52499/52499 [==============================] - 3s 59us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "52499/52499 [==============================] - 3s 57us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "52499/52499 [==============================] - 3s 62us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "52499/52499 [==============================] - 3s 57us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "52499/52499 [==============================] - 3s 63us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "52499/52499 [==============================] - 3s 56us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "52499/52499 [==============================] - 3s 59us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "52499/52499 [==============================] - 3s 57us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "52499/52499 [==============================] - 3s 57us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "52499/52499 [==============================] - 3s 60us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "52499/52499 [==============================] - 3s 57us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "52499/52499 [==============================] - 3s 55us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "52499/52499 [==============================] - 3s 54us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "52499/52499 [==============================] - 3s 58us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "52499/52499 [==============================] - 3s 57us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "52499/52499 [==============================] - 3s 57us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "52499/52499 [==============================] - 3s 56us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "52499/52499 [==============================] - 3s 63us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_5.hdf5 after update number 5\n",
      "step_data: {'train_mse': 0.009463670324746546, 'iteration': 5, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013636896186561527}\n",
      "Print iter 5: k=250, max_timesteps=10\n",
      "Env description: Runnig DAgger iteration 5 on env RoboschoolHumanoid-v1\n",
      "mean return 3.90029305440344\n",
      "std of return 3.0675035888947018\n",
      "Train on 54999 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "54999/54999 [==============================] - 4s 64us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "54999/54999 [==============================] - 3s 56us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "54999/54999 [==============================] - 3s 56us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "54999/54999 [==============================] - 3s 54us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "54999/54999 [==============================] - 3s 54us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "54999/54999 [==============================] - 3s 52us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n",
      "54999/54999 [==============================] - 3s 55us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "54999/54999 [==============================] - 3s 55us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "54999/54999 [==============================] - 3s 53us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 10/25\n",
      "54999/54999 [==============================] - 3s 51us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/25\n",
      "54999/54999 [==============================] - 3s 51us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/25\n",
      "54999/54999 [==============================] - 3s 50us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/25\n",
      "54999/54999 [==============================] - 3s 50us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/25\n",
      "54999/54999 [==============================] - 3s 51us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 15/25\n",
      "54999/54999 [==============================] - 3s 50us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/25\n",
      "54999/54999 [==============================] - 3s 49us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 17/25\n",
      "54999/54999 [==============================] - 3s 51us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 18/25\n",
      "54999/54999 [==============================] - 3s 50us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/25\n",
      "54999/54999 [==============================] - 3s 50us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 20/25\n",
      "54999/54999 [==============================] - 3s 50us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 21/25\n",
      "54999/54999 [==============================] - 3s 50us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 22/25\n",
      "54999/54999 [==============================] - 3s 53us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 23/25\n",
      "54999/54999 [==============================] - 3s 53us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 24/25\n",
      "54999/54999 [==============================] - 3s 57us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 25/25\n",
      "54999/54999 [==============================] - 3s 54us/sample - loss: 0.0168 - mean_squared_error: 0.0090 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.009042140093962793, 'iteration': 6, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013645538755128474}\n",
      "Env description: Runnig DAgger iteration 6 on env RoboschoolHumanoid-v1\n",
      "mean return 3.687139467175893\n",
      "std of return 3.5307515165579324\n",
      "Train on 57499 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "57499/57499 [==============================] - 3s 51us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/25\n",
      "57499/57499 [==============================] - 3s 51us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/25\n",
      "57499/57499 [==============================] - 3s 55us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/25\n",
      "57499/57499 [==============================] - 3s 50us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/25\n",
      "57499/57499 [==============================] - 3s 50us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 6/25\n",
      "57499/57499 [==============================] - 3s 53us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/25\n",
      "57499/57499 [==============================] - 3s 50us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/25\n",
      "57499/57499 [==============================] - 3s 53us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/25\n",
      "57499/57499 [==============================] - 3s 58us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "57499/57499 [==============================] - 3s 55us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "57499/57499 [==============================] - 3s 56us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "57499/57499 [==============================] - 3s 56us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "57499/57499 [==============================] - 3s 51us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "57499/57499 [==============================] - 3s 50us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "57499/57499 [==============================] - 3s 51us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "57499/57499 [==============================] - 3s 52us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "57499/57499 [==============================] - 3s 52us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "57499/57499 [==============================] - 3s 59us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "57499/57499 [==============================] - 3s 52us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "57499/57499 [==============================] - 3s 51us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "57499/57499 [==============================] - 3s 51us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "57499/57499 [==============================] - 3s 51us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "57499/57499 [==============================] - 3s 51us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "57499/57499 [==============================] - 3s 50us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "57499/57499 [==============================] - 3s 50us/sample - loss: 0.0164 - mean_squared_error: 0.0087 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "step_data: {'train_mse': 0.008659037611552312, 'iteration': 7, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013657833293297965}\n",
      "Env description: Runnig DAgger iteration 7 on env RoboschoolHumanoid-v1\n",
      "mean return 3.8971443829307564\n",
      "std of return 2.7648526280257846\n",
      "Train on 59999 samples, validate on 4445 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "59999/59999 [==============================] - 3s 51us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/25\n",
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 6/25\n",
      "59999/59999 [==============================] - 3s 49us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/25\n",
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 8/25\n",
      "59999/59999 [==============================] - 3s 49us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "59999/59999 [==============================] - 3s 51us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "59999/59999 [==============================] - 3s 51us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "59999/59999 [==============================] - 3s 51us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "59999/59999 [==============================] - 3s 51us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "59999/59999 [==============================] - 3s 50us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "59999/59999 [==============================] - 3s 51us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "59999/59999 [==============================] - 3s 51us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "59999/59999 [==============================] - 3s 51us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "59999/59999 [==============================] - 3s 51us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "59999/59999 [==============================] - 3s 51us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "59999/59999 [==============================] - 3s 51us/sample - loss: 0.0161 - mean_squared_error: 0.0083 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "step_data: {'train_mse': 0.008309399487705213, 'iteration': 8, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013671269674463481}\n",
      "Env description: Runnig DAgger iteration 8 on env RoboschoolHumanoid-v1\n",
      "mean return 4.033039545303397\n",
      "std of return 2.367843434763602\n",
      "Train on 62499 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "62499/62499 [==============================] - 3s 51us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "62499/62499 [==============================] - 3s 50us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "62499/62499 [==============================] - 3s 50us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "62499/62499 [==============================] - 3s 51us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/25\n",
      "62499/62499 [==============================] - 3s 50us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 6/25\n",
      "62499/62499 [==============================] - 3s 52us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/25\n",
      "62499/62499 [==============================] - 3s 51us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 8/25\n",
      "62499/62499 [==============================] - 3s 52us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "62499/62499 [==============================] - 3s 52us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "62499/62499 [==============================] - 3s 51us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "62499/62499 [==============================] - 3s 52us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "62499/62499 [==============================] - 3s 51us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "62499/62499 [==============================] - 3s 51us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "62499/62499 [==============================] - 3s 51us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "62499/62499 [==============================] - 3s 50us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "62499/62499 [==============================] - 3s 51us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "62499/62499 [==============================] - 3s 50us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "62499/62499 [==============================] - 3s 51us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "62499/62499 [==============================] - 3s 50us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "62499/62499 [==============================] - 3s 51us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "62499/62499 [==============================] - 3s 53us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62499/62499 [==============================] - 3s 50us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "62499/62499 [==============================] - 3s 49us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "62499/62499 [==============================] - 3s 48us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "62499/62499 [==============================] - 3s 48us/sample - loss: 0.0157 - mean_squared_error: 0.0080 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "step_data: {'train_mse': 0.00798913067755253, 'iteration': 9, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013686958355912082}\n",
      "Env description: Runnig DAgger iteration 9 on env RoboschoolHumanoid-v1\n",
      "mean return 4.202917182341619\n",
      "std of return 2.623229503196047\n",
      "Train on 64999 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "64999/64999 [==============================] - 3s 52us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 6/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 8/25\n",
      "64999/64999 [==============================] - 3s 50us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "64999/64999 [==============================] - 3s 50us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "64999/64999 [==============================] - 3s 48us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "64999/64999 [==============================] - 3s 48us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "64999/64999 [==============================] - 3s 48us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "64999/64999 [==============================] - 3s 48us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "64999/64999 [==============================] - 3s 48us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "64999/64999 [==============================] - 3s 48us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "64999/64999 [==============================] - 3s 49us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "64999/64999 [==============================] - 3s 48us/sample - loss: 0.0154 - mean_squared_error: 0.0077 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_10.hdf5 after update number 10\n",
      "step_data: {'train_mse': 0.007695189427662508, 'iteration': 10, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013705300994728518}\n",
      "Print iter 10: k=125, max_timesteps=20\n",
      "Env description: Runnig DAgger iteration 10 on env RoboschoolHumanoid-v1\n",
      "mean return 9.885748809257219\n",
      "std of return 4.432360553054142\n",
      "Train on 67499 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "67499/67499 [==============================] - 3s 50us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "67499/67499 [==============================] - 3s 49us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "67499/67499 [==============================] - 3s 49us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "67499/67499 [==============================] - 3s 49us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/25\n",
      "67499/67499 [==============================] - 3s 49us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 6/25\n",
      "67499/67499 [==============================] - 3s 49us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/25\n",
      "67499/67499 [==============================] - 4s 57us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 8/25\n",
      "67499/67499 [==============================] - 4s 57us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "67499/67499 [==============================] - 4s 57us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "67499/67499 [==============================] - 4s 60us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "67499/67499 [==============================] - 4s 57us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "67499/67499 [==============================] - 4s 57us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "67499/67499 [==============================] - 4s 55us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "67499/67499 [==============================] - 4s 53us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "67499/67499 [==============================] - 4s 52us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n",
      "67499/67499 [==============================] - 3s 50us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "67499/67499 [==============================] - 3s 49us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "67499/67499 [==============================] - 4s 54us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "67499/67499 [==============================] - 4s 56us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "67499/67499 [==============================] - 3s 52us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "67499/67499 [==============================] - 4s 58us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "67499/67499 [==============================] - 4s 58us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "67499/67499 [==============================] - 4s 59us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "67499/67499 [==============================] - 4s 58us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "67499/67499 [==============================] - 4s 52us/sample - loss: 0.0151 - mean_squared_error: 0.0074 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "step_data: {'train_mse': 0.007424079355129463, 'iteration': 11, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013724202892338314}\n",
      "Env description: Runnig DAgger iteration 11 on env RoboschoolHumanoid-v1\n",
      "mean return 9.303524830934323\n",
      "std of return 5.362734208507044\n",
      "Train on 69999 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "69999/69999 [==============================] - 4s 54us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "69999/69999 [==============================] - 4s 59us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "69999/69999 [==============================] - 4s 53us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "69999/69999 [==============================] - 4s 53us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/25\n",
      "69999/69999 [==============================] - 4s 53us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 6/25\n",
      "69999/69999 [==============================] - 4s 54us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/25\n",
      "69999/69999 [==============================] - 4s 55us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 8/25\n",
      "69999/69999 [==============================] - 4s 54us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/25\n",
      "69999/69999 [==============================] - 4s 53us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 10/25\n",
      "69999/69999 [==============================] - 4s 54us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/25\n",
      "69999/69999 [==============================] - 4s 53us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/25\n",
      "69999/69999 [==============================] - 4s 53us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 13/25\n",
      "69999/69999 [==============================] - 4s 53us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 14/25\n",
      "69999/69999 [==============================] - 4s 54us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/25\n",
      "69999/69999 [==============================] - 4s 55us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 16/25\n",
      "69999/69999 [==============================] - 4s 57us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 17/25\n",
      "69999/69999 [==============================] - 4s 63us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 18/25\n",
      "69999/69999 [==============================] - 5s 66us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 19/25\n",
      "69999/69999 [==============================] - 4s 63us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 20/25\n",
      "69999/69999 [==============================] - 4s 54us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 21/25\n",
      "69999/69999 [==============================] - 4s 54us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 22/25\n",
      "69999/69999 [==============================] - 4s 52us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 23/25\n",
      "69999/69999 [==============================] - 4s 56us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 24/25\n",
      "69999/69999 [==============================] - 4s 57us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 25/25\n",
      "69999/69999 [==============================] - 4s 52us/sample - loss: 0.0148 - mean_squared_error: 0.0072 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "step_data: {'train_mse': 0.007174005082768498, 'iteration': 12, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013746280351550587}\n",
      "Env description: Runnig DAgger iteration 12 on env RoboschoolHumanoid-v1\n",
      "mean return 10.058822708842925\n",
      "std of return 3.950774399215904\n",
      "Train on 72499 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "72499/72499 [==============================] - 4s 51us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 2/25\n",
      "72499/72499 [==============================] - 4s 51us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/25\n",
      "72499/72499 [==============================] - 4s 51us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/25\n",
      "72499/72499 [==============================] - 4s 52us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 5/25\n",
      "72499/72499 [==============================] - 4s 52us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 6/25\n",
      "72499/72499 [==============================] - 4s 52us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 7/25\n",
      "72499/72499 [==============================] - 4s 52us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 8/25\n",
      "72499/72499 [==============================] - 4s 53us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 9/25\n",
      "72499/72499 [==============================] - 4s 52us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72499/72499 [==============================] - 4s 54us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 11/25\n",
      "72499/72499 [==============================] - 4s 52us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 12/25\n",
      "72499/72499 [==============================] - 4s 54us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 13/25\n",
      "72499/72499 [==============================] - 4s 49us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 14/25\n",
      "72499/72499 [==============================] - 4s 49us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 15/25\n",
      "72499/72499 [==============================] - 4s 50us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 16/25\n",
      "72499/72499 [==============================] - 4s 57us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 17/25\n",
      "72499/72499 [==============================] - 4s 54us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 18/25\n",
      "72499/72499 [==============================] - 4s 57us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 19/25\n",
      "72499/72499 [==============================] - 4s 52us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 20/25\n",
      "72499/72499 [==============================] - 4s 50us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 21/25\n",
      "72499/72499 [==============================] - 4s 51us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 22/25\n",
      "72499/72499 [==============================] - 4s 50us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 23/25\n",
      "72499/72499 [==============================] - 4s 50us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 24/25\n",
      "72499/72499 [==============================] - 4s 50us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 25/25\n",
      "72499/72499 [==============================] - 4s 51us/sample - loss: 0.0146 - mean_squared_error: 0.0069 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "step_data: {'train_mse': 0.006941965264464075, 'iteration': 13, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013770505810960502}\n",
      "Env description: Runnig DAgger iteration 13 on env RoboschoolHumanoid-v1\n",
      "mean return 9.292590743245999\n",
      "std of return 5.308089090832705\n",
      "Train on 74998 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "74998/74998 [==============================] - 4s 51us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 2/25\n",
      "74998/74998 [==============================] - 4s 51us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 3/25\n",
      "74998/74998 [==============================] - 4s 50us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 4/25\n",
      "74998/74998 [==============================] - 4s 51us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 5/25\n",
      "74998/74998 [==============================] - 4s 50us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 6/25\n",
      "74998/74998 [==============================] - 4s 50us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 7/25\n",
      "74998/74998 [==============================] - 4s 51us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 8/25\n",
      "74998/74998 [==============================] - 4s 52us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 9/25\n",
      "74998/74998 [==============================] - 4s 53us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 10/25\n",
      "74998/74998 [==============================] - 4s 51us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 11/25\n",
      "74998/74998 [==============================] - 4s 51us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 12/25\n",
      "74998/74998 [==============================] - 4s 50us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 13/25\n",
      "74998/74998 [==============================] - 4s 51us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 14/25\n",
      "74998/74998 [==============================] - 4s 56us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 15/25\n",
      "74998/74998 [==============================] - 4s 50us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 16/25\n",
      "74998/74998 [==============================] - 4s 51us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 17/25\n",
      "74998/74998 [==============================] - 4s 52us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 18/25\n",
      "74998/74998 [==============================] - 5s 61us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 19/25\n",
      "74998/74998 [==============================] - 4s 57us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 20/25\n",
      "74998/74998 [==============================] - 5s 60us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 21/25\n",
      "74998/74998 [==============================] - 4s 52us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 22/25\n",
      "74998/74998 [==============================] - 4s 50us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 23/25\n",
      "74998/74998 [==============================] - 4s 50us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 24/25\n",
      "74998/74998 [==============================] - 4s 51us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 25/25\n",
      "74998/74998 [==============================] - 4s 51us/sample - loss: 0.0143 - mean_squared_error: 0.0067 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "step_data: {'train_mse': 0.006726674742825886, 'iteration': 14, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013795097848300956}\n",
      "Env description: Runnig DAgger iteration 14 on env RoboschoolHumanoid-v1\n",
      "mean return 9.445881406649889\n",
      "std of return 5.072892898524172\n",
      "Train on 77496 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "77496/77496 [==============================] - 4s 52us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 2/25\n",
      "77496/77496 [==============================] - 4s 49us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 3/25\n",
      "77496/77496 [==============================] - 4s 49us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77496/77496 [==============================] - 5s 65us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 5/25\n",
      "77496/77496 [==============================] - 5s 62us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 6/25\n",
      "77496/77496 [==============================] - 4s 57us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 7/25\n",
      "77496/77496 [==============================] - 4s 56us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 8/25\n",
      "77496/77496 [==============================] - 5s 59us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 9/25\n",
      "77496/77496 [==============================] - 4s 52us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 10/25\n",
      "77496/77496 [==============================] - 4s 54us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 11/25\n",
      "77496/77496 [==============================] - 4s 50us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 12/25\n",
      "77496/77496 [==============================] - 4s 49us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 13/25\n",
      "77496/77496 [==============================] - 4s 50us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 14/25\n",
      "77496/77496 [==============================] - 4s 50us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 15/25\n",
      "77496/77496 [==============================] - 4s 52us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 16/25\n",
      "77496/77496 [==============================] - 4s 51us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 17/25\n",
      "77496/77496 [==============================] - 4s 48us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 18/25\n",
      "77496/77496 [==============================] - 4s 51us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 19/25\n",
      "77496/77496 [==============================] - 4s 49us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 20/25\n",
      "77496/77496 [==============================] - 4s 52us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 21/25\n",
      "77496/77496 [==============================] - 4s 55us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 22/25\n",
      "77496/77496 [==============================] - 4s 54us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 23/25\n",
      "77496/77496 [==============================] - 4s 58us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 24/25\n",
      "77496/77496 [==============================] - 4s 56us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 25/25\n",
      "77496/77496 [==============================] - 4s 51us/sample - loss: 0.0141 - mean_squared_error: 0.0065 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_15.hdf5 after update number 15\n",
      "step_data: {'train_mse': 0.006526862619676766, 'iteration': 15, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013822753386924553}\n",
      "Print iter 15: k=62, max_timesteps=40\n",
      "Env description: Runnig DAgger iteration 15 on env RoboschoolHumanoid-v1\n",
      "mean return 37.89167466185968\n",
      "std of return 10.462807157290753\n",
      "Train on 79971 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "79971/79971 [==============================] - 4s 54us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 2/25\n",
      "79971/79971 [==============================] - 4s 53us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 3/25\n",
      "79971/79971 [==============================] - 4s 52us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 4/25\n",
      "79971/79971 [==============================] - 4s 52us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 5/25\n",
      "79971/79971 [==============================] - 4s 53us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 6/25\n",
      "79971/79971 [==============================] - 5s 58us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 7/25\n",
      "79971/79971 [==============================] - 5s 62us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 8/25\n",
      "79971/79971 [==============================] - 5s 57us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 9/25\n",
      "79971/79971 [==============================] - 5s 58us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 10/25\n",
      "79971/79971 [==============================] - 5s 60us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 11/25\n",
      "79971/79971 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.00 - 4s 52us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 12/25\n",
      "79971/79971 [==============================] - 5s 62us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 13/25\n",
      "79971/79971 [==============================] - 4s 55us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 14/25\n",
      "79971/79971 [==============================] - 4s 55us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 15/25\n",
      "79971/79971 [==============================] - 4s 54us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 16/25\n",
      "79971/79971 [==============================] - 4s 52us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 17/25\n",
      "79971/79971 [==============================] - 4s 53us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 18/25\n",
      "79971/79971 [==============================] - 4s 53us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 19/25\n",
      "79971/79971 [==============================] - 4s 53us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 20/25\n",
      "79971/79971 [==============================] - 4s 53us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 21/25\n",
      "79971/79971 [==============================] - 4s 53us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 22/25\n",
      "79971/79971 [==============================] - 4s 53us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 23/25\n",
      "79971/79971 [==============================] - 4s 52us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79971/79971 [==============================] - 4s 53us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0138\n",
      "Epoch 25/25\n",
      "79971/79971 [==============================] - 4s 53us/sample - loss: 0.0139 - mean_squared_error: 0.0063 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "step_data: {'train_mse': 0.0063420805811028585, 'iteration': 16, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013850404031302043}\n",
      "Env description: Runnig DAgger iteration 16 on env RoboschoolHumanoid-v1\n",
      "mean return 37.732217307391366\n",
      "std of return 10.426754898525981\n",
      "Train on 82442 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "82442/82442 [==============================] - 4s 54us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 2/25\n",
      "82442/82442 [==============================] - 4s 53us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 3/25\n",
      "82442/82442 [==============================] - 5s 65us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 4/25\n",
      "82442/82442 [==============================] - 4s 53us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 5/25\n",
      "82442/82442 [==============================] - 4s 54us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 6/25\n",
      "82442/82442 [==============================] - 5s 55us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 7/25\n",
      "82442/82442 [==============================] - 5s 56us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 8/25\n",
      "82442/82442 [==============================] - 5s 63us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 9/25\n",
      "82442/82442 [==============================] - 5s 56us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 10/25\n",
      "82442/82442 [==============================] - 5s 65us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 11/25\n",
      "82442/82442 [==============================] - 5s 65us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 12/25\n",
      "82442/82442 [==============================] - 6s 68us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 13/25\n",
      "82442/82442 [==============================] - 5s 60us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 14/25\n",
      "82442/82442 [==============================] - 4s 53us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 15/25\n",
      "82442/82442 [==============================] - 4s 53us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 16/25\n",
      "82442/82442 [==============================] - 5s 62us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 17/25\n",
      "82442/82442 [==============================] - 5s 57us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 18/25\n",
      "82442/82442 [==============================] - 5s 55us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 19/25\n",
      "82442/82442 [==============================] - 5s 55us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 20/25\n",
      "82442/82442 [==============================] - 4s 53us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 21/25\n",
      "82442/82442 [==============================] - 5s 55us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 22/25\n",
      "82442/82442 [==============================] - 4s 54us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 23/25\n",
      "82442/82442 [==============================] - 5s 60us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 24/25\n",
      "82442/82442 [==============================] - 4s 52us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 25/25\n",
      "82442/82442 [==============================] - 5s 65us/sample - loss: 0.0137 - mean_squared_error: 0.0062 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "step_data: {'train_mse': 0.006169618337134755, 'iteration': 17, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013880737026181604}\n",
      "Env description: Runnig DAgger iteration 17 on env RoboschoolHumanoid-v1\n",
      "mean return 41.40370270548508\n",
      "std of return 5.451394236720816\n",
      "Train on 84922 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "84922/84922 [==============================] - 4s 51us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 2/25\n",
      "84922/84922 [==============================] - 4s 50us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 3/25\n",
      "84922/84922 [==============================] - 4s 53us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 4/25\n",
      "84922/84922 [==============================] - 4s 53us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 5/25\n",
      "84922/84922 [==============================] - 4s 52us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 6/25\n",
      "84922/84922 [==============================] - 5s 56us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 7/25\n",
      "84922/84922 [==============================] - 5s 55us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 8/25\n",
      "84922/84922 [==============================] - 4s 52us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 9/25\n",
      "84922/84922 [==============================] - 5s 55us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 10/25\n",
      "84922/84922 [==============================] - 5s 54us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 11/25\n",
      "84922/84922 [==============================] - 5s 54us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 12/25\n",
      "84922/84922 [==============================] - 5s 53us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 13/25\n",
      "84922/84922 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.00 - 4s 52us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 14/25\n",
      "84922/84922 [==============================] - 5s 57us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 15/25\n",
      "84922/84922 [==============================] - 5s 59us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 16/25\n",
      "84922/84922 [==============================] - 5s 57us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 17/25\n",
      "84922/84922 [==============================] - 5s 57us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84922/84922 [==============================] - 5s 54us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 19/25\n",
      "84922/84922 [==============================] - 5s 55us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 20/25\n",
      "84922/84922 [==============================] - 5s 55us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 21/25\n",
      "84922/84922 [==============================] - 4s 53us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 22/25\n",
      "84922/84922 [==============================] - 4s 49us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 23/25\n",
      "84922/84922 [==============================] - 4s 49us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 24/25\n",
      "84922/84922 [==============================] - 4s 49us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 25/25\n",
      "84922/84922 [==============================] - 4s 49us/sample - loss: 0.0135 - mean_squared_error: 0.0060 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "step_data: {'train_mse': 0.006007834566063003, 'iteration': 18, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013913433808957388}\n",
      "Env description: Runnig DAgger iteration 18 on env RoboschoolHumanoid-v1\n",
      "mean return 35.21118199340743\n",
      "std of return 17.295994853819412\n",
      "Train on 87352 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "87352/87352 [==============================] - 5s 55us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 2/25\n",
      "87352/87352 [==============================] - 5s 55us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 3/25\n",
      "87352/87352 [==============================] - 4s 50us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 4/25\n",
      "87352/87352 [==============================] - 4s 50us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 5/25\n",
      "87352/87352 [==============================] - 4s 50us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 6/25\n",
      "87352/87352 [==============================] - 4s 50us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 7/25\n",
      "87352/87352 [==============================] - 5s 56us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 8/25\n",
      "87352/87352 [==============================] - 4s 51us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 9/25\n",
      "87352/87352 [==============================] - 4s 50us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 10/25\n",
      "87352/87352 [==============================] - 4s 51us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 11/25\n",
      "87352/87352 [==============================] - 4s 51us/sample - loss: 0.0133 - mean_squared_error: 0.0058 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 12/25\n",
      "87352/87352 [==============================] - 5s 54us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 13/25\n",
      "87352/87352 [==============================] - 4s 50us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 14/25\n",
      "87352/87352 [==============================] - 5s 53us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 15/25\n",
      "87352/87352 [==============================] - 5s 57us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 16/25\n",
      "87352/87352 [==============================] - 5s 54us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 17/25\n",
      "87352/87352 [==============================] - 5s 53us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 18/25\n",
      "87352/87352 [==============================] - 5s 55us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 19/25\n",
      "87352/87352 [==============================] - 5s 52us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 20/25\n",
      "87352/87352 [==============================] - 4s 51us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 21/25\n",
      "87352/87352 [==============================] - 5s 55us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 22/25\n",
      "87352/87352 [==============================] - 4s 51us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 23/25\n",
      "87352/87352 [==============================] - 4s 51us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 24/25\n",
      "87352/87352 [==============================] - 4s 51us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 25/25\n",
      "87352/87352 [==============================] - 4s 50us/sample - loss: 0.0133 - mean_squared_error: 0.0059 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "step_data: {'train_mse': 0.0058587307521916696, 'iteration': 19, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013946955330557988}\n",
      "Env description: Runnig DAgger iteration 19 on env RoboschoolHumanoid-v1\n",
      "mean return 37.44576078014739\n",
      "std of return 13.322965995031359\n",
      "Train on 89812 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "89812/89812 [==============================] - 5s 51us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 2/25\n",
      "89812/89812 [==============================] - 5s 51us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0139\n",
      "Epoch 3/25\n",
      "89812/89812 [==============================] - 5s 51us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 4/25\n",
      "89812/89812 [==============================] - 5s 58us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 5/25\n",
      "89812/89812 [==============================] - 5s 51us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 6/25\n",
      "89812/89812 [==============================] - 5s 55us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 7/25\n",
      "89812/89812 [==============================] - 5s 58us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 8/25\n",
      "89812/89812 [==============================] - 5s 54us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 9/25\n",
      "89812/89812 [==============================] - 5s 53us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 10/25\n",
      "89812/89812 [==============================] - 4s 49us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 11/25\n",
      "89812/89812 [==============================] - 4s 49us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89812/89812 [==============================] - 4s 49us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 13/25\n",
      "89812/89812 [==============================] - 4s 49us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 14/25\n",
      "89812/89812 [==============================] - 5s 51us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 15/25\n",
      "89812/89812 [==============================] - 4s 49us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 16/25\n",
      "89812/89812 [==============================] - 4s 49us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 17/25\n",
      "89812/89812 [==============================] - 4s 50us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 18/25\n",
      "89812/89812 [==============================] - 4s 49us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 19/25\n",
      "89812/89812 [==============================] - 5s 52us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 20/25\n",
      "89812/89812 [==============================] - 5s 54us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 21/25\n",
      "89812/89812 [==============================] - 5s 52us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 22/25\n",
      "89812/89812 [==============================] - 5s 52us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 23/25\n",
      "89812/89812 [==============================] - 4s 50us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 24/25\n",
      "89812/89812 [==============================] - 5s 50us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 25/25\n",
      "89812/89812 [==============================] - 5s 51us/sample - loss: 0.0131 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_20.hdf5 after update number 20\n",
      "step_data: {'train_mse': 0.005717036218984881, 'iteration': 20, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013982711713278617}\n",
      "Print iter 20: k=31, max_timesteps=80\n",
      "Env description: Runnig DAgger iteration 20 on env RoboschoolHumanoid-v1\n",
      "mean return 54.63696332596028\n",
      "std of return 9.058384989906024\n",
      "Train on 91356 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "91356/91356 [==============================] - 5s 51us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 2/25\n",
      "91356/91356 [==============================] - 5s 50us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 3/25\n",
      "91356/91356 [==============================] - 6s 66us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 4/25\n",
      "91356/91356 [==============================] - 5s 55us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 5/25\n",
      "91356/91356 [==============================] - 6s 66us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 6/25\n",
      "91356/91356 [==============================] - 5s 58us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 7/25\n",
      "91356/91356 [==============================] - 5s 55us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 8/25\n",
      "91356/91356 [==============================] - 5s 59us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 9/25\n",
      "91356/91356 [==============================] - 5s 54us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 10/25\n",
      "91356/91356 [==============================] - 5s 55us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 11/25\n",
      "91356/91356 [==============================] - 5s 56us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 12/25\n",
      "91356/91356 [==============================] - 5s 54us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 13/25\n",
      "91356/91356 [==============================] - 5s 53us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 14/25\n",
      "91356/91356 [==============================] - 6s 61us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 15/25\n",
      "91356/91356 [==============================] - 5s 60us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 16/25\n",
      "91356/91356 [==============================] - 5s 60us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 17/25\n",
      "91356/91356 [==============================] - 5s 52us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 18/25\n",
      "91356/91356 [==============================] - 5s 53us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 19/25\n",
      "91356/91356 [==============================] - 5s 55us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 20/25\n",
      "91356/91356 [==============================] - 5s 54us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 21/25\n",
      "91356/91356 [==============================] - 5s 53us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 22/25\n",
      "91356/91356 [==============================] - 5s 57us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 23/25\n",
      "91356/91356 [==============================] - 5s 59us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 24/25\n",
      "91356/91356 [==============================] - 6s 66us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 25/25\n",
      "91356/91356 [==============================] - 5s 58us/sample - loss: 0.0130 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "step_data: {'train_mse': 0.005638492012116064, 'iteration': 21, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014014942608958959}\n",
      "Env description: Runnig DAgger iteration 21 on env RoboschoolHumanoid-v1\n",
      "mean return 60.492699857802286\n",
      "std of return 20.736962250460024\n",
      "Train on 92958 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "92958/92958 [==============================] - 5s 53us/sample - loss: 0.0129 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 2/25\n",
      "92958/92958 [==============================] - 5s 53us/sample - loss: 0.0129 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 3/25\n",
      "92958/92958 [==============================] - 5s 52us/sample - loss: 0.0129 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 4/25\n",
      "92958/92958 [==============================] - 5s 53us/sample - loss: 0.0129 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 5/25\n",
      "92958/92958 [==============================] - 5s 51us/sample - loss: 0.0129 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n",
      "92958/92958 [==============================] - 5s 52us/sample - loss: 0.0129 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 7/25\n",
      "92958/92958 [==============================] - 5s 53us/sample - loss: 0.0129 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 8/25\n",
      "92958/92958 [==============================] - 5s 53us/sample - loss: 0.0129 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 9/25\n",
      "92958/92958 [==============================] - 5s 52us/sample - loss: 0.0129 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 10/25\n",
      "92958/92958 [==============================] - 5s 53us/sample - loss: 0.0129 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 11/25\n",
      "92958/92958 [==============================] - 5s 53us/sample - loss: 0.0129 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 12/25\n",
      "92958/92958 [==============================] - 5s 53us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 13/25\n",
      "92958/92958 [==============================] - 5s 53us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 14/25\n",
      "92958/92958 [==============================] - 5s 54us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 15/25\n",
      "92958/92958 [==============================] - 5s 54us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 16/25\n",
      "92958/92958 [==============================] - 5s 53us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 17/25\n",
      "92958/92958 [==============================] - 5s 52us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 18/25\n",
      "92958/92958 [==============================] - 5s 52us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 19/25\n",
      "92958/92958 [==============================] - 5s 52us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 20/25\n",
      "92958/92958 [==============================] - 5s 52us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 21/25\n",
      "92958/92958 [==============================] - 5s 52us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 22/25\n",
      "92958/92958 [==============================] - 5s 52us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 23/25\n",
      "92958/92958 [==============================] - 6s 60us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 24/25\n",
      "92958/92958 [==============================] - 5s 56us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 25/25\n",
      "92958/92958 [==============================] - 5s 55us/sample - loss: 0.0129 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "step_data: {'train_mse': 0.005558615086794068, 'iteration': 22, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014047212262235664}\n",
      "Env description: Runnig DAgger iteration 22 on env RoboschoolHumanoid-v1\n",
      "mean return 54.804157377043246\n",
      "std of return 13.779768619829564\n",
      "Train on 94554 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "94554/94554 [==============================] - 5s 55us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0140\n",
      "Epoch 2/25\n",
      "94554/94554 [==============================] - 6s 58us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 3/25\n",
      "94554/94554 [==============================] - 5s 56us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 4/25\n",
      "94554/94554 [==============================] - 5s 53us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 5/25\n",
      "94554/94554 [==============================] - 5s 52us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 6/25\n",
      "94554/94554 [==============================] - 5s 53us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 7/25\n",
      "94554/94554 [==============================] - 5s 54us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 8/25\n",
      "94554/94554 [==============================] - 5s 53us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 9/25\n",
      "94554/94554 [==============================] - 5s 52us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 10/25\n",
      "94554/94554 [==============================] - 5s 54us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 11/25\n",
      "94554/94554 [==============================] - 5s 53us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 12/25\n",
      "94554/94554 [==============================] - 5s 54us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 13/25\n",
      "94554/94554 [==============================] - 5s 53us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 14/25\n",
      "94554/94554 [==============================] - 5s 55us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 15/25\n",
      "94554/94554 [==============================] - 5s 57us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 16/25\n",
      "94554/94554 [==============================] - 5s 58us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 17/25\n",
      "94554/94554 [==============================] - 5s 58us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 18/25\n",
      "94554/94554 [==============================] - 5s 52us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 19/25\n",
      "94554/94554 [==============================] - 5s 53us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 20/25\n",
      "94554/94554 [==============================] - 5s 52us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 21/25\n",
      "94554/94554 [==============================] - 5s 50us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 22/25\n",
      "94554/94554 [==============================] - 5s 53us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 23/25\n",
      "94554/94554 [==============================] - 5s 54us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 24/25\n",
      "94554/94554 [==============================] - 5s 55us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 25/25\n",
      "94554/94554 [==============================] - 6s 61us/sample - loss: 0.0128 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "step_data: {'train_mse': 0.0054821976902161155, 'iteration': 23, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014081175292399505}\n",
      "Env description: Runnig DAgger iteration 23 on env RoboschoolHumanoid-v1\n",
      "mean return 56.26608535762099\n",
      "std of return 12.386287786669437\n",
      "Train on 96172 samples, validate on 4445 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96172/96172 [==============================] - 5s 54us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 2/25\n",
      "96172/96172 [==============================] - 5s 54us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 3/25\n",
      "96172/96172 [==============================] - 5s 56us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 4/25\n",
      "96172/96172 [==============================] - 5s 56us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 5/25\n",
      "96172/96172 [==============================] - 5s 53us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 6/25\n",
      "96172/96172 [==============================] - 5s 50us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 7/25\n",
      "96172/96172 [==============================] - 5s 49us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 8/25\n",
      "96172/96172 [==============================] - 5s 52us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 9/25\n",
      "96172/96172 [==============================] - 5s 50us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 10/25\n",
      "96172/96172 [==============================] - 5s 50us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 11/25\n",
      "96172/96172 [==============================] - 5s 51us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 12/25\n",
      "96172/96172 [==============================] - 5s 52us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 13/25\n",
      "96172/96172 [==============================] - 5s 54us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 14/25\n",
      "96172/96172 [==============================] - 5s 49us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 15/25\n",
      "96172/96172 [==============================] - 5s 56us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 16/25\n",
      "96172/96172 [==============================] - 5s 52us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 17/25\n",
      "96172/96172 [==============================] - 5s 55us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 18/25\n",
      "96172/96172 [==============================] - 5s 51us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 19/25\n",
      "96172/96172 [==============================] - 5s 52us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 20/25\n",
      "96172/96172 [==============================] - 5s 51us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 21/25\n",
      "96172/96172 [==============================] - 5s 53us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 22/25\n",
      "96172/96172 [==============================] - 5s 52us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 23/25\n",
      "96172/96172 [==============================] - 5s 52us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 24/25\n",
      "96172/96172 [==============================] - 5s 52us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 25/25\n",
      "96172/96172 [==============================] - 5s 52us/sample - loss: 0.0127 - mean_squared_error: 0.0054 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "step_data: {'train_mse': 0.005406817712276009, 'iteration': 24, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014114221306375734}\n",
      "Env description: Runnig DAgger iteration 24 on env RoboschoolHumanoid-v1\n",
      "mean return 50.76725400279411\n",
      "std of return 18.38817888774573\n",
      "Train on 97730 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "97730/97730 [==============================] - 5s 53us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 2/25\n",
      "97730/97730 [==============================] - 5s 52us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 3/25\n",
      "97730/97730 [==============================] - 5s 51us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 4/25\n",
      "97730/97730 [==============================] - 5s 53us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 5/25\n",
      "97730/97730 [==============================] - 5s 53us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 6/25\n",
      "97730/97730 [==============================] - 5s 53us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 7/25\n",
      "97730/97730 [==============================] - 5s 52us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 8/25\n",
      "97730/97730 [==============================] - 5s 50us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 9/25\n",
      "97730/97730 [==============================] - 5s 51us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 10/25\n",
      "97730/97730 [==============================] - 5s 51us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 11/25\n",
      "97730/97730 [==============================] - 5s 49us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 12/25\n",
      "97730/97730 [==============================] - 5s 52us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 13/25\n",
      "97730/97730 [==============================] - 6s 59us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 14/25\n",
      "97730/97730 [==============================] - 6s 64us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 15/25\n",
      "97730/97730 [==============================] - 5s 54us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 16/25\n",
      "97730/97730 [==============================] - 5s 53us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 17/25\n",
      "97730/97730 [==============================] - 5s 52us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 18/25\n",
      "97730/97730 [==============================] - 5s 52us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 19/25\n",
      "97730/97730 [==============================] - 5s 52us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 20/25\n",
      "97730/97730 [==============================] - 5s 53us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 21/25\n",
      "97730/97730 [==============================] - 5s 51us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97730/97730 [==============================] - 5s 52us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 23/25\n",
      "97730/97730 [==============================] - 5s 52us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 24/25\n",
      "97730/97730 [==============================] - 5s 52us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 25/25\n",
      "97730/97730 [==============================] - 5s 52us/sample - loss: 0.0126 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_25.hdf5 after update number 25\n",
      "step_data: {'train_mse': 0.005337048582474885, 'iteration': 25, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014147024779045444}\n",
      "Print iter 25: k=15, max_timesteps=160\n",
      "Env description: Runnig DAgger iteration 25 on env RoboschoolHumanoid-v1\n",
      "mean return 48.971828909391185\n",
      "std of return 19.561667587753274\n",
      "Train on 98458 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "98458/98458 [==============================] - 5s 51us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0141\n",
      "Epoch 2/25\n",
      "98458/98458 [==============================] - 5s 55us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 3/25\n",
      "98458/98458 [==============================] - 5s 55us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 4/25\n",
      "98458/98458 [==============================] - 6s 57us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 5/25\n",
      "98458/98458 [==============================] - 6s 61us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 6/25\n",
      "98458/98458 [==============================] - 6s 56us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 7/25\n",
      "98458/98458 [==============================] - 6s 57us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 8/25\n",
      "98458/98458 [==============================] - 5s 52us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 9/25\n",
      "98458/98458 [==============================] - 5s 52us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 10/25\n",
      "98458/98458 [==============================] - 6s 62us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 11/25\n",
      "98458/98458 [==============================] - 6s 62us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 12/25\n",
      "98458/98458 [==============================] - 5s 50us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 13/25\n",
      "98458/98458 [==============================] - 5s 49us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 14/25\n",
      "98458/98458 [==============================] - 5s 49us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 15/25\n",
      "98458/98458 [==============================] - 5s 49us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 16/25\n",
      "98458/98458 [==============================] - 5s 50us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 17/25\n",
      "98458/98458 [==============================] - 5s 54us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 18/25\n",
      "98458/98458 [==============================] - 5s 50us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 19/25\n",
      "98458/98458 [==============================] - 5s 51us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 20/25\n",
      "98458/98458 [==============================] - 6s 56us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 21/25\n",
      "98458/98458 [==============================] - 5s 52us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 22/25\n",
      "98458/98458 [==============================] - 5s 49us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 23/25\n",
      "98458/98458 [==============================] - 5s 49us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 24/25\n",
      "98458/98458 [==============================] - 5s 48us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 25/25\n",
      "98458/98458 [==============================] - 5s 49us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "step_data: {'train_mse': 0.00531322014528701, 'iteration': 26, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014179525682852976}\n",
      "Env description: Runnig DAgger iteration 26 on env RoboschoolHumanoid-v1\n",
      "mean return 56.70768972820894\n",
      "std of return 7.020947675424642\n",
      "Train on 99244 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "99244/99244 [==============================] - 5s 50us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 2/25\n",
      "99244/99244 [==============================] - 5s 50us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 3/25\n",
      "99244/99244 [==============================] - 5s 49us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 4/25\n",
      "99244/99244 [==============================] - 5s 55us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 5/25\n",
      "99244/99244 [==============================] - 5s 52us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 6/25\n",
      "99244/99244 [==============================] - 5s 51us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 7/25\n",
      "99244/99244 [==============================] - 5s 50us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 8/25\n",
      "99244/99244 [==============================] - 6s 59us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 9/25\n",
      "99244/99244 [==============================] - 5s 55us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 10/25\n",
      "99244/99244 [==============================] - 5s 52us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 11/25\n",
      "99244/99244 [==============================] - 5s 53us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 12/25\n",
      "99244/99244 [==============================] - 6s 63us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 13/25\n",
      "99244/99244 [==============================] - 5s 53us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 14/25\n",
      "99244/99244 [==============================] - 5s 53us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 15/25\n",
      "99244/99244 [==============================] - 5s 53us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n",
      "99244/99244 [==============================] - 5s 54us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 17/25\n",
      "99244/99244 [==============================] - 5s 52us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 18/25\n",
      "99244/99244 [==============================] - 5s 53us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 19/25\n",
      "99244/99244 [==============================] - 5s 52us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 20/25\n",
      "99244/99244 [==============================] - 5s 52us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 21/25\n",
      "99244/99244 [==============================] - 5s 50us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 22/25\n",
      "99244/99244 [==============================] - 6s 59us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 23/25\n",
      "99244/99244 [==============================] - 5s 54us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 24/25\n",
      "99244/99244 [==============================] - 5s 55us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 25/25\n",
      "99244/99244 [==============================] - 5s 52us/sample - loss: 0.0125 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "step_data: {'train_mse': 0.005286215542830388, 'iteration': 27, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014209796247152106}\n",
      "Env description: Runnig DAgger iteration 27 on env RoboschoolHumanoid-v1\n",
      "mean return 50.023636172367745\n",
      "std of return 16.47638866494938\n",
      "Train on 99996 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "99996/99996 [==============================] - 6s 55us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 2/25\n",
      "99996/99996 [==============================] - 5s 51us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 3/25\n",
      "99996/99996 [==============================] - 5s 50us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 4/25\n",
      "99996/99996 [==============================] - 6s 56us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 5/25\n",
      "99996/99996 [==============================] - 5s 53us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 6/25\n",
      "99996/99996 [==============================] - 5s 51us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 7/25\n",
      "99996/99996 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.00 - 5s 52us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 8/25\n",
      "99996/99996 [==============================] - 6s 57us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 9/25\n",
      "99996/99996 [==============================] - 6s 59us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 10/25\n",
      "99996/99996 [==============================] - 6s 56us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 11/25\n",
      "99996/99996 [==============================] - 6s 56us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 12/25\n",
      "99996/99996 [==============================] - 6s 58us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 13/25\n",
      "99996/99996 [==============================] - 5s 55us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 14/25\n",
      "99996/99996 [==============================] - 5s 53us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 15/25\n",
      "99996/99996 [==============================] - 5s 52us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 16/25\n",
      "99996/99996 [==============================] - 6s 57us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 17/25\n",
      "99996/99996 [==============================] - 5s 52us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 18/25\n",
      "99996/99996 [==============================] - 5s 53us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 19/25\n",
      "99996/99996 [==============================] - 5s 52us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 20/25\n",
      "99996/99996 [==============================] - 5s 52us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 21/25\n",
      "99996/99996 [==============================] - 5s 54us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 22/25\n",
      "99996/99996 [==============================] - 5s 53us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 23/25\n",
      "99996/99996 [==============================] - 6s 57us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 24/25\n",
      "99996/99996 [==============================] - 5s 53us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 25/25\n",
      "99996/99996 [==============================] - 6s 56us/sample - loss: 0.0124 - mean_squared_error: 0.0053 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "step_data: {'train_mse': 0.005260974696783462, 'iteration': 28, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014238644324899003}\n",
      "Env description: Runnig DAgger iteration 28 on env RoboschoolHumanoid-v1\n",
      "mean return 63.10546502103853\n",
      "std of return 9.044421438925713\n",
      "Train on 100817 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "100817/100817 [==============================] - 6s 57us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 2/25\n",
      "100817/100817 [==============================] - 5s 51us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 3/25\n",
      "100817/100817 [==============================] - 5s 53us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 4/25\n",
      "100817/100817 [==============================] - 5s 54us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 5/25\n",
      "100817/100817 [==============================] - 5s 53us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 6/25\n",
      "100817/100817 [==============================] - 6s 55us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 7/25\n",
      "100817/100817 [==============================] - 6s 57us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 8/25\n",
      "100817/100817 [==============================] - 5s 54us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0142\n",
      "Epoch 9/25\n",
      "100817/100817 [==============================] - 5s 52us/sample - loss: 0.0124 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100817/100817 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 11/25\n",
      "100817/100817 [==============================] - 5s 52us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 12/25\n",
      "100817/100817 [==============================] - 5s 54us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 13/25\n",
      "100817/100817 [==============================] - 6s 56us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 14/25\n",
      "100817/100817 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 15/25\n",
      "100817/100817 [==============================] - 6s 55us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 16/25\n",
      "100817/100817 [==============================] - 6s 61us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 17/25\n",
      "100817/100817 [==============================] - 5s 54us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 18/25\n",
      "100817/100817 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 19/25\n",
      "100817/100817 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 20/25\n",
      "100817/100817 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 21/25\n",
      "100817/100817 [==============================] - 5s 50us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 22/25\n",
      "100817/100817 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 23/25\n",
      "100817/100817 [==============================] - 5s 50us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 24/25\n",
      "100817/100817 [==============================] - 5s 50us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 25/25\n",
      "100817/100817 [==============================] - 5s 50us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "step_data: {'train_mse': 0.005232108131694819, 'iteration': 29, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014269360336751719}\n",
      "Env description: Runnig DAgger iteration 29 on env RoboschoolHumanoid-v1\n",
      "mean return 51.169934055861766\n",
      "std of return 7.193458020605226\n",
      "Train on 101579 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "101579/101579 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 2/25\n",
      "101579/101579 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 3/25\n",
      "101579/101579 [==============================] - 5s 52us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 4/25\n",
      "101579/101579 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 5/25\n",
      "101579/101579 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 6/25\n",
      "101579/101579 [==============================] - 5s 50us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 7/25\n",
      "101579/101579 [==============================] - 5s 52us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 8/25\n",
      "101579/101579 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 9/25\n",
      "101579/101579 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 10/25\n",
      "101579/101579 [==============================] - 5s 52us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 11/25\n",
      "101579/101579 [==============================] - 5s 50us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 12/25\n",
      "101579/101579 [==============================] - 6s 62us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 13/25\n",
      "101579/101579 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 14/25\n",
      "101579/101579 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 15/25\n",
      "101579/101579 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 16/25\n",
      "101579/101579 [==============================] - 6s 55us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 17/25\n",
      "101579/101579 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 18/25\n",
      "101579/101579 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 19/25\n",
      "101579/101579 [==============================] - 5s 50us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 20/25\n",
      "101579/101579 [==============================] - 5s 50us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 21/25\n",
      "101579/101579 [==============================] - 6s 54us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 22/25\n",
      "101579/101579 [==============================] - 5s 50us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 23/25\n",
      "101579/101579 [==============================] - 6s 57us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 24/25\n",
      "101579/101579 [==============================] - 6s 57us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 25/25\n",
      "101579/101579 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_30.hdf5 after update number 30\n",
      "step_data: {'train_mse': 0.005205577050963284, 'iteration': 30, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014294996552013078}\n",
      "Print iter 30: k=7, max_timesteps=320\n",
      "Env description: Runnig DAgger iteration 30 on env RoboschoolHumanoid-v1\n",
      "mean return 65.16473890272941\n",
      "std of return 10.092454459582742\n",
      "Train on 101996 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "101996/101996 [==============================] - 5s 52us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 2/25\n",
      "101996/101996 [==============================] - 6s 55us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101996/101996 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 4/25\n",
      "101996/101996 [==============================] - 5s 52us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 5/25\n",
      "101996/101996 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 6/25\n",
      "101996/101996 [==============================] - 6s 54us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 7/25\n",
      "101996/101996 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 8/25\n",
      "101996/101996 [==============================] - 5s 52us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 9/25\n",
      "101996/101996 [==============================] - 5s 54us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 10/25\n",
      "101996/101996 [==============================] - 6s 54us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 11/25\n",
      "101996/101996 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 12/25\n",
      "101996/101996 [==============================] - 5s 53us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 13/25\n",
      "101996/101996 [==============================] - 5s 52us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 14/25\n",
      "101996/101996 [==============================] - 5s 54us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 15/25\n",
      "101996/101996 [==============================] - 6s 54us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 16/25\n",
      "101996/101996 [==============================] - 5s 52us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 17/25\n",
      "101996/101996 [==============================] - 5s 50us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 18/25\n",
      "101996/101996 [==============================] - 5s 52us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 19/25\n",
      "101996/101996 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 20/25\n",
      "101996/101996 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 21/25\n",
      "101996/101996 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 22/25\n",
      "101996/101996 [==============================] - 5s 51us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 23/25\n",
      "101996/101996 [==============================] - 5s 49us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 24/25\n",
      "101996/101996 [==============================] - 5s 52us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 25/25\n",
      "101996/101996 [==============================] - 6s 54us/sample - loss: 0.0123 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "step_data: {'train_mse': 0.0051971748553488175, 'iteration': 31, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014321366560787753}\n",
      "Env description: Runnig DAgger iteration 31 on env RoboschoolHumanoid-v1\n",
      "mean return 60.28214153831545\n",
      "std of return 11.18036597687736\n",
      "Train on 102373 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "102373/102373 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 2/25\n",
      "102373/102373 [==============================] - 5s 50us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 3/25\n",
      "102373/102373 [==============================] - 5s 51us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 4/25\n",
      "102373/102373 [==============================] - 5s 50us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 5/25\n",
      "102373/102373 [==============================] - 5s 50us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 6/25\n",
      "102373/102373 [==============================] - 7s 64us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 7/25\n",
      "102373/102373 [==============================] - 5s 50us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 8/25\n",
      "102373/102373 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 9/25\n",
      "102373/102373 [==============================] - 6s 55us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 10/25\n",
      "102373/102373 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 11/25\n",
      "102373/102373 [==============================] - 6s 54us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 12/25\n",
      "102373/102373 [==============================] - 6s 63us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 13/25\n",
      "102373/102373 [==============================] - 5s 49us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 14/25\n",
      "102373/102373 [==============================] - 5s 50us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 15/25\n",
      "102373/102373 [==============================] - 6s 58us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 16/25\n",
      "102373/102373 [==============================] - 6s 54us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 17/25\n",
      "102373/102373 [==============================] - 7s 66us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 18/25\n",
      "102373/102373 [==============================] - 5s 51us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 19/25\n",
      "102373/102373 [==============================] - 5s 49us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 20/25\n",
      "102373/102373 [==============================] - 5s 50us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 21/25\n",
      "102373/102373 [==============================] - 6s 56us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 22/25\n",
      "102373/102373 [==============================] - 6s 54us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 23/25\n",
      "102373/102373 [==============================] - 7s 65us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n",
      "102373/102373 [==============================] - 9s 84us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 25/25\n",
      "102373/102373 [==============================] - 6s 60us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "step_data: {'train_mse': 0.005189830898175759, 'iteration': 32, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014347302688754377}\n",
      "Env description: Runnig DAgger iteration 32 on env RoboschoolHumanoid-v1\n",
      "mean return 52.61098774062786\n",
      "std of return 27.65655687489633\n",
      "Train on 102730 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "102730/102730 [==============================] - 5s 49us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 2/25\n",
      "102730/102730 [==============================] - 5s 48us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0143\n",
      "Epoch 3/25\n",
      "102730/102730 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 4/25\n",
      "102730/102730 [==============================] - 6s 56us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/25\n",
      "102730/102730 [==============================] - 6s 61us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 6/25\n",
      "102730/102730 [==============================] - 6s 59us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 7/25\n",
      "102730/102730 [==============================] - 6s 54us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 8/25\n",
      "102730/102730 [==============================] - 5s 53us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 9/25\n",
      "102730/102730 [==============================] - 6s 55us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 10/25\n",
      "102730/102730 [==============================] - 6s 54us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 11/25\n",
      "102730/102730 [==============================] - 5s 51us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 12/25\n",
      "102730/102730 [==============================] - 5s 50us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 13/25\n",
      "102730/102730 [==============================] - 5s 48us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 14/25\n",
      "102730/102730 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 15/25\n",
      "102730/102730 [==============================] - 5s 49us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 16/25\n",
      "102730/102730 [==============================] - 5s 49us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 17/25\n",
      "102730/102730 [==============================] - 6s 63us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 18/25\n",
      "102730/102730 [==============================] - 6s 56us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 19/25\n",
      "102730/102730 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 20/25\n",
      "102730/102730 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 21/25\n",
      "102730/102730 [==============================] - 5s 51us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 22/25\n",
      "102730/102730 [==============================] - 5s 50us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 23/25\n",
      "102730/102730 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 24/25\n",
      "102730/102730 [==============================] - 6s 54us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 25/25\n",
      "102730/102730 [==============================] - 7s 63us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "step_data: {'train_mse': 0.005182961830392533, 'iteration': 33, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014369666875180558}\n",
      "Env description: Runnig DAgger iteration 33 on env RoboschoolHumanoid-v1\n",
      "mean return 58.71411513695368\n",
      "std of return 10.403744241804285\n",
      "Train on 103087 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "103087/103087 [==============================] - 5s 50us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 2/25\n",
      "103087/103087 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 3/25\n",
      "103087/103087 [==============================] - 6s 54us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 4/25\n",
      "103087/103087 [==============================] - 6s 56us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/25\n",
      "103087/103087 [==============================] - 6s 57us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 6/25\n",
      "103087/103087 [==============================] - 6s 55us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 7/25\n",
      "103087/103087 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 8/25\n",
      "103087/103087 [==============================] - 6s 54us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 9/25\n",
      "103087/103087 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 10/25\n",
      "103087/103087 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 11/25\n",
      "103087/103087 [==============================] - 5s 53us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 12/25\n",
      "103087/103087 [==============================] - 5s 51us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 13/25\n",
      "103087/103087 [==============================] - 6s 56us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 14/25\n",
      "103087/103087 [==============================] - 6s 59us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 15/25\n",
      "103087/103087 [==============================] - 5s 50us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 16/25\n",
      "103087/103087 [==============================] - 5s 49us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 17/25\n",
      "103087/103087 [==============================] - 5s 51us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n",
      "103087/103087 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 19/25\n",
      "103087/103087 [==============================] - 5s 51us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 20/25\n",
      "103087/103087 [==============================] - 5s 49us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 21/25\n",
      "103087/103087 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 22/25\n",
      "103087/103087 [==============================] - 5s 49us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 23/25\n",
      "103087/103087 [==============================] - 5s 52us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 24/25\n",
      "103087/103087 [==============================] - 5s 53us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 25/25\n",
      "103087/103087 [==============================] - 6s 58us/sample - loss: 0.0122 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "step_data: {'train_mse': 0.005175989091015805, 'iteration': 34, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014393191343167308}\n",
      "Env description: Runnig DAgger iteration 34 on env RoboschoolHumanoid-v1\n",
      "mean return 47.99815446933187\n",
      "std of return 14.614411976079674\n",
      "Train on 103434 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "103434/103434 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 2/25\n",
      "103434/103434 [==============================] - 5s 47us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 3/25\n",
      "103434/103434 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 4/25\n",
      "103434/103434 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/25\n",
      "103434/103434 [==============================] - 6s 55us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 6/25\n",
      "103434/103434 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 7/25\n",
      "103434/103434 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 8/25\n",
      "103434/103434 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 9/25\n",
      "103434/103434 [==============================] - 6s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 10/25\n",
      "103434/103434 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 11/25\n",
      "103434/103434 [==============================] - 6s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 12/25\n",
      "103434/103434 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 13/25\n",
      "103434/103434 [==============================] - 5s 49us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 14/25\n",
      "103434/103434 [==============================] - 8s 81us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 15/25\n",
      "103434/103434 [==============================] - 12s 116us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 16/25\n",
      "103434/103434 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 17/25\n",
      "103434/103434 [==============================] - 6s 56us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 18/25\n",
      "103434/103434 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 19/25\n",
      "103434/103434 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 20/25\n",
      "103434/103434 [==============================] - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 21/25\n",
      "103434/103434 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 22/25\n",
      "103434/103434 [==============================] - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 23/25\n",
      "103434/103434 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 24/25\n",
      "103434/103434 [==============================] - 5s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 25/25\n",
      "103434/103434 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_35.hdf5 after update number 35\n",
      "step_data: {'train_mse': 0.005169253615618006, 'iteration': 35, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014415231860381676}\n",
      "Print iter 35: k=3, max_timesteps=640\n",
      "Env description: Runnig DAgger iteration 35 on env RoboschoolHumanoid-v1\n",
      "mean return 66.9659465415374\n",
      "std of return 7.371084279427893\n",
      "Train on 103608 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "103608/103608 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 2/25\n",
      "103608/103608 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 3/25\n",
      "103608/103608 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 4/25\n",
      "103608/103608 [==============================] - 6s 57us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/25\n",
      "103608/103608 [==============================] - 6s 56us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 6/25\n",
      "103608/103608 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 7/25\n",
      "103608/103608 [==============================] - 6s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 8/25\n",
      "103608/103608 [==============================] - 7s 68us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 9/25\n",
      "103608/103608 [==============================] - 6s 56us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 10/25\n",
      "103608/103608 [==============================] - 6s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103608/103608 [==============================] - 6s 55us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 12/25\n",
      "103608/103608 [==============================] - 6s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 13/25\n",
      "103608/103608 [==============================] - 6s 55us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 14/25\n",
      "103608/103608 [==============================] - 6s 57us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 15/25\n",
      "103608/103608 [==============================] - 6s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 16/25\n",
      "103608/103608 [==============================] - 6s 60us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 17/25\n",
      "103608/103608 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 18/25\n",
      "103608/103608 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 19/25\n",
      "103608/103608 [==============================] - 6s 55us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 20/25\n",
      "103608/103608 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.00 - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 21/25\n",
      "103608/103608 [==============================] - 6s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 22/25\n",
      "103608/103608 [==============================] - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 23/25\n",
      "103608/103608 [==============================] - 6s 55us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 24/25\n",
      "103608/103608 [==============================] - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 25/25\n",
      "103608/103608 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "step_data: {'train_mse': 0.005170399560938445, 'iteration': 36, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014435931079872108}\n",
      "Env description: Runnig DAgger iteration 36 on env RoboschoolHumanoid-v1\n",
      "mean return 59.339318643150904\n",
      "std of return 1.2468347276442202\n",
      "Train on 103759 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "103759/103759 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 2/25\n",
      "103759/103759 [==============================] - 6s 55us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 3/25\n",
      "103759/103759 [==============================] - 5s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 4/25\n",
      "103759/103759 [==============================] - 6s 57us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/25\n",
      "103759/103759 [==============================] - 6s 58us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 6/25\n",
      "103759/103759 [==============================] - 6s 56us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 7/25\n",
      "103759/103759 [==============================] - 6s 57us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 8/25\n",
      "103759/103759 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 9/25\n",
      "103759/103759 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 10/25\n",
      "103759/103759 [==============================] - 5s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 11/25\n",
      "103759/103759 [==============================] - 6s 56us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 12/25\n",
      "103759/103759 [==============================] - 6s 55us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 13/25\n",
      "103759/103759 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 14/25\n",
      "103759/103759 [==============================] - 6s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 15/25\n",
      "103759/103759 [==============================] - 6s 55us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 16/25\n",
      "103759/103759 [==============================] - 5s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 17/25\n",
      "103759/103759 [==============================] - 6s 55us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 18/25\n",
      "103759/103759 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0144\n",
      "Epoch 19/25\n",
      "103759/103759 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 20/25\n",
      "103759/103759 [==============================] - 5s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 21/25\n",
      "103759/103759 [==============================] - 6s 58us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 22/25\n",
      "103759/103759 [==============================] - 6s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 23/25\n",
      "103759/103759 [==============================] - 5s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 24/25\n",
      "103759/103759 [==============================] - 6s 55us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 25/25\n",
      "103759/103759 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "step_data: {'train_mse': 0.005172059642605084, 'iteration': 37, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.01445730250643437}\n",
      "Env description: Runnig DAgger iteration 37 on env RoboschoolHumanoid-v1\n",
      "mean return 59.71658607007702\n",
      "std of return 0.8742363003666627\n",
      "Train on 103926 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "103926/103926 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 2/25\n",
      "103926/103926 [==============================] - 6s 57us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 3/25\n",
      "103926/103926 [==============================] - 5s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 4/25\n",
      "103926/103926 [==============================] - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n",
      "103926/103926 [==============================] - 6s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 6/25\n",
      "103926/103926 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 7/25\n",
      "103926/103926 [==============================] - 5s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 8/25\n",
      "103926/103926 [==============================] - 5s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 9/25\n",
      "103926/103926 [==============================] - 6s 56us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 10/25\n",
      "103926/103926 [==============================] - 6s 59us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/25\n",
      "103926/103926 [==============================] - 8s 81us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 12/25\n",
      "103926/103926 [==============================] - 6s 61us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 13/25\n",
      "103926/103926 [==============================] - 6s 58us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 14/25\n",
      "103926/103926 [==============================] - 6s 56us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 15/25\n",
      "103926/103926 [==============================] - 6s 60us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 16/25\n",
      "103926/103926 [==============================] - 6s 57us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 17/25\n",
      "103926/103926 [==============================] - 6s 56us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 18/25\n",
      "103926/103926 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 19/25\n",
      "103926/103926 [==============================] - 6s 56us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 20/25\n",
      "103926/103926 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 21/25\n",
      "103926/103926 [==============================] - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 22/25\n",
      "103926/103926 [==============================] - 8s 79us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 23/25\n",
      "103926/103926 [==============================] - 6s 59us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 24/25\n",
      "103926/103926 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 25/25\n",
      "103926/103926 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "step_data: {'train_mse': 0.005172735420946669, 'iteration': 38, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014475165921857689}\n",
      "Env description: Runnig DAgger iteration 38 on env RoboschoolHumanoid-v1\n",
      "mean return 53.39990443555629\n",
      "std of return 30.034401386478777\n",
      "Train on 104097 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "104097/104097 [==============================] - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 2/25\n",
      "104097/104097 [==============================] - 5s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 3/25\n",
      "104097/104097 [==============================] - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 4/25\n",
      "104097/104097 [==============================] - 6s 53us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 5/25\n",
      "104097/104097 [==============================] - 6s 58us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 6/25\n",
      "104097/104097 [==============================] - 6s 59us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 7/25\n",
      "104097/104097 [==============================] - 6s 57us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 8/25\n",
      "104097/104097 [==============================] - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 9/25\n",
      "104097/104097 [==============================] - 5s 51us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 10/25\n",
      "104097/104097 [==============================] - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/25\n",
      "104097/104097 [==============================] - 5s 52us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 12/25\n",
      "104097/104097 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 13/25\n",
      "104097/104097 [==============================] - 6s 58us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 14/25\n",
      "104097/104097 [==============================] - 6s 54us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 15/25\n",
      "104097/104097 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 16/25\n",
      "104097/104097 [==============================] - 5s 49us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 17/25\n",
      "104097/104097 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 18/25\n",
      "104097/104097 [==============================] - 5s 49us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 19/25\n",
      "104097/104097 [==============================] - 5s 48us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 20/25\n",
      "104097/104097 [==============================] - 5s 50us/sample - loss: 0.0121 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 21/25\n",
      "104097/104097 [==============================] - 5s 49us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 22/25\n",
      "104097/104097 [==============================] - 5s 48us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 23/25\n",
      "104097/104097 [==============================] - 5s 52us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 24/25\n",
      "104097/104097 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 25/25\n",
      "104097/104097 [==============================] - 6s 54us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_data: {'train_mse': 0.005172794789173263, 'iteration': 39, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014492904149118115}\n",
      "Env description: Runnig DAgger iteration 39 on env RoboschoolHumanoid-v1\n",
      "mean return 59.62017213723252\n",
      "std of return 10.052076228759622\n",
      "Train on 104258 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "104258/104258 [==============================] - 6s 56us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 2/25\n",
      "104258/104258 [==============================] - 6s 61us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 3/25\n",
      "104258/104258 [==============================] - 5s 53us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 4/25\n",
      "104258/104258 [==============================] - 5s 53us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 5/25\n",
      "104258/104258 [==============================] - 6s 54us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 6/25\n",
      "104258/104258 [==============================] - 6s 55us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 7/25\n",
      "104258/104258 [==============================] - 6s 53us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 8/25\n",
      "104258/104258 [==============================] - 5s 50us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 9/25\n",
      "104258/104258 [==============================] - 5s 50us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 10/25\n",
      "104258/104258 [==============================] - 5s 52us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/25\n",
      "104258/104258 [==============================] - 6s 61us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 12/25\n",
      "104258/104258 [==============================] - 7s 68us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 13/25\n",
      "104258/104258 [==============================] - 6s 60us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 14/25\n",
      "104258/104258 [==============================] - 6s 56us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 15/25\n",
      "104258/104258 [==============================] - 6s 53us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 16/25\n",
      "104258/104258 [==============================] - 5s 52us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 17/25\n",
      "104258/104258 [==============================] - 5s 49us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 18/25\n",
      "104258/104258 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 19/25\n",
      "104258/104258 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 20/25\n",
      "104258/104258 [==============================] - 5s 49us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 21/25\n",
      "104258/104258 [==============================] - 5s 52us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 22/25\n",
      "104258/104258 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 23/25\n",
      "104258/104258 [==============================] - 5s 49us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 24/25\n",
      "104258/104258 [==============================] - 5s 50us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 25/25\n",
      "104258/104258 [==============================] - 5s 50us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_40.hdf5 after update number 40\n",
      "step_data: {'train_mse': 0.005172825475005465, 'iteration': 40, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014510525529444452}\n",
      "Print iter 40: k=1, max_timesteps=1280\n",
      "Env description: Runnig DAgger iteration 40 on env RoboschoolHumanoid-v1\n",
      "mean return 49.51315271245984\n",
      "std of return 0.0\n",
      "Train on 104301 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "104301/104301 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 2/25\n",
      "104301/104301 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 3/25\n",
      "104301/104301 [==============================] - 5s 52us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 4/25\n",
      "104301/104301 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 5/25\n",
      "104301/104301 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 6/25\n",
      "104301/104301 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 7/25\n",
      "104301/104301 [==============================] - 5s 50us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 8/25\n",
      "104301/104301 [==============================] - 5s 50us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 9/25\n",
      "104301/104301 [==============================] - 5s 50us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 10/25\n",
      "104301/104301 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/25\n",
      "104301/104301 [==============================] - 5s 50us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 12/25\n",
      "104301/104301 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 13/25\n",
      "104301/104301 [==============================] - 6s 54us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 14/25\n",
      "104301/104301 [==============================] - 5s 50us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 15/25\n",
      "104301/104301 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 16/25\n",
      "104301/104301 [==============================] - 5s 52us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 17/25\n",
      "104301/104301 [==============================] - 5s 50us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 18/25\n",
      "104301/104301 [==============================] - 5s 52us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104301/104301 [==============================] - 5s 51us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 20/25\n",
      "104301/104301 [==============================] - 5s 49us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 21/25\n",
      "104301/104301 [==============================] - 5s 49us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 22/25\n",
      "104301/104301 [==============================] - 53s 505us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 23/25\n",
      "104301/104301 [==============================] - 7s 63us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 24/25\n",
      "104301/104301 [==============================] - 53s 504us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 25/25\n",
      "104301/104301 [==============================] - 6s 56us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "step_data: {'train_mse': 0.005178428163748159, 'iteration': 41, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014526486770467688}\n",
      "Env description: Runnig DAgger iteration 41 on env RoboschoolHumanoid-v1\n",
      "mean return 70.75922735820932\n",
      "std of return 0.0\n",
      "Train on 104365 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "104365/104365 [==============================] - 6s 56us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 2/25\n",
      "104365/104365 [==============================] - 5s 53us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 3/25\n",
      "104365/104365 [==============================] - 6s 57us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 4/25\n",
      "104365/104365 [==============================] - 6s 59us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 5/25\n",
      "104365/104365 [==============================] - 6s 61us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 6/25\n",
      "104365/104365 [==============================] - 6s 56us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 7/25\n",
      "104365/104365 [==============================] - 5s 48us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 8/25\n",
      "104365/104365 [==============================] - 5s 48us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 9/25\n",
      "104365/104365 [==============================] - 6s 54us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 10/25\n",
      "104365/104365 [==============================] - 6s 60us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/25\n",
      "104365/104365 [==============================] - 6s 62us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 12/25\n",
      "104365/104365 [==============================] - 7s 63us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 13/25\n",
      "104365/104365 [==============================] - 6s 59us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 14/25\n",
      "104365/104365 [==============================] - 6s 56us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 15/25\n",
      "104365/104365 [==============================] - 6s 54us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 16/25\n",
      "104365/104365 [==============================] - 5s 49us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 17/25\n",
      "104365/104365 [==============================] - 5s 49us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 18/25\n",
      "104365/104365 [==============================] - 6s 54us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 19/25\n",
      "104365/104365 [==============================] - 6s 56us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 20/25\n",
      "104365/104365 [==============================] - 6s 62us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 21/25\n",
      "104365/104365 [==============================] - 6s 61us/sample - loss: 0.0120 - mean_squared_error: 0.0052 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 22/25\n",
      "102656/104365 [============================>.] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0052"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-008457406e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Print iter %d: k=%d, max_timesteps=%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-149-1b25781ab5a5>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, k, update_epoch_num, max_timesteps, aggregate)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_trajectories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Update policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_epoch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_epoch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Increase the internal update count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-149-1b25781ab5a5>\u001b[0m in \u001b[0;36mupdate_policy\u001b[0;34m(self, X_new, y_new, update_epoch_num, batch_size, aggregate)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_epoch_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             )\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_model_filename = 'hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5'\n",
    "env_name = 'RoboschoolHumanoid-v1'\n",
    "\n",
    "dest_model_dir = 'hw1/models/DAgger/%s_max_timesteps_5' % env_name\n",
    "\n",
    "dagger = DAgagger(env_name=env_name, model_filename=initial_model_filename, update_epoch_num=25, saved_iterations=5, \n",
    "                  batch_size=64, dest_model_dir=dest_model_dir)\n",
    "\n",
    "\n",
    "max_timesteps = 5\n",
    "k=500\n",
    "    \n",
    "for i in range(50):\n",
    "    if i and not i%5:\n",
    "        k = int(k/ 2.0)\n",
    "        max_timesteps *= 2\n",
    "        print(\"Print iter %d: k=%d, max_timesteps=%d\" % (i, k, max_timesteps))\n",
    "        \n",
    "    dagger.step(k=k, max_timesteps=max_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env description: Runnig DAgger iteration 41 on env RoboschoolHumanoid-v1\n",
      "mean return 51.942120897670904\n",
      "std of return 16.772169513646137\n",
      "Train on 106435 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "106435/106435 [==============================] - 7s 69us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 2/25\n",
      "106435/106435 [==============================] - 5s 51us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 3/25\n",
      "106435/106435 [==============================] - 6s 55us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 4/25\n",
      "106435/106435 [==============================] - 6s 53us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 5/25\n",
      "106435/106435 [==============================] - 5s 50us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 6/25\n",
      "106435/106435 [==============================] - 6s 53us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 7/25\n",
      "106435/106435 [==============================] - 6s 57us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 8/25\n",
      "106435/106435 [==============================] - 5s 51us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 9/25\n",
      "106435/106435 [==============================] - 5s 50us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 10/25\n",
      "106435/106435 [==============================] - 5s 50us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/25\n",
      "106435/106435 [==============================] - 5s 50us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 12/25\n",
      "106435/106435 [==============================] - 6s 53us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 13/25\n",
      "106435/106435 [==============================] - 6s 55us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0145\n",
      "Epoch 14/25\n",
      "106435/106435 [==============================] - 5s 50us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 15/25\n",
      "106435/106435 [==============================] - 5s 50us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 16/25\n",
      "106435/106435 [==============================] - 5s 50us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 17/25\n",
      "106435/106435 [==============================] - 5s 51us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 18/25\n",
      "106435/106435 [==============================] - 6s 54us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 19/25\n",
      "106435/106435 [==============================] - 6s 57us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 20/25\n",
      "106435/106435 [==============================] - 6s 52us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 21/25\n",
      "106435/106435 [==============================] - 5s 51us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 22/25\n",
      "106435/106435 [==============================] - 5s 50us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 23/25\n",
      "106435/106435 [==============================] - 6s 53us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 24/25\n",
      "106435/106435 [==============================] - 5s 51us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 25/25\n",
      "106435/106435 [==============================] - 5s 51us/sample - loss: 0.0119 - mean_squared_error: 0.0051 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "step_data: {'train_mse': 0.005089967047809741, 'iteration': 42, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014558603091731345}\n",
      "Env description: Runnig DAgger iteration 42 on env RoboschoolHumanoid-v1\n",
      "mean return 51.90052872954897\n",
      "std of return 14.068411816751418\n",
      "Train on 108398 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "108398/108398 [==============================] - 6s 53us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 2/25\n",
      "108398/108398 [==============================] - 6s 52us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 3/25\n",
      "108398/108398 [==============================] - 6s 57us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 4/25\n",
      "108398/108398 [==============================] - 6s 53us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 5/25\n",
      "108398/108398 [==============================] - 6s 53us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 6/25\n",
      "108398/108398 [==============================] - 6s 54us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 7/25\n",
      "108398/108398 [==============================] - 6s 52us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 8/25\n",
      "108398/108398 [==============================] - 6s 52us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 9/25\n",
      "108398/108398 [==============================] - 5s 51us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 10/25\n",
      "108398/108398 [==============================] - 5s 50us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 11/25\n",
      "108398/108398 [==============================] - 7s 66us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 12/25\n",
      "108398/108398 [==============================] - 328s 3ms/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 13/25\n",
      "108398/108398 [==============================] - 8s 70us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 14/25\n",
      "108398/108398 [==============================] - 7s 62us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 15/25\n",
      "108398/108398 [==============================] - 6s 58us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 16/25\n",
      "108398/108398 [==============================] - 6s 54us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 17/25\n",
      "108398/108398 [==============================] - 6s 54us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 18/25\n",
      "108398/108398 [==============================] - 6s 53us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 19/25\n",
      "108398/108398 [==============================] - 6s 54us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 20/25\n",
      "108398/108398 [==============================] - 6s 53us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n",
      "108398/108398 [==============================] - 5s 50us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 22/25\n",
      "108398/108398 [==============================] - 5s 50us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 23/25\n",
      "108398/108398 [==============================] - 5s 50us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 24/25\n",
      "108398/108398 [==============================] - 5s 50us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 25/25\n",
      "108398/108398 [==============================] - 5s 50us/sample - loss: 0.0118 - mean_squared_error: 0.0050 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "step_data: {'train_mse': 0.005007862717025816, 'iteration': 43, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014580019333478335}\n",
      "Env description: Runnig DAgger iteration 43 on env RoboschoolHumanoid-v1\n",
      "mean return 52.95224977828467\n",
      "std of return 12.422554627558297\n",
      "Train on 110452 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "110452/110452 [==============================] - 6s 52us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 2/25\n",
      "110452/110452 [==============================] - 6s 56us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 3/25\n",
      "110452/110452 [==============================] - 6s 59us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 4/25\n",
      "110452/110452 [==============================] - 6s 58us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 5/25\n",
      "110452/110452 [==============================] - 6s 55us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 6/25\n",
      "110452/110452 [==============================] - 6s 56us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 7/25\n",
      "110452/110452 [==============================] - 6s 51us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 8/25\n",
      "110452/110452 [==============================] - 6s 51us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 9/25\n",
      "110452/110452 [==============================] - 5s 50us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 10/25\n",
      "110452/110452 [==============================] - 6s 51us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 11/25\n",
      "110452/110452 [==============================] - 5s 50us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 12/25\n",
      "110452/110452 [==============================] - 6s 50us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 13/25\n",
      "110452/110452 [==============================] - 6s 50us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 14/25\n",
      "110452/110452 [==============================] - 6s 56us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 15/25\n",
      "110452/110452 [==============================] - 5s 49us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 16/25\n",
      "110452/110452 [==============================] - 5s 50us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 17/25\n",
      "110452/110452 [==============================] - 6s 50us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 18/25\n",
      "110452/110452 [==============================] - 6s 51us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 19/25\n",
      "110452/110452 [==============================] - 5s 49us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 20/25\n",
      "110452/110452 [==============================] - 5s 49us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 21/25\n",
      "110452/110452 [==============================] - 5s 49us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 22/25\n",
      "110452/110452 [==============================] - 6s 50us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 23/25\n",
      "110452/110452 [==============================] - 5s 50us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 24/25\n",
      "110452/110452 [==============================] - 6s 52us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 25/25\n",
      "110452/110452 [==============================] - 6s 50us/sample - loss: 0.0117 - mean_squared_error: 0.0049 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "step_data: {'train_mse': 0.0049259529846683, 'iteration': 44, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014604517433861297}\n",
      "Env description: Runnig DAgger iteration 44 on env RoboschoolHumanoid-v1\n",
      "mean return 55.04847205378676\n",
      "std of return 20.65186709611876\n",
      "Train on 112502 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "112502/112502 [==============================] - 6s 50us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 2/25\n",
      "112502/112502 [==============================] - 6s 49us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 3/25\n",
      "112502/112502 [==============================] - 6s 50us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 4/25\n",
      "112502/112502 [==============================] - 6s 51us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 5/25\n",
      "112502/112502 [==============================] - 6s 50us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 6/25\n",
      "112502/112502 [==============================] - 6s 53us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 7/25\n",
      "112502/112502 [==============================] - 6s 50us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 8/25\n",
      "112502/112502 [==============================] - 6s 51us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 9/25\n",
      "112502/112502 [==============================] - 6s 52us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 10/25\n",
      "112502/112502 [==============================] - 6s 51us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 11/25\n",
      "112502/112502 [==============================] - 6s 51us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 12/25\n",
      "112502/112502 [==============================] - 6s 51us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 13/25\n",
      "112502/112502 [==============================] - 6s 50us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 14/25\n",
      "112502/112502 [==============================] - 6s 50us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n",
      "112502/112502 [==============================] - 6s 49us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 16/25\n",
      "112502/112502 [==============================] - 5s 49us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 17/25\n",
      "112502/112502 [==============================] - 5s 49us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 18/25\n",
      "112502/112502 [==============================] - 5s 48us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 19/25\n",
      "112502/112502 [==============================] - 5s 48us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 20/25\n",
      "112502/112502 [==============================] - 6s 51us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 21/25\n",
      "112502/112502 [==============================] - 5s 49us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 22/25\n",
      "112502/112502 [==============================] - 6s 49us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 23/25\n",
      "112502/112502 [==============================] - 5s 49us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 24/25\n",
      "112502/112502 [==============================] - 6s 49us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 25/25\n",
      "112502/112502 [==============================] - 7s 64us/sample - loss: 0.0116 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_45.hdf5 after update number 45\n",
      "step_data: {'train_mse': 0.004847791977991142, 'iteration': 45, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014630027535553097}\n",
      "Env description: Runnig DAgger iteration 45 on env RoboschoolHumanoid-v1\n",
      "mean return 54.890376764580864\n",
      "std of return 11.715422722389384\n",
      "Train on 114529 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "114529/114529 [==============================] - 6s 56us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 2/25\n",
      "114529/114529 [==============================] - 6s 49us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 3/25\n",
      "114529/114529 [==============================] - 6s 49us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 4/25\n",
      "114529/114529 [==============================] - 6s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 5/25\n",
      "114529/114529 [==============================] - 6s 49us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 6/25\n",
      "114529/114529 [==============================] - 6s 51us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 7/25\n",
      "114529/114529 [==============================] - 5s 47us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 8/25\n",
      "114529/114529 [==============================] - 5s 46us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 9/25\n",
      "114529/114529 [==============================] - 5s 47us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 10/25\n",
      "114529/114529 [==============================] - 6s 49us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 11/25\n",
      "114529/114529 [==============================] - 5s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 12/25\n",
      "114529/114529 [==============================] - 6s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 13/25\n",
      "114529/114529 [==============================] - 5s 47us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 14/25\n",
      "114529/114529 [==============================] - 5s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 15/25\n",
      "114529/114529 [==============================] - 5s 47us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 16/25\n",
      "114529/114529 [==============================] - 6s 52us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 17/25\n",
      "114529/114529 [==============================] - 5s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 18/25\n",
      "114529/114529 [==============================] - 5s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 19/25\n",
      "114529/114529 [==============================] - 5s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0146\n",
      "Epoch 20/25\n",
      "114529/114529 [==============================] - 5s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 21/25\n",
      "114529/114529 [==============================] - 5s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 22/25\n",
      "114529/114529 [==============================] - 6s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 23/25\n",
      "114529/114529 [==============================] - 5s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 24/25\n",
      "114529/114529 [==============================] - 6s 49us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 25/25\n",
      "114529/114529 [==============================] - 6s 48us/sample - loss: 0.0115 - mean_squared_error: 0.0048 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "step_data: {'train_mse': 0.00477379121104178, 'iteration': 46, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014654840748690426}\n",
      "Env description: Runnig DAgger iteration 46 on env RoboschoolHumanoid-v1\n",
      "mean return 53.45291451562882\n",
      "std of return 13.123424286264509\n",
      "Train on 116538 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "116538/116538 [==============================] - 6s 48us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 2/25\n",
      "116538/116538 [==============================] - 6s 50us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 3/25\n",
      "116538/116538 [==============================] - 6s 48us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 4/25\n",
      "116538/116538 [==============================] - 6s 48us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 5/25\n",
      "116538/116538 [==============================] - 6s 51us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 6/25\n",
      "116538/116538 [==============================] - 8s 68us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 7/25\n",
      "116538/116538 [==============================] - 7s 60us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116538/116538 [==============================] - 7s 57us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 9/25\n",
      "116538/116538 [==============================] - 6s 52us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 10/25\n",
      "116538/116538 [==============================] - 6s 52us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 11/25\n",
      "116538/116538 [==============================] - 6s 51us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 12/25\n",
      "116538/116538 [==============================] - 6s 52us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 13/25\n",
      "116538/116538 [==============================] - 6s 49us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 14/25\n",
      "116538/116538 [==============================] - 6s 48us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 15/25\n",
      "116538/116538 [==============================] - 6s 48us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 16/25\n",
      "116538/116538 [==============================] - 6s 48us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 17/25\n",
      "116538/116538 [==============================] - 6s 48us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 18/25\n",
      "116538/116538 [==============================] - 6s 48us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 19/25\n",
      "116538/116538 [==============================] - 6s 48us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 20/25\n",
      "116538/116538 [==============================] - 6s 49us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 21/25\n",
      "116538/116538 [==============================] - 6s 48us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 22/25\n",
      "116538/116538 [==============================] - 6s 49us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 23/25\n",
      "116538/116538 [==============================] - 6s 48us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 24/25\n",
      "116538/116538 [==============================] - 6s 49us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 25/25\n",
      "116538/116538 [==============================] - 6s 49us/sample - loss: 0.0114 - mean_squared_error: 0.0047 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "step_data: {'train_mse': 0.0047040758759105085, 'iteration': 47, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014682503676249726}\n",
      "Env description: Runnig DAgger iteration 47 on env RoboschoolHumanoid-v1\n",
      "mean return 54.17623938588989\n",
      "std of return 17.11351495038905\n",
      "Train on 118591 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 2/25\n",
      "118591/118591 [==============================] - 6s 51us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 3/25\n",
      "118591/118591 [==============================] - 6s 49us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 4/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 5/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 6/25\n",
      "118591/118591 [==============================] - 6s 49us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 7/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 8/25\n",
      "118591/118591 [==============================] - 6s 49us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 9/25\n",
      "118591/118591 [==============================] - 6s 49us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 10/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 11/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 12/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 13/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 14/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 15/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 16/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 17/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 18/25\n",
      "118591/118591 [==============================] - 6s 48us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 19/25\n",
      "118591/118591 [==============================] - 6s 49us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 20/25\n",
      "118591/118591 [==============================] - 7s 56us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 21/25\n",
      "118591/118591 [==============================] - 7s 62us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 22/25\n",
      "118591/118591 [==============================] - 7s 56us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 23/25\n",
      "118591/118591 [==============================] - 7s 62us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 24/25\n",
      "118591/118591 [==============================] - 8s 64us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 25/25\n",
      "118591/118591 [==============================] - 7s 61us/sample - loss: 0.0113 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "step_data: {'train_mse': 0.004635226211626708, 'iteration': 48, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014711670659293144}\n",
      "Env description: Runnig DAgger iteration 48 on env RoboschoolHumanoid-v1\n",
      "mean return 49.44021297287832\n",
      "std of return 15.777803408823758\n",
      "Train on 120555 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "120555/120555 [==============================] - 6s 53us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "120555/120555 [==============================] - 6s 50us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 3/25\n",
      "120555/120555 [==============================] - 6s 49us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 4/25\n",
      "120555/120555 [==============================] - 6s 48us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 5/25\n",
      "120555/120555 [==============================] - 6s 49us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 6/25\n",
      "120555/120555 [==============================] - 6s 49us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 7/25\n",
      "120555/120555 [==============================] - 6s 49us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 8/25\n",
      "120555/120555 [==============================] - 6s 49us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 9/25\n",
      "120555/120555 [==============================] - 6s 49us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 10/25\n",
      "120555/120555 [==============================] - 6s 49us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 11/25\n",
      "120555/120555 [==============================] - 6s 49us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 12/25\n",
      "120555/120555 [==============================] - 6s 49us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 13/25\n",
      "120555/120555 [==============================] - 6s 48us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 14/25\n",
      "120555/120555 [==============================] - 6s 50us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 15/25\n",
      "120555/120555 [==============================] - 6s 50us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 16/25\n",
      "120555/120555 [==============================] - 6s 48us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 17/25\n",
      "120555/120555 [==============================] - 6s 49us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 18/25\n",
      "120555/120555 [==============================] - 6s 49us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 19/25\n",
      "120555/120555 [==============================] - 6s 48us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 20/25\n",
      "120555/120555 [==============================] - 8s 66us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 21/25\n",
      "120555/120555 [==============================] - 6s 52us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 22/25\n",
      "120555/120555 [==============================] - 7s 56us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 23/25\n",
      "120555/120555 [==============================] - 7s 58us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 24/25\n",
      "120555/120555 [==============================] - 7s 55us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 25/25\n",
      "120555/120555 [==============================] - 51s 421us/sample - loss: 0.0112 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "step_data: {'train_mse': 0.00457267574863382, 'iteration': 49, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014744499279629378}\n",
      "Env description: Runnig DAgger iteration 49 on env RoboschoolHumanoid-v1\n",
      "mean return 50.04781394975747\n",
      "std of return 12.095676237597713\n",
      "Train on 122530 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "122530/122530 [==============================] - 6s 48us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 2/25\n",
      "122530/122530 [==============================] - 8s 62us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 3/25\n",
      "122530/122530 [==============================] - 6s 47us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 4/25\n",
      "122530/122530 [==============================] - 6s 52us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0147\n",
      "Epoch 5/25\n",
      "122530/122530 [==============================] - 6s 47us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 6/25\n",
      "122530/122530 [==============================] - 6s 47us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 7/25\n",
      "122530/122530 [==============================] - 6s 48us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 8/25\n",
      "122530/122530 [==============================] - 6s 48us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 9/25\n",
      "122530/122530 [==============================] - 6s 48us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 10/25\n",
      "122530/122530 [==============================] - 6s 49us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 11/25\n",
      "122530/122530 [==============================] - 6s 46us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 12/25\n",
      "122530/122530 [==============================] - 6s 47us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 13/25\n",
      "122530/122530 [==============================] - 6s 47us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 14/25\n",
      "122530/122530 [==============================] - 6s 47us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 15/25\n",
      "122530/122530 [==============================] - 6s 46us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 16/25\n",
      "122530/122530 [==============================] - 6s 48us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 17/25\n",
      "122530/122530 [==============================] - 6s 48us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 18/25\n",
      "122530/122530 [==============================] - 6s 49us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 19/25\n",
      "122530/122530 [==============================] - 6s 49us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 20/25\n",
      "122530/122530 [==============================] - 6s 49us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 21/25\n",
      "122530/122530 [==============================] - 6s 49us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 22/25\n",
      "122530/122530 [==============================] - 6s 48us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25\n",
      "122530/122530 [==============================] - 6s 49us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 24/25\n",
      "122530/122530 [==============================] - 6s 49us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 25/25\n",
      "122530/122530 [==============================] - 6s 48us/sample - loss: 0.0111 - mean_squared_error: 0.0045 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_50.hdf5 after update number 50\n",
      "step_data: {'train_mse': 0.004512170957879216, 'iteration': 50, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014775025375738242}\n",
      "Env description: Runnig DAgger iteration 50 on env RoboschoolHumanoid-v1\n",
      "mean return 56.37308946484004\n",
      "std of return 22.64966752875922\n",
      "Train on 124688 samples, validate on 4445 samples\n",
      "Epoch 1/25\n",
      "124688/124688 [==============================] - 6s 49us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 2/25\n",
      "124688/124688 [==============================] - 6s 49us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 3/25\n",
      "124688/124688 [==============================] - 6s 51us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 4/25\n",
      "124688/124688 [==============================] - 7s 54us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 5/25\n",
      "124688/124688 [==============================] - 6s 48us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 6/25\n",
      "124688/124688 [==============================] - 7s 53us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 7/25\n",
      "124688/124688 [==============================] - 6s 48us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 8/25\n",
      "124688/124688 [==============================] - 6s 48us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 9/25\n",
      "124688/124688 [==============================] - 6s 48us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 10/25\n",
      "124688/124688 [==============================] - 6s 49us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 11/25\n",
      "124688/124688 [==============================] - 6s 48us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 12/25\n",
      "124688/124688 [==============================] - 6s 49us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 13/25\n",
      "124688/124688 [==============================] - 6s 49us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 14/25\n",
      "124688/124688 [==============================] - 6s 49us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 15/25\n",
      "124688/124688 [==============================] - 6s 49us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 16/25\n",
      "124688/124688 [==============================] - 6s 49us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 17/25\n",
      "124688/124688 [==============================] - 6s 49us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 18/25\n",
      "124688/124688 [==============================] - 6s 48us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 19/25\n",
      "124688/124688 [==============================] - 6s 49us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 20/25\n",
      "124688/124688 [==============================] - 6s 48us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 21/25\n",
      "124688/124688 [==============================] - 6s 49us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 22/25\n",
      "124688/124688 [==============================] - 6s 48us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 23/25\n",
      "124688/124688 [==============================] - 6s 48us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 24/25\n",
      "124688/124688 [==============================] - 6s 48us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "Epoch 25/25\n",
      "124688/124688 [==============================] - 6s 48us/sample - loss: 0.0110 - mean_squared_error: 0.0044 - val_loss: 0.0214 - val_mean_squared_error: 0.0148\n",
      "step_data: {'train_mse': 0.004447237782074195, 'iteration': 51, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.014805885739460782}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    dagger.step(k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf {dest_model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env description: Runnig DAgger iteration 10 on env RoboschoolHumanoid-v1\n",
      "mean return 56.421413149089496\n",
      "std of return 8.435957417536272\n",
      "Train on 48641 samples, validate on 4445 samples\n",
      "Epoch 1/5\n",
      "48641/48641 [==============================] - 2s 49us/sample - loss: 0.0180 - mean_squared_error: 0.0102 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/5\n",
      "48641/48641 [==============================] - 2s 47us/sample - loss: 0.0180 - mean_squared_error: 0.0102 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/5\n",
      "48641/48641 [==============================] - 2s 47us/sample - loss: 0.0180 - mean_squared_error: 0.0102 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/5\n",
      "48641/48641 [==============================] - 2s 47us/sample - loss: 0.0180 - mean_squared_error: 0.0102 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/5\n",
      "48641/48641 [==============================] - 3s 52us/sample - loss: 0.0180 - mean_squared_error: 0.0102 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.010198454198388263, 'iteration': 11, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013621744314623018}\n",
      "Env description: Runnig DAgger iteration 11 on env RoboschoolHumanoid-v1\n",
      "mean return 59.56979507232288\n",
      "std of return 24.286346186337084\n",
      "Train on 49456 samples, validate on 4445 samples\n",
      "Epoch 1/5\n",
      "49456/49456 [==============================] - 2s 47us/sample - loss: 0.0179 - mean_squared_error: 0.0100 - val_loss: 0.0215 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/5\n",
      "49456/49456 [==============================] - 2s 50us/sample - loss: 0.0179 - mean_squared_error: 0.0100 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/5\n",
      "49456/49456 [==============================] - 2s 48us/sample - loss: 0.0179 - mean_squared_error: 0.0100 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/5\n",
      "49456/49456 [==============================] - 3s 51us/sample - loss: 0.0179 - mean_squared_error: 0.0100 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/5\n",
      "49456/49456 [==============================] - 3s 51us/sample - loss: 0.0179 - mean_squared_error: 0.0100 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.010031448280699037, 'iteration': 12, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.01362169499707184}\n",
      "Env description: Runnig DAgger iteration 12 on env RoboschoolHumanoid-v1\n",
      "mean return 49.41134374609052\n",
      "std of return 17.735138580866657\n",
      "Train on 50225 samples, validate on 4445 samples\n",
      "Epoch 1/5\n",
      "50225/50225 [==============================] - 3s 50us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/5\n",
      "50225/50225 [==============================] - 2s 48us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/5\n",
      "50225/50225 [==============================] - 2s 48us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/5\n",
      "50225/50225 [==============================] - 3s 54us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/5\n",
      "50225/50225 [==============================] - 2s 48us/sample - loss: 0.0177 - mean_squared_error: 0.0099 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.009879445268371525, 'iteration': 13, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013623766771920502}\n",
      "Env description: Runnig DAgger iteration 13 on env RoboschoolHumanoid-v1\n",
      "mean return 55.3840456076948\n",
      "std of return 7.782086714640666\n",
      "Train on 50982 samples, validate on 4445 samples\n",
      "Epoch 1/5\n",
      "50982/50982 [==============================] - 2s 48us/sample - loss: 0.0176 - mean_squared_error: 0.0097 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/5\n",
      "50982/50982 [==============================] - 3s 49us/sample - loss: 0.0176 - mean_squared_error: 0.0097 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/5\n",
      "50982/50982 [==============================] - 2s 48us/sample - loss: 0.0176 - mean_squared_error: 0.0097 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/5\n",
      "50982/50982 [==============================] - 2s 48us/sample - loss: 0.0176 - mean_squared_error: 0.0097 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/5\n",
      "50982/50982 [==============================] - 3s 49us/sample - loss: 0.0176 - mean_squared_error: 0.0097 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "step_data: {'train_mse': 0.009733841449551242, 'iteration': 14, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.01362498083918446}\n",
      "Env description: Runnig DAgger iteration 14 on env RoboschoolHumanoid-v1\n",
      "mean return 56.34108633585061\n",
      "std of return 20.338054476844402\n",
      "Train on 51784 samples, validate on 4445 samples\n",
      "Epoch 1/5\n",
      "51784/51784 [==============================] - 2s 46us/sample - loss: 0.0174 - mean_squared_error: 0.0096 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/5\n",
      "51784/51784 [==============================] - 3s 51us/sample - loss: 0.0174 - mean_squared_error: 0.0096 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/5\n",
      "51784/51784 [==============================] - 3s 48us/sample - loss: 0.0174 - mean_squared_error: 0.0096 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/5\n",
      "51784/51784 [==============================] - 2s 48us/sample - loss: 0.0174 - mean_squared_error: 0.0096 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/5\n",
      "51784/51784 [==============================] - 3s 49us/sample - loss: 0.0174 - mean_squared_error: 0.0096 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Saving model RoboschoolHumanoid-v1_DAgger_update_15.hdf5 after update number 15\n",
      "step_data: {'train_mse': 0.009584543294963435, 'iteration': 15, 'dataset_name': 'RoboschoolHumanoid-v1', 'test_mse': 0.013626467288425528}\n",
      "Env description: Runnig DAgger iteration 15 on env RoboschoolHumanoid-v1\n",
      "mean return 51.56595614420483\n",
      "std of return 19.757257547157597\n",
      "Train on 52539 samples, validate on 4445 samples\n",
      "Epoch 1/5\n",
      "52539/52539 [==============================] - 3s 49us/sample - loss: 0.0173 - mean_squared_error: 0.0094 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 2/5\n",
      "52539/52539 [==============================] - 3s 53us/sample - loss: 0.0173 - mean_squared_error: 0.0094 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 3/5\n",
      "52539/52539 [==============================] - 3s 62us/sample - loss: 0.0173 - mean_squared_error: 0.0094 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/5\n",
      "52539/52539 [==============================] - 3s 48us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/5\n",
      "52539/52539 [==============================] - 3s 48us/sample - loss: 0.0173 - mean_squared_error: 0.0095 - val_loss: 0.0214 - val_mean_squared_error: 0.0136\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-815668937a8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-134-9aa8553e2737>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, k, update_epoch_num, aggregate)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving model %s after update number %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_step_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_step_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-9aa8553e2737>\u001b[0m in \u001b[0;36mcalc_step_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_step_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Update the steps statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mstep_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mstep_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~tf/srv/keras_helpers/model_helper.py\u001b[0m in \u001b[0;36mcalc_mse\u001b[0;34m(model, dataset_name, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mtrain_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mtest_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       return training_arrays.predict_loop(\n\u001b[0;32m-> 1113\u001b[0;31m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3035\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3037\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3038\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    480\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m       \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    dagger.step(k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = \n",
    "\n",
    "# load model\n",
    "model = \n",
    "k = 5 # number of trajectories in each iterasion\n",
    "iterations = 10  # number of iterasion in the loop\n",
    "\n",
    "# Stats array to save the average reward and the test MSE after each trajectory \n",
    "model_return_means = []\n",
    "model_return_stds = []\n",
    "model_mse = []\n",
    "\n",
    "\n",
    "env_name = 'RoboschoolAnt-v1'\n",
    "X_train, X_test, y_train, y_test = get_datasets(dataset_name=env_name, dataset_dir=EXPERT_DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedModelPolicy():\n",
    "    \"\"\"\n",
    "    A policy class that is based on the ANN trained for each environment\n",
    "    \"\"\"\n",
    "    def __init__(self, env_name, model_filename=None):\n",
    "        self._env_name = env_name\n",
    "        \n",
    "        if model_filename is None:\n",
    "            model_filename = env_to_model[env_name]\n",
    "        self._model = tf.keras.models.load_model(model_filename)\n",
    "        \n",
    "    def act(self, ob):\n",
    "        action = self._model.predict(ob.reshape(1, ob.shape[0]))\n",
    "        return action[0]\n",
    "    \n",
    "    \n",
    "import gym\n",
    "import roboschool\n",
    "from hw1.run_expert import run_policy\n",
    "\n",
    "def run_supervised_model_policy(num_rollouts, env_name, max_timesteps=None, render=False, verbose=True):\n",
    "    assert env_name in AVAILABLE_ENVS\n",
    "    env = gym.make(env_name)\n",
    "    policy = SupervisedModelPolicy(env_name)\n",
    "    description = \"Supervised model policy for module %s\" % env_name\n",
    "    return run_policy(env=env, policy=policy, num_rollouts=num_rollouts, description=description, max_timesteps=max_timesteps, render=render, verbose=verbose)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model_filename = 'hw1/models/model_RoboschoolHumanoid-v1_layers_100_3_neurons_l2_0.0001_Adam_optimizer_0.001_lr_None_dropout_without_batchnorm/base.hdf5'\n",
    "env_name = 'RoboschoolHumanoid-v1'\n",
    "model = \n",
    "\n",
    "# load model\n",
    "model = \n",
    "k = 5 # number of trajectories in each iterasion\n",
    "iterations = 10  # number of iterasion in the loop\n",
    "\n",
    "# Stats array to save the average reward and the test MSE after each trajectory \n",
    "model_return_means = []\n",
    "model_return_stds = []\n",
    "model_mse = []\n",
    "\n",
    "\n",
    "env_name = 'RoboschoolAnt-v1'\n",
    "X_train, X_test, y_train, y_test = get_datasets(dataset_name=env_name, dataset_dir=EXPERT_DATA_DIR)\n",
    "\n",
    "for i in range(iterations):\n",
    "    print(\"Running iteration number %d\" % i)\n",
    "    \n",
    "    # generate k trajectories.\n",
    "    returns, _X, _y\n",
    "    \n",
    "    # Calculate and add returns mean and std\n",
    "    model_return_means.append(returns.mean())\n",
    "    model_return_stds.append(returns.std())\n",
    "    \n",
    "    # Calculate and add returns train MSE\n",
    "    test_mse = \n",
    "    model_mse.append(test_mse)\n",
    "    \n",
    "    # concat new \n",
    "    X_train, y_train\n",
    "    \n",
    "    # Save model after iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import Callback, LambdaCallback, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from hw1.manage_datasets import get_datasets\n",
    "from keras_helpers.model_helper import create_model, get_model_name, calc_mse\n",
    "from keras_helpers.keras_train_stats import KerasTrainStats\n",
    "\n",
    "\n",
    "\n",
    "ANT_SAVED_MODELS_DIR = 'hw1/ant_models'\n",
    "MODEL_FILE_NAME = \"base.hdf5\"\n",
    "create_dir_if_not_exists(SAVED_MODELS_DIR)\n",
    "\n",
    "model_mse = []\n",
    "\n",
    "env_name = 'RoboschoolAnt-v1'\n",
    "# Load the datasets once\n",
    "X_train, X_test, y_train, y_test = get_datasets(dataset_name=env_name, dataset_dir=EXPERT_DATA_DIR)\n",
    "\n",
    "for train_size in range(10000, 50000, 10000):  # [10000, 20000, 30000, 40000]\n",
    "    print(\"Training a FC ANN for env %s over a training set size %d \" % (env_name, train_size))\n",
    "    \n",
    "    # Define the model params   \n",
    "    config_dict = dict(\n",
    "        input_dim=len(X_train[1, :]),\n",
    "        output_dim=len(y_train[1, :]),\n",
    "        units=100,\n",
    "        layers = 3,\n",
    "        l2_reg = 1e-04,\n",
    "        optimizer_cls=keras.optimizers.Adam,\n",
    "        lr = 1e-03,\n",
    "        dropout=None,\n",
    "        use_batchnorm=False)\n",
    "    \n",
    "    # Create the model\n",
    "    model = create_model(**config_dict)\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = config_dict['optimizer_cls'](lr=config_dict['lr'])\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    \n",
    "    # Set a unique name/directory for the model\n",
    "    base_name = \"%s_training_set_size_%d\" % (env_name, train_size)\n",
    "    model_name = get_model_name(base_name=base_name, **config_dict)\n",
    "    model_path = os.path.join(SAVED_MODELS_DIR, model_name)\n",
    "    print(\"model_name='%s'\" % model_name)\n",
    "    print(\"model_path='%s'\" % model_path)\n",
    "    create_dir_if_not_exists(model_path)\n",
    "    model_filename = os.path.join(model_path, MODEL_FILE_NAME)\n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_mean_squared_error', factor=0.5, patience=5, verbose=1)\n",
    "    tf_board = TensorBoard()\n",
    "\n",
    "    # Define a train_stats object\n",
    "    train_stats = KerasTrainStats(model_name=model_name, history_dir=model_path)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "\n",
    "    _ = model.fit([X_train[0:train_size]], y_train[0:train_size],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[train_stats.print_callback, reduce_lr, tf_board],\n",
    "        validation_data=([X_test], y_test)\n",
    "        )\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(model_filename)\n",
    "    print(model_filename)\n",
    "    \n",
    "    # Calculate the MSE for each \n",
    "    res = calc_mse(model, env_name, X_train, X_test, y_train, y_test)\n",
    "    res['model_name'] = model_name\n",
    "    res['model_path'] = model_path\n",
    "    model_mse.append(res)\n",
    "    print(\"Done training model for %s\" % env_name)\n",
    "    #print(\"KerasTrainStats(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='%s MSE')\" % dataset_name)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DAgger](DAgger.png \"DAgger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\set$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\set{x, y, z}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/srv\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment 1.ipynb\r\n",
      "\u001b[0m\u001b[01;34mlogs\u001b[0m/\r\n",
      "\u001b[01;34mmodel_RoboschoolHalfCheetah-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\u001b[0m\u001b[K/\r\n",
      "\u001b[01;34mmodel_RoboschoolHopper-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\u001b[0m\u001b[K/\r\n",
      "\u001b[01;34mmodel_RoboschoolHumanoid-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\u001b[0m\u001b[K/\r\n",
      "\u001b[01;34mmodel_RoboschoolReacher-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\u001b[0m\u001b[K/\r\n",
      "\u001b[01;34mmodel_RoboschoolWalker2d-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\u001b[0m\u001b[K/\r\n",
      "\u001b[01;34mmodel_task_1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls /tf/srv/hw1/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_name</th>\n",
       "      <th>dataset_size</th>\n",
       "      <th>expert_mean</th>\n",
       "      <th>model_mean</th>\n",
       "      <th>expert_std</th>\n",
       "      <th>model_std</th>\n",
       "      <th>model_to_expert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RoboschoolAnt-v1</td>\n",
       "      <td>50000</td>\n",
       "      <td>1818.829300</td>\n",
       "      <td>1155.299427</td>\n",
       "      <td>381.867818</td>\n",
       "      <td>549.261430</td>\n",
       "      <td>0.635188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RoboschoolWalker2d-v1</td>\n",
       "      <td>50000</td>\n",
       "      <td>2205.412558</td>\n",
       "      <td>159.524857</td>\n",
       "      <td>81.940065</td>\n",
       "      <td>91.897977</td>\n",
       "      <td>0.072333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RoboschoolHumanoid-v1</td>\n",
       "      <td>44444</td>\n",
       "      <td>2848.910280</td>\n",
       "      <td>20.586368</td>\n",
       "      <td>1033.996305</td>\n",
       "      <td>7.856815</td>\n",
       "      <td>0.007226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RoboschoolHalfCheetah-v1</td>\n",
       "      <td>42602</td>\n",
       "      <td>2271.298439</td>\n",
       "      <td>139.417104</td>\n",
       "      <td>909.003381</td>\n",
       "      <td>125.292634</td>\n",
       "      <td>0.061382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RoboschoolHopper-v1</td>\n",
       "      <td>35778</td>\n",
       "      <td>1541.857022</td>\n",
       "      <td>685.327100</td>\n",
       "      <td>687.020552</td>\n",
       "      <td>617.383461</td>\n",
       "      <td>0.444482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RoboschoolReacher-v1</td>\n",
       "      <td>7500</td>\n",
       "      <td>18.612237</td>\n",
       "      <td>10.669455</td>\n",
       "      <td>10.257760</td>\n",
       "      <td>10.375653</td>\n",
       "      <td>0.573249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   env_name  dataset_size  expert_mean   model_mean   expert_std   model_std  model_to_expert\n",
       "0          RoboschoolAnt-v1         50000  1818.829300  1155.299427   381.867818  549.261430         0.635188\n",
       "5     RoboschoolWalker2d-v1         50000  2205.412558   159.524857    81.940065   91.897977         0.072333\n",
       "1     RoboschoolHumanoid-v1         44444  2848.910280    20.586368  1033.996305    7.856815         0.007226\n",
       "2  RoboschoolHalfCheetah-v1         42602  2271.298439   139.417104   909.003381  125.292634         0.061382\n",
       "4       RoboschoolHopper-v1         35778  1541.857022   685.327100   687.020552  617.383461         0.444482\n",
       "3      RoboschoolReacher-v1          7500    18.612237    10.669455    10.257760   10.375653         0.573249"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolAnt-v1\n",
      "Domain name: RoboschoolAnt-v1\n",
      "(45000, 28) (5000, 28) (45000, 8) (5000, 8)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'RoboschoolAnt-v1'\n",
    "X_train, X_test, y_train, y_test = get_datasets(dataset_name=dataset_name, dataset_dir=EXPERT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolWalker2d-v1\n",
      "Domain name: RoboschoolWalker2d-v1\n",
      "(45000, 22) (5000, 22) (45000, 6) (5000, 6)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'RoboschoolWalker2d-v1'\n",
    "X_train, X_test, y_train, y_test = get_datasets(dataset_name=dataset_name, dataset_dir=EXPERT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolHumanoid-v1\n",
      "Domain name: RoboschoolHumanoid-v1\n",
      "(39999, 44) (4445, 44) (39999, 17) (4445, 17)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'RoboschoolHumanoid-v1'\n",
    "X_train, X_test, y_train, y_test = get_datasets(dataset_name=dataset_name, dataset_dir=EXPERT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RoboschoolWalker2d-v1'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolWalker2d-v1\n"
     ]
    }
   ],
   "source": [
    "expert_data = load_dataset(dataset_name=env_name, dataset_dir=EXPERT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['actions', 'observations', 'returns'])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expert_data['observations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_returns = expert_data['returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.9400649404929"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_returns.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw1.manage_datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolAnt-v1\n"
     ]
    }
   ],
   "source": [
    "me = load_dataset(dataset_name='RoboschoolAnt-v1', dataset_dir=SUPERVISED_MODELD_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 373.56518299, 1291.01069281, 1747.96353957, 1571.43485949,\n",
       "       1383.50511714, 1825.14143744,  648.89877643, 1354.88951954,\n",
       "        901.30792767, 2005.75257601, 1242.026895  , 1719.62684183,\n",
       "        889.3563027 ,  874.87763802,  508.6513738 ,  877.32661354,\n",
       "        402.25314381, 1586.11007942,  894.41708172, 2006.69756769,\n",
       "        775.41780876,  497.490444  , 1615.4953213 , 1374.01016225,\n",
       "       1526.94650445, 1588.63658939,  743.74945793, 1851.75426934,\n",
       "       2119.04780919, 1168.08002264,  551.90119724, 1749.96432383,\n",
       "       1432.41217066,  761.05494486,  334.88374563, 2044.74708007,\n",
       "        836.16923429,  290.57604421,  303.40597124,  696.84630395,\n",
       "       1132.4167428 ,  719.22797839, 1497.94839319,  668.54452527,\n",
       "       1896.03474356, 1947.30508422,  759.73376709,  442.96192309,\n",
       "        667.42625141, 1665.96934467])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me['returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir=EXPERT_DATA_DIR\n",
    "SUPERVISED_MODELD_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = hist(me['returns'], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolAnt-v1\n"
     ]
    }
   ],
   "source": [
    "me2 = load_dataset(dataset_name='RoboschoolAnt-v1', dataset_dir=EXPERT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = hist(me2['returns'], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Input, Embedding\n",
    "from tensorflow.keras.callbacks import Callback, LambdaCallback, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Bayesian Methods for Hackers style sheet\n",
    "plt.style.use('bmh')\n",
    "\n",
    "def create_model(input_dim, output_dim, num_hidden=3, units=100, l2_reg=0.0001, \n",
    "                 dropout=None, use_batchnorm=True, **kwargs):\n",
    "    \"\"\"\n",
    "    This method wraps the creation of a Keras fully connected model\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(input_dim, ), name=\"input\")\n",
    "\n",
    "    # Define model architecture \n",
    "    if use_batchnorm:\n",
    "        layer = BatchNormalization()(input_layer)\n",
    "    else:\n",
    "        layer = input_layer\n",
    "\n",
    "    if dropout is not None:\n",
    "        # Add dropout layer\n",
    "        layer = Dropout(dropout)(layer)\n",
    "\n",
    "    for i in range(1, num_hidden+1):\n",
    "        layer = Dense(units=units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(layer)\n",
    "        if use_batchnorm:\n",
    "            layer = BatchNormalization()(layer)\n",
    "\n",
    "        # Add dropout layer\n",
    "        if dropout is not None:\n",
    "            layer = Dropout(dropout)(layer)\n",
    "\n",
    "    # Add a prediction layer\n",
    "    predictions = Dense(output_dim, activation=None)(layer)\n",
    "\n",
    "    # Note using the input object 'page_id_mapping_input' not 'page_id_embedings'\n",
    "    model = tf.keras.Model(inputs=[input_layer], outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_name(dataset_name, input_dim, output_dim, units=100, layers=3, l2_reg=1e-04, \n",
    "                   lr=1e-03, dropout=None, use_batchnorm=False):\n",
    "    \"\"\"\n",
    "    Defines a model name and creates relevant directories\n",
    "    \"\"\"\n",
    "    model_name = \"model_{dataset_name}__{lr}_lr_{dropout}_dropout_{layers}_layers_{units}_neurons_batch_norm_l2_{l2_reg}\".format(**config_dict)\n",
    "    model_path = \"%s/%s\" % (SAVED_MODELS_DIR, model_name)\n",
    "\n",
    "    ! mkdir -p {model_path}\n",
    "\n",
    "    filepath=\"%s/weights-improvement-dummy-{epoch:02d}-{val_loss:.2f}.hdf5\" % model_path\n",
    "\n",
    "\n",
    "    print(\"model_name='%s'\" % model_name)\n",
    "    print(\"model_path='%s'\" % model_path)\n",
    "    print(\"KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='%s MSE')\" % dataset_name)\n",
    "\n",
    "    return model_name, model_path\n",
    "\n",
    "\n",
    "def get_compiled_model(dataset_name, input_dim, output_dim, units=100, layers=3, l2_reg=1e-04, \n",
    "                   lr=1e-03, dropout=None, use_batchnorm=False):\n",
    "    \n",
    "    # Get model names\n",
    "    model_name, model_path = get_model_name(dataset_name=dataset_name, input_dim=input_dim, \n",
    "                                            output_dim=output_dim, units=units, layers=layers, \n",
    "                                            l2_reg=l2_reg, lr=lr, dropout=dropout, use_batchnorm=use_batchnorm)\n",
    "    \n",
    "    # Create a model\n",
    "    model = create_model(input_dim=input_dim, output_dim=output_dim, num_hidden=layers, units=units, \n",
    "                         l2_reg=l2_reg, dropout=dropout, use_batchnorm=use_batchnorm)\n",
    "    \n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    \n",
    "    return model, model_name, model_path\n",
    "    \n",
    "\n",
    "def calc_mse(model, dataset_name, X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    \"\"\"Helper function that calculates the MSE for each of the train/validation/test sets\"\"\"\n",
    "    y_pred_train = model.predict([X_train])\n",
    "    train_mse = mean_squared_error(y_pred_train, y_train)\n",
    "\n",
    "    y_pred_val = model.predict([X_val])\n",
    "    val_mse = mean_squared_error(y_pred_val, y_val)\n",
    "\n",
    "    y_pred_test = model.predict([X_test])\n",
    "    test_mse = mean_squared_error(y_pred_test, y_test)\n",
    "\n",
    "    return dict(dataset_name=dataset_name, train_mse=train_mse, val_mse=val_mse, test_mse=test_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "config_dict = dict(\n",
    "    input_dim=20,\n",
    "    output_dim=3,\n",
    "    units=100,\n",
    "    layers = 3,\n",
    "    l2_reg = 1e-04,\n",
    "    lr = 1e-03,\n",
    "    dropout=None,\n",
    "    use_batchnorm=False)\n",
    "\n",
    "model = create_model(**config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b7be228d4297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SVG' is not defined"
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets load methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RoboschoolAnt-v1', 'RoboschoolHumanoid-v1', 'RoboschoolHalfCheetah-v1', 'RoboschoolReacher-v1', 'RoboschoolHopper-v1', 'RoboschoolWalker2d-v1']\n"
     ]
    }
   ],
   "source": [
    "EXPERT_DATA_DIR = os.path.join(os.getcwd().replace('/notebooks', ''), 'expert_data')\n",
    "datasets = ['RoboschoolAnt-v1', 'RoboschoolHumanoid-v1', 'RoboschoolHalfCheetah-v1', 'RoboschoolReacher-v1', 'RoboschoolHopper-v1', 'RoboschoolWalker2d-v1']\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def load_dataset(dataset_name, dataset_dir):\n",
    "    print(\"loading dataset %s\" % dataset_name)\n",
    "    pickle_filename = '%s.pkl' % dataset_name\n",
    "    with open(os.path.join(dataset_dir, pickle_filename), 'rb') as f:\n",
    "        expert_data = pickle.load(f)\n",
    "    return expert_data\n",
    "\n",
    "\n",
    "def get_datasets(dataset_name, dataset_dir):\n",
    "    expert_data = load_dataset(dataset_name=dataset_name, dataset_dir=dataset_dir)\n",
    "    X = expert_data['observations']\n",
    "    y = expert_data['actions']\n",
    "    \n",
    "    # Use 80% of the samples as the train set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    # Leave 10% for each validation/test set\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1)\n",
    "    print(\"Domain name: %s\" % dataset_name)\n",
    "    print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSORBOARD_COMMAND = \"tensorboard --logdir=notebooks/logs\"\n",
    "TENSORBOARD_COMMAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Input, Embedding\n",
    "from tensorflow.keras.callbacks import Callback, LambdaCallback, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Bayesian Methods for Hackers style sheet\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class KerasTrainStats():\n",
    "    \"\"\"\n",
    "    Helper class that defines the training history object for each model\n",
    "\n",
    "    The class pickles and saves the history object to disk\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, history_dir):\n",
    "        # Local import of a Keras package\n",
    "        from keras.callbacks import LambdaCallback\n",
    "\n",
    "        # Try loading history if the file exists\n",
    "        history = self.load_model_history(model_name, history_dir)\n",
    "\n",
    "        # Else, create an empty history dict\n",
    "        if not history:\n",
    "            history = {'loss': [],  # training loss at the end of each epoch of training\n",
    "                       'val_loss': []  # validation (eval) loss at the end of each epoch of training\n",
    "                       }\n",
    "\n",
    "        self.history = history\n",
    "        self.history_dir = history_dir\n",
    "        self.model_name = model_name\n",
    "\n",
    "        # Define the LambdaCallback\n",
    "        self.print_callback = LambdaCallback(on_epoch_end=self.on_epoch_end)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        # Function invoked at end of each epoch.\n",
    "        # It appends the 'loss', 'val_loss' and any other key found in logs to the history and save to a file\n",
    "        # TODO while training in a different window a notebook to see a plot 'loss' and 'val_loss' vs. number of epochs. look at 171219-plot for an example\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history[k] = self.history.get(k, []) + [v]\n",
    "\n",
    "        history_filename = '%s/history.%s.pkl' % (self.history_dir, self.model_name)\n",
    "        with open(history_filename, 'wb') as fp:\n",
    "            pickle.dump(self.history, fp, -1)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model_history(model_name, history_dir):\n",
    "        history_filename = '%s/history.%s.pkl' % (history_dir, model_name)\n",
    "\n",
    "        if not os.path.isfile(history_filename):\n",
    "            return False\n",
    "\n",
    "        with open(history_filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def plt_history(self, start_epoch=0, figsize=(20, 10), model_name=None, history_dir=None, title=None, metric_str='loss'):\n",
    "        \"\"\"Plot the train/validation loss values\"\"\"\n",
    "        if history_dir is None:\n",
    "            history_dir = self.history_dir\n",
    "\n",
    "\n",
    "        if model_name is None:\n",
    "            # Try to load the history from a file before using self.history. This is ment for the usecase that a model\n",
    "            # is trained in a different process/notebook and we want to present the latest history.\n",
    "            history = self.load_model_history(self.model_name, history_dir=history_dir) or self.history\n",
    "        else:\n",
    "            # If model_name is given, load the history from a file\n",
    "            history = self.load_model_history(model_name, history_dir=history_dir)\n",
    "            if not history:\n",
    "                raise Exception(\"Cannot find history object for model_name={model_name}\".format(model_name))\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        _loss = history[metric_str][start_epoch:]\n",
    "        _val_loss = history['val_%s' % metric_str][start_epoch:]\n",
    "\n",
    "        train_loss_plot, = plt.plot(range(start_epoch + 1, start_epoch + len(_loss) + 1), _loss, label='Train %s' % metric_str)\n",
    "        val_loss_plot, = plt.plot(range(start_epoch + 1, start_epoch + len(_val_loss) + 1), _val_loss,\n",
    "                                  label='Validation %s' % metric_str)\n",
    "\n",
    "        plt.legend(handles=[train_loss_plot, val_loss_plot])\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(metric_str)\n",
    "\n",
    "        if title is not None:\n",
    "            _ = plt.title(title)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def create_model(input_dim, output_dim, num_hidden=3, units=100, l2_reg=0.0001, \n",
    "                 dropout=None, use_batchnorm=True, **kwargs):\n",
    "    \"\"\"\n",
    "    This method wraps the creation of a Keras fully connected model\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(input_dim, ), name=\"input\")\n",
    "\n",
    "    # Define model architecture \n",
    "    if use_batchnorm:\n",
    "        layer = BatchNormalization()(input_layer)\n",
    "    else:\n",
    "        layer = input_layer\n",
    "\n",
    "    if dropout is not None:\n",
    "        # Add dropout layer\n",
    "        layer = Dropout(dropout)(layer)\n",
    "\n",
    "    for i in range(1, num_hidden+1):\n",
    "        layer = Dense(units=units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(layer)\n",
    "        if use_batchnorm:\n",
    "            layer = BatchNormalization()(layer)\n",
    "\n",
    "        # Add dropout layer\n",
    "        if dropout is not None:\n",
    "            layer = Dropout(dropout)(layer)\n",
    "\n",
    "    # Add a prediction layer\n",
    "    predictions = Dense(output_dim, activation=None)(layer)\n",
    "\n",
    "    # Note using the input object 'page_id_mapping_input' not 'page_id_embedings'\n",
    "    model = tf.keras.Model(inputs=[input_layer], outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_name(dataset_name, input_dim, output_dim, units=100, layers=3, l2_reg=1e-04, \n",
    "                   lr=1e-03, dropout=None, use_batchnorm=False):\n",
    "    \"\"\"\n",
    "    Defines a model name and creates relevant directories\n",
    "    \"\"\"\n",
    "    model_name = \"model_{dataset_name}__{lr}_lr_{dropout}_dropout_{layers}_layers_{units}_neurons_batch_norm_l2_{l2_reg}\".format(**config_dict)\n",
    "    model_path = \"%s/%s\" % (SAVED_MODELS_DIR, model_name)\n",
    "\n",
    "    ! mkdir -p {model_path}\n",
    "\n",
    "    filepath=\"%s/weights-improvement-dummy-{epoch:02d}-{val_loss:.2f}.hdf5\" % model_path\n",
    "\n",
    "\n",
    "    print(\"model_name='%s'\" % model_name)\n",
    "    print(\"model_path='%s'\" % model_path)\n",
    "    print(\"KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='%s MSE')\" % dataset_name)\n",
    "\n",
    "    return model_name, model_path\n",
    "\n",
    "\n",
    "def get_compiled_model(dataset_name, input_dim, output_dim, units=100, layers=3, l2_reg=1e-04, \n",
    "                   lr=1e-03, dropout=None, use_batchnorm=False):\n",
    "    \n",
    "    # Get model names\n",
    "    model_name, model_path = get_model_name(dataset_name=dataset_name, input_dim=input_dim, \n",
    "                                            output_dim=output_dim, units=units, layers=layers, \n",
    "                                            l2_reg=l2_reg, lr=lr, dropout=dropout, use_batchnorm=use_batchnorm)\n",
    "    \n",
    "    # Create a model\n",
    "    model = create_model(input_dim=input_dim, output_dim=output_dim, num_hidden=layers, units=units, \n",
    "                         l2_reg=l2_reg, dropout=dropout, use_batchnorm=use_batchnorm)\n",
    "    \n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    \n",
    "    return model, model_name, model_path\n",
    "    \n",
    "\n",
    "def calc_mse(model, dataset_name, X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    \"\"\"Helper function that calculates the MSE for each of the train/validation/test sets\"\"\"\n",
    "    y_pred_train = model.predict([X_train])\n",
    "    train_mse = mean_squared_error(y_pred_train, y_train)\n",
    "\n",
    "    y_pred_val = model.predict([X_val])\n",
    "    val_mse = mean_squared_error(y_pred_val, y_val)\n",
    "\n",
    "    y_pred_test = model.predict([X_test])\n",
    "    test_mse = mean_squared_error(y_pred_test, y_test)\n",
    "\n",
    "    return dict(dataset_name=dataset_name, train_mse=train_mse, val_mse=val_mse, test_mse=test_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --user pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model, 'my_first_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import SVG\n",
    "# from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODELS_DIR = '/tf/srv/hw1/notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolAnt-v1\n",
      "(40000, 28) (5000, 28) (5000, 28) (40000, 8) (5000, 8) (5000, 8)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'RoboschoolAnt-v1'\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_datasets(dataset_name=dataset_name)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='model_task_1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "model_path='/tf/srv/hw1/notebooks/model_task_1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "config_dict = dict(\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    units=100,\n",
    "    layers = 3,\n",
    "    l2_reg = 1e-04,\n",
    "    lr = 1e-03,\n",
    "    dropout=None,\n",
    "    use_batchnorm=False)\n",
    "\n",
    "\n",
    "model_name = \"model_task_1__{lr}_lr_{dropout}_dropout_{layers}_layers_{units}_neurons_batch_norm_l2_{l2_reg}\".format(**config_dict)\n",
    "model_path = \"%s/%s\" % (SAVED_MODELS_DIR, model_name)\n",
    "\n",
    "! mkdir -p {model_path}\n",
    "\n",
    "filepath=\"%s/weights-improvement-dummy-{epoch:02d}-{val_loss:.2f}.hdf5\" % model_path\n",
    "\n",
    "\n",
    "print(\"model_name='%s'\" % model_name)\n",
    "print(\"model_path='%s'\" % model_path)\n",
    "print(\"KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(**config_dict)\n",
    "\n",
    "# Callbacks\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error', verbose=1, save_best_only=True, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mean_squared_error', factor=0.5, patience=5, verbose=1)\n",
    "tf_board = TensorBoard()\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "# Define a scope object\n",
    "scope = KerasTrainScope(model_name=model_name, history_dir=model_path)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 5000 samples\n",
      "Epoch 1/200\n",
      "40000/40000 [==============================] - 2s 42us/sample - loss: 0.3940 - mean_squared_error: 0.3671 - val_loss: 0.2368 - val_mean_squared_error: 0.2075\n",
      "Epoch 2/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.2028 - mean_squared_error: 0.1725 - val_loss: 0.1945 - val_mean_squared_error: 0.1637\n",
      "Epoch 3/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.1712 - mean_squared_error: 0.1399 - val_loss: 0.1695 - val_mean_squared_error: 0.1379\n",
      "Epoch 4/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.1546 - mean_squared_error: 0.1229 - val_loss: 0.1550 - val_mean_squared_error: 0.1232\n",
      "Epoch 5/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.1421 - mean_squared_error: 0.1103 - val_loss: 0.1471 - val_mean_squared_error: 0.1153\n",
      "Epoch 6/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.1347 - mean_squared_error: 0.1030 - val_loss: 0.1380 - val_mean_squared_error: 0.1064\n",
      "Epoch 7/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.1285 - mean_squared_error: 0.0971 - val_loss: 0.1337 - val_mean_squared_error: 0.1024\n",
      "Epoch 8/200\n",
      "40000/40000 [==============================] - 1s 32us/sample - loss: 0.1232 - mean_squared_error: 0.0920 - val_loss: 0.1320 - val_mean_squared_error: 0.1010\n",
      "Epoch 9/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.1190 - mean_squared_error: 0.0881 - val_loss: 0.1243 - val_mean_squared_error: 0.0936\n",
      "Epoch 10/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.1156 - mean_squared_error: 0.0850 - val_loss: 0.1224 - val_mean_squared_error: 0.0921\n",
      "Epoch 11/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.1126 - mean_squared_error: 0.0824 - val_loss: 0.1173 - val_mean_squared_error: 0.0873\n",
      "Epoch 12/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.1096 - mean_squared_error: 0.0798 - val_loss: 0.1129 - val_mean_squared_error: 0.0832\n",
      "Epoch 13/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.1069 - mean_squared_error: 0.0773 - val_loss: 0.1121 - val_mean_squared_error: 0.0827\n",
      "Epoch 14/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.1053 - mean_squared_error: 0.0761 - val_loss: 0.1142 - val_mean_squared_error: 0.0852\n",
      "Epoch 15/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.1028 - mean_squared_error: 0.0739 - val_loss: 0.1058 - val_mean_squared_error: 0.0770\n",
      "Epoch 16/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.1008 - mean_squared_error: 0.0723 - val_loss: 0.1070 - val_mean_squared_error: 0.0786\n",
      "Epoch 17/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0993 - mean_squared_error: 0.0710 - val_loss: 0.1052 - val_mean_squared_error: 0.0770\n",
      "Epoch 18/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0977 - mean_squared_error: 0.0696 - val_loss: 0.1060 - val_mean_squared_error: 0.0782\n",
      "Epoch 19/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0962 - mean_squared_error: 0.0685 - val_loss: 0.1036 - val_mean_squared_error: 0.0761\n",
      "Epoch 20/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0950 - mean_squared_error: 0.0675 - val_loss: 0.0998 - val_mean_squared_error: 0.0724\n",
      "Epoch 21/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0937 - mean_squared_error: 0.0665 - val_loss: 0.1000 - val_mean_squared_error: 0.0729\n",
      "Epoch 22/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0927 - mean_squared_error: 0.0657 - val_loss: 0.0983 - val_mean_squared_error: 0.0714\n",
      "Epoch 23/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0918 - mean_squared_error: 0.0650 - val_loss: 0.0981 - val_mean_squared_error: 0.0715\n",
      "Epoch 24/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0903 - mean_squared_error: 0.0638 - val_loss: 0.0965 - val_mean_squared_error: 0.0700\n",
      "Epoch 25/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0896 - mean_squared_error: 0.0633 - val_loss: 0.0964 - val_mean_squared_error: 0.0702\n",
      "Epoch 26/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0887 - mean_squared_error: 0.0625 - val_loss: 0.0963 - val_mean_squared_error: 0.0703\n",
      "Epoch 27/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0876 - mean_squared_error: 0.0616 - val_loss: 0.0937 - val_mean_squared_error: 0.0678\n",
      "Epoch 28/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0873 - mean_squared_error: 0.0615 - val_loss: 0.0916 - val_mean_squared_error: 0.0659\n",
      "Epoch 29/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0858 - mean_squared_error: 0.0602 - val_loss: 0.0931 - val_mean_squared_error: 0.0675\n",
      "Epoch 30/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0854 - mean_squared_error: 0.0599 - val_loss: 0.0929 - val_mean_squared_error: 0.0676\n",
      "Epoch 31/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0851 - mean_squared_error: 0.0598 - val_loss: 0.0932 - val_mean_squared_error: 0.0680\n",
      "Epoch 32/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0841 - mean_squared_error: 0.0590 - val_loss: 0.0940 - val_mean_squared_error: 0.0690\n",
      "Epoch 33/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0835 - mean_squared_error: 0.0585 - val_loss: 0.0898 - val_mean_squared_error: 0.0649\n",
      "Epoch 34/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0828 - mean_squared_error: 0.0580 - val_loss: 0.0885 - val_mean_squared_error: 0.0638\n",
      "Epoch 35/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0825 - mean_squared_error: 0.0578 - val_loss: 0.0871 - val_mean_squared_error: 0.0625\n",
      "Epoch 36/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0816 - mean_squared_error: 0.0571 - val_loss: 0.0861 - val_mean_squared_error: 0.0617\n",
      "Epoch 37/200\n",
      "40000/40000 [==============================] - 2s 40us/sample - loss: 0.0813 - mean_squared_error: 0.0570 - val_loss: 0.0876 - val_mean_squared_error: 0.0633\n",
      "Epoch 38/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0809 - mean_squared_error: 0.0567 - val_loss: 0.0885 - val_mean_squared_error: 0.0644\n",
      "Epoch 39/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0804 - mean_squared_error: 0.0563 - val_loss: 0.0889 - val_mean_squared_error: 0.0648\n",
      "Epoch 40/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0797 - mean_squared_error: 0.0557 - val_loss: 0.0866 - val_mean_squared_error: 0.0627\n",
      "Epoch 41/200\n",
      "38976/40000 [============================>.] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.0555\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "40000/40000 [==============================] - 2s 42us/sample - loss: 0.0795 - mean_squared_error: 0.0556 - val_loss: 0.0908 - val_mean_squared_error: 0.0670\n",
      "Epoch 42/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0730 - mean_squared_error: 0.0493 - val_loss: 0.0820 - val_mean_squared_error: 0.0584\n",
      "Epoch 43/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0729 - mean_squared_error: 0.0493 - val_loss: 0.0808 - val_mean_squared_error: 0.0572\n",
      "Epoch 44/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0726 - mean_squared_error: 0.0490 - val_loss: 0.0801 - val_mean_squared_error: 0.0566\n",
      "Epoch 45/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0725 - mean_squared_error: 0.0490 - val_loss: 0.0806 - val_mean_squared_error: 0.0572\n",
      "Epoch 46/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0722 - mean_squared_error: 0.0488 - val_loss: 0.0799 - val_mean_squared_error: 0.0566\n",
      "Epoch 47/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0716 - mean_squared_error: 0.0484 - val_loss: 0.0822 - val_mean_squared_error: 0.0590\n",
      "Epoch 48/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0713 - mean_squared_error: 0.0481 - val_loss: 0.0814 - val_mean_squared_error: 0.0583\n",
      "Epoch 49/200\n",
      "39936/40000 [============================>.] - ETA: 0s - loss: 0.0713 - mean_squared_error: 0.0483\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0713 - mean_squared_error: 0.0483 - val_loss: 0.0798 - val_mean_squared_error: 0.0568\n",
      "Epoch 50/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0680 - mean_squared_error: 0.0450 - val_loss: 0.0767 - val_mean_squared_error: 0.0538\n",
      "Epoch 51/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0678 - mean_squared_error: 0.0449 - val_loss: 0.0787 - val_mean_squared_error: 0.0558\n",
      "Epoch 52/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0676 - mean_squared_error: 0.0448 - val_loss: 0.0766 - val_mean_squared_error: 0.0538\n",
      "Epoch 53/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0674 - mean_squared_error: 0.0446 - val_loss: 0.0763 - val_mean_squared_error: 0.0535\n",
      "Epoch 54/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0673 - mean_squared_error: 0.0446 - val_loss: 0.0762 - val_mean_squared_error: 0.0535\n",
      "Epoch 55/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0672 - mean_squared_error: 0.0445 - val_loss: 0.0758 - val_mean_squared_error: 0.0532\n",
      "Epoch 56/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0669 - mean_squared_error: 0.0442 - val_loss: 0.0759 - val_mean_squared_error: 0.0533\n",
      "Epoch 57/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0669 - mean_squared_error: 0.0443 - val_loss: 0.0760 - val_mean_squared_error: 0.0534\n",
      "Epoch 58/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0666 - mean_squared_error: 0.0441 - val_loss: 0.0750 - val_mean_squared_error: 0.0525ss: 0.0665 - mean_squared_error\n",
      "Epoch 59/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0665 - mean_squared_error: 0.0441 - val_loss: 0.0756 - val_mean_squared_error: 0.0531\n",
      "Epoch 60/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0664 - mean_squared_error: 0.0440 - val_loss: 0.0750 - val_mean_squared_error: 0.0526\n",
      "Epoch 61/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0661 - mean_squared_error: 0.0438 - val_loss: 0.0754 - val_mean_squared_error: 0.0531\n",
      "Epoch 62/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0661 - mean_squared_error: 0.0439 - val_loss: 0.0747 - val_mean_squared_error: 0.0525ss: 0.0659 - mean_squ\n",
      "Epoch 63/200\n",
      "40000/40000 [==============================] - 2s 42us/sample - loss: 0.0660 - mean_squared_error: 0.0437 - val_loss: 0.0744 - val_mean_squared_error: 0.0522\n",
      "Epoch 64/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0658 - mean_squared_error: 0.0436 - val_loss: 0.0740 - val_mean_squared_error: 0.0518\n",
      "Epoch 65/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0656 - mean_squared_error: 0.0435 - val_loss: 0.0745 - val_mean_squared_error: 0.0524\n",
      "Epoch 66/200\n",
      "40000/40000 [==============================] - 1s 32us/sample - loss: 0.0655 - mean_squared_error: 0.0434 - val_loss: 0.0741 - val_mean_squared_error: 0.0521\n",
      "Epoch 67/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0654 - mean_squared_error: 0.0433 - val_loss: 0.0742 - val_mean_squared_error: 0.0522\n",
      "Epoch 68/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0651 - mean_squared_error: 0.0431 - val_loss: 0.0739 - val_mean_squared_error: 0.0519\n",
      "Epoch 69/200\n",
      "38528/40000 [===========================>..] - ETA: 0s - loss: 0.0651 - mean_squared_error: 0.0432\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0651 - mean_squared_error: 0.0432 - val_loss: 0.0744 - val_mean_squared_error: 0.0525\n",
      "Epoch 70/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0634 - mean_squared_error: 0.0415 - val_loss: 0.0729 - val_mean_squared_error: 0.0510\n",
      "Epoch 71/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0633 - mean_squared_error: 0.0414 - val_loss: 0.0729 - val_mean_squared_error: 0.0511\n",
      "Epoch 72/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0632 - mean_squared_error: 0.0413 - val_loss: 0.0725 - val_mean_squared_error: 0.0507\n",
      "Epoch 73/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0631 - mean_squared_error: 0.0413 - val_loss: 0.0729 - val_mean_squared_error: 0.0511\n",
      "Epoch 74/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0631 - mean_squared_error: 0.0413 - val_loss: 0.0724 - val_mean_squared_error: 0.0506\n",
      "Epoch 75/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0630 - mean_squared_error: 0.0412 - val_loss: 0.0726 - val_mean_squared_error: 0.0509\n",
      "Epoch 76/200\n",
      "40000/40000 [==============================] - 1s 37us/sample - loss: 0.0629 - mean_squared_error: 0.0412 - val_loss: 0.0722 - val_mean_squared_error: 0.0505\n",
      "Epoch 77/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0628 - mean_squared_error: 0.0411 - val_loss: 0.0723 - val_mean_squared_error: 0.0507\n",
      "Epoch 78/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0627 - mean_squared_error: 0.0411 - val_loss: 0.0723 - val_mean_squared_error: 0.0506\n",
      "Epoch 79/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0626 - mean_squared_error: 0.0410 - val_loss: 0.0718 - val_mean_squared_error: 0.0502\n",
      "Epoch 80/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0626 - mean_squared_error: 0.0410 - val_loss: 0.0728 - val_mean_squared_error: 0.0512\n",
      "Epoch 81/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0626 - mean_squared_error: 0.0410 - val_loss: 0.0721 - val_mean_squared_error: 0.0505\n",
      "Epoch 82/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0625 - mean_squared_error: 0.0409 - val_loss: 0.0719 - val_mean_squared_error: 0.0504\n",
      "Epoch 83/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0624 - mean_squared_error: 0.0408 - val_loss: 0.0717 - val_mean_squared_error: 0.0502\n",
      "Epoch 84/200\n",
      "39424/40000 [============================>.] - ETA: 0s - loss: 0.0623 - mean_squared_error: 0.0408\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0623 - mean_squared_error: 0.0408 - val_loss: 0.0720 - val_mean_squared_error: 0.0505\n",
      "Epoch 85/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0614 - mean_squared_error: 0.0399 - val_loss: 0.0711 - val_mean_squared_error: 0.0497\n",
      "Epoch 86/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0614 - mean_squared_error: 0.0399 - val_loss: 0.0711 - val_mean_squared_error: 0.0497\n",
      "Epoch 87/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0613 - mean_squared_error: 0.0399 - val_loss: 0.0710 - val_mean_squared_error: 0.0496\n",
      "Epoch 88/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0612 - mean_squared_error: 0.0398 - val_loss: 0.0712 - val_mean_squared_error: 0.0498\n",
      "Epoch 89/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0612 - mean_squared_error: 0.0398 - val_loss: 0.0712 - val_mean_squared_error: 0.0498\n",
      "Epoch 90/200\n",
      "38720/40000 [============================>.] - ETA: 0s - loss: 0.0611 - mean_squared_error: 0.0397\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0612 - mean_squared_error: 0.0398 - val_loss: 0.0712 - val_mean_squared_error: 0.0498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0607 - mean_squared_error: 0.0393 - val_loss: 0.0706 - val_mean_squared_error: 0.0492\n",
      "Epoch 92/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0607 - mean_squared_error: 0.0393 - val_loss: 0.0707 - val_mean_squared_error: 0.0493\n",
      "Epoch 93/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0607 - mean_squared_error: 0.0393 - val_loss: 0.0706 - val_mean_squared_error: 0.0492\n",
      "Epoch 94/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0607 - mean_squared_error: 0.0393 - val_loss: 0.0707 - val_mean_squared_error: 0.0493\n",
      "Epoch 95/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0606 - mean_squared_error: 0.0392 - val_loss: 0.0708 - val_mean_squared_error: 0.0495\n",
      "Epoch 96/200\n",
      "38848/40000 [============================>.] - ETA: 0s - loss: 0.0606 - mean_squared_error: 0.0392\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0606 - mean_squared_error: 0.0392 - val_loss: 0.0705 - val_mean_squared_error: 0.0491\n",
      "Epoch 97/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0603 - mean_squared_error: 0.0390 - val_loss: 0.0704 - val_mean_squared_error: 0.0491\n",
      "Epoch 98/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0603 - mean_squared_error: 0.0390 - val_loss: 0.0705 - val_mean_squared_error: 0.0491\n",
      "Epoch 99/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0603 - mean_squared_error: 0.0390 - val_loss: 0.0704 - val_mean_squared_error: 0.0491\n",
      "Epoch 100/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0603 - mean_squared_error: 0.0390 - val_loss: 0.0705 - val_mean_squared_error: 0.0491\n",
      "Epoch 101/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0603 - mean_squared_error: 0.0389 - val_loss: 0.0704 - val_mean_squared_error: 0.0490\n",
      "Epoch 102/200\n",
      "39040/40000 [============================>.] - ETA: 0s - loss: 0.0604 - mean_squared_error: 0.0390\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0603 - mean_squared_error: 0.0389 - val_loss: 0.0704 - val_mean_squared_error: 0.0490\n",
      "Epoch 103/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0602 - mean_squared_error: 0.0388 - val_loss: 0.0704 - val_mean_squared_error: 0.0490\n",
      "Epoch 104/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0601 - mean_squared_error: 0.0388 - val_loss: 0.0703 - val_mean_squared_error: 0.0489\n",
      "Epoch 105/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0601 - mean_squared_error: 0.0388 - val_loss: 0.0703 - val_mean_squared_error: 0.0489\n",
      "Epoch 106/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0601 - mean_squared_error: 0.0388 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 107/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0601 - mean_squared_error: 0.0388 - val_loss: 0.0703 - val_mean_squared_error: 0.0490\n",
      "Epoch 108/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0601 - mean_squared_error: 0.0388 - val_loss: 0.0703 - val_mean_squared_error: 0.0489\n",
      "Epoch 109/200\n",
      "39616/40000 [============================>.] - ETA: 0s - loss: 0.0601 - mean_squared_error: 0.0388\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0601 - mean_squared_error: 0.0388 - val_loss: 0.0703 - val_mean_squared_error: 0.0489\n",
      "Epoch 110/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0601 - mean_squared_error: 0.0387 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 111/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0600 - mean_squared_error: 0.0387 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 112/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0600 - mean_squared_error: 0.0387 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 113/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0600 - mean_squared_error: 0.0387 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 114/200\n",
      "39488/40000 [============================>.] - ETA: 0s - loss: 0.0600 - mean_squared_error: 0.0387\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "40000/40000 [==============================] - 2s 38us/sample - loss: 0.0600 - mean_squared_error: 0.0387 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 115/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0600 - mean_squared_error: 0.0387 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 116/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0600 - mean_squared_error: 0.0387 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 117/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0600 - mean_squared_error: 0.0387 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 118/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0600 - mean_squared_error: 0.0387 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 119/200\n",
      "39104/40000 [============================>.] - ETA: 0s - loss: 0.0601 - mean_squared_error: 0.0387\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0600 - mean_squared_error: 0.0387 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 120/200\n",
      "40000/40000 [==============================] - 2s 42us/sample - loss: 0.0600 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 121/200\n",
      "40000/40000 [==============================] - 1s 37us/sample - loss: 0.0600 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 122/200\n",
      "40000/40000 [==============================] - 1s 37us/sample - loss: 0.0600 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 123/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0600 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 124/200\n",
      "38784/40000 [============================>.] - ETA: 0s - loss: 0.0600 - mean_squared_error: 0.0387\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0600 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 125/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0600 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 126/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0600 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 127/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0600 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 128/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0600 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 129/200\n",
      "38976/40000 [============================>.] - ETA: 0s - loss: 0.0600 - mean_squared_error: 0.0386\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0600 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 130/200\n",
      "40000/40000 [==============================] - 2s 39us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 131/200\n",
      "40000/40000 [==============================] - 2s 39us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 132/200\n",
      "40000/40000 [==============================] - 2s 38us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 133/200\n",
      "40000/40000 [==============================] - 1s 37us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 134/200\n",
      "39104/40000 [============================>.] - ETA: 0s - loss: 0.0599 - mean_squared_error: 0.0386\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 135/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 136/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 137/200\n",
      "40000/40000 [==============================] - 1s 37us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 138/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 139/200\n",
      "39552/40000 [============================>.] - ETA: 0s - loss: 0.0600 - mean_squared_error: 0.0387\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 140/200\n",
      "40000/40000 [==============================] - 2s 38us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 141/200\n",
      "40000/40000 [==============================] - 2s 43us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 142/200\n",
      "40000/40000 [==============================] - 2s 40us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 143/200\n",
      "40000/40000 [==============================] - 2s 43us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 144/200\n",
      "39616/40000 [============================>.] - ETA: 0s - loss: 0.0599 - mean_squared_error: 0.0386\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "40000/40000 [==============================] - 2s 39us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 145/200\n",
      "40000/40000 [==============================] - 2s 40us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 146/200\n",
      "40000/40000 [==============================] - 2s 40us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 147/200\n",
      "40000/40000 [==============================] - 2s 39us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 148/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 149/200\n",
      "38656/40000 [===========================>..] - ETA: 0s - loss: 0.0599 - mean_squared_error: 0.0386\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 150/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 151/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 152/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 153/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 154/200\n",
      "39744/40000 [============================>.] - ETA: 0s - loss: 0.0599 - mean_squared_error: 0.0386\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 155/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 156/200\n",
      "40000/40000 [==============================] - 1s 33us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 157/200\n",
      "40000/40000 [==============================] - 2s 42us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 158/200\n",
      "40000/40000 [==============================] - 2s 43us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 159/200\n",
      "38720/40000 [============================>.] - ETA: 0s - loss: 0.0599 - mean_squared_error: 0.0386\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "40000/40000 [==============================] - 2s 45us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 160/200\n",
      "40000/40000 [==============================] - 3s 66us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 161/200\n",
      "40000/40000 [==============================] - 2s 61us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 162/200\n",
      "40000/40000 [==============================] - 2s 41us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 163/200\n",
      "40000/40000 [==============================] - 2s 38us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 164/200\n",
      "39552/40000 [============================>.] - ETA: 0s - loss: 0.0600 - mean_squared_error: 0.0387\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "40000/40000 [==============================] - 2s 42us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 165/200\n",
      "40000/40000 [==============================] - 2s 51us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 166/200\n",
      "40000/40000 [==============================] - 2s 51us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 167/200\n",
      "40000/40000 [==============================] - 2s 42us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 168/200\n",
      "40000/40000 [==============================] - 2s 38us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 169/200\n",
      "38464/40000 [===========================>..] - ETA: 0s - loss: 0.0600 - mean_squared_error: 0.0387\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "40000/40000 [==============================] - 2s 45us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 42us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 171/200\n",
      "40000/40000 [==============================] - 2s 55us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 172/200\n",
      "40000/40000 [==============================] - 2s 43us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 173/200\n",
      "40000/40000 [==============================] - 2s 52us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 174/200\n",
      "39936/40000 [============================>.] - ETA: 0s - loss: 0.0599 - mean_squared_error: 0.0386\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "40000/40000 [==============================] - 2s 38us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 175/200\n",
      "40000/40000 [==============================] - 2s 40us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 176/200\n",
      "40000/40000 [==============================] - 2s 45us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 177/200\n",
      "40000/40000 [==============================] - 2s 47us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 178/200\n",
      "40000/40000 [==============================] - 2s 38us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 179/200\n",
      "38528/40000 [===========================>..] - ETA: 0s - loss: 0.0600 - mean_squared_error: 0.0387\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
      "40000/40000 [==============================] - 1s 37us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 180/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 181/200\n",
      "40000/40000 [==============================] - 2s 57us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 182/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 183/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 184/200\n",
      "39168/40000 [============================>.] - ETA: 0s - loss: 0.0600 - mean_squared_error: 0.0387\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 185/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 186/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 187/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 188/200\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 189/200\n",
      "39936/40000 [============================>.] - ETA: 0s - loss: 0.0599 - mean_squared_error: 0.0386\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 190/200\n",
      "40000/40000 [==============================] - 1s 35us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 191/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 192/200\n",
      "40000/40000 [==============================] - 2s 44us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 193/200\n",
      "40000/40000 [==============================] - 2s 39us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 194/200\n",
      "39872/40000 [============================>.] - ETA: 0s - loss: 0.0599 - mean_squared_error: 0.0386\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 2.980232380322967e-11.\n",
      "40000/40000 [==============================] - 2s 38us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 195/200\n",
      "40000/40000 [==============================] - 2s 42us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 196/200\n",
      "40000/40000 [==============================] - 1s 36us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 197/200\n",
      "40000/40000 [==============================] - 1s 37us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 198/200\n",
      "40000/40000 [==============================] - 1s 37us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 199/200\n",
      "39680/40000 [============================>.] - ETA: 0s - loss: 0.0599 - mean_squared_error: 0.0386\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 1.4901161901614834e-11.\n",
      "40000/40000 [==============================] - 2s 39us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n",
      "Epoch 200/200\n",
      "40000/40000 [==============================] - 2s 39us/sample - loss: 0.0599 - mean_squared_error: 0.0386 - val_loss: 0.0702 - val_mean_squared_error: 0.0489\n"
     ]
    }
   ],
   "source": [
    "_ = model.fit([X_train], y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[scope.print_callback, reduce_lr, tf_board],\n",
    "          validation_data=([X_val], y_val)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope.plt_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='model_task_1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
    "model_path='/tf/srv/hw1/notebooks/model_task_1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
    "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/srv/hw1/notebooks/model_task_1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_task_1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\n"
     ]
    }
   ],
   "source": [
    "model_filename = os.path.join(model_path, model_name)\n",
    "model.save(model_filename)\n",
    "print(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 970 ms, sys: 220 ms, total: 1.19 s\n",
      "Wall time: 933 ms\n"
     ]
    }
   ],
   "source": [
    "%time res = calc_results(model, X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_mse': 0.0462646886159824,\n",
       " 'train_mse': 0.03862083526901778,\n",
       " 'val_mse': 0.04887514734632932}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model for each domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RoboschoolAnt-v1', 'RoboschoolHumanoid-v1', 'RoboschoolHalfCheetah-v1', 'RoboschoolReacher-v1', 'RoboschoolHopper-v1', 'RoboschoolWalker2d-v1']\n"
     ]
    }
   ],
   "source": [
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolHumanoid-v1\n"
     ]
    }
   ],
   "source": [
    "expert_data = load_dataset(dataset_name='RoboschoolHumanoid-v1', dataset_dir=EXPERT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44444, 44)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_data['observations'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoboschoolAnt-v1\n",
      "loading dataset RoboschoolAnt-v1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tf/srv/expert_data/RoboschoolAnt-v1.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-28794459e1b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mexpert_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEXPERT_DATA_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpert_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpert_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-39c4b5cc38f0>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(dataset_name, dataset_dir)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading dataset %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpickle_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s.pkl'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mexpert_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexpert_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tf/srv/expert_data/RoboschoolAnt-v1.pkl'"
     ]
    }
   ],
   "source": [
    "for name in datasets:\n",
    "    print(name)\n",
    "    expert_data = load_dataset(dataset_name=name, dataset_dir=EXPERT_DATA_DIR)\n",
    "    print(expert_data['observations'].shape, expert_data['actions'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoboschoolHumanoid-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolHumanoid-v1\n",
      "DOmain name: RoboschoolHumanoid-v1\n",
      "(35581, 44) (4448, 44) (4448, 44) (35581, 17) (4448, 17) (4448, 17)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'RoboschoolHumanoid-v1'\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_datasets(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='model_RoboschoolHumanoid-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "model_path='/tf/srv/hw1/notebooks/model_RoboschoolHumanoid-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "config_dict = dict(\n",
    "    dataset_name=dataset_name,\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    units=100,\n",
    "    layers = 3,\n",
    "    l2_reg = 1e-04,\n",
    "    lr = 1e-03,\n",
    "    dropout=None,\n",
    "    use_batchnorm=False)\n",
    "\n",
    "\n",
    "model_name = \"model_{dataset_name}__{lr}_lr_{dropout}_dropout_{layers}_layers_{units}_neurons_batch_norm_l2_{l2_reg}\".format(**config_dict)\n",
    "model_path = \"%s/%s\" % (SAVED_MODELS_DIR, model_name)\n",
    "\n",
    "! mkdir -p {model_path}\n",
    "\n",
    "filepath=\"%s/weights-improvement-dummy-{epoch:02d}-{val_loss:.2f}.hdf5\" % model_path\n",
    "\n",
    "\n",
    "print(\"model_name='%s'\" % model_name)\n",
    "print(\"model_path='%s'\" % model_path)\n",
    "print(\"KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(**config_dict)\n",
    "\n",
    "# Callbacks\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error', verbose=1, save_best_only=True, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mean_squared_error', factor=0.5, patience=5, verbose=1)\n",
    "tf_board = TensorBoard()\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "# Define a scope object\n",
    "scope = KerasTrainScope(model_name=model_name, history_dir=model_path)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35581 samples, validate on 4448 samples\n",
      "Epoch 1/200\n",
      "35581/35581 [==============================] - 2s 50us/sample - loss: 0.0836 - mean_squared_error: 0.0646 - val_loss: 0.0571 - val_mean_squared_error: 0.0397\n",
      "Epoch 2/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0533 - mean_squared_error: 0.0365 - val_loss: 0.0495 - val_mean_squared_error: 0.0333\n",
      "Epoch 3/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0471 - mean_squared_error: 0.0314 - val_loss: 0.0445 - val_mean_squared_error: 0.0293\n",
      "Epoch 4/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0437 - mean_squared_error: 0.0289 - val_loss: 0.0428 - val_mean_squared_error: 0.0283\n",
      "Epoch 5/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0415 - mean_squared_error: 0.0273 - val_loss: 0.0402 - val_mean_squared_error: 0.0264\n",
      "Epoch 6/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0395 - mean_squared_error: 0.0259 - val_loss: 0.0384 - val_mean_squared_error: 0.0251\n",
      "Epoch 7/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0381 - mean_squared_error: 0.0250 - val_loss: 0.0374 - val_mean_squared_error: 0.0246\n",
      "Epoch 8/200\n",
      "35581/35581 [==============================] - 2s 44us/sample - loss: 0.0368 - mean_squared_error: 0.0242 - val_loss: 0.0366 - val_mean_squared_error: 0.0241\n",
      "Epoch 9/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0357 - mean_squared_error: 0.0234 - val_loss: 0.0359 - val_mean_squared_error: 0.0238\n",
      "Epoch 10/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0349 - mean_squared_error: 0.0229 - val_loss: 0.0354 - val_mean_squared_error: 0.0236\n",
      "Epoch 11/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0343 - mean_squared_error: 0.0225 - val_loss: 0.0338 - val_mean_squared_error: 0.0222\n",
      "Epoch 12/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0335 - mean_squared_error: 0.0220 - val_loss: 0.0344 - val_mean_squared_error: 0.0231\n",
      "Epoch 13/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0328 - mean_squared_error: 0.0215 - val_loss: 0.0328 - val_mean_squared_error: 0.0217\n",
      "Epoch 14/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0322 - mean_squared_error: 0.0212 - val_loss: 0.0330 - val_mean_squared_error: 0.0221\n",
      "Epoch 15/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0320 - mean_squared_error: 0.0211 - val_loss: 0.0317 - val_mean_squared_error: 0.0209\n",
      "Epoch 16/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0313 - mean_squared_error: 0.0206 - val_loss: 0.0316 - val_mean_squared_error: 0.0210\n",
      "Epoch 17/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0309 - mean_squared_error: 0.0203 - val_loss: 0.0315 - val_mean_squared_error: 0.0211\n",
      "Epoch 18/200\n",
      "35581/35581 [==============================] - 2s 43us/sample - loss: 0.0305 - mean_squared_error: 0.0201 - val_loss: 0.0307 - val_mean_squared_error: 0.0204\n",
      "Epoch 19/200\n",
      "35581/35581 [==============================] - 1s 40us/sample - loss: 0.0301 - mean_squared_error: 0.0199 - val_loss: 0.0306 - val_mean_squared_error: 0.0204\n",
      "Epoch 20/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0297 - mean_squared_error: 0.0196 - val_loss: 0.0317 - val_mean_squared_error: 0.0216\n",
      "Epoch 21/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0294 - mean_squared_error: 0.0194 - val_loss: 0.0306 - val_mean_squared_error: 0.0206\n",
      "Epoch 22/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0292 - mean_squared_error: 0.0193 - val_loss: 0.0295 - val_mean_squared_error: 0.0197\n",
      "Epoch 23/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0288 - mean_squared_error: 0.0190 - val_loss: 0.0299 - val_mean_squared_error: 0.0201\n",
      "Epoch 24/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0286 - mean_squared_error: 0.0188 - val_loss: 0.0289 - val_mean_squared_error: 0.0193\n",
      "Epoch 25/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0283 - mean_squared_error: 0.0187 - val_loss: 0.0292 - val_mean_squared_error: 0.0196\n",
      "Epoch 26/200\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0280 - mean_squared_error: 0.0185 - val_loss: 0.0295 - val_mean_squared_error: 0.0200\n",
      "Epoch 27/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0278 - mean_squared_error: 0.0184 - val_loss: 0.0287 - val_mean_squared_error: 0.0194\n",
      "Epoch 28/200\n",
      "35581/35581 [==============================] - 2s 52us/sample - loss: 0.0276 - mean_squared_error: 0.0182 - val_loss: 0.0288 - val_mean_squared_error: 0.0195\n",
      "Epoch 29/200\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0274 - mean_squared_error: 0.0182 - val_loss: 0.0276 - val_mean_squared_error: 0.0184\n",
      "Epoch 30/200\n",
      "35581/35581 [==============================] - 2s 45us/sample - loss: 0.0272 - mean_squared_error: 0.0180 - val_loss: 0.0275 - val_mean_squared_error: 0.0183\n",
      "Epoch 31/200\n",
      "35581/35581 [==============================] - 2s 44us/sample - loss: 0.0271 - mean_squared_error: 0.0179 - val_loss: 0.0276 - val_mean_squared_error: 0.0186\n",
      "Epoch 32/200\n",
      "35581/35581 [==============================] - 2s 46us/sample - loss: 0.0268 - mean_squared_error: 0.0178 - val_loss: 0.0282 - val_mean_squared_error: 0.0192\n",
      "Epoch 33/200\n",
      "35581/35581 [==============================] - 2s 64us/sample - loss: 0.0267 - mean_squared_error: 0.0177 - val_loss: 0.0275 - val_mean_squared_error: 0.0186\n",
      "Epoch 34/200\n",
      "35581/35581 [==============================] - 2s 45us/sample - loss: 0.0265 - mean_squared_error: 0.0176 - val_loss: 0.0272 - val_mean_squared_error: 0.0183\n",
      "Epoch 35/200\n",
      "35200/35581 [============================>.] - ETA: 0s - loss: 0.0263 - mean_squared_error: 0.0174\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "35581/35581 [==============================] - 2s 44us/sample - loss: 0.0263 - mean_squared_error: 0.0174 - val_loss: 0.0274 - val_mean_squared_error: 0.0186\n",
      "Epoch 36/200\n",
      "35581/35581 [==============================] - 2s 47us/sample - loss: 0.0249 - mean_squared_error: 0.0161 - val_loss: 0.0257 - val_mean_squared_error: 0.0169\n",
      "Epoch 37/200\n",
      "35581/35581 [==============================] - 1s 41us/sample - loss: 0.0248 - mean_squared_error: 0.0160 - val_loss: 0.0259 - val_mean_squared_error: 0.0171\n",
      "Epoch 38/200\n",
      "35581/35581 [==============================] - 2s 43us/sample - loss: 0.0247 - mean_squared_error: 0.0160 - val_loss: 0.0255 - val_mean_squared_error: 0.0168\n",
      "Epoch 39/200\n",
      "35581/35581 [==============================] - 1s 40us/sample - loss: 0.0246 - mean_squared_error: 0.0159 - val_loss: 0.0257 - val_mean_squared_error: 0.0170\n",
      "Epoch 40/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0245 - mean_squared_error: 0.0158 - val_loss: 0.0256 - val_mean_squared_error: 0.0170\n",
      "Epoch 41/200\n",
      "35581/35581 [==============================] - 1s 39us/sample - loss: 0.0244 - mean_squared_error: 0.0158 - val_loss: 0.0253 - val_mean_squared_error: 0.0167\n",
      "Epoch 42/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0243 - mean_squared_error: 0.0157 - val_loss: 0.0261 - val_mean_squared_error: 0.0175\n",
      "Epoch 43/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0242 - mean_squared_error: 0.0157 - val_loss: 0.0259 - val_mean_squared_error: 0.0174\n",
      "Epoch 44/200\n",
      "35581/35581 [==============================] - 1s 41us/sample - loss: 0.0241 - mean_squared_error: 0.0156 - val_loss: 0.0252 - val_mean_squared_error: 0.0167\n",
      "Epoch 45/200\n",
      "35581/35581 [==============================] - 1s 42us/sample - loss: 0.0240 - mean_squared_error: 0.0155 - val_loss: 0.0252 - val_mean_squared_error: 0.0168\n",
      "Epoch 46/200\n",
      "34944/35581 [============================>.] - ETA: 0s - loss: 0.0239 - mean_squared_error: 0.0154\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0239 - mean_squared_error: 0.0155 - val_loss: 0.0253 - val_mean_squared_error: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0231 - mean_squared_error: 0.0147 - val_loss: 0.0243 - val_mean_squared_error: 0.0159\n",
      "Epoch 48/200\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0231 - mean_squared_error: 0.0147 - val_loss: 0.0243 - val_mean_squared_error: 0.0159\n",
      "Epoch 49/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0230 - mean_squared_error: 0.0147 - val_loss: 0.0246 - val_mean_squared_error: 0.0162\n",
      "Epoch 50/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0230 - mean_squared_error: 0.0146 - val_loss: 0.0241 - val_mean_squared_error: 0.0158\n",
      "Epoch 51/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0229 - mean_squared_error: 0.0146 - val_loss: 0.0243 - val_mean_squared_error: 0.0160\n",
      "Epoch 52/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0229 - mean_squared_error: 0.0145 - val_loss: 0.0245 - val_mean_squared_error: 0.0161\n",
      "Epoch 53/200\n",
      "35581/35581 [==============================] - 1s 40us/sample - loss: 0.0229 - mean_squared_error: 0.0145 - val_loss: 0.0240 - val_mean_squared_error: 0.0157\n",
      "Epoch 54/200\n",
      "35581/35581 [==============================] - 2s 45us/sample - loss: 0.0228 - mean_squared_error: 0.0145 - val_loss: 0.0244 - val_mean_squared_error: 0.0161\n",
      "Epoch 55/200\n",
      "34624/35581 [============================>.] - ETA: 0s - loss: 0.0228 - mean_squared_error: 0.0145\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "35581/35581 [==============================] - 1s 42us/sample - loss: 0.0228 - mean_squared_error: 0.0145 - val_loss: 0.0245 - val_mean_squared_error: 0.0162\n",
      "Epoch 56/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0223 - mean_squared_error: 0.0141 - val_loss: 0.0239 - val_mean_squared_error: 0.0156\n",
      "Epoch 57/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0223 - mean_squared_error: 0.0140 - val_loss: 0.0238 - val_mean_squared_error: 0.0155\n",
      "Epoch 58/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0223 - mean_squared_error: 0.0140 - val_loss: 0.0239 - val_mean_squared_error: 0.0156\n",
      "Epoch 59/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0222 - mean_squared_error: 0.0140 - val_loss: 0.0237 - val_mean_squared_error: 0.0155\n",
      "Epoch 60/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0222 - mean_squared_error: 0.0140 - val_loss: 0.0236 - val_mean_squared_error: 0.0154\n",
      "Epoch 61/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0222 - mean_squared_error: 0.0140 - val_loss: 0.0237 - val_mean_squared_error: 0.0155\n",
      "Epoch 62/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0221 - mean_squared_error: 0.0140 - val_loss: 0.0236 - val_mean_squared_error: 0.0155\n",
      "Epoch 63/200\n",
      "35581/35581 [==============================] - 1s 40us/sample - loss: 0.0221 - mean_squared_error: 0.0139 - val_loss: 0.0237 - val_mean_squared_error: 0.0155\n",
      "Epoch 64/200\n",
      "35581/35581 [==============================] - 1s 42us/sample - loss: 0.0221 - mean_squared_error: 0.0139 - val_loss: 0.0236 - val_mean_squared_error: 0.0155\n",
      "Epoch 65/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0221 - mean_squared_error: 0.0139 - val_loss: 0.0235 - val_mean_squared_error: 0.0153\n",
      "Epoch 66/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0220 - mean_squared_error: 0.0139 - val_loss: 0.0235 - val_mean_squared_error: 0.0153\n",
      "Epoch 67/200\n",
      "35581/35581 [==============================] - 1s 40us/sample - loss: 0.0220 - mean_squared_error: 0.0139 - val_loss: 0.0236 - val_mean_squared_error: 0.0155\n",
      "Epoch 68/200\n",
      "35581/35581 [==============================] - 1s 39us/sample - loss: 0.0220 - mean_squared_error: 0.0139 - val_loss: 0.0235 - val_mean_squared_error: 0.0154\n",
      "Epoch 69/200\n",
      "35581/35581 [==============================] - 1s 41us/sample - loss: 0.0219 - mean_squared_error: 0.0138 - val_loss: 0.0235 - val_mean_squared_error: 0.0154\n",
      "Epoch 70/200\n",
      "34752/35581 [============================>.] - ETA: 0s - loss: 0.0219 - mean_squared_error: 0.0138\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0219 - mean_squared_error: 0.0138 - val_loss: 0.0234 - val_mean_squared_error: 0.0153\n",
      "Epoch 71/200\n",
      "35581/35581 [==============================] - 1s 39us/sample - loss: 0.0217 - mean_squared_error: 0.0136 - val_loss: 0.0232 - val_mean_squared_error: 0.0151\n",
      "Epoch 72/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0217 - mean_squared_error: 0.0136 - val_loss: 0.0232 - val_mean_squared_error: 0.0151\n",
      "Epoch 73/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0217 - mean_squared_error: 0.0136 - val_loss: 0.0232 - val_mean_squared_error: 0.0151\n",
      "Epoch 74/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0216 - mean_squared_error: 0.0136 - val_loss: 0.0232 - val_mean_squared_error: 0.0151\n",
      "Epoch 75/200\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0216 - mean_squared_error: 0.0135 - val_loss: 0.0232 - val_mean_squared_error: 0.0151\n",
      "Epoch 76/200\n",
      "35008/35581 [============================>.] - ETA: 0s - loss: 0.0216 - mean_squared_error: 0.0135 ETA: 0s - loss: 0.0216 - \n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0216 - mean_squared_error: 0.0135 - val_loss: 0.0233 - val_mean_squared_error: 0.0152\n",
      "Epoch 77/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0215 - mean_squared_error: 0.0134 - val_loss: 0.0231 - val_mean_squared_error: 0.0150\n",
      "Epoch 78/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0215 - mean_squared_error: 0.0134 - val_loss: 0.0231 - val_mean_squared_error: 0.0150\n",
      "Epoch 79/200\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0215 - mean_squared_error: 0.0134 - val_loss: 0.0232 - val_mean_squared_error: 0.0151\n",
      "Epoch 80/200\n",
      "35581/35581 [==============================] - 1s 40us/sample - loss: 0.0215 - mean_squared_error: 0.0134 - val_loss: 0.0231 - val_mean_squared_error: 0.0150\n",
      "Epoch 81/200\n",
      "35581/35581 [==============================] - 2s 45us/sample - loss: 0.0215 - mean_squared_error: 0.0134 - val_loss: 0.0231 - val_mean_squared_error: 0.0150\n",
      "Epoch 82/200\n",
      "35008/35581 [============================>.] - ETA: 0s - loss: 0.0215 - mean_squared_error: 0.0134\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0215 - mean_squared_error: 0.0134 - val_loss: 0.0231 - val_mean_squared_error: 0.0150\n",
      "Epoch 83/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0214 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0150\n",
      "Epoch 84/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0214 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 85/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0214 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0150\n",
      "Epoch 86/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0214 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 87/200\n",
      "35008/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0133\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0214 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0150\n",
      "Epoch 88/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 89/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 90/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 91/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 92/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 93/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 94/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 95/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 96/200\n",
      "34560/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0133\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0133 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 97/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 98/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 99/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 100/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 101/200\n",
      "34816/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 102/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 103/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 104/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0230 - val_mean_squared_error: 0.0149\n",
      "Epoch 105/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 106/200\n",
      "34304/35581 [===========================>..] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 107/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 108/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 109/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 110/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 111/200\n",
      "34752/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 112/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 113/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 114/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 115/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 116/200\n",
      "34496/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 117/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 118/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 119/200\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 120/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 121/200\n",
      "34048/35581 [===========================>..] - ETA: 0s - loss: 0.0212 - mean_squared_error: 0.0132\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 122/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 123/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 124/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 125/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 126/200\n",
      "34688/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "35581/35581 [==============================] - 1s 33us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 127/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 128/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 130/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 131/200\n",
      "34304/35581 [===========================>..] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 132/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 133/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 134/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 135/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 136/200\n",
      "34432/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 137/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 138/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 139/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 140/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 141/200\n",
      "35136/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 142/200\n",
      "35581/35581 [==============================] - 1s 33us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 143/200\n",
      "35581/35581 [==============================] - 2s 48us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 144/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 145/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 146/200\n",
      "35456/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 147/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 148/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 149/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 150/200\n",
      "35581/35581 [==============================] - 1s 34us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 151/200\n",
      "34112/35581 [===========================>..] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 152/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 153/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 154/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 155/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 156/200\n",
      "34944/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 157/200\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 158/200\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 159/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 160/200\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 161/200\n",
      "34816/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132 ETA: 0s - loss: 0.0213 - mean_squared_error\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 162/200\n",
      "35581/35581 [==============================] - 1s 35us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 163/200\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 164/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 165/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 166/200\n",
      "34560/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
      "35581/35581 [==============================] - 1s 41us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 167/200\n",
      "35581/35581 [==============================] - 1s 41us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 168/200\n",
      "35581/35581 [==============================] - 2s 50us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 169/200\n",
      "35581/35581 [==============================] - 1s 42us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 170/200\n",
      "35581/35581 [==============================] - 1s 40us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 171/200\n",
      "34816/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n",
      "35581/35581 [==============================] - 1s 41us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 172/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 173/200\n",
      "35581/35581 [==============================] - 1s 39us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 174/200\n",
      "35581/35581 [==============================] - 1s 40us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 175/200\n",
      "35581/35581 [==============================] - 1s 39us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 176/200\n",
      "34880/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 177/200\n",
      "35581/35581 [==============================] - 1s 39us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 178/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 179/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 180/200\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 181/200\n",
      "34624/35581 [============================>.] - ETA: 0s - loss: 0.0212 - mean_squared_error: 0.0132\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 2.980232380322967e-11.\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 182/200\n",
      "35581/35581 [==============================] - 1s 42us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 183/200\n",
      "35581/35581 [==============================] - 2s 43us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 184/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 185/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 186/200\n",
      "34432/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0133\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 1.4901161901614834e-11.\n",
      "35581/35581 [==============================] - 1s 37us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 187/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 188/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 189/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 190/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 191/200\n",
      "35328/35581 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0132\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 7.450580950807417e-12.\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 192/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 193/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 194/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 195/200\n",
      "35581/35581 [==============================] - 1s 36us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 196/200\n",
      "34304/35581 [===========================>..] - ETA: 0s - loss: 0.0212 - mean_squared_error: 0.0132\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 3.725290475403709e-12.\n",
      "35581/35581 [==============================] - 1s 40us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 197/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 198/200\n",
      "35581/35581 [==============================] - 2s 45us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 199/200\n",
      "35581/35581 [==============================] - 2s 44us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n",
      "Epoch 200/200\n",
      "35581/35581 [==============================] - 1s 38us/sample - loss: 0.0213 - mean_squared_error: 0.0132 - val_loss: 0.0229 - val_mean_squared_error: 0.0149\n"
     ]
    }
   ],
   "source": [
    "_ = model.fit([X_train], y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[scope.print_callback, reduce_lr, tf_board],\n",
    "          validation_data=([X_val], y_val)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='model_RoboschoolHumanoid-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
    "model_path='/tf/srv/hw1/notebooks/model_RoboschoolHumanoid-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
    "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/srv/hw1/notebooks/model_RoboschoolHumanoid-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolHumanoid-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\n"
     ]
    }
   ],
   "source": [
    "model_filename = os.path.join(model_path, model_name)\n",
    "model.save(model_filename)\n",
    "print(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_mse': 0.01429732729699864,\n",
       " 'train_mse': 0.013212775651986579,\n",
       " 'val_mse': 0.014890401553409038}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_results(model, X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoboschoolHalfCheetah-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mkdir -p {model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolHalfCheetah-v1\n",
      "DOmain name: RoboschoolHalfCheetah-v1\n",
      "(35689, 26) (4462, 26) (4461, 26) (35689, 6) (4462, 6) (4461, 6)\n",
      "model_name='model_RoboschoolHalfCheetah-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "model_path='/tf/srv/hw1/notebooks/model_RoboschoolHalfCheetah-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='RoboschoolHalfCheetah-v1 MSE')\n"
     ]
    }
   ],
   "source": [
    "# Get the datasets\n",
    "dataset_name = 'RoboschoolHalfCheetah-v1'\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_datasets(dataset_name)\n",
    "\n",
    "\n",
    "# Define model\n",
    "config_dict = dict(\n",
    "    dataset_name=dataset_name,\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    units=100,\n",
    "    layers = 3,\n",
    "    l2_reg = 1e-04,\n",
    "    lr = 1e-03,\n",
    "    dropout=None,\n",
    "    use_batchnorm=False)\n",
    "\n",
    "model, model_name, model_path = get_compiled_model(**config_dict)\n",
    "\n",
    "\n",
    "### Callbacks\n",
    "# Reduce learning rate dynamically\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mean_squared_error', factor=0.5, patience=5, verbose=1)\n",
    "tf_board = TensorBoard()\n",
    "\n",
    "# Define a scope object\n",
    "scope = KerasTrainScope(model_name=model_name, history_dir=model_path)\n",
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35689 samples, validate on 4462 samples\n",
      "Epoch 1/100\n",
      "35689/35689 [==============================] - 3s 73us/sample - loss: 0.2269 - mean_squared_error: 0.2040 - val_loss: 0.1073 - val_mean_squared_error: 0.0835\n",
      "Epoch 2/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0940 - mean_squared_error: 0.0698 - val_loss: 0.0821 - val_mean_squared_error: 0.0576\n",
      "Epoch 3/100\n",
      "35689/35689 [==============================] - 2s 51us/sample - loss: 0.0758 - mean_squared_error: 0.0513 - val_loss: 0.0696 - val_mean_squared_error: 0.0452\n",
      "Epoch 4/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0670 - mean_squared_error: 0.0428 - val_loss: 0.0658 - val_mean_squared_error: 0.0418\n",
      "Epoch 5/100\n",
      "35689/35689 [==============================] - 2s 49us/sample - loss: 0.0616 - mean_squared_error: 0.0380 - val_loss: 0.0645 - val_mean_squared_error: 0.0411\n",
      "Epoch 6/100\n",
      "35689/35689 [==============================] - 2s 45us/sample - loss: 0.0574 - mean_squared_error: 0.0343 - val_loss: 0.0587 - val_mean_squared_error: 0.0361\n",
      "Epoch 7/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0542 - mean_squared_error: 0.0318 - val_loss: 0.0562 - val_mean_squared_error: 0.0342\n",
      "Epoch 8/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0515 - mean_squared_error: 0.0298 - val_loss: 0.0529 - val_mean_squared_error: 0.0315\n",
      "Epoch 9/100\n",
      "35689/35689 [==============================] - 2s 42us/sample - loss: 0.0496 - mean_squared_error: 0.0285 - val_loss: 0.0507 - val_mean_squared_error: 0.0299\n",
      "Epoch 10/100\n",
      "35689/35689 [==============================] - 1s 42us/sample - loss: 0.0476 - mean_squared_error: 0.0271 - val_loss: 0.0466 - val_mean_squared_error: 0.0264\n",
      "Epoch 11/100\n",
      "35689/35689 [==============================] - 2s 47us/sample - loss: 0.0459 - mean_squared_error: 0.0260 - val_loss: 0.0454 - val_mean_squared_error: 0.0257\n",
      "Epoch 12/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0444 - mean_squared_error: 0.0251 - val_loss: 0.0498 - val_mean_squared_error: 0.0307\n",
      "Epoch 13/100\n",
      "35689/35689 [==============================] - 2s 42us/sample - loss: 0.0428 - mean_squared_error: 0.0239 - val_loss: 0.0437 - val_mean_squared_error: 0.0250\n",
      "Epoch 14/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0418 - mean_squared_error: 0.0234 - val_loss: 0.0426 - val_mean_squared_error: 0.0244\n",
      "Epoch 15/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0409 - mean_squared_error: 0.0229 - val_loss: 0.0414 - val_mean_squared_error: 0.0236\n",
      "Epoch 16/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0398 - mean_squared_error: 0.0222 - val_loss: 0.0432 - val_mean_squared_error: 0.0258\n",
      "Epoch 17/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0389 - mean_squared_error: 0.0217 - val_loss: 0.0391 - val_mean_squared_error: 0.0220\n",
      "Epoch 18/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0381 - mean_squared_error: 0.0212 - val_loss: 0.0384 - val_mean_squared_error: 0.0217\n",
      "Epoch 19/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0371 - mean_squared_error: 0.0206 - val_loss: 0.0380 - val_mean_squared_error: 0.0217\n",
      "Epoch 20/100\n",
      "35689/35689 [==============================] - 1s 38us/sample - loss: 0.0368 - mean_squared_error: 0.0206 - val_loss: 0.0382 - val_mean_squared_error: 0.0221\n",
      "Epoch 21/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0360 - mean_squared_error: 0.0201 - val_loss: 0.0368 - val_mean_squared_error: 0.0210\n",
      "Epoch 22/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0351 - mean_squared_error: 0.0194 - val_loss: 0.0369 - val_mean_squared_error: 0.0213\n",
      "Epoch 23/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0347 - mean_squared_error: 0.0193 - val_loss: 0.0350 - val_mean_squared_error: 0.0197\n",
      "Epoch 24/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0344 - mean_squared_error: 0.0192 - val_loss: 0.0349 - val_mean_squared_error: 0.0198\n",
      "Epoch 25/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0336 - mean_squared_error: 0.0187 - val_loss: 0.0353 - val_mean_squared_error: 0.0204\n",
      "Epoch 26/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0333 - mean_squared_error: 0.0186 - val_loss: 0.0337 - val_mean_squared_error: 0.0191\n",
      "Epoch 27/100\n",
      "35689/35689 [==============================] - 1s 41us/sample - loss: 0.0328 - mean_squared_error: 0.0183 - val_loss: 0.0335 - val_mean_squared_error: 0.0191\n",
      "Epoch 28/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0324 - mean_squared_error: 0.0181 - val_loss: 0.0328 - val_mean_squared_error: 0.0186\n",
      "Epoch 29/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0318 - mean_squared_error: 0.0176 - val_loss: 0.0337 - val_mean_squared_error: 0.0197\n",
      "Epoch 30/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0317 - mean_squared_error: 0.0177 - val_loss: 0.0333 - val_mean_squared_error: 0.0194\n",
      "Epoch 31/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0312 - mean_squared_error: 0.0174 - val_loss: 0.0330 - val_mean_squared_error: 0.0193\n",
      "Epoch 32/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0309 - mean_squared_error: 0.0173 - val_loss: 0.0327 - val_mean_squared_error: 0.0191\n",
      "Epoch 33/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0309 - mean_squared_error: 0.0173 - val_loss: 0.0314 - val_mean_squared_error: 0.0179\n",
      "Epoch 34/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0300 - mean_squared_error: 0.0166 - val_loss: 0.0320 - val_mean_squared_error: 0.0187\n",
      "Epoch 35/100\n",
      "35689/35689 [==============================] - 1s 38us/sample - loss: 0.0299 - mean_squared_error: 0.0166 - val_loss: 0.0316 - val_mean_squared_error: 0.0184\n",
      "Epoch 36/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0297 - mean_squared_error: 0.0166 - val_loss: 0.0324 - val_mean_squared_error: 0.0194\n",
      "Epoch 37/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0295 - mean_squared_error: 0.0165 - val_loss: 0.0304 - val_mean_squared_error: 0.0175\n",
      "Epoch 38/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0293 - mean_squared_error: 0.0165 - val_loss: 0.0299 - val_mean_squared_error: 0.0171\n",
      "Epoch 39/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0289 - mean_squared_error: 0.0161 - val_loss: 0.0310 - val_mean_squared_error: 0.0183\n",
      "Epoch 40/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0289 - mean_squared_error: 0.0162 - val_loss: 0.0319 - val_mean_squared_error: 0.0194\n",
      "Epoch 41/100\n",
      "35689/35689 [==============================] - 1s 41us/sample - loss: 0.0284 - mean_squared_error: 0.0159 - val_loss: 0.0300 - val_mean_squared_error: 0.0175\n",
      "Epoch 42/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0283 - mean_squared_error: 0.0159 - val_loss: 0.0303 - val_mean_squared_error: 0.0180\n",
      "Epoch 43/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0279 - mean_squared_error: 0.0155 - val_loss: 0.0291 - val_mean_squared_error: 0.0168\n",
      "Epoch 44/100\n",
      "35689/35689 [==============================] - 2s 42us/sample - loss: 0.0278 - mean_squared_error: 0.0156 - val_loss: 0.0293 - val_mean_squared_error: 0.0172\n",
      "Epoch 45/100\n",
      "35689/35689 [==============================] - 2s 46us/sample - loss: 0.0280 - mean_squared_error: 0.0159 - val_loss: 0.0309 - val_mean_squared_error: 0.0188\n",
      "Epoch 46/100\n",
      "35689/35689 [==============================] - 2s 43us/sample - loss: 0.0275 - mean_squared_error: 0.0155 - val_loss: 0.0284 - val_mean_squared_error: 0.0164\n",
      "Epoch 47/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0273 - mean_squared_error: 0.0153 - val_loss: 0.0282 - val_mean_squared_error: 0.0163\n",
      "Epoch 48/100\n",
      "35689/35689 [==============================] - 1s 42us/sample - loss: 0.0273 - mean_squared_error: 0.0155 - val_loss: 0.0283 - val_mean_squared_error: 0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0271 - mean_squared_error: 0.0153 - val_loss: 0.0283 - val_mean_squared_error: 0.0165\n",
      "Epoch 50/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0267 - mean_squared_error: 0.0150 - val_loss: 0.0301 - val_mean_squared_error: 0.0184\n",
      "Epoch 51/100\n",
      "35264/35689 [============================>.] - ETA: 0s - loss: 0.0269 - mean_squared_error: 0.0153\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "35689/35689 [==============================] - 2s 53us/sample - loss: 0.0270 - mean_squared_error: 0.0153 - val_loss: 0.0281 - val_mean_squared_error: 0.0165\n",
      "Epoch 52/100\n",
      "35689/35689 [==============================] - 1s 38us/sample - loss: 0.0240 - mean_squared_error: 0.0125 - val_loss: 0.0257 - val_mean_squared_error: 0.0142\n",
      "Epoch 53/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0240 - mean_squared_error: 0.0125 - val_loss: 0.0251 - val_mean_squared_error: 0.0137\n",
      "Epoch 54/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0238 - mean_squared_error: 0.0124 - val_loss: 0.0251 - val_mean_squared_error: 0.0137\n",
      "Epoch 55/100\n",
      "35689/35689 [==============================] - 1s 38us/sample - loss: 0.0237 - mean_squared_error: 0.0124 - val_loss: 0.0250 - val_mean_squared_error: 0.0136\n",
      "Epoch 56/100\n",
      "35689/35689 [==============================] - 1s 38us/sample - loss: 0.0236 - mean_squared_error: 0.0123 - val_loss: 0.0261 - val_mean_squared_error: 0.0148\n",
      "Epoch 57/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0235 - mean_squared_error: 0.0123 - val_loss: 0.0257 - val_mean_squared_error: 0.0144\n",
      "Epoch 58/100\n",
      "35456/35689 [============================>.] - ETA: 0s - loss: 0.0234 - mean_squared_error: 0.0122\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "35689/35689 [==============================] - 1s 41us/sample - loss: 0.0234 - mean_squared_error: 0.0122 - val_loss: 0.0255 - val_mean_squared_error: 0.0143\n",
      "Epoch 59/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0221 - mean_squared_error: 0.0109 - val_loss: 0.0238 - val_mean_squared_error: 0.0127\n",
      "Epoch 60/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0220 - mean_squared_error: 0.0109 - val_loss: 0.0236 - val_mean_squared_error: 0.0126\n",
      "Epoch 61/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0220 - mean_squared_error: 0.0109 - val_loss: 0.0240 - val_mean_squared_error: 0.0130\n",
      "Epoch 62/100\n",
      "35689/35689 [==============================] - 1s 38us/sample - loss: 0.0219 - mean_squared_error: 0.0109 - val_loss: 0.0241 - val_mean_squared_error: 0.0131\n",
      "Epoch 63/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0219 - mean_squared_error: 0.0109 - val_loss: 0.0240 - val_mean_squared_error: 0.0130\n",
      "Epoch 64/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0218 - mean_squared_error: 0.0108 - val_loss: 0.0234 - val_mean_squared_error: 0.0125\n",
      "Epoch 65/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0217 - mean_squared_error: 0.0108 - val_loss: 0.0237 - val_mean_squared_error: 0.0128\n",
      "Epoch 66/100\n",
      "35689/35689 [==============================] - 1s 38us/sample - loss: 0.0216 - mean_squared_error: 0.0108 - val_loss: 0.0234 - val_mean_squared_error: 0.0125\n",
      "Epoch 67/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0215 - mean_squared_error: 0.0107 - val_loss: 0.0231 - val_mean_squared_error: 0.0123\n",
      "Epoch 68/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0215 - mean_squared_error: 0.0107 - val_loss: 0.0233 - val_mean_squared_error: 0.0125\n",
      "Epoch 69/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0214 - mean_squared_error: 0.0106 - val_loss: 0.0234 - val_mean_squared_error: 0.0126\n",
      "Epoch 70/100\n",
      "35689/35689 [==============================] - 2s 44us/sample - loss: 0.0214 - mean_squared_error: 0.0106 - val_loss: 0.0235 - val_mean_squared_error: 0.0128\n",
      "Epoch 71/100\n",
      "35689/35689 [==============================] - 2s 50us/sample - loss: 0.0213 - mean_squared_error: 0.0106 - val_loss: 0.0240 - val_mean_squared_error: 0.0133\n",
      "Epoch 72/100\n",
      "35072/35689 [============================>.] - ETA: 0s - loss: 0.0213 - mean_squared_error: 0.0106\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "35689/35689 [==============================] - 2s 48us/sample - loss: 0.0213 - mean_squared_error: 0.0106 - val_loss: 0.0230 - val_mean_squared_error: 0.0123\n",
      "Epoch 73/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0205 - mean_squared_error: 0.0099 - val_loss: 0.0227 - val_mean_squared_error: 0.0121\n",
      "Epoch 74/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0205 - mean_squared_error: 0.0099 - val_loss: 0.0225 - val_mean_squared_error: 0.0119\n",
      "Epoch 75/100\n",
      "35689/35689 [==============================] - 1s 38us/sample - loss: 0.0205 - mean_squared_error: 0.0099 - val_loss: 0.0224 - val_mean_squared_error: 0.0118\n",
      "Epoch 76/100\n",
      "35689/35689 [==============================] - 2s 44us/sample - loss: 0.0204 - mean_squared_error: 0.0098 - val_loss: 0.0225 - val_mean_squared_error: 0.0119\n",
      "Epoch 77/100\n",
      "35689/35689 [==============================] - 2s 48us/sample - loss: 0.0204 - mean_squared_error: 0.0098 - val_loss: 0.0224 - val_mean_squared_error: 0.0118\n",
      "Epoch 78/100\n",
      "35689/35689 [==============================] - 1s 41us/sample - loss: 0.0204 - mean_squared_error: 0.0098 - val_loss: 0.0228 - val_mean_squared_error: 0.0122\n",
      "Epoch 79/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0204 - mean_squared_error: 0.0098 - val_loss: 0.0222 - val_mean_squared_error: 0.0116\n",
      "Epoch 80/100\n",
      "35689/35689 [==============================] - 1s 38us/sample - loss: 0.0203 - mean_squared_error: 0.0098 - val_loss: 0.0223 - val_mean_squared_error: 0.0118\n",
      "Epoch 81/100\n",
      "35689/35689 [==============================] - 1s 38us/sample - loss: 0.0203 - mean_squared_error: 0.0098 - val_loss: 0.0224 - val_mean_squared_error: 0.0119\n",
      "Epoch 82/100\n",
      "35689/35689 [==============================] - 1s 35us/sample - loss: 0.0203 - mean_squared_error: 0.0098 - val_loss: 0.0221 - val_mean_squared_error: 0.0116\n",
      "Epoch 83/100\n",
      "35689/35689 [==============================] - 1s 37us/sample - loss: 0.0202 - mean_squared_error: 0.0097 - val_loss: 0.0221 - val_mean_squared_error: 0.0116\n",
      "Epoch 84/100\n",
      "34176/35689 [===========================>..] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0097\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "35689/35689 [==============================] - 1s 37us/sample - loss: 0.0202 - mean_squared_error: 0.0097 - val_loss: 0.0221 - val_mean_squared_error: 0.0117\n",
      "Epoch 85/100\n",
      "35689/35689 [==============================] - 1s 41us/sample - loss: 0.0198 - mean_squared_error: 0.0094 - val_loss: 0.0218 - val_mean_squared_error: 0.0114\n",
      "Epoch 86/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0198 - mean_squared_error: 0.0093 - val_loss: 0.0219 - val_mean_squared_error: 0.0115\n",
      "Epoch 87/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0198 - mean_squared_error: 0.0093 - val_loss: 0.0218 - val_mean_squared_error: 0.0114\n",
      "Epoch 88/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0197 - mean_squared_error: 0.0093 - val_loss: 0.0218 - val_mean_squared_error: 0.0114\n",
      "Epoch 89/100\n",
      "35689/35689 [==============================] - 1s 40us/sample - loss: 0.0197 - mean_squared_error: 0.0093 - val_loss: 0.0218 - val_mean_squared_error: 0.0114\n",
      "Epoch 90/100\n",
      "34816/35689 [============================>.] - ETA: 0s - loss: 0.0197 - mean_squared_error: 0.0093\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0197 - mean_squared_error: 0.0093 - val_loss: 0.0218 - val_mean_squared_error: 0.0114\n",
      "Epoch 91/100\n",
      "35689/35689 [==============================] - 1s 38us/sample - loss: 0.0195 - mean_squared_error: 0.0091 - val_loss: 0.0216 - val_mean_squared_error: 0.0112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "35689/35689 [==============================] - 1s 36us/sample - loss: 0.0195 - mean_squared_error: 0.0091 - val_loss: 0.0216 - val_mean_squared_error: 0.0112\n",
      "Epoch 93/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0195 - mean_squared_error: 0.0091 - val_loss: 0.0216 - val_mean_squared_error: 0.0112\n",
      "Epoch 94/100\n",
      "35689/35689 [==============================] - 2s 42us/sample - loss: 0.0195 - mean_squared_error: 0.0091 - val_loss: 0.0216 - val_mean_squared_error: 0.0112\n",
      "Epoch 95/100\n",
      "35689/35689 [==============================] - 1s 39us/sample - loss: 0.0195 - mean_squared_error: 0.0091 - val_loss: 0.0216 - val_mean_squared_error: 0.0112\n",
      "Epoch 96/100\n",
      "34112/35689 [===========================>..] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.0091\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "35689/35689 [==============================] - 1s 37us/sample - loss: 0.0195 - mean_squared_error: 0.0091 - val_loss: 0.0215 - val_mean_squared_error: 0.0112\n",
      "Epoch 97/100\n",
      "35689/35689 [==============================] - 1s 36us/sample - loss: 0.0193 - mean_squared_error: 0.0090 - val_loss: 0.0215 - val_mean_squared_error: 0.0112\n",
      "Epoch 98/100\n",
      "35689/35689 [==============================] - 1s 35us/sample - loss: 0.0193 - mean_squared_error: 0.0090 - val_loss: 0.0215 - val_mean_squared_error: 0.0112\n",
      "Epoch 99/100\n",
      "35689/35689 [==============================] - 1s 36us/sample - loss: 0.0193 - mean_squared_error: 0.0090 - val_loss: 0.0216 - val_mean_squared_error: 0.0112\n",
      "Epoch 100/100\n",
      "35689/35689 [==============================] - 1s 36us/sample - loss: 0.0193 - mean_squared_error: 0.0090 - val_loss: 0.0215 - val_mean_squared_error: 0.0112\n"
     ]
    }
   ],
   "source": [
    "_ = model.fit([X_train], y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[scope.print_callback, reduce_lr, tf_board],\n",
    "          validation_data=([X_val], y_val)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model for RoboschoolHalfCheetah-v1: /tf/srv/hw1/notebooks/model_RoboschoolHalfCheetah-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolHalfCheetah-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\n"
     ]
    }
   ],
   "source": [
    "model_filename = os.path.join(model_path, model_name)\n",
    "model.save(model_filename)\n",
    "print(\"Saved model for %s: %s\" % (dataset_name, model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJsAAAJdCAYAAACVlnaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xt8VNW9///Xyv0eLgkJICKCigRFAUUU8UIV8K6ItX7V2vqt1lr7O6eeY2utvXlaqdX2aKtt/VpbqbaoFS0qCgKiqIgXFDAiIsidyYVLQkLCJJP1+2NPYgiZECQrm9nzfj4e8yAzs2bPZ8/M+zxOP661trHWIiIiIiIiIiIi0hWS/C5ARERERERERESCQ80mERERERERERHpMmo2iYiIiIiIiIhIl1GzSUREREREREREuoyaTSIiIiIiIiIi0mXUbBIRERERERERkS6jZpOIiIi0MMYcYYyxxphxPtexzhjz4254H6fna4z5mTHmszaPTTXGrDHGRIwxfzuAY11njGns8iK70KHy+xERERF/qdkkIiISAMaYv0X/R76NNjE2GWOmG2P6+11bvIl+hle38/hBN3uMMcnAo8BTwOHA/9fquauNMa8bY6qMMbXGmI+MMff48R0aY35sjFnX3e+7P8aY/zXGLDHG7O7sdxH93qwxJmSMSW3zXKExZk/bBpkx5jhjzExjzNbo85uNMS8YY05sNWZdq8y1vr3QdWcsIiISn9RsEhERCY5FQF+8JsZVwInA075WJG31BXKA2dbazdbaKgBjzF+AvwCvA5OBYcD3gGLgVp9qPRQlA/8AHjrA10WARuDCNo9/A9ja+gFjTCGwIDr+IuBo4ArgfaBXm9f/Gu87bX3bp1EpIiKSaNRsEhERCY6wtTYUbWK8DjwMjDXG5DUPMMbkGmP+bIypiM7YeM8Yc247xzrCGDPfGFNnjFlrjLmy9ZPGmGOMMS8aY2qit+eNMUNaPZ9njPlrdDbJHmPMRmPMb9sc42ZjzMfR58uNMc+0qSHNGHO/MWa7MabMGPM7Y0xKq9enGmOmRWedhKPHuqrNe/Q1xswwxuyMnstCY8zoA/9o92WM6WmMedwYsyF67FXGmFuNMSbG+OuAjdG7r0dnwZxpjJkCfBP4urX2x9bat6y16621C6y11wJ3tTnOacaYpdHZPe8bY05q8/wQY8wz0XPeYYyZa4w5rs2YUdHHa6K/hZnGmIGt6rwLGNhqts7Pos9dFZ1ZVGWMqYz+Bo5u53T7RWcC7Y7+fq7bz2f5regxM9o8/oPo55sEYK29xVp7P/BRR8eL4VHgW62ObYD/i9fka+00oAD4prX23eh38aa19qfW2vltxtZEM9f6tvNL1CYiIhIoajaJiIgEkDGmH3A53oyOSKunHgUm4s2+OAF4E3jBGDO0zSHuiY49AW8myRPNS4iMMZnAXCADOCN6ywFeNsakRV//P8BI4GLgKOCrwMpW9f0cb1bIQ8BxwCRgaZsabsGbdTIm+vd3ga+3ev5XeM2D/wCGA48DjxtjJkTfwwDPAUOBC4CTgTLgFWNMQQcfX2el4zU9LsGbiXQX8HPguhjjn4zWAN7n0hd4C7gG+MxaO6O9F1lrd7S6mwTcjbf8biRQDjzV3IQzxhQBb0QfPx04BVgFLIzO2MEYMwx4DVgMjAbOxvuNvBJt9jyJ991s4ovZOve2Oufm7/ac6OtebPW9N5sGTAeOB2YAj8RoSjV7CkiLfi6tXQs8bq1t6uC1nfUI8BVjzOHR+2fhNZX+1WZc80ynK5ubXCIiInKArLW66aabbrrppluc34C/4S37qQF2AzZ6u7fVmCHRx85r89qlwKPRv4+IjrmrzZi3gL9H/74++h4FrZ4vAuqAa6P3/w38LUat2dGx/9XB+awDZrV57CXgn9G/s4A9wHfajHkWWBD9e0L0XIa1ej4dr5nwkzbnO67VGAvURz/L1rd6oHE/38P9wCut7v8Mr5FEB+/3cdtzjXHs66KvHdnqsTHRx45p9X5vt3mdAdYA/9HqtzKjzZj06Hd6SfT+j4F1naipV/T9T2tzft9vNSYZ2AXcuJ9jzQBebHV/dOtza+ez6PC7aG8sMBv4eav3eyDGd/ILIAxUA69GP9dj2/mN7mnnd3JbV2ZbN91000033eLxpv9aIyIiEhxL8GYinYw3y2YxXtOg2bDov6+3ed3rQEmbxxa3uf9mqzElwMfW2srmJ621ZXgzaJrHPARcbrxNru83xkxuNUukBG9W1Nz9nM+Hbe5vwWtqgdc4S2vnXF5rU+c2a+3Hrercg/c5tT3ftu7A+yxb337SeoAxJskY80NjzIfRJWU1wLeBgfs5dlvtLruLwQLLWt3fEv23+XM5CRjVanljDV6j5wi8GWbNYy5tM2Yb3ndyFB0wxpxgjHnWGPO5MWYXsCH6VNtzbvnurLURvJlWRdFj/Kj1extjTo8OfQw41xjTJ3r/WuAda+2qDj+RA/Mw8M3oDLBLgf/X3iBr7U+i9V4HvA1MAZa3XaYJPMi+v5N2jykiIpJIUvY/REREROJEnbX2s+jfHxljBgO/p9U+Nd3FWjsnulxpInAm3hK3Fc1L3Dop3PawdN8WAGWtPksAjDHlbcbcCtwO/CfwAV5T5z+B8w/wvVo36fanKdq8aWaj/ya1+nc+3pLDtqpajfk73lK3trbFemNjTBZeg/ANvI21y6JPleI1/lrr6Lv7E96yuWabo//OBSqBq4wxDwJX4s0o6kov4DWIngCWWmtXGGOOaG+g9ZYvzgRmGmN+BMwBfom3rLTZ9ra/ExEREdGeTSIiIkH2M+AbrTbELo3+O77NuPHsu+HyKW3un4q33Kv5OMNa73sUnSlyTOvjWGu3W2v/aa29Ea8Bcwbe7KqP8ZaktbcxeWd9hreEqe25nNGqhlKgd3SPouY60/GWnn2ZDabbGg+8bK191Fr7QbTp0OHMoBgeB4aYNpuwNzPG9DyAY72H17jaZK39rM2totWY44E17Yxp3h8qjLf8rbVjgULgDmvtQmvtSqAnBzYzq/l30fo966KPR/CaQNfgXZEvH2+pW5ex1jbi7UU2gQOYgWSttXhNwT77GysiIiKa2SQiIhJY1trVxpjn8WZjTLTWrjHGPA08ZIy5EVgP3IS3uXbb5UHXG2M+wWtMXA2MxdukG7yZHT8BnjTG/Ddes+FevBkqTwIYY36Jd6n4UqAJ+D94+9lssNbWGGPuA35mjKkDXgEy8faSuruT57bbGPMAcJcxpgJvadnleBtMnxMdtgB4B/iHMeZmvJk9d+ItF/tjZ95nP1YB1xhjzsI792vxGlk7OnzVvufyL2PMdOAxY0wJ3r5Cm4FBeMu4dgDf7+Th/oC3p9a/jTH/g3f1u8PwmjcvWmvfwttY/R28zdTvByrwltldAtxvrV0LfA4UG2PGAqvx9nNaj9fguyX6/R2BNzvK0nWm480Y+znwgrV2e+snjXfFwxzg8Oj9E6JPfWatrenke/wCb2+tdr8nY8yFwNfwGl2r8H6/Z+JdMfDZNsNzjDHFbR5rsNbGnCEmIiKSCDSzSUREJNh+g7cPzpnR+/8XbznQ43gNmtOAC6y1n7R53Q+BG4DleDNNrrbWLgWIzkQ5F6/x8DrePkm1wCRrbfPyqXq8/1H/Pl/MpJlsrW1eynUn3r5I38ObZTQX7wpnB+IOvNkp/xs9xtXROudH67R4DZRPgBeBd4Fi4JzW+00dhLvwzv3feHtc9cTbcPqAWWu/jvd5n4n3/azEW+5VhvcddvY4ZXiNwUq8JWCr8GYLDSR6lbXojKRT8Zo2c/Bmmv0/vIbfzuihngOexvvcKvA2va7E+4zPwWsi3gv8F14zpktYa5fj7fd0Al7jqa1H8JYs/hxv5tUH0dvodsbGeo8Ga21lm+WIrZXiNSan4f1+l+Jd/a/56oet/QDvc219e62ztYiIiASV8f7/MBERERERERERkYOnmU0iIiIiIiIiItJl1GwSEREREREREZEuo2aTiIiIiIiIiIh0GTWbRERERERERESky6jZJCIiIiIiIiIiXSbF7wJcW7hwoU1PT/e7DBERERERERGRwNi9e3flhAkTCtt7LvDNpvT0dIYOHep3GSKHtI0bNzJgwAC/yxAJJOVLxB3lS8Qd5UvEjSBla+nSpetjPadldCKCMcbvEkQCS/kScUf5EnFH+RJxI1GypWaTiNCrVy+/SxAJLOVLxB3lS8Qd5UvEjUTJlppNIkJFRYXfJYgElvIl4o7yJeKO8iXiRqJkK/B7NonI/uXl5fldgkhgKV8i7ihfIu4oX3uz1lJTU4O11u9SJM5lZWVRXV3tdxkHxBhDTk7OAS0BVLNJRIhEIn6XIBJYypeIO8qXiDvK195qampIT08nLS3N71IkzjU0NJCamup3GQckHA5TU1NDbm5up1+jZXQiQm1trd8liASW8iXijvIl4o7ytTdrrRpN0iWampr8LuGApaWlHfCsPjWbRITi4mK/SxAJLOVLxB3lS8Qd5UvEjXib1fRlqdkkIoRCIb9LEAks5UvEHeVLxB3lS8SNhoYGv0voFmo2iUjCdNdF/KB8ibijfIm4o3wdWrZv38748eMZP348Q4cOpaSkpOV+OBzu1DFuvvlmVq9e7bjSxLBw4UKuvvrqL/XaA9lkO55pg3ARIT8/3+8SRAJL+RJxR/kScUf5OrT06tWL119/HYBp06aRnZ3NLbfcstcYay3WWpKS2p9T8uCDDzqvM57t7/PrKsnJyQA0NjaSkvJFS6bt/Vi6q86DpWaTiFBZWUl2drbfZYgEkvIl4o7yJeKO8hXbuY984OS4c//viQf8mrVr13LVVVdx/PHHs3z5cmbOnMk999zD8uXLqaur49JLL+W2224DYPLkydxzzz0ce+yxDBkyhG984xvMmzePzMxMnnjiCQoLC/c69i9/+Uu2bNnC2rVr2bx5M3fffTeLFy9mwYIFDBgwgCeeeIKUlBSWLl3KT37yE2praykoKODBBx+kT58+/PWvf+Xxxx8nHA4zePBg/vjHP5KZmcmNN95Iz549+eCDDygvL+euu+7iggsuaPf8tmzZwvXXX09tbS2NjY387ne/Y8yYMUyfPp3f//735OfnM2zYMLKzs7n77ru58cYbueiiizj//PMBGDBgABs3bqS6upprrrmGqqoqGhsbufPOO5k4cWK7n19paSm/+c1vCIfDHHnkkfz+978nOzubuXPn8uMf/5isrCzGjBnT4fdSU1PDD37wA1atWkVDQwO33347kyZNYvr06bz00kvU1taSlJTEf/zHf3DfffeRnZ3N559/zpIlS3jggQeYMWMGANdddx033HBDu3X269fvgH8v3enQboWJSLfQf7kScUf5EnFH+RJxR/mKH6tXr+amm27i7bffpl+/fvz0pz9lwYIFLFq0iIULF/LJJ5/s85rq6mpOPfVUFi1axEknncQTTzzR7rHXr1/P888/z/Tp07nhhhuYMGECb731FklJScyfP589e/Zw++2389hjj/Hqq69yxRVX8Ktf/QqAiy++mPnz57No0SIGDRrEP//5z5bjVlZW8vLLL/P4449z1113xTy3p59+mkmTJvH666+zaNEiSkpK2Lx5M/feey9z5sxh9uzZrFy5cr+fUWZmJn//+99ZuHAhzz77LHfccUe7n19qair3338/zz33HAsXLqSkpIQ///nP7N69m//8z//kySef5NVXX2Xr1q0dvt9vfvMbzj77bObNm8e///1v7rzzTurr6wEoLS1l+vTpPPfccwB8+OGH3HvvvSxZsoT33nuPp59+mvnz5zNnzhz+8pe/8PHHH+9T56HeaALNbBIR6PQ6bxE5cMqXiDvKl4g7yldsX2YGkkuDBg3ixBO/qOmZZ57h8ccfp7GxkVAoxKpVqxg6dOher8nMzOScc84B4IQTTmDx4sXtHvucc84hJSWFYcOGAXDWWWcBMGzYMDZs2MCnn37KJ598wqWXXgpAJBJpaYSUlpZy9913U1VVRU1NDRMnTmw57nnnnYcxhpKSkg4bNyeeeCLf//73qa+v5/zzz2f48OHMnz+f8ePH06tXLwAuueQSNm3a1OFnZK3lF7/4BW+//TZJSUls3ryZbdu27fP5vfPOO6xatYpJkyYBXg5OOeUUVq1axZAhQxg0aBAAU6dO5cknn4z5fq+++irz5s3j/vvvB6C+vr6lxjPOOIMePXq0jB09ejSHHXYYAG+//TYXXnghmZmZAJx//vksXryYs846a5/v+VCnZpOIUFdX53cJIoGlfIm4o3yJuKN8xY+srKyWv9esWcOf//xn5s2bR35+PjfeeCN79uzZ5zWtN4BPSkqisbGx3WOnpaW1jGnvNdZaSkpKmD179j6vvemmm3jqqacYNmwY06dP57333mt5Lj09veVva23Mcxs/fjyzZs1i7ty53HTTTXzve99rqak9KSkpNDU1AV7jq/m8ZsyYQXV1NQsXLiQlJYWSkpKWmUatPz9rLRMmTOBPf/rTXsf94IMDWzppreXxxx9vaU41e+utt1oaSc06u1y1dZ3xQMvoRITi4mK/SxAJLOVLxB3lS8Qd5Ss+7dq1i5ycHHJzcwmFQixYsMDp+x1zzDFs3bqV999/H/BmAjUva9u9ezdFRUU0NDTwzDPPfKnjb9y4kaKiIq677jquuuoqli9fzujRo1m0aBE7duwgHA4za9aslvEDBgxg2bJlALzwwgtEIhHAWzZYUFBASkpKh8vgTj75ZN58803WrVsHQG1tLWvWrOGYY45hzZo1rF+/Hmvtfs/n7LPP5uGHH265v3z58pa/mzcIb8/YsWN58cUXqauro6amhtmzZzN27NiOP6RDlGY2iQihUIiBAwf6XYZIIClfIu4oXyLuKF/xacSIERxzzDGMGTOGww47bL8bWR+s9PR0/va3v/HDH/6QXbt2EYlEuPnmmzn22GO5/fbbmTBhAgUFBYwcObJlJtGBeO2113jooYdITU0lJyeHP/3pT/Tv359bb72Vc889t2WD8GbXXXcdV199NXPmzGHixIktM6i++tWv8rWvfY3TTjuNkSNHMnjw4Hbfr0+fPjzwwANcf/31LUtJ77zzTgYPHsxvf/tbrrjiipYNwjtaunfbbbfxox/9iNNOO42mpiaOPPLIln2xmhtg7Rk1ahRTpkxhwoQJAHzzm99k2LBhrF279sA+uEOA6WjKWhAsXrzYtl2fKiJ727p1K3379vW7DJFAUr5E3FG+RNxRvvZWXV1NXl6e32VIO6ZPn87KlSu5++67/S6lU8LhcIdLAQ9V7WVg6dKl70+YMGF0e+O1jE5EyM3N9bsEkcBSvkTcUb5E3FG+RNzoaBldkGgZnYiwbds2cnJy/C5DJJCULxF3lC8Rd5Qv6U4rVqzg5ptv3uuxzMxM5syZs9/XXnvtta7K2q/p06fzyCOP7PXYqaeeyrRp02K+prGxMSEaTmo2iQg9e/b0uwSRwFK+RNxRvkTcUb6kOx133HG8/vrrfpdxwK699toDbnalpCRGG0bL6EREl7YVcUj5EnFH+RJxR/kScaOpqcnvErpFYrTU4tyeiu1sePQZIrvrGPrz7/ldjgTQl7kyhIh0jvIl4o7yJeKO8iXiRqI0mzSzKQ7YxghrfvdXNjw2k8Za/RcG6XrFxcV+lyASWMqXiDvKl4g7ypeIG6mpqX6X0C3UbIoDGX0LyR9ZQlN9mG2vveN3ORJAoVDI7xJEAkv5EnFH+RJxR/kScaOhocHvErqFmk1xomjy6QCUzX7N50okiDIyMvwuQSSwlC8Rd5QvEXeUr0PLRRddxPz58/d67I9//CO33nprh68bMGAAAFu3buXrX/96u2MuvPBCPvjggw6P88c//pHdu3e33L/iiiuoqqrqTOnSRlJS59ow//jHP7jtttscV+OOmk1xos/kMwComPcmTQ2NPlcjQZOZmel3CSKBpXyJuKN8ibijfB1aLrvsMmbOnLnXYzNnzmTKlCmden3fvn157LHHvvT7/+lPf9pr0/innnqK/Pz8L328RNXY2NjpZlNXvV9H9zv7ui9DG4THiZwhA8k+aiC1q9ez4+0P6X36aL9LkgDZsWMHeXl5fpchEkjKl4g7ypeIO8pXbC8Xn+rkuJNCb8V87uKLL+ZXv/oV4XCYtLQ0NmzYQCgUYuzYsdTU1HD11Vezc+dOGhoauOOOOzjvvPP2ev2GDRu48soreeutt6irq+O73/0uH330EUcfffReTaRbb72VDz74gLq6Oi666CJuv/12/vznPxMKhbjooovo3bs3s2bNYsSIESxYsIDevXvz4IMP8sQTTwBwzTXXcNNNN7FhwwamTp3KKaecwjvvvEPfvn154okn9mli3nzzzWRkZLB8+XIqKyv5/e9/z4wZM3j33XcZPXo0Dz74IAALFixg2rRphMNhjjjiCP7whz+Qk5PDPffcw5w5c6irq+Pkk0/md7/7HcYYLrzwQkaNGsUbb7xBVVUVDzzwAGPHjm33s125ciW33HIL4XCYpqYmHnvsMQYPHsx9993HjBkzKCgooH///owYMYJbbrmFCy+8kF/84heceOKJbNu2jbPPPptly5axYcMGvv3tb7fMAPv1r3/NmDFjeOONN/jVr35Fjx49WL16NW+88QbPPPMMDz/8MOFwmFGjRnHvvfeSnJzME088wf/+7/+Sn59PSUkJ6enpMX8TlZWVfP/732fz5s0A/PKXv+SUU05h2rRprFu3jnXr1nHYYYdx9tln88ILL1BbW0skEuH555/npz/9KfPmzcMYw6233spll122T53vvvtuzPfuDDWb4kjR5DNYu3o6ZS+9rmaTdKnevXv7XYJIYClfIu4oXyLuKF+Hlp49ezJy5EjmzZvHeeedx8yZM7nkkkswxpCRkcH06dPJy8tj27ZtnHvuuUyePBljTLvHevTRR8nMzGTJkiWUlpZy5plntjz34x//mJ49exKJRLjkkksoLS3lxhtv5KGHHmLWrFn7/C4+/PBD/vGPf/DKK69greWcc87htNNOo0ePHqxdu5ZHHnmE+++/n2984xs8//zzXHHFFfvUs3PnTubOnctLL73EVVddxcsvv8zQoUOZMGECK1asoF+/ftx33308++yzZGdnc//99/PQQw9x22238a1vfatlqdm3v/1t5syZw6RJkwBvds68efN45ZVXuOeee3j22Wfb/Tz+9re/ceONNzJ16lTC4TCRSIQPP/yQmTNn8tprr9HY2MhZZ53FiBEjOvyOCgoKmDlzJhkZGaxZs4ZvfetbLFiwAIDly5fz5ptvMnDgQFauXMmzzz7LSy+9RGpqKv/1X//F008/zZlnnsm0adN49dVXycvL46KLLuL444+P+X6333473/nOdzjllFPYtGkTU6ZMYcmSJQCsWrWK2bNnk5mZyT/+8Q+WLVvGG2+8Qc+ePZk1axYrVqxg0aJFbNu2jQkTJnDqqafuU+fBUrMpjvSZNJ61D0yn/OXXOfaX/xnz/3iIHKhdu3aRk5PjdxkigaR8ibijfIm4o3zF1tEMJJemTJnCzJkzW5pNDzzwAADWWv7nf/6Ht956i6SkJLZu3Up5eTlFRUXtHmfx4sXccMMNAJSUlFBSUtLy3HPPPcdjjz1GY2MjZWVlfPLJJ3s939bbb7/N+eefT3Z2NgAXXHABixcvZvLkyQwcOJDjjjsOgBNOOIENGza0e4xJkyZhjGHYsGH06dOHYcOGATB06FA2bNjAli1bWLVqFZMnTwYgHA5z0kknAbBo0SIeeOAB6urq2LlzJ0OHDm1pNl1wwQUAjBgxIuZ7A5x00kncd999bNmyhQsuuIDBgwezePFizj//fLKyslpq3J/GxkZuu+02VqxYQXJyMmvWrGl5buTIkS0NnIULF7Js2TImTJgAQH19PQUFBbz//vuMGzeOgoICAC699NK9jtHWa6+9xqpVq1ru19TUUFNT01Jv61lkZ555Jj179gS872zKlCkkJyfTp08fTjvtND744ANyc3P3qvNgqdkUR/JPGEp630Lqt5RTvewT8k841u+SJCDC4bDfJYgElvIl4o7yJeKO8nXomTx5MnfccQfLli2jrq6OE044AYCnn36ayspKXn31VVJTUxkxYgR79uw54OOvX7+eP/zhD8yfP58ePXpw8803f6njNEtLS2v5OykpKeY+QM3jkpKS2n1NcnIyZ555Jo888sher6uvr+e///u/mT9/PocddhjTpk2jvr6+5fnmJWjJyckd7kF0+eWXM2rUKObOnctXv/pVfvvb33Z4XikpKTQ1NbXU0Oyhhx6isLCQRYsW0dTURN++fVuea25agdccvPLKK/nJT36y13FffPHFDt+3raamJubOndvuZv6t3w9oaQbuT9vXHQxtEB5HTFISRROjV6V7SVelk65TXFzsdwkigaV8ibijfIm4o3wdenJychg3bhy33HILl112Wcvj1dXVFBYWkpqayqJFi9i4cWOHxxk7diz/+te/APj4448pLS0FvNlsWVlZ5OXlUV5ezrx58/Z67+ZZM22PNXv2bHbv3k1tbS0vvvhizL2RvqzRo0ezZMkS1q5dC0BtbS2fffZZSyOsd+/e1NTUMGvWrC91/HXr1nHEEUdw4403MnnyZEpLSzn11FOZPXs2dXV17Nq1izlz5rSMHzBgAMuWLQPY6z2rq6spKioiKSmJJ598kkgk0u77nXXWWcyaNYuKigrA2x9t48aNjBo1ijfffJPt27fT0NDAv//97w7rPuuss3j44Ydb7q9YsaJT5zt27FieffZZIpEIlZWVvPXWW4wcObJTrz0QajbFmT7neVelK39pkc+VSJCEQiG/SxAJLOVLxB3lS8Qd5evQNGXKFD766KO9rkI3depUPvjgA0477TRmzJjBUUcd1eExvvnNb1JbW8uYMWOYNm1ay15Ew4cP5/jjj2fMmDHccMMNjBkzpuU1X//615k6dSoXXXTRXscaMWIEX/va1/jKV77COeecwzXXXNPhPkNfRkFBAQ8++CDf+ta3GDduHBMnTmT16tXk5+dz7bXXctppp3H55Zdz4oknfqnjP/fcc5x66qmMHz+elStXcuWVVzJixAguvfSvRXaKAAAgAElEQVRSxo8fzxVXXLHXsb/73e/y6KOPcsYZZ7B9+/aWx6+//npmzJjB6aefzurVq2POJjryyCP50Y9+xJQpUxg3bhyXXXYZoVCI4uJifvCDHzBx4kQmT57M0Ucf3WHd06ZN48MPP2TcuHGccsop/PWvf+3U+V5wwQWUlJRw+umnc/HFF/Ozn/0s5pLLg2GstV1+0EPJ4sWL7dChQ/0uo8s0NTSyYPj5NFbt4vQ3Z5A9+HC/S5IAKC8vp0+fPn6XIRJIypeIO8qXiDvK196qq6t1db4ENm3aNLKzs7nlllsO+lgNDQ2kpqZ2QVXdq70MLF269P0JEya0e/UyzWyKM0mpKfQ5x9spvuyl132uRoKi9dpoEelaypeIO8qXiDvKl4gbiXKhL20QHof6TD6DLf+aQ9lLr3Hkd6/2uxwJgKqqKnr06OF3GSKBpHyJuKN8ibijfEnQzJ8/n5///Od7PTZw4ED+/ve/7/e1P/zhD7usjkgkQkpK51sx99133z77N1188cXceuutXVaTC1pGF4caa+tYUDKZpvowZy6bRUZRgd8lSZyrra3t9BUKROTAKF8i7ihfIu4oX3vTMjrpKpFIhOTkZL/LOGBaRpcAUrIzKTjjZADKX9ZG4XLwqqqq/C5BJLCULxF3lC8Rd5QvETdiXaUuaNRsilN9Jo0HoPxl7dskB6+hocHvEkQCS/kScUf5EnFH+dqbMYZwOOx3GRIA8bi6LBwOH/BeU922Z5MxZhJwP5AMPGKtndbm+XRgOjAK2AZ81Vq7zhhzMvBw8zDgZ9baZ6OvWQfsAiJAo7W23elbQdTn3HGQlMS2N96nobqG1Lwcv0uSOFZcXOx3CSKBpXyJuKN8ibijfO0tJyeHmpoa6uvr/S5F4lwkEmHPnj1+l3FAjDHk5BxYz6Fbmk3GmGTgQeAcYBPwrjFmlrX241bDrgd2WGuHGGOuBH4NfBX4CBhtrW00xvQFlhljnrfWNkZfd5a1trI7zuNQkta7Bz3HjGDH4g+omP8W/S491++SJI6FQiEGDhzodxkigaR8ibijfIm4o3ztzRhDbm6u32VIAKxfvz4hstVdy+hOBj6z1q611oaBGcDFbcZcDDwW/ftfwARjjLHW7m7VWMoA4m/OmSNF50WX0s3WUjo5ONr8UcQd5UvEHeVLxB3lS8SNRMlWdzWb+gMbW93fFH2s3THR5lIV0BvAGDPGGFMKrAC+3ar5ZIG5xpj3jTE3OKz/kNRnotdsqljwNpH6+JqGJ4eWeLwagki8UL5E3FG+RNxRvkTcSJRsddueTQfDWrsEKDHGHAs8Zox5yVpbD4yz1m42xvQBXjHGfGKt3WuaT3l5Oddffz0pKSlEIhEuu+wybr75ZkKhENnZ2SQnJ1NdXU1hYSHbt2/HWkthYSFlZWUtaxJramooKiqioqICYwy9evWioqKCvLw8IpEItbW1FBcXEwqFSE1NJT8/n8rKSvLz8wmHw9TV1bU8n5aWRm5uLtu2baNnz57U1dVRX1/f8nxGRgaZmZns2LGD3r17s2vXLsLhcMvzmZmZpKWlUVVVRUFBARlDB1H/yeeEFiymsWRQIM6pqqqKhoaGlud1Tu7PaePGjYTD4UCdUxC/J51TfJ5TOBymvr4+UOcUxO9J5xSf57Rx40YaGhoCdU5B/J50TvF5Ts3HDtI5BfF70jnF3zlFIhGqq6sDcU4dMd2xE7oxZizext4To/dvB7DW3t1qzJzomMXGmBQgBBTaNgUaYxYAt1lr32vz+M+AGmvtva0fX7x4sR06dKiDszo0fHbfo3z2m0c47P9cyPD7bve7HIlTu3fvJisry+8yRAJJ+RJxR/kScUf5EnEjSNlaunTp+xMmTGj3Qm3dtYzuXeAoY8wgY0wacCUwq82YWcDXo39fDiyw1troa1IAjDEDgaHAOmNMtjEmN/p4NnAu3mbiCaXovDMAKH95ETYS8bkaiVfbt2/3uwSRwFK+RNxRvkTcUb5E3EiUbHVLsym6x9J3gTnASuApa22pMeYXxpiLosP+AvQ2xnwGfB/4YfTxcXhXoPsQeBb4TvTqc0XAG8aYZcA7wIvW2pe743wOJTlDjyRzYD/C23ay872E67VJF+mOGY4iiUr5EnFH+RJxR/kScSNRstVtezZZa2cDs9s89pNWf9cDU9t53d+Bv7fz+FpgRNdXGl+MMRRNPoN1f/onZbNfo+eYhP9I5EsoLCz0uwSRwFK+RNxRvkTcUb5E3EiUbHXXMjpxqGiyd1W6spdfT5guqXStsrIyv0sQCSzlS8Qd5UvEHeVLxI1EyZaaTQHQY/Rw0gp6Urd+CzUr1/hdjsSh5isdiEjXU75E3FG+RNxRvkTcSJRsqdkUACY5mT4TxwFQ9tLrPlcjIiIiIiIiIolMzaaAKJrsXZWu7KXXfK5E4lFNTY3fJYgElvIl4o7yJeKO8iXiRqJkS82mgOg1bhTJ2Vns+mg1uzds9bsciTNFRUV+lyASWMqXiDvKl4g7ypeIG4mSLTWb4sSexiY2VdXHfD45I53CCWMBKH9ZS+nkwFRUVPhdgkhgKV8i7ihfIu4oXyJuJEq21GyKAxt21nPp9OXcOWdth+P6TD4d0L5NcuCMMX6XIBJYypeIO8qXiDvKl4gbiZItNZviQP+8dFKSDJur97Bjd0PMcYUTTsWkprBjyTLClTu6sUKJd7169fK7BJHAUr5E3FG+RNxRvkTcSJRsqdkUB5KTDMf2yQbgo7LamONS83LoPW4UNDVR/sqb3VWeBECiTOUU8YPyJeKO8iXijvIl4kaiZEvNpjgxvLi52dTxzvV9olelK5/7hvOaJDjy8vL8LkEksJQvEXeULxF3lC8RNxIlW2o2xYnhRTkAlIZiz2wCKBg/GoCd7yzHWuu8LgmGSCTidwkigaV8ibijfIm4o3yJuJEo2VKzKU4M7ZNFkoHPtu2mriH2jzNzYH/SevcgvG0ndes3d2OFEs9qaztuYorIl6d8ibijfIm4o3yJuJEo2VKzKU5kpiYzpHcWTRY+Kd8dc5wxhvxRwwHY+X5pd5Unca64uNjvEkQCS/kScUf5EnFH+RJxI1GypWZTHCnp5L5NPUZHm03vfeS8JgmGUCjkdwkigaV8ibijfIm4o3yJuJEo2VKzKY4079v00X72berRMrNJzSbpnNTUVL9LEAks5UvEHeVLxB3lS8SNRMmWmk1xpKTIm9m0sryWSFPszb/zTxgKSUnsKv2MyO767ipP4lh+fr7fJYgElvIl4o7yJeKO8iXiRqJkS82mONIrK5V+eenUNzaxZntdzHEp2VnkDhuMjUSoWrayGyuUeFVZWel3CSKBpXyJuKN8ibijfIm4kSjZUrMpzgyPzm4qDe1n36ZR2rdJOi9RuusiflC+RNxRvkTcUb5E3EiUbKnZFGdKiqP7NpV1ct+mpboinexfOBz2uwSRwFK+RNxRvkTcUb5E3EiUbKnZFGdaz2yyNva+Ta2vSNfROBGAurrYyzJF5OAoXyLuKF8i7ihfIm4kSrbUbIozh+Wnk5+Rwva6Rrbuit0RzRp0GKm98glXbKduw9ZurFDiUXFxsd8liASW8iXijvIl4o7yJeJGomRLzaY4Y4xpmd30UQf7Nhlj6DGyBICdS7Vvk3QsFAr5XYJIYClfIu4oXyLuKF8ibiRKttRsikPN+zaV7m/fptHaJFw6Jy0tze8SRAJL+RJxR/kScUf5EnEjUbKlZlMc6szMJtAV6aTzcnNz/S5BJLCULxF3lC8Rd5QvETcSJVtqNsWhIQVZpCcbNlbtYWddQ8xx+SceC0lJ7CpdTaRuTzdWKPFm27ZtfpcgEljKl4g7ypeIO8qXiBuJki01m+JQSpJhaB9vdtPH5bGX0qXkZJM79EhsY4Tq5Z90V3kSh3r27Ol3CSKBpXyJuKN8ibijfIm4kSjZUrMpTg2P7tv0UajjfZvyR0U3CddSOulAolx+U8QPypeIO8qXiDvKl4gbiZItNZviVEl036bSsk7u27S01HlNEr/q6+v9LkEksJQvEXeULxF3lC8RNxIlW2o2xalj+2STZGB1ZR31jU0xx7W+Ip21trvKkzhTXFzsdwkigaV8ibijfIm4o3yJuJEo2VKzKU5lpyVzZK9MGpssn1bEXkqXfeQAUnvksqeskvpNoW6sUOJJKKTfhogrypeIO8qXiDvKl4gbiZItNZviWEmRt2/Tig72bTJJSeSPjM5uel9L6aR9GRkZfpcgEljKl4g7ypeIO8qXiBuJki01m+LY8OLO7tsU3ST8fW0SLu3LzMz0uwSRwFK+RNxRvkTcUb5E3EiUbKnZFMeaNwn/uKyWSFPs/Zha9m3SzCaJYceOHX6XIBJYypeIO8qXiDvKl4gbiZItNZviWEF2GsW5aexuaGLdjtiXT8w/cRgYQ/WKVUTq93RjhRIvevfu7XcJIoGlfIm4o3yJuKN8ibiRKNlSsynODY/Obvqog32bUvNyyDn6CGxDI9UrPu2u0iSO7Nq1y+8SRAJL+RJxR/kScUf5EnEjUbKlZlOcKyn2Ngn/aH/7NrUspdO+TbKvcDjsdwkigaV8ibijfIm4o3yJuJEo2VKzKc61ntlkbQf7No06DoCd76nZJPsqLi72uwSRwFK+RNxRvkTcUb5E3EiUbKnZFOcG9MggNz2ZbbsbKKuJ3SHVFemkI6FQyO8SRAJL+RJxR/kScUf5EnEjUbKlZlOcSzKm5ap0He3blH3UQFLyc9mztYL6LeXdVZ7EiUS5/KaIH5QvEXeULxF3lC8RNxIlW2o2BcDwIm/fptIO9m0ySUn0GDkM0FI62VdaWprfJYgElvIl4o7yJeKO8iXiRqJkS82mACgpjs5sKos9swkgf6S3lG7H+yuc1yTxpaqqyu8SRAJL+RJxR/kScUf5EnEjUbKlZlMAHFWQRWqyYf2OeqrrG2OOa74iXdX7pd1VmsSJgoICv0sQCSzlS8Qd5UvEHeVLxI1EyZaaTQGQlpzEMYVZAHxcHnt2U48TvWV0VctX0bQnMS63KJ2TKN11ET8oXyLuKF8i7ihfIm4kSrbUbAqIln2bQrH3bUrtkUf2UUdgww1Uf/Rpd5UmcaChocHvEkQCS/kScUf5EnFH+RJxI1GypWZTQAzv5L5NzUvpdmopnbRSXFzsdwkigaV8ibijfIm4o3yJuJEo2VKzKSCG9cnGAJ9W7Cbc2BRzXI9R3ibhuiKdtBYKhfwuQSSwlC8Rd5QvEXeULxE3EiVbajYFRE56CoN6ZdDQZPm0cnfMcT1GNc9sUrNJvpCdne13CSKBpXyJuKN8ibijfIm4kSjZUrMpQEqi+zZ9VBZ736acYwaRkptN/eYy6rdWdFdpcohLTk72uwSRwFK+RNxRvkTcUb5E3EiUbKnZFCDN+zaVhmLv22SSksiPXpVOs5ukWXV1td8liASW8iXijvIl4o7yJeJGomRLzaYAaZ7ZVFpWS5O1Mce1LKXTvk0SVVhY6HcJIoGlfIm4o3yJuKN8ibiRKNlSsylA+uSk0ScnlZpwhPU76mOOa7ki3VJdkU4827dv97sEkcBSvkTcUb5E3FG+RNxIlGyp2RQwrWc3xZI/0rsiXfWyT2gKN3RLXXJosx3MhBORg6N8ibijfIm4o3yJuJEo2VKzKWCGF3n7Nq0Ixd4kPK1nHtlDDqdpT5jqj1Z3V2lyCEuUqZwiflC+RNxRvkTcUb5E3EiUbKnZFDAj+uYCsHTzLiJNsTum+SObl9Jp3yaBsrIyv0sQCSzlS8Qd5UvEHeVLxI1EyZaaTQEzoEc6fXPTqKpvZFXF7pjjWvZt0ibhAuTk5PhdgkhgKV8i7ihfIu4oXyJuJEq21GwKGGMMYw7PB2DJhqqY43qq2SQiIiIiIiIiDqjZFEAnD8gDYMnG6phjco4ZRHJ2FvWbQtSXVXZXaXKIqqmJvceXiBwc5UvEHeVLxB3lS8SNRMmWmk0BdHzfHDJSkli7vY7ymnC7Y0xyMvknHgtA1ful3VmeHIKKior8LkEksJQvEXeULxF3lC8RNxIlW2o2BVBachKj+nsbhb/TweymnicdB0Dla+90S11y6KqoqPC7BJHAUr5E3FG+RNxRvkTcSJRsqdkUUCd3Yt+movPPBCD073k07Wl/BpQkBmOM3yWIBJbyJeKO8iXijvIl4kaiZEvNpoBq3rfpgy27qG9sandM3vCjyR02hIaduyh/5c3uLE8OMb169fK7BJHAUr5E3FG+RNxRvkTcSJRsqdkUUL2zUjm6IItwxLJsy66Y4/pdMRmAzU+91F2lySEoUaZyivhB+RJxR/kScUf5EnEjUbKlZlOAdeaqdP2mTMQkJ1M5fzF7KrZ3V2lyiMnLy/O7BJHAUr5E3FG+RNxRvkTcSJRsqdkUYKe02rfJWtvumPTCXhScfQo2EmHrzLndWZ4cQiKRiN8liASW8iXijvIl4o7yJeJGomRLzaYAG1KQSa/MFCpqG/h8e33Mcf21lC7h1dbW+l2CSGApXyLuKF8i7ihfIm4kSrbUbAqwJGM4qWUpXeyr0vU5dxypPXLZVbqa6tLV3VWeHEKKi4v9LkEksJQvEXeULxF3lC8RNxIlW2o2BdyYlqV0sfdtSkpPo+8l5wCw+anZ3VKXHFpCoZDfJYgElvIl4o7yJeKO8iXiRqJkS82mgBvZL5fUJMPK8lqq6htjjut3xXkAbP3XHJoaYo+TYEpNTfW7BJHAUr5E3FG+RNxRvkTcSJRsqdkUcFlpyRzXNwcLvNvBVenyTzyW7KMGEt62k8pX3+6+AuWQkJ+f73cJIoGlfIm4o3yJuKN8ibiRKNlSsykBjOnEvk3GGPpHZzdtflJL6RJNZWWl3yWIBJbyJeKO8iXijvIl4kaiZEvNpgTQvG/Te5t20dhkY47rd/kkSEqi/JU3CW+P3ZiS4EmU7rqIH5QvEXeULxF3lC8RNxIlW2o2JYB+eekMyE+nNhzh47KamOMy+hbSe/xobLiBrc/N68YKxW/hcNjvEkQCS/kScUf5EnFH+RJxI1GypWZTgmie3fR2B1elA+j/VW8p3ZZD7Kp0dZtCvH7KVDY89qzfpQRSXV2d3yWIBJbyJeKO8iXijvIl4kaiZEvNpgRxyuHRfZs2dLw8rmjSGaTkZlP14UpqVn3eHaV1yrZF77F73WZCzy/wu5RAKi4u9rsEkcBSvkTcUb5E3FG+RNxIlGyp2ZQghhXlkJ2WzMaqPWyp3hNzXHJmOsUXnQ3A5kNodlPdphAAe0IVPlcSTKFQyO8SRAJL+RJxR/kScUf5EnEjUbKlZlOCSEkyjD4sF9j/7Kb+Xz0fgC3PzMFGIs5r64z6zWXev6HE2Lm/u6WlpfldgkhgKV8i7ihfIu4oXyJuJEq21GxKIGMGePs2LdnY8b5NPU46jqxBh7EnVEnl6+92R2n71TyzKVKzm8aaWp+rCZ7c3Fy/SxAJLOVLxB3lS8Qd5UvEjUTJlppNCeSkAXkYYMXWGnaHY89YMsbQb+pkALY89VI3Vdex5plNoNlNLmzbts3vEkQCS/kScUf5EnFH+RJxI1GypWZTAsnPSOHYPtk0NFmWbtnV4dh+l08CoOyl12iorumO8mKyTU3UtWo2ad+mrtezZ0+/SxAJLOVLxB3lS8Qd5UvEjUTJlppNCWZMJ69Kl3V4X3qdNpKm+jChWfO7o7SYwpU7sOGGlvv1W9Vs6mqJcvlNET8oXyLuKF8i7ihfIm4kSrbUbEowzfs2vbOxmiZrOxzb/4rzANjs81K65v2amu3RMrouV19f73cJIoGlfIm4o3yJuKN8ibiRKNlSsynBDOqVQWF2KjvqGvmssuOOatEFZ5KclcnOd5ZT+/mmbqpwX/Wbyva+r2V0Xa64uNjvEkQCS/kScUf5EnFH+RJxI1Gy1W3NJmPMJGPMKmPMZ8aYH7bzfLox5sno80uMMUdEHz/ZGPNh9LbMGHNpZ48p+zLGtMxuens/S+lSsrMouuAsALY8Ndt5bbE0z2xK79Mb0MwmF0Kh0P4HiciXonyJuKN8ibijfIm4kSjZ6pZmkzEmGXgQmAwMA75mjBnWZtj1wA5r7RDgd8Cvo49/BIy21p4ATAL+bIxJ6eQxpR0t+zZt7LjZBND/Cu+qdJufegnb1OS0rljqNnth7DF6OKCZTS5kZGT4XYJIYClfIu4oXyLuKF8ibiRKtrprZtPJwGfW2rXW2jAwA7i4zZiLgceif/8LmGCMMdba3dbaxujjGUDzRkOdOaa044R+uaQnG1ZX1rFtd0OHY3udeiIZhxVTv7mM7W990E0V7q0+OrOpxyiv2aSZTV0vMzPT7xJEAkv5EnFH+RJxR/kScSNRstVdzab+wMZW9zdFH2t3TLS5VAX0BjDGjDHGlAIrgG9Hn+/MMaUd6SlJnNAvF/A2Cu+ISUqi/9QvZjf5oW6zt2dT/qgSAPaUVfo2yyqoduzY4XcJIoGlfIm4o3yJuKN8ibiRKNlK8buAzrDWLgFKjDHHAo8ZYzrd9SgvL+f6668nJSWFSCTCZZddxs0330woFCI7O5vk5GSqq6spLCxk+/btWGspLCykrKyMnJwcAGpqaigqKqKiogJjDL169aKiooK8vDwikQi1tbUUFxcTCoVITU0lPz+fyspK8vPzCYfD1NXVtTyflpZGbm4u27Zto2fPntTV1VFfX9/yfEZGBpmZmezYsYPevXuza9cuwuFwy/OZmZmkpaVRVVVFQUEBVVVVNDQ0tDzf2XMakt3IEmDhqhDHZdd1eE4pZ4yE3/2Vrc/Pp/8PrieSmtyt57R7w1YAdqQnkdIjl8adu1i3vJS+Q48K/PfUXecUDocpKysL1DkF8XvSOcXnOWVmZrJ169ZAnVMQvyedU3yeUzgcpry8PFDnFMTvSecUn+eUlZXFli1bAnVOQfyedE7xd055eXmsX78+EOfUEWOt7XBAVzDGjAV+Zq2dGL1/O4C19u5WY+ZExyw2xqQAIaDQtinQGLMAuA1I3d8xARYvXmyHDh3q7NziVXlNmKtnlJKRksS/rjmOtOSOJ7m9feGN7Hx3BSf+9W6KJp/RTVVCY00t84acQ1JGGud8/ipvnn0tNSvXMHbuX8k//phuqyPotm7dSt++ff0uQySQlC8Rd5QvEXeULxE3gpStpUuXvj9hwoTR7T3XXcvo3gWOMsYMMsakAVcCs9qMmQV8Pfr35cACa62NviYFwBgzEBgKrOvkMSWGPjlpHNkrg/rGJpZvrdnv+B6jjwNg18q1rkvbS90mbwldRv9ijDFkFBcC2repq4XDYb9LEAks5UvEHeVLxB3lS8SNRMlWtzSbonssfReYA6wEnrLWlhpjfmGMuSg67C9Ab2PMZ8D3gR9GHx8HLDPGfAg8C3zHWlsZ65jdcT5BMebwfADmf7Z9v2Nzhx4JQM0n3dtsqo/u15TZvwiA9GJvqp6uSNe1iouL/S5BJLCULxF3lC8Rd5QvETcSJVvdNbMJa+1sa+3R1trB1tpfRh/7ibV2VvTvemvtVGvtEGvtydbatdHH/26tLbHWnmCtHWmtfa6jY0rnTTqmN0kGFq7ZQXlNx93VnGMGAVCzqrtnNnlXoss8zAtky8ymrWo2daVQKOR3CSKBpXyJuKN8ibijfIm4kSjZ6rZmkxx6+uamc/qgHkQsPFfacfMm+6gjwBhq12ygKdzQPQXyxcymjOaZTX2jzaYyLaPrSoly+U0RPyhfIu4oXyLuKF8ibiRKttRsSnBTj/eaOLM/qaQ2HIk5LiU7k8zD+2IbI9Su3dhd5bXMbGpuNmU0L6PTzKYulZaW5ncJIoGlfIm4o3yJuKN8ibiRKNlSsynBHV2QxYi+OexuaOLFlR3PFvJj36aWPZuiy+jSizWzyYWqqiq/SxAJLOVLxB3lS8Qd5UvEjUTJlppNwtTj+wDwbGkFDZGmmONyjok2m1Z93i11Qes9m9rMbNIG4V2qoKDA7xJEAkv5EnFH+RJxR/kScSNRsqVmk3DSYXkc0TODbbsbeHXNjpjjcppnNnXTJuFNjY3ecjljyOjrNcTSCnpiUpJp2F5FpH5Pt9SRCBKluy7iB+VLxB3lS8Qd5UvEjUTJlppNgjGGy4/zmjlPryjHWtvuuOYr0u3qpplNe7ZWQFMT6X16k5TurWs1SUmkF3md4D1l27qljkTQ0NB9m76LJBrlS8Qd5UvEHeVLxI1EyZaaTQLAWYN7UpCVyvod9by7qbrdMdmDD4ekJHZ/vqlbZhXVNV+JLrqErllLs0lL6bpMcXGx3yWIBJbyJeKO8iXijvIl4kaiZEvNJgEgNTmJS4Z7m28/vby83THJGelkH3kYNDVR+9l65zXVN+/X1H/vMGb09erUFem6TigU8rsEkcBSvkTcUb5E3FG+RNxIlGyp2SQtzh9aQFZqEsu21vBpxe52x3TnJuF1ba5E1yy9uHkZna5I11Wys7P9LkEksJQvEXeULxF3lC8RNxIlW2o2SYvstGTOG+o1cp5eXtbumOZm065P3G8S3nwluoz+ey+ja7kinWY2dZnk5GS/SxAJLOVLxB3lS8Qd5UvEjUTJlppNspdLhxeSbGDRup1srd53X6bmTcK7Y2ZT/abozKYBbWc2ecvoNLOp61RXt79Pl4gcPOVLxB3lS8Qd5UvEjUTJlppNspfC7DTOGtKLJgszP9p376bcodFldL7ObNKeTV2tsLDQ7xJEAkv5EnFH+RJxR/kScSNRsqVmk+xj6nF9AHj50+1U1zfu9VzWkQMwqSnUbdhCY22dsxqstdTvb88mXY2uy2zfvt3vEkQCS/kScUf5EnFH+RJxI1GypWaT7GNQr0xGH5bLnsYmZq3ce6laUmoK2YMPB6D2U3dL6Rp27iKyu47knCxS8nL2eq7lanRllVhrndWQSPQ5irijfIm4o3yJuKN8ibiRKNlSs0naNfV4b+nav0sr2NPYtNdzzfs27XK4b1P9pq2AN6vJGIyZ2XEAACAASURBVLPXcyk52SRnZ9FUt4fGql3OakgkiTKVU8QPypeIO8qXiDvKl4gbiZItNZukXSf0zWFI70yq6ht5ZfXe0/y6Y9+muuYldG32a2qW0Td6RbqQNgnvCmVl7V99UEQOnvIl4o7yJeKO8iXiRqJkS80maZcxpmV20zMryok0fTHVL+eYaLPJ4cymls3B2+zX1Cy9SPs2daWcnJz9DxKRL0X5EnFH+RJxR/kScSNRsqVmk8Q0flAPinLS2Fy9h8Ubqloez2me2bTK3cym+k3Nm4PHmtmkK9KJiIiIiIiIHIrUbJKYkpMMlw33mjr/Wl7e8njWwH4kZaRRv6WchuoaJ++935lNxV5de8q0jK4r1NS4+R5FRPkScUn5EnFH+RJxI1GypWaTdGjSMb3JTU/m4/JaSkNeKExyMtlDBgJQ4+iKdPUtezbFajZF92zSzKYuUVTU/gwyETl4ypeIO8qXiDvKl4gbiZItNZukQ5mpyVxwrNfYeWrFF7ObXG8S3jyzKTPGzKaM5plN2rOpS1RU6HMUcUX5EnFH+RJxR/kScSNRsqVmk+zXJcMKSU02vL2+io076wHIOWYQ4GaT8Ej9HsIV2zHJyaQX9W53TMueTboaXZcwxvhdgkhgKV8i7ihfIu4oXyJuJEq21GyS/eqZlcpXhvTCArM+9po7OccMBtzMbKrf4s2gSu9biElObnfMF1ejU7OpK/Tq1cvvEkQCS/kScUf5EnFH+RJxI1GypWaTdMpFw7zmziurt1HXEHE6s6llv6YYS+igVbOpYjtNjY1dXkOiSZSpnCJ+UL5E3FG+RNxRvkTcSJRsqdkknTK4dxYlRdnsbmhi/mc7yBxQTHJWJnvKtxHeXtWl71W3sXm/ptgbpyWlppBW0BOamghX7OjS909EeXl5fpcgEljKl4g7ypeIO8qXiBuJki01m6TTmmc3zfq4Aowh5+gjAKhZ1bVL6eo2e82mjA5mNkGrfZt0RbqDFolE/C5BJLCULxF3lC8Rd5QvETcSJVtqNkmnjTuiBz0zU1i3o54VoRpyHF2Rrr75SnT9O74kZHrzFenK1Gw6WLW1tX6XIBJYypeIO8qXiDvKl4gbiZItNZuk01KTkzhvaPPspkpn+zbVRfds2t/MpvRir5b6rdok/GAVF3f8WYvIl6d8ibijfIm4o3yJuJEo2VKzSQ7I+UN7k2TgzXU7sUcMBGCXs5lN+1lG1zyzKaSZTQcrFAr5XYJIYClfIu4oXyLuKF8ibiRKttRskgNSkJ3GqQN7ELHwVlI+ADWffo61tkuOb5uaqNtSDkDGfpbRtezZFNLMpoOVmprqdwkigaV8ibijfIm4o3yJuJEo2VKzSQ7YxdGNwl+oaCI5N5uG7VWEK7Z3ybH3VGzHhhtI7ZVPSnZmh2PTi7w6NLPp4OXn5/tdgkhgKV8i7ihfIu4oXyJuJEq21GySA3Z83xwG9sxge32EpiMOB7pu36b66H5NmfvZrwm+mNm0RzObDlplpT5DEVeULxF3lC8Rd5QvETcSJVtqNskBM8Zw4bHerKKNPfsAsGtV1+zbVLfRW7+6vyV08MXMpnrNbDpoidJdF/GD8iXijvIl4o7yJeJGomRLzSb5Ur4ypBdZqUmszvVmF9V00SbhBzKzKbVXPknpaTRW19BYW9cl75+owuGw3yWIBJbyJeKO8iXijvIl4kaiZEvNJvlSstKSOeeoXlT26Qt03TK6uk3/P3v3Hd9mde9x/HMkW5Z3vJ04iRMygRJGgDDLSNmjpVCg7S2Fpi29hdJSRqEbyizQlg4ubaGUUUq5cKGsMMoKI6yEFUb2tOPteNuypXP/sOyEkCHZOpGj5/t+vfSy9OgZv4fwJS//OOc8sY9sMsZsXLep1htDEV3p6lKzTsQV5UvEHeVLxB3lS8QNr2RLzSYZspN2LaGxbAwAbR+vSMgT6bqr+ptNsYxsAsgoj06lW6+pdMNRXh7bP28RiZ/yJeKO8iXijvIl4oZXsqVmkwzZ+IIgU6eMpisrm3BbBz0JaPh0rYtOo4thZBNAsHxgkXA1m4ajpqYm2SWIpCzlS8Qd5UvEHeVLxA2vZEvNJhmWk3crpaG0f3RT60fLh32+gZFNwVhHNo2OTqPTE+mGJRAIJLsEkZSlfIm4o3yJuKN8ibjhlWyp2STDcmBlPh0VFQB8/ObHwzpXX3sHvRva8AUDBIoLYjomWNY/sklPpBue3NzcZJcgkrKULxF3lC8Rd5QvETe8ki01m2RY/D7DuL2mArBqwfCaTQNT6IIV5RhjYjpGI5sSo7GxMdkliKQs5UvEHeVLxB3lS8QNr2RLzSYZtn0P/QwAkRVrqG0b+mMcu6NPoot1vSbQyKZEKSiIbSSZiMRP+RJxR/kScUf5EnHDK9lSs0mGbfSMKQAU1a3nsQ/rhnyerqro4uAxrtcEkDE62mzS0+iGxSuP3xRJBuVLxB3lS8Qd5UvEDa9kS80mGbZAYT6+4kLSe0O89NoSQn2RIZ2nKzqyKRjXyKboNLraBqy1Q7quQHd3d7JLEElZypeIO8qXiDvKl4gbXsmWmk2SEKN23QWAjLXreHFl85DO0T2EkU3+rCBp+bnY3j56GzcM6boC5eWx/zMXkfgoXyLuKF8i7ihfIm54JVtqNklC5E7vbzYV167nkQ+Htlj3QLMpnpFNAMHy/tFN3bVaJHyoampqkl2CSMpSvkTcUb5E3FG+RNzwSrbUbJKEyJk2EYDyxhoW13eyuL4j7nMMTKPLHBtfsykj2mzq0bpNQxYMBpNdgkjKUr5E3FG+RNxRvkTc8Eq21GyShMiJjmyqbO4fnRTv6KZIX1//It/GEBxdGtexwXI9kW64MjMzk12CSMpSvkTcUb5E3FG+RNzwSrbUbJKEyJnaP7Ipo6oKXyTCCyuaaezsjfn4nvX1EImQUVqELyMQ17UHnkjXU6NpdEPV3Dy0dbZEZPuULxF3lC8Rd5QvETe8ki01myQh0vNyCFaUYUO9HBHspjdsuWfh+piP7xpYrynOKXSw8Yl0Gtk0dEVFRckuQSRlKV8i7ihfIu4oXyJueCVbajZJwgyMbjoh2InPwNzFjazdENtjHbsH1muqiH9l/sGRTVqzacja2tqSXYJIylK+RNxRvkTcUb5E3PBKttRskoQZWLcpuG4dx0wtImLhjrdiG900MLIpc2z8zabBNZv0NLohC4VCyS5BJGUpXyLuKF8i7ihfIm54JVtqNknCDDyRrn3xCr62TzkZfsPLqzbwUd32n0w38CS6YEX80+j0NLrhKy+Pv8knIrFRvkTcUb5E3FG+RNzwSrbUbJKEyY2ObGr/eAXF2QFO+Uz/U+Vue6Maa+02j+1eFx3ZNG4I0+hKCsHnI9S4gUgo9kXJZaOamppklyCSspQvEXeULxF3lC8RN7ySLTWbJGGyp0wAoGP5GiKhXk6fUUpuhp/3a9p5c13rNo8dzsgm4/eTUVoIQI+m0g2JVx6/KZIMypeIO8qXiDvKl4gbXsmWmk2SMGnZmWRWjsH2helYsZacjDS+vFf/SKXb36gmHNny6CZrLd3DWLMJNlm3qUbNpqEIBALJLkEkZSlfIu4oXyLuKF8ibnglW2o2SULlTItOpVu8EoCTdy2mNCedlc3dPLe8aYvH9Da3Eu7swp+TRVpezpCuO/hEuhqt2zQULS0tyS5BJGUpXyLuKF8i7ihfIm54JVtqNklCbVwkvL/ZFEjz8fWZowG4c8F6Qn2RTx3TXdU/hS5zbDnGmCFdN1jWv0h4t5pNQ1JcXJzsEkRSlvIl4o7yJeKO8iXihleypWaTJNTgIuGLVwxuO3JSIbsUBqlr7+WRDz/dDBpYrylzCOs1DRgc2bRe0+iGwivddZFkUL5E3FG+RNxRvkTc8Eq21GyShNo4smljs8nvM3xjvzEA/PPdWtp7+j5xTFd0vabgENdrgk3WbKrVyKah6O3VU/xEXFG+RNxRvkTcUb5E3PBKttRskoTKnlwJPh8dK9YRatwwuH2/sXnsOTqHtp4w/3qv7hPHdK8dmEY3jJFN5f1DETWyaWjKy4fe6BORbVO+RNxRvkTcUb5E3PBKttRskoTyBzMoPGAviER4e86PifSEADDGMCc6uumhRXU0dIQGj0nsyCY1m4aipqYm2SWIpCzlS8Qd5UvEHeVLxA2vZEvNJkm4GX/8ORnlxTS/9g6LLroOay0A00uzOXTiKEJhy90LNwase3DNpqE3mzaObKofvJ7ELjs7O9kliKQs5UvEHeVLxB3lS8QNr2RLzSZJuOCYUva56wb8mUGqH3iS5b+5Y/C7c/Ydjc/AU0saWdPcDWwc2ZQ5jJFNaXk5+DODhDu76GvrGN4NeJDf7092CSIpS/kScUf5EnFH+RJxwyvZUrNJnMifMY09/3wlGMOyG26j+v+eBmBsfpDjpxUTsfC3t6oJd/cQqm/CpPnJKCsa8vWMMRufSFejqXTxam1tTXYJIilL+RJxR/kScUf5EnHDK9lSs0mcKT36EKZfeQEA7//gappffxeAr+5TTkaaj1dXt/D+e6sACI4uxQyzw5tR1j+VrrtGT6SLV0lJSbJLEElZypeIO8qXiDvKl4gbXsmWmk3iVOU3T2f8OadiQ70sPOcyOlauoygrndP2KAXgsec/BCBYMfQn0Q0IDoxsWq9mU7yampqSXYJIylK+RNxRvkTcUb5E3PBKttRsEqeMMUz/1fcpmX0gvU0tLPiviwk1t3LaHqXkB9NoXFUNQObYBDSb9ES6IdOi6iLuKF8i7ihfIu4oXyJueCVbajaJc760NPb885Xk7j6FzuVrePucy8i0Yb6yVxl5G/q7uoExw282bfpEOomPV4ZyiiSD8iXijvIl4o7yJeKGV7KlZpPsEGk52cy8+wYyyoppfu0dFl10HcdPL6K8swWAD2zWsK8xMLKpRyOb4lZbW5vsEkRSlvIl4o7yJeKO8iXihleypWaT7DDBMaXsc/cN+DODVD/wJGt/fxdTwx0APNueRnVrz7DOPzCyqVsjm+KWk5OT7BJEUpbyJeKO8iXijvIl4oZXsqVmk+xQ+TOmseetV4AxLPv1Xwkv+giAptwC/vDK2mHNX80YWLNJT6MTERERERERSZqYm03GGDWmJCFKjzmU6VdcAECkOwSALStmQVUbL6zYMOTzBsuKAAjVNWHD4eEXOkSRUC/vfOfnrLz1n0mrIV7t7e3JLkEkZSlfIu4oXyLuKF8ibnglWzE1kIwxfqDDGJPhuB7xiMpvnc74c04FIFA0irMPngjAra+to72nb0jn9GUESC8chQ2H6WloTlit8Wp86S1qHv4PK35/V9JqiFdZ2fAXaBeRLVO+RNxRvkTcUb5E3PBKtmJqNllrw8ASoMhtOeIVxhim/+r7TL54DrtecxHHTCti97Jsmrv6+Ntb64d83uDo6CLhNclbJLzhhdcB6G1qIZTEplc86us19VDEFeVLxB3lS8Qd5UvEDa9kK56pcf8AHjPGfN0YM9sYc+TAy1Vxktp8aWlMvngOoz8/G58xfP+QcfgNPP5RAx/VdQzpnMHoIuE9SVy3qeGFNwbfty9bnbQ64mGMSXYJIilL+RJxR/kScUf5EnHDK9mKp9n030AB8EvgNuD26Ou2xJclXjShIJPTZpRhgZtfXkNfJP7FwpP9RLquqlo6lq4a/NyxkzSbCgsLk12CSMpSvkTcUb5E3FG+RNzwSrZibjZZaydu5bWLywLFW766dznluQFWNHXz0KK6uI8feCJdT21yptENTKEb0LF052g2eWUop0gyKF8i7ihfIu4oXyJueCVbcT1hzhiTZoz5rDHmy8aYQ40xaa4KE28Kpvk4/6CxANy1sIbatlB8xyd5ZFPD8/3NpqLD9gN2npFNeXl5yS5BJGUpXyLuKF8i7ihfIm54JVsxN5uMMdOBj4B7gQuAfwIfG2N2dVSbeNT+4/I5bOIoevoi/Gn+WqyNfTrdwMim7iSs2RTp66PxpbcAmPCtMwBo30lGNoXD4WSXIJKylC8Rd5QvEXeULxE3vJKteEY23QL8BRhnrT3QWjsWuDW6XSShvnPgWLLSfby2ppVXVrfEfFwyn0bX8s5H9LW0kTVxLEWH7Y9J89O1dj3hrp4dXku8OjqGtiC7iGyf8iXijvIl4o7yJeKGV7IVT7NpL+A39pPDTH4X3S6SUEVZ6XxjvzEA3PLqOjpDsXV/M8qS9zS6gSl0xYfPwpeeRtaECrCWzpVrd3gt8SovL092CSIpS/kScUf5EnFH+RJxwyvZiqfZVA0cttm2Q6PbRRLuhOnFTCvJoqGzlzsXrI/pmEDRKEx6Gr0b2nb4iKKBxcGLj5gFQPbkSmDnmEpXU1OT7BJEUpbyJeKO8iXijvIl4oZXshVPs+nHwCPGmPuMMdcbY+4DHoluF0k4v8/w/YPH4TPw7w/rWdrQud1jjM9HRmkRAD21O250U++GVlre/giTnkbhwfsAG5tNO8Mi4enp6ckuQSRlKV8i7ihfIu4oXyJueCVbMTebrLWPAHsDi4Dc6M+Z1tp/x3K8MeZYY8xiY8wyY8xlW/g+wxjzr+j3rxtjJkS3H2WMWWCMeT/688hNjnkhes53oq/SWO9Hdg6Ti7M4ZfcSIhZufnkt4cj2FwsfWLdpRz6RrnHeWxCJULDfDNKys4BNRzat2mF1DFV+fn6ySxBJWcqXiDvKl4g7ypeIG17JVkzNJmOM3xjzArDGWnuVtfa70Z9LYj0e+BNwHLAb8GVjzG6b7TYHaLbWTgZ+C1wf3d4AnGSt3QP4OnD3Zsd91Vq7V/RVF0s9snM5a+ZoSrLTWdLQyWMfbX/h74En0vXU7rhFwjdOodt/cFvO1AnAzjGyqaFhxy+oLuIVypeIO8qXiDvKl4gbXslWTM0ma20YmBjr/luwP7DMWrvCWhsC7gM+v9k+nwfujL5/AJhtjDHW2rettQPrQn0AZBpjMoZYh+yEMtP9fPfAsQDc83bNdhcLD5b3LxLe8PzrfHI9ezestRubTYfPGtyePWk8AB3L12AjEed1DIdXuusiyaB8ibijfIm4o3yJuOGVbKXFse8VwP8YY34BrAMGf4u31m7vN+kKYNNHcq0DZm1tH2ttnzGmBSiif2TTgFOBhdbaTVd+vsMYEwYeBK7a7Gl51NXVMWfOHNLS0giHw3zxi1/kvPPOo6amhuzsbPx+P62trZSUlNDU1IS1lpKSEmpra8nJyQGgvb2dsrIy6uvrMcZQWFhIfX09eXl5hMNhOjo6KC8vp6amhvT0dPLz82loaCA/P59QKERXV9fg94FAgNzcXBobGykoKKCrq4vu7u7B74PBIJmZmTQ3N1NUVERbWxuhUGjw+8zMTAKBAC0tLRQXF9PS0kJvb+/g96l6T7vm+ZiUn8bylj7+/uoyTpqUtdV78h2wB+bv/0fVv56gkwhTfnE+kUjE2T1lNrXTXV2HvyCPwOTxrF69evCe/EWjCDduYPXC9zElo0bsn1N1dTU9PT36d0/3pHtycE/GGLq6ulLqnlLxz0n3tHPeU3V1NaFQKKXuKRX/nHRPO+c9+Xw+Ojs7U+qeUvHPSfe0891Teno6LS0tKXFP22JiHflhjBloKG16gAGstda/nWNPA4611n4z+vlrwCxr7fmb7LMous+66Ofl0X0aop93p39B8qOttcuj2yqstVXGmFz6m033WGvv2vTa8+fPt9OnT4/pHmVke299Gxc/voysdB93nbE7ecGt90rrnn6Ft7/5Y2yol/FzTmPXqy7EGOOkrlV/vo+Pf/F7xpx2DDP++ItPfPfGF8+n6dWFzLz3N5QceYCT6yfC6tWrqaysTHYZIilJ+RJxR/kScUf5EnEjlbK1cOHCBbNnz953S9/FMy1uYvS1yyavgc/bUwWM2+Tz2Oi2Le5jjEkD8oHG6OexwEPAWQONJgBrbVX0ZxtwL/3T9SRFzRidyz4VuXT2Rvjf97e9PFfp0Qez9+3XYALprLn9AT66/CZnU+q2NIVuQPaUneOJdOXl5ckuQSRlKV8i7ihfIu4oXyJueCVbMS8QTv96SjXW2tWbv2I4xZvAFGPMRGNMADiT/lFKm3qE/gXAAU4DnrPWWmPMKOBx4DJr7Sub1JRmjCmOvk8HTqT/CXmSws6eORqAhxfV0dTZu819S486mH3uuA5fRoA1f/8/PrzsxoSvnRTu6qFp/tsAFB326V7nztJsqqmpSXYJIilL+RJxR/kScUf5EnHDK9naIQuEW2v7gPOBp4CPgPuttR8YY640xpwc3e12oMgYswz4IXBZdPv5wGTg58aYd6KvUiADeMoY8x7wDv0jo/46lPpk5zG9NJsDK/PpCVv++U7tdvcvmX0ge/+9v+G09s6HEt5wan7jXSLdIfL2mEpGSeGnvs+Z3N9sal86sptNgUAg2SWIpCzlS8Qd5UvEHeVLxA2vZGtHLRCOtfYJ4InNtv18k/fdwJe2cNxVwFVbOe3MmCqXlHL2zNG8trqFJz5u4LQ9SinL3XZYS444gH3uvJ6FZ/+ItXc9jA2H2f2GH2F8Q3244kYNz/dPoSvawhQ6gOzJO8fIptzc3GSXIJKylC8Rd5QvEXeULxE3vJKteH7bvg04C1gBhIBeoC/6U2SHmViYyeGTCuiNWO55e31MxxQfPot97roBXzDAun88yqKLrkvICKdtrdcEEBxTij8zSKi+id4NrcO+niuNjY3JLkEkZSlfIu4oXyLuKF8ibnglWztqgXCRhDprn9H4DDyztIl1Ld0xHVP82f2YefeN+DIzqPrnYyy68BpsODzkGrrX19P+8Qr8WZkU7LfHFvcxPt/guk3tI3h0U0FBQbJLEElZypeIO8qXiDvKl4gbXslWzM2mTRYDXwuE4lwgXCShKvIzOGZqERELdy2IbXQTQNGh+zLz7hvxZwap+tcTvP+DoTecBkY1FR68D75A+lb3G5xKN4LXberq6kp2CSIpS/kScUf5EnFH+RJxwyvZirnZZIwZZYy5F+gGlkW3nWyM2dp6SiJOfXXvctJ9hhdWbGB5Y2fMxxUdMpOZ/7gJf2aQ6v+dy/vfv2pIDaftTaEbsDOs29TdHdvoMBGJn/Il4o7yJeKO8iXihleyFc80uluBFqCS/jWbAOYDZyS6KJFYlOYEOHHXYgDujGN0E0DhQXsz896b8GdlUv3AUyy/+a64jrfhMI3z3gSg+IhtN5tydoJmU3l5ebJLEElZypeIO8qXiDvKl4gbXslWPM2m2cAF1tr1RJ9EZ62tB0pdFCYSizP3LCMjzcdra1r5qK4jrmMLD9ybvW6/GoBlN95O06tvx3xsy7uL6W1uJXP8GLImjt3mvoNrNo3gaXQ1NTXJLkEkZSlfIu4oXyLuKF8ibnglW/E0m1qA4k03GGPGA/ENKRFJoIKsdL64ewkAf3+rOu7jS444gF0uOAsiEd797i8INTTHdNymU+iMMdvcN2viWPD56FpdTaQntM19kyUYDCa7BJGUpXyJuKN8ibijfIm44ZVsxdNsug140BhzBOAzxhwI3En/9DqRpDltRinZAT9vV7fzdnVb3MdPvvSbjNp/Bj01Dbx3wVXYSGS7xww2m47Yf7v7+oMZZI0fjQ2H6VxVFXd9O0JmZmaySxBJWcqXiDvKl4g7ypeIG17JVjzNpuuBfwF/AtKBvwH/Bm52UJdIzHIz0vjSHv2zOf/+VjXW2riO96Wlsef/XEF6QR4Nz81n1a33bXP/3tZ2WhZ8gEnzU3TIvjFdY2CR8PYRum5Tc3NsI7pEJH7Kl4g7ypeIO8qXiBteyVbMzSbb72Zr7W7W2mxr7a7W2t/ZTX6zN8Zc5qZMkW075TMl5AfT+Kiuk9fXtsZ9fGZFGXvc/FMAllzzP2xYsGir+za+9BY2HGbUvp8hLTc7pvMPPpFu6aq4a9sRioqKkl2CSMpSvkTcUb5E3FG+RNzwSrbiGdkUix8n+HwiMclM9/PlvcqA/tFNkThHNwGUHn0Ileeege0L8865P6d3w5abVpuu1xSrnKkTgJH7RLq2tvinH4pIbJQvEXeULxF3lC8RN7ySrUQ3m7a9UrKIQydOL6Y4O50VTd3MW7FhSOeY9pPvkrfndLrX1bDoh9d+akqetZaG5+NvNg1OoxuhT6QLhUbmwuUiqUD5EnFH+RJxR/kSccMr2Up0syn+4SQiCRJI8/HVvcsBuGvhesKR+P919AXS2esvvyItN5vaJ15kzd8e/MT3HcvX0L2uhvTCUeTNmBbzeQen0S1bE/eaUjtCeXl5sksQSVnKl4g7ypeIO8qXiBteyVaim00iSXXM1CLG5AVY19LD7W8ObTpdVmUFn7npcgA+vuIPtLy3ePC7xhfeAKD4sP0wvtjjEyjMJ71wFOGOTnpqGuKuybWamppklyCSspQvEXeULxF3lC8RN7ySLU2jk5SS5jOcO2ssPgMPvF/HNc+toqcvEvd5yk8+knFfPwUb6uXdc39GX1sHMLT1mgbkTB2YSrcq7mNd88rjN0WSQfkScUf5EnFH+RJxwyvZSnSz6aUEn08kbgdW5nPVMZPISvcxb+UGLnl8Kc2dvXGfZ/oVF5C722Q6V65j0SXXE+kJ0fTKQgCKDt8/7vNtfCLdyFu3KRAIJLsEkZSlfIm4o3yJuKN8ibjhlWxts9lkjDkyltfA/tba492XLLJ9+47N43cnT6UsJ8DH9Z1875HFrGzqiusc/mAGe/7lV/izMql5+D8suuhawl3d5Ow6iWBZcdw1bVy3aeQ1m1paWpJdgkjKUr5E3FG+RNxRvkTc8Eq2tjey6fbNXk8Cc4F7oj+fBG5zWaDIUE0oyOT3J09l19Is6tp7ufDRJby5tjWuc+RMrmT3X18CQPUDTwFDm0I3cC4Ymc2m4uL4m2ciEhvlS8Qd5UvEHeVLxA2vZGubzSZr7cSBF/BX4A9AgbV2DFAA/D66XWREKshK59fHT+GwXUbR2RvhZ08vq4+0ZQAAIABJREFU55EP6+M6x5jTjqXizBMGPxcfMbRmU/aU6JpNI7DZ5JXuukgyKF8i7ihfIu4oXyJueCVb8azZdCFwmbW2EyD683Lghy4KE0mUjDQflx8xga/sVUbEwh9fXcct89cRjsT+pLpdr/4heXtOJ2viWAr2nzGkOjLHluMLBuhZXz+44PhI0dsb/5pWIhIb5UvEHeVLxB3lS8QNr2QrnmZTB7D5qsj7AZ2JK0fEDZ8xnL3vGC49rJJ0n+HhD+r5xTMr6AyFYzo+LTuTA5/4K4e+ch/+YMaQajB+P9m7jAdG3lS68vLyZJcgkrKULxF3lC8Rd5QvETe8kq14mk0/A540xtxrjLneGHMv/Ws2/dRNaSKJ97kphVx3/GTyMvy8sbaVCx9dQl17KKZjjd+P8Q3vAY4Di4SPtKl0NTU1yS5BJGUpXyLuKF8i7ihfIm54JVsx/+Zsrb0bmAV8BOQBHwMHRLeL7DT2KM/h5pOnMTY/g5XN3Xzv34tZXL9jprWN1CfSZWdnJ7sEkZSlfIm4o3yJuKN8ibjhlWzFNUzDWvshcDVwpbX2yuhnkZ1ORX4GN588lb3G5NDc1cfFjy3l5ZUbnF83e0p0Gt3SkdVs8vv9yS5BJGUpXyLuKF8i7ihfIm54JVsxN5uMMaOiU+e6gWXRbScbY65yVZyIS7kZaVx9zCSOmVpIT9hy5bMruf/dWqyNfeHweOVMmQBA+whrNrW2tia7BJGUpXyJuKN8ibijfIm44ZVsxTOy6VagBagEBha5mQ+ckeiiRHaUdL+PHx46njn7jQHgtjer+d3La+mL40l18RhYILxz1ToivX1OrjEUJSUlyS5BJGUpXyLuKF8i7ihfIm54JVvxNJtmAxdYa9cDFsBaWw+UuihMZEcxxnDGnmX8dPYEAn7D3MWN/OTJZbT3JL4Z5M8KEhxbju3to2tNdcLPP1RNTU3JLkEkZSlfIu4oXyLuKF8ibnglW/E0m1qA4k03GGPGA+sTWpFIknx2YgE3njCFgsw03q5u5/uPLGF9a0/Cr5MzZeQtEu5y6qCI1ylfIu4oXyLuKF8ibnglW/E0m24DHjTGHAH4jDEHAnfSP71OJCVML83m9ydPo7IgyNqWHi54ZAkf1ib2SXXZA+s2LVmV0PMOh1eGcookg/Il4o7yJeKO8iXihleyFU+z6XrgX8CfgHTgb8C/gZsd1CWSNGW5AX530lRmVuTS0t3HJU8s5YXlzQk7f/bkkTeyqba2NtkliKQs5UvEHeVLxB3lS8QNr2QrpmaTMcYPnAPcaq3dzVqbba3d1Vr7O+uVMWDiKdkBP1cdM4kTpxfTG7Zc8/wq/vF2TUKGPOZEm03tI6jZlJOTk+wSRFKW8iXijvIl4o7yJeKGV7IVU7PJWhsGfmOtTfwCNiIjlN9n+N7BYzl3VgUGuHPBen7z0hoiw2w4ZQ+u2bTGM/N1RURERERExDvimUb3qDHmJGeViIxAxhhO3aOUXxw1kYw0H08taeLet2uGdc5AcQFp+bn0tbQRakjc9LzhaG9vT3YJIilL+RJxR/kScUf5EnHDK9mKp9kUBB4wxrxgjLnbGHPXwMtVcSIjxUGVo/j57IkY4K6FNby2pmXI5zLGDD6RbqQsEl5WVpbsEkRSlvIl4o7yJeKO8iXihleyFU+zaRFwDfA8sAxYvslLJOXtNy6Ps/cdDcB1z69i7YbuIZ9rpC0SXl9fn+wSRFKW8iXijvIl4o7yJeKGV7KVFuuO1torXBYisjM4c88yljZ08fKqDfzymRX8/vPTyA744z7PSGs2GWOSXYJIylK+RNxRvkTcUb5E3PBKtuIZ2YQxJmCM2cMYc4Qx5siBl6viREYaYwyXHDaeyoIga1t6uOHF1UNaMDxnyshqNhUWFia7BJGUpXyJuKN8ibijfIm44ZVsxdxsMsYcAqwGXgSeAR4AngJuc1OayMiUme7nl5+bSHbAz6urW/jnO7VxnyN7ygRg5KzZ5JWhnCLJoHyJuKN8ibijfIm44ZVsxTOy6bfAr621hUBb9OevgFucVCYyglXkB7n8iMr+BcMXrOf1OBcMzxw/GpOeRndVLX0dXW6KjENeXl6ySxBJWcqXiDvKl4g7ypeIG17JVjzNpqnAzZttuw64MHHliOw89h+Xz9dnjsYC172wmqqW2BcM96WlkT1xHACdK9Y4qjB24XA42SWIpCzlS8Qd5UvEHeVLxA2vZCueZlMLMNCCW2+M2Q0oAHISXpXITuLMvco4uDKfjlCYXz6zks5Q7P/hyI6u29Q+AtZt6ujoSHYJIilL+RJxR/kScUf5EnHDK9mKp9n0f8Dx0fd/A54HFtC/dpOIJ/mM4ZLDKhk/KsjqDd3cOG81NsYFw7MnjwegY2nyRzaVl5cnuwSRlKV8ibijfIm4o3yJuOGVbMXcbLLW/sBae2/0/Y3AacC3oi8Rz8oK+PnlUf0Lhr+8qoX73o1twfCc6CLhHUtXuSsuRjU1NckuQSRlKV8i7ihfIu4oXyJueCVb8Yxs+gRr7UvW2rnW2kgiCxLZGY3ND3LZ4f0Lhv/9rfW8sXb7C4ZnTx450+jS09OTXYJIylK+RNxRvkTcUb5E3PBKtmJuNhljXjLGzNvSy2WBIjuLWePz+drAguHPr6aqpWeb+w9Mo+tcsRab5EXi8vPzk3p9kVSmfIm4o3yJuKN8ibjhlWzFM7LpNuD2TV6PA+XAfxzUJbJT+speZRxUmU97KMxlc5expKFzq/um5WSTMbqESE+IrnXJG0rZ+PJbrH7yxaRdXyTVNTQ0JLsEkZSlfIm4o3yJuOGVbMWzZtOdm72up3/B8KPclSeycxlYMHxaSRa17SEufHQJj3/csNVFwzeu27Tjp9JFekJ8ePlNvHnaBaz53jW0fbxih9cg4gVe+b9XIsmgfIm4o3yJuOGVbA15zaaoKmBGIgoRSRXZAT83nTCFE6cX0xu23PzyWm6ct4buvk8vbza4btMOXiS8q6qW1085jzV3PNi/IRJh2Q237dAaRLwiFAoluwSRlKV8ibijfIm44ZVsxbNm0zc2e51P/1S619yVJ7JzCqT5uOCQcVx6WCUZfsMzS5v4wSOLqWrp/sR+A82mtfc8QuNLb+2Q2hpefINXjzqbloUfEKwoY587r8dkBKh9/AVa3v5wh9Qg4iVdXV3JLkEkZSlfIu4oXyJueCVb8Yxs+tpmr2OBV4GvOKhLJCV8bkohv//8NCryMljR1M15Dy/m5ZUbBr8vP+kIMseNpnP5Gt780gUs+K+LaV+yykktNhJh+W/v4K0zL6S3qYXiI2Zx0DN/p/SYQxn3jVMBWHLdn51cW8TLysvLk12CSMpSvkTcUb5E3PBKtuJZs+mIzV4nWmt/aq1tdFmgyM5uYmEmf/zCNA6ZMIrO3ghXPruSv7xeRV/EklFSyCHz7mXKj7+DPyeL+v+8yitHfI0PfnQDPfVNCash1NzKwq9dwtLr/wrA5IvnMPOeGwkU9s8XDp5yJGl5OTS++CaNLy9I2HVFBGpqkvcAAJFUp3yJuKN8ibjhlWzFM41ul1heLosV2VllB/z8bPYEzp1Vgd/AA+/XcenjS2ns6MWfmcGkC87is/PvZ9xZp2CtZe2dDzHvwNNZ/vu7CHf1DOvaLe9+zPyjz6H+2fmkF+Qx8x83MfniORi/f3CfzJJCJn63f5Dikmtv3eqC5iISv0AgkOwSRFKW8iXijvIl4oZXshXPNLplwNLoa9P3A58HtonIFhhjOHWPUm48YQpFWeksqu3guw9/zLvVbQBklBSy+68v4ZDn76Zk9oGE2ztZes2tvHTImVQ/+BQ28ukFxrfFWsvae/7N6yd/h66168nbczoHPX0HJUce8Kl9c3NzqfzW6QSKRtGy4APqn3klIfcsIv35EhE3lC8Rd5QvETe8kq14mk1zgPuA6UAw+vNeYI611hd9+bd1AhGB3ctzuOWUaew1Jofmrj5+NHcZD75fNziaKGfaRGb+4yb2vf9mcnefQndVLe+ddwXzj/smDfPepHN1NZ2rq/pfq9bRsTL6WrG2/7V8De1LV7HoB1fzwcXXE+kJMe6sUzjgkVvJHDd6izU1NjaSlp3FLj/4OgBLrv1z3M0tEdmyxkbNNhdxRfkScUf5EnHDK9kysU6XMcasA6ZYa7s22ZYFLLHWjnVU37DNnz/fTp8+PdlliHxKOGK5a8F6/vluLQAn7VrMdw8ci99nBvex4TBV989l6XV/oae2Ie5r+DIz2P36S6k4/bht7tfa2kpeXh6RnhDzDjqD7qpaZtzyS8Z88ei4rykinzSQLxFJPOVLxB3lS8SNVMrWwoULF8yePXvfLX0Xz8gmHzBhs22VgEYziQyB32c4Z78x/PiICaT7DY9+1MAvnllBZyg8uI/x+xn75RM59NV/MfniOWTtMo7g2HIyx43uf40f0/+qHEPWhIr+18SxZO0yjoID9+bAx/+63UYTbHz8pi8jwOSL5gCw7Nd/JdLb5+TeRbzEK4+3FUkG5UvEHeVLxA2vZCstjn1/CzxnjLkDWAuMA86ObheRITp8UgEl2en84pkVvLG2lYseX8qvjt6F4uyNC8elZWcy+eI5TL54jpMauru7B9+POf1YVt5yDx3L1lB132OM+9oXnFxTxCs2zZeIJJbyJeKO8iXihleyFfPIJmvtDcA5QBlwMlAOfMNa+2tHtYl4xu7lOdx88jQq8jJY3tjFBf9ewvLGzh12/fLy8sH3vrQ0plz6bQCW3fS3YT8NT8TrNs2XiCSW8iXijvIl4oZXshXPNDqstU9aa+dYa4+z1n7DWvukq8JEvKYiP4ObT57KZ8qzaejs5YePLeWNtS075No1NTWf+Fx24uHk7TGVnpoG1vz9wR1Sg0iq2jxfIpI4ypeIO8qXiBteyVbMzSZjzA+NMXtF388yxqwxxqw0xhzkrjwRb8kLpnHdcZM5YlIBXb0Rfv70Ch77KP6FweMVDAY/8dn4fEy57FwAVvzhbvraOuI+Z6wPHxBJdZvnS0QSR/kScUf5EnHDK9mKZ2TThcDK6PvrgN8AV6E1m0QSKuD3cdnhlXxlrzIiFn7/ylr+8noVEYfNm8zMzE9tKz7yAAoO2JPephZW3vrPmM8Vamjmg0tv4OnKw1l9+wOJLFNkp7SlfIlIYihfIu4oXyJueCVb8TSb8q21LcaYXGBP4A/W2tuBaW5KE/EuYwxn7zuGiz47Hr+BB96v46pnV9HTF3Fyvebm5i3WMDC6adWt9xFq3LDNc0R6Qqy85V7mHXg6a+96CBvqZeWf7sGGw9s8TiTVbSlfIpIYypeIO8qXiBteyVY8zaa10SlzZwLzrLVhY0weoN8kRRw5ZmoR1xw7meyAn5dXbeCSx5eyoas34dcpKira4vbCA/ai+MgDCXd0suIPd29xH2sttXNf5OXDvsriK/9IX1sHxUceSLCijO7qOhpfWZjwekV2JlvLl4gMn/Il4o7yJeKGV7IVT7PpEuAB4CfAr6LbTgTeSHRRIrLR3hW5/O6kKZTlBPi4vpMfPbGMlu6+hF6jra1tq99Nvbz/yXRr7niQ7uq6T3zX+sFS3jzte7x9zuV0rqoie8oEZt77G/a99yYqzjgBgOr7n0horSI7m23lS0SGR/kScUf5EnHDK9mKudlkrX3CWjvGWjvBWrsguvl/gZMH9jHGfDnRBYoIVBZkcvPJUxmXn8HK5m5+9MQyWhPYcAqFQlv9Lm+PaZSfPJtIT4hlv70DgJ76JhZdfB2vfu5sml5ZSHpBHrtecxEHP3cXJUceAEDF6ccCUPv4i/S1x7/AuEiq2Fa+RGR4lC8Rd5QvETe8kq14RjZ9irW211q76ZyePw+zHhHZisKsdH59whTG5mewoqmLH81NXMOpvLx8m99PvvSbGL+fqnsfY/HV/8O8A09n3T2PYPw+Kr99Bp+dfz+V3zgVX3ra4DFZE8ZSMGtPwl3d1Dz6fELqFNkZbS9fIjJ0ypeIO8qXiBteydawmk1bYBJ8PhHZRFFWOjccP4WKvAyWN3Zx2dxltPUMv+FUU1Ozze9zJldSccbx2HCYlX+4m3B7JyVHHczBL9zDrld+n/RReVs8bszpxwFQdf/cYdcosrPaXr5EZOiULxF3lC8RN7ySrUQ3m9w9m11EACjKTueGEyYzJi+DZY1dXD53Oe3DbDjF8vjNSRd9g4yyYnJ2ncS+9/2WmXffQM7kym0eU37SkfiCAZrnv03n6uph1Siys/LK421FkkH5EnFH+RJxwyvZSnSzSUR2gOLsADecMJnRuQGWNHRy+ZPL6QgN/cGQgUBgu/tkVpRx+NsPc8jzd1N8+KyYzpuel0PZcYcBUP3gU0OuT2RnFku+RGRolC8Rd5QvETe8ki01m0R2UiXZAW44YQrluQEW13fy4yeXDbnh1NLSEtN+xhf/fzIGptJV/+9crNXgR/GeWPMlIvFTvkTcUb5E3PBKthLdbFqT4POJyDaU5gS44fgplOUE+Kiuk588uZzOITSciouLHVQXPfdn9yOjvJjOlevY8Ob7zq4jMlK5zJeI1ylfIu4oXyJueCVbcTWbjDH5xpj9jTFHbvoa+N5a+5nElygi21KW2z+lrjQnnQ/rOvjJU/E3nFx2143fz5hTjwGg6v4nnF1HZKTyyv+9EkkG5UvEHeVLxA2vZCvmZpMx5mygGngUuH2T121OKhORmJXnZnDD8VMoyU7ng9oOfvr0crp6Y2849fb2OqwOxnypfypdzb+fJdzV4/RaIiON63yJeJnyJeKO8iXihleylRbHvlcDp1lr9QxzkRFodF4GN5wwhYsfX8qimg4ufHQJ4/KDhK0lHCH60278HH0fsZZJBUG+WxEhmOZmGbfc6buQN2M6re99TN1T8xj9haOcXEdkJCovL092CSIpS/kScUf5EnHDK9mK5zfLNOBpV4WIyPCNyesf4VSUlc6Kpm5eXLmBl1e1MH9NC2+sbWVBVRvvVLfzfk07H9Z1sLi+k6UNXTy5tHlYC4zHoiK6UHjV/U86u4bISFRTU5PsEkRSlvIl4o7yJeKGV7IVz8im64GfGmN+Za2NuCpIRIanIj+DW784nYVVbRjA7zP4feA3Br/P4DMb3/t9hs5QmBteWMWimg4ufWIp1xw7mfxgPP9piM3oU47i4yv+QMMLr9Nd20CwzBsL44lkZ2cnuwSRlKV8ibijfIm44ZVsxfMb5YVAOXCpMaZx0y+steMTWpWIDEt+MI0jJhXEvP8Vh5dz7av1LG3o4uLHlnLtcZMozg4ktKZA0ShKPncQdXPnsf7Bp5n43a8k9Pybstay+rb78QczGPe1Lzi7jkgs/H5/sksQSVnKl4g7ypeIG17JVjzT6P4L+BxwPPC1zV4ishMLhru46cSpVBYEWb2hmx8+tpT1rYlfyHvjVLonsNYm/PwDll73Zz7+2c18cMmvaV+6ytl1RGLR2tqa7BJEUpbyJeKO8iXihleyFXOzyVr74tZeLgsUEfdKSkooykrnphOmMK0ki5q2EBc+toTVzV2Jvc7sg0gvzKf94xW0vr8koecesOKP97Di5rsGP6++7X+dXEckViUlJckuQSRlKV8i7ihfIm54JVtxPXrKGLOXMeZ7xpgrjDFXDrxcFSciO0ZTUxMAecE0rj9uMjPKc2jq7OOix5aypKEzYdfxBdIZfUr/k+iq738iYecdsPbuh1ly1S0ATLrwnOh15tK7wRv/90BGpoF8iUjiKV8i7ihfIm54JVsxN5uMMd8GXgGOBH4E7AFcBEx2U5qI7CibTmnLCvi5+thJzBqXR2tPmEsfX8p769sTdq2K048HoPr/niES6k3Yedc//AwfXHoDALtdexFTfvQtij67H+Gubtbd+1jCriMSL5dTRkW8TvkScUf5EnHDK9mKZ2TTpcCx1tpTgK7oz9OAxP22KCJJsflQzow0Hz//3EQO22UUnb0RfvzkMt5Y25KQa+XNmEbOtIn0Nm2g4fnXEnLOumde4b3zrwRrmfLj7zD+nFMBqPzm6QCs/tsDRPr6EnItkXh5Zai0SDIoXyLuKF8ibnglW/E0m0qttS9F30eMMT5r7VzgpFgONsYca4xZbIxZZoy5bAvfZxhj/hX9/nVjzITo9qOMMQuMMe9Hfx65yTEzo9uXGWN+b4wxcdyPiETV1tZ+alu638dlh0/guGlFhMKWXz6zknkrmod9LWPM4OimqvvnDvt8ja8s5J1v/QTbF2bieV9ll+9tfGZByecOJGviWLrX1VD35EvbOIuIO1vKl4gkhvIl4o7yJeKGV7IVT7Np3UADCFgCfN4YcygQ2t6Bxhg/8CfgOGA34MvGmN02220O0GytnQz8Frg+ur0BOMlauwfwdeDuTY75H+BbwJTo69g47kdEonJycra43e8z/OCQcZy2Ryl9Ecs1z6/i6SWNw77e6FOPBp+PuqdfJtQ09BFTLW9/yMKzLiXSHWLcWV9g6k+/y6Y9Z+PzUTnnSwCsvu3+YdctMhRby5eIDJ/yJeKO8iXihleyFU+z6dfArtH3VwL3AM8BV8Rw7P7AMmvtCmttCLgP+Pxm+3weuDP6/gFgtjHGWGvfttZWR7d/AGRGR0GNBvKsta/Z/kmPdwFfiON+RCQGxhi+tf8Yzpo5moiF37y0hvmrhzelLlheQvFh+2F7+1j/8H+GdI62j1fw1ld+SLijk9GnHMVu117ElgY3Vpx5PGm52TS/9i6t7y8eVt0iIiIiIiKyfWmx7mit/fsm7+caYwqAgLU2lpWDK4C1m3xeB8za2j7W2j5jTAtQRP/IpgGnAguttT3GmIroeTY9Z8XmF66rq2POnDmkpaURDof54he/yHnnnUdNTQ3Z2dn4/X5aW1spKSmhqakJay0lJSXU1tYOdhzb29spKyujvr4eYwyFhYXU19eTl5dHOBymo6OD8vJyampqSE9PJz8/n4aGBvLz8wmFQnR1dQ1+HwgEyM3NpbGxkYKCArq6uuju7h78PhgMkpmZSXNzM0VFRbS1tREKhQa/z8zMJBAI0NLSQnFxMS0tLfT29g5+r3vSPQ3lnqqqqujr69vmPR1dkUln5yge+GgDVz+3kkv2H8WEHDPkewrOngXPv866+x6D2fvGdU/5oQhvnXY+fc2tFBwxi/yLz6Kto2Orf055J3yWpvvm8tHv76T8p+futH9OqfjvnhfuKRQKDb5S5Z5S8c9J97Rz3lNVVRXhcDil7ikV/5x0TzvnPYVCIXp6elLqnlLxz0n3tPPdUzgcpr29PSXuaVtMPCuhG2OKgOOB0dbaXxtjxgA+a+267Rx3Gv2Li38z+vlrwCxr7fmb7LMous+66Ofl0X0aop93Bx4BjrbWLjfG7AtcZ639XPT7Q4EfWWtP3PTa8+fPt9OnT4/5HkW8qLu7m2AwuN39rLX87uW1zF3cSG6Gn9+eNJXxo7Z/3JaEu3p4fsaJ9LV1cMi8e8mZOiG2Wmvqef3z/03X6moKD9qHmf+4CX9mxjaP6VxdxbwDTsekp3H4gofIKCkcUs0iQxFrvkQkfsqXiDvKl4gbqZSthQsXLpg9e/a+W/ou5ml0xpjDgMXAV4GfRTdPoX/dpO2pAsZt8nlsdNsW9zHGpAH5QGP081jgIeAsa+3yTfYfu51zikgM6uvrY9rPGMMFB4/jgPF5tPWE+fGTy2jsGNoDKf2ZGZSf3L/ef9X9T2x3f2st3dV1vHXGD+haXU3+Xruyz13Xb7fRBJBVWUHp0QdjQ72svfOhIdUrMlSx5ktE4qd8ibijfIm44ZVsxTyNDvgdcIa19lljzMAjqV6nfz2m7XkTmGKMmUh/Q+hM4Cub7fMI/QuAzwdOA56z1lpjzCjgceAya+0rAztba9cbY1qNMQdE6zgL+EMc9yMiUfE8yNHvM/z4yIn86ImlfFTXyU+eWsZNJ04lO+CP+7oVpx/Pun88SvUDTzLh3DPpqamne3093VW1/T+r6+heXzf4M9Ld/zyCnKkTmXnvb0jLyY75WpXfOoO6p15mzZ0Pscv3voYvIxB3vSJDoQelirijfIm4o3yJuOGVbMXTbJpgrX02+n5g7l0olnNE12A6H3gK8AN/s9Z+YIy5EnjLWvsIcDtwtzFmGdBEf0MK4HxgMvBzY8zPo9uOttbWAd8F/g5kAnOjLxGJU2FhfNPKgmk+rjx6Ehc+uoQVTd388pkVXH3sJAL+eJ45AKP2n0HWhAo6V1Xx/B4nbnf/tLwc8veczh5/+BmBwvy4rlV48D7k7jaZtg+Xsf6RZ6n40nFxHe+StdYzf+l4Ubz5EpHYKV8i7ihfIm54JVsxr9lkjHkFuNJa+5QxpslaW2iMORr4sbX2cJdFDofWbBLZvtWrV1NZWRn3cTVtPfzgkSU0dfVx2MRRXH7kBHxxNk3W3PkQH15+E2m52QTHlBIcXUpwTAnBMWUER5f0bxtTSnB0SVwjmbZk3b2PsuiH15I3YzoHPnX7iGnwvHPuz2h88Q3GfvVkKr99BsGybS+2JzuXoeZLRLZP+RJxR/kScSOVsrWtNZviaTYdADxG/5S204G7gJOBk621byao1oRTs0lk+5qbmykoKBjSscsbO7nosaV09kY45TMlfGdWRdxNnEhfH760eAZaDk24q4cXZn6B3qYWZj1yKwX7z3B+ze1pePEN3jrjB4OfTSCdijOOZ+J/f4XsXcZt40jZWQwnXyKybcqXiDvKl4gbqZSthCwQbq19DZgBfAD8DVgB7DuSG00iEptwODzkYycVZfGLo3YhzWd4aFE9D7xfF/c5dkSjCfoXJR/3tc8DsOov/9oh19wWG4mw5KpbABh31imUnXA4trePdXf/m5cOPpO3v/kTWt75KMlVynANJ18ism3Kl4g7ypeIG17JVjxPo8sH5gAHAlOB2cAdxpinHdUmIjtIR0fHsI7fe0wulxzWPxT0r29U8+yypkSU5cT4s0/FpPmpmzuPrnU1Sa2Uwu7OAAAgAElEQVRl/cP/ofX9JQTHlDL9igvY+/ZrOOSlexn7lZMwaX5qH3ue+cfO4c0vXUDDvDeJdSSqjCzDzZeIbJ3yJeKO8iXihleyFc9qvv8LHA48C9wH/GuTl4jsxMrLy4d9jiMmFfDtWRUA3DRvDQvWtQ77nC4ER5dQftKR2HCYNXc8mLQ6Ij0hll77ZwAmX/JN/JkZAORMruQzv7mcw954kAn//RX82Vk0vvQWb53+feYfM4eaR57DeuT/hqSKRORLRLZM+RJxR/kSccMr2Yqn2XQAcJy19o/W2ts3fbkqTkR2jJqaxIzwOW2PUk79TAl9EcuVz67kgfdqeae6jdbuvoScP1Eqv3U6AOv+8Qh9HV1JqWHNnQ/RtXY9OdMmUnH6p5+MFxxdwvRfnM/hC/6PKZd9m0DRKFrf+5h3vv1Tnt/r87xz7s9Yc+dDtC9d5akRT72t7Xxw6Q00zNt5ZnAnKl8i8mnKl4g7ypeIG17JVjwLpbwMTAfec1SLiCRJenp6ws71rVkVNHX18fzyZv7yRvXg9pLsdCYVZTKpKItdCjOZVJRJeW4g7qfXJcKofXYnf5/daVn4AdUPPsX4s76wQ6/f29rO8t/9HYCpP/kuxu/f6r7po/KY9IOzmXDul6m67zFW3vpPulZXU/PvZ6n597MABEoKKTxwbwoP2pvCg/Yhe0rliHnSXqItveZW1t71EM2vvcMh8/6R7HK2yYbDLL7yT/QW58P3vp7sckRSUiL//hKRT1K+RNzwSrbieRpdKfAE8DpQu+l31torE19aYuhpdCLb19HRQXZ2dsLO1xexPLesiQ/rOljR2MXKpi56wp/+b01Wuo+JhZnsUpjJmLwMRucFGJ2bQXlugMz0rTdgEmH9w8/w7nd+QfaUCRwy7x87tDmz5NpbWXHzXRQcsCf7P3RLXNe21tKxfA1Nr75N06sLaX71bXrqGj+xT6C4gMKD9qHwoL0pPmIWWZUVib6FpGh5bzHzj50DkQgAh75yH9mTxie5qq1be8+/+eDi6zGBdGZ/+ARpOYnLmIj0S/TfXyKykfIl4kYqZWtbT6OLZ2TT1cA4YBWQt8l278zfEElRDQ0NCf0PXprPcPTUIo6eWgRAOGKpau1hRWMXy5u6WN7YyYqmLpo6+/igtoMPaj+9SN6oYBqj8wKU52YwOjfA6Lz+nxMKMskLDv/pdWUnHEHG6D/SsXQVjS++QfHhs4Z9zlh019QPPglv2s/Oi7vJZYwhZ3IlOZMrGX/WF7bafKp55FlqHukf+ZQzfRdKjz2U0qMPJX+v6RhfPDOoRwYbifDh5TdCJIIvGCDSHaJ27jx2Of+/kl3aFvW1d7D0+r8CYEO91P9nPqO/8LkkVyWSehL995eIbKR8ibjhlWzF8xvbmcBUa+16V8WISHLk5+c7Pb/fZxg/Ksj4UUEOn1QwuL25s5flTV2sau6mpq2H9a0h1rf1UNsWYkN3Hxu6+/iorvMT5wr4DZccVslhuxRsfpm4+NLTGH/2F1l67Z9Z/df7d1izadmNtxPp6qHshMMZNfMzwz7fNptPLy+g4fnXaP94Be0fr2DF7+4ko7yY0qMPofSYQyk6ZCa+jEAC7sq9qn89QcuCD8goLWLK5eey6MJrqJ374ohtNq344z2E6pswgXRsqJfaJ15Us0nEAdd/f4l4mfIl4oZXshVPs2kF0OuqEBFJnlAolJTrFmSls29WOvuOzfvE9oi1NHb2sr411N+EaguxvrWHtS3dLG3o4prnVtHU2cspnykd1vXH/dfnWf7bO6h/dj4dy9eQPWk8kd4+eje00tvUQqi5hd7mFnqbWwk19b+P9PYx9ssnkrvrpLiv175kFevufQzj9zPl8nOHVfvWbN58ioR6aZr/NnVPvkTd0y/TXVXL2rseZu1dD+PPzqL4iFmUHXsoxbMPIlCQt/0LJEHvhlaWXHULANN+fh6lxx3Gh5ffSMuCD+iubSBYVpzkCj+pq6qWVbf+E4A9bv4J7/33L6n/z6uEu3vwBzOSXJ1IaknW318iXqB8ibjhlWzF02y6G3jEGPMHPr1m03MJrUpEdqiuruQ8kW1rfMZQkh2gJDvAjNE5g9uttdz/Xh23v1nN/7xWRX1HL9/cf8yQFxkPFI1izBePYd29j/Laid/G9oXpa/v0lL7NrfvHo+x9+9Vxj4Zacu2tEIkw9qxTyJlcOaSa4+ULpFN82P4UH7Y/u17zQ1rfX0LdUy9R99RLtC1aSu1jz1P72POY9DT2vOWXlJ905A6pKx5Lr/8rocYNFBywJ6NPPQZjDMWH7U/dUy9T99TLO3yB9+1Zeu2fiXSHKD95NmNOOZolv7uT7sUraZz3JqVHH5Ls8kRSykj7+0sklShfIm54JVvxNJvOi/68ZrPtFtglMeWISDKUl5cnu4SYGGM4Y88yirLSuWneah54v47Gzl4u/ux40v1DW4dowrlnUvXAk/Q2t/Zv8PlIH5VLekE+gYI80gvyN74vzKf13Y+pfeJFFvzXxex+42WMPfOEmK7T/MZ71M2dhz8zyKSLzhlSrcNljCF/xjTyZ0xjyiXfpGvteuqeepmax1+gef7bfPTzmyk56uARNfqmddES1tz5EMbvZ7drLhpc46r02M/2N5vmvjiimk0t73xE9QNPYgLpTP3JfwMw+qQjWbn4dmoee0HNJvl/9u47Oo76auP4d7ZJq1VdrbotWbJsy72BccMUgxstYFpohlATIKEklPCGEEo6ARIIobcAoZiOG924g3u3JUuW1XtfabW78/4hWdi4qI5G2rmfc3Qk787O3kHnYaSr+d0RPay/nL+E6I8kX0JowyjZ6nCzSVXVVC0LEULop6ioiJSU3rnSpiecMcRJlN3Cg19k81VWJVXuZu4/Iw2HrfN3sAsdlsop697F19DY0liKCD3uAG3V72fPI0+T/dTrbLvtERrzihh858+OO+hbVVV2ty4DG3TTT/vMsi/7wARSrruI5J/NZ9UZV1O7I5MD//2QQdddrHdpwMGh4I+C30/y9RcTNiK97bnYWdPBZKJ8xXqaa+qwhoceZ0+9Q1VVdj3wLwBSrr2IkJREAJQThwNQuuxb/M1eTNbuD7gXQrTob+cvIfoTyZcQ2jBKtvrfLYmEED3OZusfQ6IPNXFAOI+eNYQou4WNBXXc+cleyuu7NlYuOD4GR9pAbFHh7d6pTTGZGPa7mxn+xzvBZCLz7y+w7Y4/4W/2HvM1JUu/pWrdFqzOSFJ/cVmXatSSYjKRftd1AOx74lV8DY06V9Qi/+3FVH23FVuMk/TfXHfYc7boSKJOGova7KX0i1U6VXi4kiXLqVyzCaszgsG3LWh7PGxoKo4hg2iuqqVi9UYdKxQi8PTH85cQ/YXkSwhtGCVb0mwSQhAWFqZ3CV2S7grh8XOHMiAiiH0Vbm77eA+5Vb3TKEn52XzGv/hHTPYg8t/8hA1X/QZv3ZHznvxeL3se+U9LvXdcgyWsb97mNHb2yYSPzcBTWkHuy+/pXQ7N1bXseegpoGUo+NGuXIqbNwOAksXf9mptR+P3NLP7oZar19LvvBZrxA+ZCgsLI+6sUwAo/vRrPcoTImD11/OXEP2B5EsIbRglW9JsEkJQXl6udwldlhAWxGPnDGV4bAjFdR5u/3gP24vreuW94+bMYNLCJ7E6Iyn7ai1rf/ILGotKD9sm/61F1O/NwZ6SyMA+NFvoxxRFYchd1wOw78n/HrVx1pv2/rV1KPhJY0m8cM5Rt4md3dJsKv1iNb7Gpt4s7wi5r75Pw74DONKTj/g+l5eXEzfvVABKFi9H9ft1qLDneOvdrLvwVvb88T96lyJEvz5/CdHXSb6E0IZRsiXNJiEEUVFRepfQLRHBFv4ybwiTk8OpbfJx96JMVuZU9cp7R04YyeRPnyUkdQC12/ay5qwbqN21DwBfQyOZf3segKH33ojJZu2VmrrKdfpkIk8YRXNFFftfeLfb+yv/9ntynn+7042rmm17yH3pPTCZGP7HO445DyskOYHw0UPx1TdQsWJ9t+vtquaqGrIefRGAYb+7+YiZTFFRUYSPHkrwgHiaSsqpWr9djzJ7TPGnX1OxYj05z/4Pf5Mxbt0r+q7+fv4Soi+TfAmhDaNkS5pNQoiAuP1msMXE789IY+6waDw+lYe+yOaV9YVsL66jyavtlSSO1AFM/vgZIiaOpDG/mLXn3kT5yg3kPP82TUVlhI/JIP7cmZrW0BMURWHI3TcAkPP0GzTXdP0KsZpte/j+8jvZ9X+Ps3zyxex/ceFx51odpKoqO377D/D7SfnZfMJHDjnu9rFzWq5uKl78TZdr7a6sx16mubIG59QJxBzlbnNutxtFUX5YSvfJV71dYo8qeHcJAP5GD9WbdupcjTC6QDh/CdFXSb6E0IZRsiXNJiEEjY19YyB0d5lNCrdNH8hVExPwq/D6xiJu/3gv572ymZ+/v4vHV+SyeHc5+8rd+Pxqj763zRXFpHf+RezcGXhr6vj+p7ez7/FXABj2u1+0O3i8r3BOn0jUlPE0V9WS88z/urQPb30Dm268H9XTjM0Vhaeskp2/fZQVMy6j6KMvUdVj/7cveGcJVeu2YHNFHTEU/Gji5rbObVq6AtXn61K93dGQk8f+F98FRWHYA7ce9Sqsg/mKP+s0AIoXfXPc/wZ9WWNhKeXfft/274o1m3SsRojAOX8J0RdJvoTQhlGy1T9++xFCaCo+Pl7vEnqMoihcMT6eh2alMWdoNGnOYACyyt0s2lXOY9/mctP7u/jJq1u445M9PLMmj6+zKqlubP+qm/aYQ4IZ//wjJF97IaqnGV+DG9dpJxF98gnd3ndvaZnd1NLk2f/sW3gqazq9jx33/oOGrFxCM9I4Zd1Cxr/4JxzpyTRk57Hphv9jzVk3HPWubM3Vtex+8EmgZTnaoUO2jyV0+GDsKYl4yiqp+n5bp2vtrt0PP43a7CXxorlEjBl21G0O5ivyhFEExUbjPlBI7bY9vVlmjyl8/zNQVSyt35tKaTYJnQXS+UuIvkbyJYQ2jJIt8wMPPKB3DZrKy8t7wOVy6V2GEH1afn4+kZGRepfRowZEBDMlJYKzh8cwf3QsJw4MZ1CUndAgMx6vn6pGLyV1zewsaeDbnCo+2FZKTqWbsCALcaG2Y84Jao9iMuE6fTK2qAh8DW5G/PnX2Jz967+tfWACleu2UL83B8Vi6lSzLP+dxWT9/QVM9iBOfOsJghNiCB0yiIFX/YSg+BhqNu+iPnM/+W8tonrzLsJGpBPkalm3vufhf1OxYj2Rk8Yw/KFfdeh7oCgKjXlFVK3fhjUyHNepJ3X5uDurcu1mdj/4JCZ7EBNe/ssx7zR4MF+KotCQnU/N5l3YXFFET5/Ya7X2lB13/w1PaQUZD9xK6ReraSqtJPXmy/rNlXsi8ATi+UuIvkLyJYQ2AilbhYWFhWlpac8e7Tn56VAIQXBwsN4laMpuNTM6PpQLR8dy3+mpvHLJSN65YjQPz07jqgnxTEgKw6eqfLOvirsXZfKzd3by9uZiKt3NXXo/RVFIue4iTvrgaULTU3r4aHrHkLtb7ky3/7l38JRVdug19Vm57Lj77wCMeOQOQoeltj1nslhIvuonnLz6LdLvuh6zI4TSz1ay8vSr2Hr7Hyn9YjX7X1wIJhMj/nRnp5oXcfNaZiGVLFnea8vTVL+fXQ/8C4DUmy4jOCHmmNsemq+2uU2f6jdjqqtqd2RSuyMTa2QYAy47h5DUAfjqG6jdtlfv0oSBBfr5Swg9Sb6E0IZRsiXNJiEEdrtd7xJ6XUSwhUkDI7hiQgJ/npvOq5eM5MoJ8bgcVgpqmnj+uwIuf3M7D32Rzfq8Gvz9dMZOV0VOHEXMzCn4Gtzse+r1drf3N3nYdOPv8DW4STj/TJJ+evZRt7M4Qki/4xpmrHmb5Gvmo5gU8t/8hPWX3wl+P8lXX9DuUPAjaj1hFLboSBpy8qlrvROg1go//JzqjTsIio0m9ZbLj7vtoflyTp2AJSKMuj3Z1O3N0bjKnlXw7lIA4s+diSnIRtTkcQBHXRLZX3kqqvG5m/QuQ3SCEc9fQvQWyZcQ2jBKtqTZJISgsrJjV64EsthQG1dOSOC1S0by0Kw0piRH4FdVvs2u4t4lWVz99g7e3FRERUPXrnbqj9Lvarm6KfflhTSVlB93290PPUXttr3YUxIZ+de72l0CFxTjZMSf7mT68jeIP+f0lsdio9uuqOoMxWwmds7JABQvXt7p13eWz93EnoefBiD97uuxOEKOu/2h+TJZLcS23rGueFH/ubpJ9fkoeH8ZAIkXzgHA2dpsCpS5Te68Ir45cT6brr9P71JEJ8j5SwjtSL6E0IZRsiXNJiEE0dHRepfQZ5hNCiclR/CHWWn899KRLJiYQGyolaJaDy99X8jlb27j98v2sWp/Fd4evqNdXxMxNoPYuTPwu5vY989Xj7ldydJv2f/8OyhWC+OeeeiYs4uOxpE2kHHPPczJK//HlM9e6tBQ8KOJndN6V7rF2jdw9j//Fo35xYQOH8yAS89qd/sf5yv+7FOB/rWUrmLVRpoKS7EnJxJ54mgAoqaMB1pmV6l+v57l9YiiT77CV99A6eeraCwu07sc0UFy/hJCO5IvIbRhlGxJs0kIQW1trd4l9Ekuh43Lx8fzysUjeWT2YKalRKACq3OreeCzbC57YxvPrMkju8Ktd6maGfKbljvTHXjtQxoLSo543p1fzNbbHgFg6H0/J2Lc8C69j2NwMsFxXb+ZQ/TJJ2B2hFCzdQ/uA4Vd3k97PJU17PvnawBkPHAritnc7mt+nK/oGZMwh9ip2bJL01p7Uv47SwBInD+77ao1+8B4gpPiaK6qpW53tp7l9YiSJd8e9WvRt8n5SwjtSL6E0IZRsiXNJiEEHo9H7xL6NLNJ4cSB4fz+zDTe+Okorp+USEpkMFWNXhZuK+XG93Zxywe7+WhHKbVNXr3L7VFhI9KJP3cm/iYPWU+8cthzfq+XLTc/QHNlDTEzpzDohkt0qhLMwUHEnD4ZgOIl2i2ly/nPG3hr64k++QRcp0zq0Gt+nC+zPYiYmVOA3ln2112+hkaKP/0agMQLZ7c9rigKUZPHAlCxun8vpfOUV1G5bkvbv4t74Qo50TPk/CWEdiRfQmjDKNmSZpMQgvj4eL1L6DecIVYuGhPHs/Mz+Oe5Qzk7w4XDZmZPWQNPrsrj0je28ciX2XyfV4MvQJbZpd/5M1AU8t74+LArcbIefYnKNZsJinMx+on/69Qd5LQQO/fgUjptrkrxlFWy/7l3gJZZTR11tHy13ZVu0dc9UpuWipcux1ffQMT4ETgGJx/2XNvcpn4+JLz081Xg97dcmWcyUbFiPc3VxvirY38n5y8htCP5EkIbRsmWNJuEEBQVFeldQr+jKAoZsQ5+OX0g/7tsFPeelsKEpDC8PpVv9lXx2yVZLHh7Oxvz+/8vrKHDUkm44EzUZi9Zj70MQPmK9WQ9/jIoCmOe+j02V5SuNQLEnDEVxWqhYs0mPOVVPb7/fU+9jq/Bjev0KUSdMLrDrztavmJmTkWxWalcu4Wm0oqeLLPHFbbehe7gYPBDtd2Rbs0m1H58x8aSpS0NyqRL5uGcPA7V62tpQIk+T85fQmhH8iWENoySLWk2CSEMc/tNrQRZTJw22Mmf56bzWutQ8YQwGyV1zdy7JJP3t5X061/EAdLvvBbFbCb/rUVUrd/Glpv/AKrK4NuvIXr6RL3LA8AaHopz2gTw+yn5bGWP7ruppJzclxcCMOSu6zr12qPlyxLmaFmGp6qUaLjsr7uaSiso+3odisVMwnkzj3jekZ6CzRWFp7SChn0HdKiw+3zuJsq+WgtA7OyTiZ3XcoVcf7pboJHJ+UsI7Ui+hNCGUbIlzSYhBDabTe8SAkZsaMtQ8ZcuHsFPx8bhV+HpNfk8ujwXj7f/3rHLkTaQxIvmoPp8rLvgFpqKy4iaPJbBd1ytd2mHiZvbsjytp+9Kt++fr+J3NxE75+ROD0E/Vr7i5rXUWtQ6D6mjypZ/x+abH6A+O69Tr+uKwg8+Q/X5cJ02+ahXr7XMbfrh6qb+qPzb7/C5Gwkfk0FwYixxrXc2LPtqLT53k87VifbI+UsI7Ui+hNCGUbIlzSYhBNXV1XqXEHBMisI1JyZy3+mDCLKYWLa3gl9/upfy+ma9S+uywbdfg2Ix42/yYI0KZ8xTD2CyWPQu6zCxs6cDUPbNOrz1PXOXwMaCEnJf/QCAIXd1fFbTQcfKV+ys6Shmc8t8oKqadvejqir7nvwv3196O4ULl7Hzt492upbOKjjOErqDfpjb1D+bTQfvPBc752QA7APiCR+Tga/BTfm33+lZmugAOX8JoR3JlxDaMEq2pNkkhMDl6vot58XxnZIWxePnDCEu1Mau0gZu/nAXO0vq9S6rS0JSEkm5/hIUq4XRT/wf9qQ4vUs6QnB8DBETRuJv9FD+zboe2WfW46+gepqJP+d0wkakd/r1x8qXLTqSqCkt84HaW/bnrXez+ab72fPwv8HvR7FZKftqLVUbtne6no6q25tDzeZdWMIcxM6afsztoqa0XtnUD4eEqz4fJctWABDXOmAeIE6W0vUbcv4SQjuSLyG0YZRsSbNJCGGY7rpeBkeH8K/zhjImPpSKBi+//mQvy/aU611Wlwy7/2Zm7lpy3OaD3g42DXqiUdCQW0jemx+DopD+62u7tI/j5Stu3qnA8Wtt2J/P2nNupOjDLzA7Qhj/0p9IvemnAGT+/cUu1dQRBQtbrmqKO/s0zPagY24XlpGGJSKMxvziw+5W2B9UbdiBp6wSe3IioRlpbY+3LcdctgK/16tXeaID5PwlhHYkX0JowyjZkmaTEILm5v67tKu/iLRb+fO8dM4d4aLZr/L35bk8vToPn79jg8NVVaW41sOK7Cp2l+p3ZZSiKFgcIbq9f0fEtjabSj9fib+5e42CrMdeQm32knDBmYQOS+3SPo6Xr4ONsbKv1hx12V/ZN+tYPftn1O7IJGRwMlMWP0/c3FMYdOOlmEPslH25muqNO7pU1/Gofv8PS+jmzz7utorZTNSkMUD/m9tUsrhlOHvsnJNRFKXtccfQQYQMTqa5oprKtVv0Kk90gJy/hNCO5EsIbRglW9JsEkIQHx+vdwmGYDEp3DJ1ILdNH4jFpPD+9lJ+uySTmsYjGyJ1TV7W59XwxsYi7l+WxaVvbOPKt7bz4BfZ3PrhHh7+IpuSOo8OR9H3haan4BgyiOaqWiq70fyoz86j4O3FKGYz6Xd27aomOH6+ghNiiDxhFP5GD2VfrWl7vG0+00/voLmqlpgzpzFl8fOEDh0EtCzBS/7ZfAAy//FSl2s7lsp1W2jMKyI4KQ7n1PHtbu+c0rJNd/5766F4aeu8ptknH/a4oijEtc5w6ulh86JnyflLCO1IvoTQhlGyJc0mIQRFRUV6l2Ao8zJc/G1eOlF2CxsL6rjlw92sya3mox2l/PWb/Vz7zg4ueG0r9y7J4uX1hazJraHS7SUsyMz4xFCCzArLs6u49p0d/HdjEU39+C53WmlbStd65UpXZD36AqrPR+JFc3CkDezyftrLV9tSuta70v14PtPg269hwit/wRoeetjrUm/6KWZ7MKWfraR6864u13c0Be8uASDhglkopvZ/VPjhjnSbe7QOLdXtzaEhKxdrVDhRJ4054vmDdwssXrwcVe3YFYii98n5SwjtSL6E0IZRsiXNJiEEDodD7xIMZ2R8KP86bxhDXHaKaj3cv2wfT67K4/O9FRyobsJqVhgeG8JPRsZwz6kpvHTRCN69YjR/mTeEFy4awSlpkTT5VF5dX8h17+5kRU6V/EJ8iIPNppIlXWsU1O3JoWDhMhSLmcG3X9OtWtrL18Fh1CWfraRuT84R85mG3H39URs+NlcUA6++AICsf/Tc7CZfYxNFH30JtL+E7qDw0UMxh9hpyMqlqaR/zCM7eBe6mJlTj3pXxYjxIwiKc9GYX0zNlt29XZ7oIDl/CaEdyZcQ2jBKtqTZJITAbDbrXYIhxYba+MfZQzl3hIs0p50zhji5ZeoAnjxvGB9cNYYnzh3GL6YM4PR0J0kRQW0zZWJDbdx3eip/m5dOalQwxXUeHvw8m3uXZJFb2ajzUfUN4WMzCEqIobGghJpNOzv9+sy/vwCqyoDLziEkJbFbtbSXr5BBAwgbOQRfXQMrz1hwxHym40n9xWWY7EGULF1BzdaeaYiUfr4Kb00d4aOHEnbI0OzjMVktRJ44CoCK1f1jKV3JwSV0h9yF7lCKyURs61K6YllK12fJ+UsI7Ui+hNCGUbIlzSYhBDU1NXqXYFhBFhO3TB3Ify7I4K5TUjh3RAxDY0Kwmtv/3/PYxDD+fX4GN08ZQKjNzIb8Wm58byf/WZNHvcfXC9X3XYrJRFzrHJ6N1/8fZV+v7fBra3dkUvTRFyg2K2m/WtDtWjqSr4NLtlRP8xHzmY4nKMZJ8lXnAz03u6ltCV0Hr2o6yNm6lK4/zG1qKimnav12TEE2XKdOOuZ2B78vJd1Yjim0JecvIbQj+RJCG0bJljSbhBDExMToXYLoIrNJ4byRMbx08QjOyojGr8J720q55u0dLN1Tjt/AS+vSbltA+OihNOYV8f2lt7P1Vw/jqWz/5L73b88DkHzVT7AnxXW7jo7ka8Bl5xAxYSTpd11/1PlMx5N68+WYgm2ULF5Ozfa93SkVT0U1pV+sBpOJhPPP7NRrf5jb1PebTSXLVoCqEn3yCce9u6Jz6gQsEWHU7c6mft+BXqxQdJScv4TQjuRLCG0YJVvSbBJCUFFRoXcJopsigi38anoyT/5kGCNiHVQ1enl0eS7zX9vKXYv28vy6fJbvq6Swtqlbs508Pn+/uWoqOD6GyYufZ+h9P8cUZCP/rUWsmHEZRZ98dczXVG/eRcni5ZjsQaT98qoeqaMj+QpOiGHKoudIv+OaDg3kPlRQbEXyYj4AACAASURBVDQDW69uyurm1U1FH32B2uwlesYJBMe5OvXaiPEjMAXZqNuZ1aGmnp4Ozms6uEzuWExWC7FnTgWgeJEspeuL5PwlhHYkX0JowyjZOnIiphDCcGSwdOAY4grhsXOG8EVmJa+sL6S4zsOmgjo2FdS1bRMWZGaoK4QhrhCGukIYGhNCjMOKX4XyhmZK6zyU1DdTWu+htK71c+vXVY1ezArcd3oq01MjdTzSjjFZLKTdeiWxc2ew/dd/pnLNZjZddx9xZ53KiD/dSVBs9GHbZ/71OQCSr55/xHNd1Rv5Sr35cg68+j7Fn35N7Y5Mwkakd2k/BQuXApB04ZxOv9YcHETE+BFUrtlE1brNxM4+fiNHL976Bsq//R4UhdhZ09vdPnbODAreXUrx4m9Iu+WKXqhQdIacv4TQjuRLCG0YJVvSbBJCGOZSTqNQFIUzhjiZmR5FeUMze8vc7ClrYE9pA3vKGqhu9LI+v5b1+bVtrwmxmmj0+vG3c+4zKeBT4S9f5xAbNpShrmMvQepLQtNTmPTeUxx45X12P/w0xZ9+TcXK9Qx74JckXTIPRVGo/H4rpV+sxhxiJ+3my3vsvXsjX8FxLgZecR77n3+HzH+8xPjnH+n0Phpy8qj6bivmEDux7QwmPxbnlHFUrtlExaqNfbbZVPb1OvxNHiImjuxQQ9F12mRMwTaq12+nsaiU4Hj5/2VfIucvIbQj+RJCG0bJljSbhBAUFxeTkpKidxmihymKgsthw+WwMSUlAmj5S0ppfTN7yhrY29p82lPWQG2TDwVw2i3EhNqIcViJcbR+DrW1fB1qxWm38viKXJbuqeD3y/bxr/OG4nLY9D3QDlJMJpKvmU/MmdPYftffKPtyNdtue4TC95cx8m/3kPnXlllNKddfhM0V1WPv21v5Sr3lCg689iHFn3xF7c4swoYP7tTrC95tuaopbt4MLA57l2roD3ObDi6hi2tnCd1BFocd1ymTKFm6gpIl35J89QValic6Sc5fQmhH8iWENoySLWk2CSEIDe34MGLRvymKQmyojdhQG9MHtSyDU1WVqkYvoTZzh+6C98tpAymo8bC1qI77l+3j0bOHYLf2n1u42gfEM/H1v1O4cCk7f/c45d98x4oZP8Xf6MES5mDQTZf16Pv1Vr6C42MYcNk55L60kKzHXmbcsw91+LVly78j9+X3AEjswhK6gyJPGIViNlOzdQ/eunosoY4u70sLfq+X0s9XAi3L4zoqdu4plCxdQfHib6TZ1MfI+UsI7Ui+hNCGUbIlA8KFEMLgFEUhym7tUKMJwGo28fszUkkMt5FZ7uYvX+/vd3e9UxSFxAvnMH35G8SfOxN/oweAQTdeii0qXOfqui7t1itRbFaKPv6Sut3Z7W7fXFPHtjv/xPcX/wpPWSVRk8finD6xy+9vcYQQPjYD/H4qv9va5f1opXLtFporawgZnEzokEEdfl3srOkoZjMVKzfQXNW3h58LIYQQQvQF0mwSQlBXV9f+RkIcIjzYwoOzBhNqM7NqfzUvfVegd0ldEhTjZNyzDzHh1b8x+M6fkXpzzw+A7s18BSfGMuCnZ4OqkvX4y8fdtvTzVaw45XLyXv8YxWZlyL03cuI7/8Jk6d5Fz87WpXSVfXApXcnS1iV0nZwnZXNGEDV5LKrXR+nnq7QoTXSRnL+E0I7kSwhtGCVb0mwSQhAXF6d3CaIfSo4M5nczUzEp8NaWEpbuKde7pC6LnTWNIb+5DrM9qMf33dv5Srv1ShSrhcIPPqdub84Rz3sqa9hy60Osv+LXNBWWEjF+BFOXvcTgXy3AZO3+6vq2uU2r+1azSVXVtnlNsR2c13SouNah6cWLl/doXaJ75PwlhHYkX0JowyjZkmaTEILS0lK9SxD91PikMG6dNhCAJ1YcYEthbTuvMJ7ezpd9QPwxr24qXrKcladcTsE7izEF2xh2/y2c9PF/CMtI67H3j5o0GhSF6o078Lmbemy/3VW3ax/u3AJs0ZFEThzZ6dcfbFCVfbmmTx2X0cn5SwjtSL6E0IZRsiXNJiEEiqLoXYLox87KcHHBqBi8fpU/fJ5NfrX8In4oPfLVdnXT+59Tn5WLp7yKTTfdz8ar76GppJzISWOY9sWrpP7ism4vm/sxa2Q4YSPSUZu9VG3Y3qP77o6SJS1XJMW0zl/qLPuAeMLHZOBzN1K+fF1Plye6SM5fQmhH8iWENoySLWk2CSFwOp16lyD6uesnJXHSwHBqm3z8blkWtU1evUvqM/TIl31gAkmXzAO/n623PcKKGZdR9MHnmO3BZDx8Gyd98G8cg5M1e/+oyWOBvjW3qXhx67ymLiyhOyhuXssd7IoXfdMjNYnuk/OXENqRfAmhDaNkS5pNQgjDXMoptGM2Kdx72iBSo4LJq27i4S+y8fr71x3qtKJXvtJ+uQDFYqbqu614yqtwTp3AtK9eZdB1F6OYtD39O6eMB/pOs6mxoISaLbsw24OJnjGpy/s5OLep5LOV+L3SUO0L5PwlhHYkX0JowyjZkmaTEILw8P57q3fRd4TYzDw4azBRdgsbC+p4ctUBVFUaTnrlKyQ5gbRbryIozsWIv/yGE9/9JyGDBvTKe0ed1Hpl0/db8Xuae+U9j+fgXeiiT53UrSHwjqGDCBmcTHNFNZVrNvdUeaIb5PwlhHYkX0JowyjZkmaTEAKfz6d3CSJAxIXZeODMNKxmhUW7ynl5fSHf59WwuaCWHcX17C1rIKfSTX51IyV1Hiobmqlr8tLk9QdsY0rPfA25+3pO2/wRyQvO1/xqpkMFxThxDEnB726iesuuXnvfYylubTbFzu76EjpombEQN7d1Kd1iWUrXF8j5SwjtSL6E0IZRstWzU0GFEP1SfX09LpdL7zJEgBge6+A3M1L441c5vLmpmDcp7tDrTAo4bGYcNjOhh3wODTIf8XhSeBCDnHYcts4Peu5tRs1X1ORx1O/dT+XqTUSdMFq3Oppr6qhYuQFMJmLPnNbt/cXNO4XsJ/9LyZJvGf7w7YYZ8tlXGTVfQvQGyZcQ2jBKtqTZJIQgPj5e7xJEgDl1cBQ+VeWbfZV4fCpen0qz30+zT2358PvxtH7t9as0+1r+Xdvko7ap43/tiQ+zkea0t32kOu0khNsw9aEGgFHz5Zw8jrzXPmyZ23TrlbrVUfblGtRmL1GTx2KLjuz2/iLGDSco3kVjfjE1m3cRMW54D1Qpusqo+RKiN0i+hNCGUbIlzSYhBEVFRaSkpOhdhggwM9OdzEzv+N02vH6VBo+PutaP+qZDvm79qGvyUdPk5UBVI/srGymq9VBU62HV/uq2/QRbTKQ6g0lz2kmODMZsUvD6WxpeXv8xPnwqoUFm5o+KJdph7dH/DkbNV9TkcQBUrtuC6vOhmHvuKjTV78dTVonf04zq9eJv9qJ6fa2fD/86/61Pge4voTtIMZmInX0yB155n+Ily6XZpDOj5kuI3iD5EkIbRsmWNJuEEFitPfvLtRBdYTEphAdbCA/u2KnJ61fJq24ku8LNvnI3+yoa2VfhpryhmZ0lDewsaeh0DYt3l3PT5CRmDXH22PIoo+bLnhSHPTkRd24BNdsziRgzrFv7ayqtoPybdZR+uYayr9fRXFHVqdfHzpnRrfc/bF+zpnPglfcpX/493HNjj+1XdJ5R8yVEb5B8CaENo2RLmk1CCCIiIvQuQYhOs5gUBkXZGRRl57TBPzxe3ehlX4Wb7Ao3edVNAFhNCmaTguXHH+aWz2aTwur91aw7UMOjy3P5OquS26YnExdm63adRs5X1ORxuHMLyH3hHRIumEXIoCSCk+IwWdr/8cPv9VK9YQdlX62h9Is11Pxo0LjVGYHZHoxiNqNYLZgsBz9bUKwWFIsFk9WCYjYTNXksjtSeuxNf1EljUMxmajbvwltXjyXU0WP7Fp1j5HwJoTXJlxDaMEq2pNkkhKCsrAyHQ35ZEoEhItjC+MQwxieGdep184ZF80VmJU+vyWN9fi03vLeTa09M5Ozhrm7NgDJyvqKnTaDg7UXkv9XyAaBYzNgHxGMflERIchIhg374MIc6qFi5nrIv11C2/Du81bVt+zIF2XBOHY/rtMm4TjsJR3qKbsO5LaEOwsdlUL1+O5VrNhNzxlRd6hDGzpcQWpN8CaENo2RLmk1CCMN014U4HkVROGOIk4lJYTy5Oo9vs6t4clUeX++r5M6Tk0mKCO70Pn1+1dD5Sjj/TJqra6ndkUlDTj4N+/NpKixt+Tonn/J2Xh+SNpCY0yfjOm0yzinjMYd0/nuglehpE6lev53ylRuk2aQjI+dLCK1JvoTQhlGyJc0mIQQej0fvEoToM6JCrPxuZmprs+kA24rqufG9XSyYmMAFo2Ixm459NU2Vu5ntxfWtH3XsLXMTG2Lm1ukmJg4I78Wj6BtMNiuDbrjksMd8jU24cwtbm095uPcXtDWiPOXVRE4c2dpgOomQQT239K2nOaeOZ98/X6Vi5Qa9SzE0OX8JoR3JlxDaMEq2pNkkhMDtdutdghB9zsmpkYxNCOU/a/P5fG8Fz60rYHl2FXfOSGZQlB1VVSmoaWJbcT3bi+rZVlzXNiPqUAV1Xu5dksWM1EhunJxEjKP7c6D6M3NwEKFDBxE6dJDepXRL5IljUKwWarbtobm6FmtE55Ztip4h5y8htCP5EkIbRsmWNJuEEMTHx+tdghB9UniwhbtOSeHUtEgeX3GA3aUN/OL93YxLDCWzzE1Vo/ew7YPMChmxDkbFhzIyzsEQVwifbC/mf1vLWJ5dxboDNVwxIZ7zR8ZgNZt0OirREywOOxHjR1C1bguVazcTO2u63iUZkpy/hNCO5EsIbRglW/KTrhCCoqIivUsQok+bNDCC5+YP56yMaLx+le/zaqlq9BIZbGFaSgQ3nJTEP88dyvsLxvK3s4awYGICJwwIJyLYwnSXlxcuHM70QZE0ev08v66An7+/m80Fte2/sejToqdNAKB85XqdKzEuOX8JoR3JlxDaMEq25MomIQQ2m7GX9QjREQ6bmV9NT2bOsGgOVDUxPDaExPCgdu+IZrPZiA21cf8ZqXyfV8NTq/LIrWrkN4syOW1wFDeclER0iLWXjkL0JOe0CWQ99rLMbdKRnL+E0I7kSwhtGCVbcmWTEIKwMJk1IkRHDYtxcMYQJ0kRwe02muDwfJ0wIJxn5mewYGICNrPCV1mVXPvODt7bVoLPr2pZttBA5MTRKDYrtdsz8VTW6F2OIcn5SwjtSL6E0IZRsiVXNgkhKC8vJzQ0VO8yhAhIP86XzWzi8vHxnJ4exX9W57M6t5r/rMln2Z5yJiaFYzYpLR8KrZ8VTIf+26QQYjVx0sAIQmzmXj2Weo+PRbvK+HRXOcmRQdx+cjJRduNelWW2BxE5cRSVqzdSuXojcfNO0bskw5HzlxDakXwJoQ2jZEuaTUIIoqKi9C5BiIB1rHwlhAXxh1lprMmt5qlVeeyraGRfRWPH92u3cNXEBOYMjcZsav8Kq+4oqfPw/rYSFu8up6HZD0BBTRM/f38X9546iLGJxvgL3dE4p46ncvVGyleul2aTDuT8JYR2JF9CaMMo2ZJmkxACt9tNeHi43mUIEZDay9fk5AjGJ4bxVVYlNY1efKqKz6/iU2n57FdbH6Pt630VbnaXNvDEigN8sL2UGyYlceLAns/wntIG3t1azPLsKg6u8hubEMrZw118vKOMLUV13L04kyvGx/PTcfGaN736ouhpE8l69EUqVm3UuxRDkvOXENqRfAmhDaNkS5pNQggaGzt+NYUQonM6kq8gi4k5w6I7vE9VVVmeXcUL3xWwv7KR+5ZmMTEpjOsnJZEWbe9OufhVlbW5NSzcWsKWojoATAqcPjiK+aNjGeIKAWD6oEhe21DIm5uKeXVDEVuK6rjn1EE4DTbsPHLiSEzBNup2ZuEpq8TmMsZfK/sKOX8JoR3JlxDaMEq2zA888IDeNWgqLy/vAZfLpXcZQvRpdrsdi0V6z0JoQYt8KYrCoCg7Zw134bCZ2V3awP6qRhbtLqOkrpmhMSGEWDs3z8nd7GPZ3gr+8vV+PtpRRnGdhxCrifNGxnDvaYOYPSz6sLvmmRSFcYlhjIxz8H1eLTmVjXyRWUF6dAgJ4UE9erx9mWIxU75iPe7cQiLGjyB0WKreJRmKnL+E0I7kSwhtBFK2CgsLC9PS0p492nOBcYRCiG4pKioiJSVF7zKECEha5stmNnHRmDhmDY3mvxuK+GRnKUv2lPP1vkouHhPL/NGx2H/UdKr3+MitaiS3qpH9lY0caP26qNbDwfvhxTisnD8qlrnDonG0M4R8QlI4T1+QwZ+/ymFzYR33LM7k8vHxXD7eOMvqoqdNoGLFeipWbiD+nNP1LsdQ5PwlhHYkX0JowyjZkmaTEILg4GC9SxAiYPVGviKCLdw8dQDnjXTx3LoCVu+v5tUNRXy6q5yzh7uocnvJrXKTW9VEeUPzUfdhUmCYK4TzR8VwcmoUlk40iqJDrPx5bjqvbyzi9Y1F/HdjEVtbl9VFOwJ/WZ1z2kTgOcpXbtC7FMOR85cQ2pF8CaENo2RLmk1CCOz27s14EUIcW2/ma0BEMH84M40thbU8szafvWVuXllfeNg2NrPCwMhgkiODGRgZTEpkMMmRQSSGB2E1m7r83maTwlUTExidENp2ldNN7+/i7lNTOGFAYA/BjBg3HLM9mPq9OTSVVhAU49S7JMOQ85cQ2pF8CaENo2RLmk1CCCorKw1xRwQh9KBHvsYkhPGv84bxdVYl24rriQ+ztTaVgokNtWm6vG18YhhPn5/BX77OYWNBHfctyWJCUhjjEsMYlxhKenRIl97f4/Wzs6SeTYV1bCqopbrRy/jEMKakRDAmIRRbNxpl3WWyWYmcNJryb76jYuUGEn5yhm61GI2cv4TQjuRLCG0YJVvSbBJCEB3d8btgCSE6R698mRSF09OdnJ7e+1fZOEOs/HFOOm9uLua/GwpZn1/L+vxaAEKsJsYkhLY0nxLCGOQMxqQc2Xzy+VX2lDWwqaCWTQW1bC+ux+NTD9smr7qJj3eWYbeamJgUzpSUcCYNjCAiuPd/vHFOm9jSbFolzabeJOcvIbQj+RJCG0bJljSbhBDU1tYSGhqqdxlCBCSj5stsUrhifDzzhkWzubCWTQV1bC6spaDGw5rcGtbk1gAQHmRmbGIY4xJCSXXa2VXawOaCWrYW1dHQ7D9sn2nOYMYmhjE+MYyIYAvrDtSwen81+yrcrMipYkVOFSYFRsQ5mJwcwZTkCAZG9s5chOhpE9gLMreplxk1X0L0BsmXENowSrak2SSEwOPx6F2CEAHL6Plyhlg5bbCT0wa3XGFVUudpuVqpdTlcWX0z32ZX8W121RGvHRARxLiEluV3YxJCibQfPmx8eKyDBRMTKK71sCa3mtW51WwprGNbUT3biup5fl0BAyKCOHlQJGePcBHjsHX7eCrdzXy4vZQ1udUsmJjIlJQIAMLHZGB2hNCQlUtjUSnB8THdfi/RPqPnSwgtSb6E0IZRsqWoqtr+Vv3Y6tWr1YyMDL3LEKJPa2pqIigoSO8yhAhIkq9jU1WVghoPmwpr2VxQS25VI+nRIYxLDGNsYmiXmkP1Hh/r82pYnVvNugM11Db5ADArMCMtivNHxpAR6+j0fgtrmnh3awlL95S3LeebmBTGn+amt23z/WV3UvblasY89XsS58/u9HuIzpN8CaEdyZcQ2gikbG3YsGH9zJkzTzjac3JlkxCCoqIiUlJS9C5DiIAk+To2RVFIiggiKSKIszJcPbJPh83MjLQoZqRF4fOrbC2q49OdZXybU8VXWZV8lVXJiFgH54+KYfqgyHaHlWeWNfDWlmK+za7C3/r3ufGJoWwsqGNPWQOqqqK0zpxyTh1P2ZerqVi1QZpNvUTyJYR2JF9CaMMo2eq1ZpOiKHOAJwAz8Lyqqn/+0fNBwKvARKAcuERV1RxFUaKBd4ETgZdVVb3lkNd8DSQA7taHZqmqWqL1sQgRaIxy+00h9CD50o/ZpLTeBS+MkjoPH+0oZdGucnaU1LPjy3piHFbOGxnD3GHRhAX98CORqqpsKqjjrS3FbGgdbG5W4IwhTi4aHcugqGAueX0bVY1eCms9JIa3/HUyetoEACpkblOvkXwJoR3JlxDaMEq2eqXZpCiKGXgKOBPIA75TFOUjVVV3HLLZtUClqqrpiqJcCvwFuARoBH4HjGr9+LHLVVX9XtMDECLA2Wzdn2MihDg6yVffEBtq47pJSVw+Pp7P9lbwwfZS8qqbeH5dAa9tKGLWECfnjYghp9LNW1uK2VvW8nesYIuJeRnRXDAqltjQH76Xw2JCWHught2lDW3NprDRQ7GEOWjIycedX4w9KU6XYzUSyZcQ2pF8CaENo2TL1EvvMwnIVFV1n6qqHuB/wHk/2uY84JXWr98FZiqKoqiqWq+q6gpamk5CCA1UV1frXYIQAUvy1bfYrWbOHRHD8xcO5+HZaUxICqPJ6+fjnWVct3AnD3+Zw94yNxHBFhZMTOC/l47kpskDDms0AQyNCQFgT2l922Mmi4WoyeMAubqpt0i+hNCO5EsIbRglW721jC4JOHDIv/OAk461jaqqXkVRqoFooKydfb+kKIoPWAg8rAb6xHMhNOBy9cysFCHEkSRffZNJUZg0MIJJAyPIrnDzwfZSPs+swBVi5cLRscwaGk2Q5dh/kxvW2mzaXdZw2OPOaRMo/WwlFSvXk3TxXE2PQUi+hNCS5EsIbRglW/19QPjlqqrmK4oSRkuz6Upa5j61KSkp4dprr8ViseDz+bjgggu4+eabKSoqwuFwYDabqampISYmhoqKClRVJSYmhuLiYkJDQwGoq6sjLi6O0tJSFEXB6XRSWlpKeHg4Pp+P+vp64uPjKSoqwmq1EhERQVlZGREREXg8Htxud9vzNpuNsLAwysvLiYqKwu1209jY2PZ8cHAwdrudyspKoqOjqa2txePxtD1vt9ux2WxUV1fjcrmorq6mubm57Xk5JjmmrhxTdnY2MTExAXVMgfh9kmPqn8fk9/sJDg4OqGMKtO+TqbaS68dHc8lgS2vN4RTlHzjuMYU0VgCwt7SB7Jwc4mJjqaiooDk9qeXnj+XrKC8vl++TxseUnZ1NbGxsQB1TIH6f5Jj65zGpqhpwxxSI3yc5pv53TIqiUFZWFhDHdDxKb1wIpCjKFOABVVVnt/77XgBVVf90yDZLW7dZrSiKBSgCYg5eqaQoytXACYcOCP/Rexz1+dWrV6sZGRk9f1BCBJD9+/cb4o4IQuhB8hW4rvzfdorrPDxzQQapzpZhn6rfz5cj5tJcVcuMdQsJSU7QucqO83u9FH/6Dc4p4wiKjda7nA6RfAmhHcmXENoIpGxt2LBh/cyZM0842nO9NbPpO2CIoiipiqLYgEuBj360zUfAgtavLwS+PN6SOEVRLIqiuFq/tgJnA9t6vHIhDCA+Pl7vEoQIWJKvwNU2t+mQpXSKyXTI3Kb1utTVVVmPvsTmG3/HilMup+jTr/Uup0MkX0JoR/IlhDaMkq1eaTapquoFbgGWAjuBt1VV3a4oyoOKopzbutkLQLSiKJnAHcA9B1+vKEoO8A/gakVR8hRFGQEEAUsVRdkCbALyged643iECDRFRUV6lyBEwJJ8Ba62uU2lR85tgv41JLy5upb9z7/d8nVlDZuu/S1bb/8j3vqGdl6pL8mXENqRfAmhDaNkq9dmNqmqughY9KPH7j/k60bgomO8dtAxdjuxp+oTwsgcDofeJQgRsCRfgWuY6+Ad6Q5vyERPa/nxpGLVBlRVRVGUXq+ts3JffBdvbT3OqROIm3cKux96ivw3P6Fy9UbGPPV7IieO0rvEo5J8CaEdyZcQ2jBKtnprGZ0Qog8zm816lyBEwJJ8Ba4hrhAUYF+FG4/P3/Z4aEYaVmcEjQUlNOTk61dgB3nrG8h59i0ABt9xNSnXXcSUpS8SNnIIDTn5rD3352T+/QX8Xq/OlR5J8iWEdiRfQmjDKNmSZpMQgpqaGr1LECJgSb4CV4jNzMDIYLx+lewKd9vjismEc8p4oH/MbTrwygc0V9YQeeJonK1XZYVlpDFl0XMM+vllqH4/mX9/gbXn/ZyGnDydqz2c5EsI7Ui+hNCGUbIlzSYhBDExMXqXIETAknwFtqHHnNt0cCndxl6vqTN87iayn34DgMG3XX3Ykj9TkI2M39/Cie88QXBiLNXrt7Ny5tXkvfkJvXE3446QfAmhHcmXENowSrak2SSEoKKiQu8ShAhYkq/AdnBu0xHNpqkHr2za0GcaM0eT9/pHeEorCB+Tgev0yUfdJnr6CUz78lXiz52Jr76Bbbf/kU3X3YenorqXqz2S5EsI7Ui+hNCGUbLVawPChRB9V1/+RUiI/k7yFdgOXtn04yHhocNSsbmiaCouoz4rl9D0FD3KOy5/k4fsf78OwODbFxx3kLk1MpyxzzxIzJlT2XHvoxR/+jWV67YQM3MKERNGEjlhBKEZaZgsvfujpeRLCO1IvoTQhlGyJc0mIYRhLuUUQg+Sr8A22GnHrEBuVSMNHh8htpahn4qi4Jw6gaKPvqBi5YY+2WzKf3sRjQUlhGakETv75Ha3VxSFpIvmEjVpLFtufZCqdVvI/9+n5P/vUwBM9iAixmQQMX4EEeNHEDlhBMED4jW9G5/kSwjtSL6E0IZRsiXNJiEExcXFpKT0vV+EhAgEkq/AZrOYSHXaySx3k1newJiEsLbnnNN+aDYlLzhfxyqP5G/2su+frwGts5pMHZ+sEJKSyEkf/JvqjTuo2rCd6g07qN64g4acfCrXbqZy7ea2bW0xTiLGjyBm5hQGXvWTHm88Sb6E0I7kSwhtGCVb0mwSQhAaGqp3CUIELMlX4BsWE0JmuZvdpUc2mwAqVrXMbdLyCp/OKnxvGe4DhTjSk4k/57ROv14xmYicOIrIiaPaBQDI5wAAIABJREFUHvOUV1G9aecPDahNO/CUVlC6bAWly1YQlpFG1Elje/IwJF9CaEjyJYQ2jJItaTYJIYQQQnTD0BgHn+4qP2Juk2NwMkFxrpa5TXtyCB2WqlOFh1N9PrL++SoAab9cgGI298h+bdGRxMycQszMKS3vo6o05OST9Y+XKHhnMfnvLunxZpMQQggh+ia5G50Qgrq6Or1LECJgSb4CX9sd6coObzYpikL0yRMB2Hr7H2kq7Rt3nyn6+CsasnKxJyeScP6Zmr2Poig4UgeQevPlLe/70Zf4mzw9+h6SLyG0I/kSQhtGyZY0m4QQxMXF6V2CEAFL8hX4UqKCCTIrFNV6qG70Hvbc4DuvJXhAPNUbtrN67nXU7szSqcoWqt9P1uMvA5D2yysxWbW/yD0sI42wUUPwVtdS+sXqHt235EsI7Ui+hNCGUbIlzSYhBKWlpXqXIETAknwFPrNJIb316qYjltKlDmDK4ueJmDCSxrwi1pxzI6VfrtGjTABKln5L3a59BCfGknTR3F5738T5swEoeHdJj+5X8iWEdiRfQmjDKNmSZpMQok8NrRUi0Ei+jGFYzNGX0gEExTiZtPBJ4s+dia+ugfVX/Jrclxb2domoqkrWY68AkHrzFZiCbL323gnnnwkmEyWfr8JTWdNj+5V8CaEdyZcQ2jBKtqTZJITA6XTqXYIQAUvyZQwHm017SuuP+rzZHsTY//yBwbdfDX4/O+59lJ3/9xiqz9drNZZ9uYaaLbuwxTgZcNk5vfa+AMHxMUSfPBHV00zxJ1/22H4lX0JoR/IlhDaMki1pNgkhDHMppxB6kHwZw1CXA2hZRqeq6lG3UUwmhtx9A6P/+TsUq4X9z7/DhgV34607eoOqJ7Vc1fQSAKk/vwyzPUjz9/yxxPlzACh4d2mP7VPyJYR2JF9CaMMo2ZJmkxCC8PBwvUsQImBJvowhMdxGWJCZCreXsobm426bdPFcTnznn1idEZR+voq15/4cd16RpvVVrFxP1ffbsDojGLjgJ5q+17HEnXUKZnswlWs307C/oEf2KfkSQjuSLyG0YZRsSbNJCIGvF5dxCGE0ki9jUBSFIa1DwneXHjm36ceck8cx+dPnCBmcTO2OTNbMu57qjTs0qy/rsZcBGHTDJVgcIZq9z/FYHCHEzp0BQOH7y3pkn5IvIbQj+RJCG0bJlvb3uxVC9Hn19fW4XC69yxAiIEm+jGOYK4QN+bXsKW1g+qDIdrd3pA5gyqfPsvHa31KxcgNrL7iZjPtvwRoVQXNNHd6aOry1dXhr6vHW1tFc/cO/m2vqMNuDcKSn4Bic3PI5PRnH4BRsUYf/xbRy3RYqVm7AEh5K8s8u1OrwOyRx/mwK31tGwbtLSPvVgm4PSZV8CaEdyZcQ2jBKtqTZJIQgPj5e7xKECFiSL+MYGtPxK5sOskaGc8Kbj7Hjnr+T98bH7Lj30U69Z/3e/Uc8ZouOPKz5VLL0WwBSrr0Ia3hop/bf06JPORGbK4r6zFxqNu8iYtzwbu1P8iWEdiRfQmjDKNmSZpMQgqKiIlJSUvQuQ4iAJPkyjoN3pNtb1jIkvKNX7ZhsVkY+eg/hYzMoWboCi8OOJdyBJTwMa7gDS1golvBQrBGhrV+3POatraM+M5f6zP3UZ7V+zszFU16Fp7yKyrWb297D7Agh5fqLNTnuzjBZLCScfyb7n3ubgoVLu91sknwJoR3JlxDaMEq2pNkkhMBqtepdghABS/JlHC6HDWeIhYoGLwU1TSRFBHf4tYqikLzgfJIXnN+p9wwfNfSwf6t+P42FpS3Np70tTSj3/nwSzj8TmzOiU/vWSuL82ex/7m0K3/+MYb+/BZOl6z+OSr6E0I7kSwhtGCVb0mwSQhAR0Td+AREiEEm+jGWYy8Hq3Gp2lzZ0qtnUUxSTCXtSHPakOFwzTuz19++I8LEZONKTqc/Mpfyb74iZOaXL+5J8CaEdyZcQ2jBKtuRudEIIysrK9C5BiIAl+TKWtrlNZR2f22Q0iqKQeOEcAAoWLu3WviRfQmhH8iWENoySLWk2CSEM010XQg+SL2M5OLdpd4k0m44n4fxZABQv/gZvXX2X9yP5EkI7ki8htGGUbEmzSQiBx+PRuwQhApbky1iGulqaTVnlDfj8qs7V9F0hKYlEnTQWv7uJ4kXLu7wfyVdgUv1+vUsQSL6E0IpRsiXNJiEEbrdb7xKECFiSL2MJD7aQEGajyaeSUynf++NJvHA2AAULl3R5H5KvwKL6/ez503/4ImMORR9/qXc5hif5EkIbRsmWNJuEEMTHx+tdghABS/JlPAfnNu0plaV0xxN/zukoNivl366nsai0a/uQfAUMv6eZLbc+yL4nXsVbU8f2u/+Op6Ja77IMTfIlhDaMki1pNgkhKCoq0rsEIQKW5Mt4hsU4ABkS3h5rZDixZ0wFv5/C9z/r0j4kX4GhuaaO7y+7g8KFyzA7QggbkU5zRRV7Hvm33qUZmuRLCG0YJVvSbBJCYLPZ9C5BiIAl+TKeYXJlU4d19650PZ0vv6eZxoIS/E3GmKfRFzQWlLD2vJ9TsWI9QbHRTHr/KcY++xCKzUre6x9TuXaz3iUalpy/hNCGUbJl0bsAIYT+wsLC9C5BiIAl+TKe9Gg7JgWyK9x4vH5sFvnb3rHEzJyCJSKM2m17qd2ZRdjwwZ16fXfy5Wtsom7XPqq37KZm625qNu+mdlcWqqcZAGtUOEGx0QTFuVo/ogmKdxEce8jXCbGYbNYu12B0tTuzWH/5nTQWlOBIT2biG48RkpwAQNotV5L1jxfZftdfmfr5K5is8mtLb5PzlxDaMEq25P/aQgjKy8sJDQ3VuwwhApLky3jsVjPJkcHkVDaSVeFmeKxD75L6LFOQjfhzTyfvtQ8pWLiUYf/3i069vqP58rmbqN2xl5otu9uaS3W79qF6fUdsa3NF0VxVQ3Nly0fd7uxj7jcoNppxL/6RqBNGd6puAeUrN7Dxmnvw1tQROWkME175K7ao8Lbn0355JYXvLaVudzY5z/yPtFuu0LFaY5LzlxDaMEq2pNkkhCAqKkrvEoQIWJIvYxoWE0JOZSO7Sxuk2dSOpAvnkPfahxS+t4yhv70JxdTxK8Hay5fP3UTmP14k55n/tV2x1EZRcAwZRPiYoUSMySB89DDCRw/FEuZA9fvxlFfRVFJOU3E5TUVlNJWUtXxdXEZjcRmNecU0FZfx3UW/ZNwzDxE7a3pXDt+QCj/4jC2/fBjV00zcWacy5snfY7YHHbaNOTiIEX/+Nd9fejuZj75A/Lkz2656Er1Dzl9CaMMo2ZJmkxACt9tNeHh4+xsKITpN8mVMQ10hLN1TwZ7SeiBG73L6tMgTR2MfmID7QCEVqzYSPX1ih197vHxVrNnEtjv/TENWLigKoRlphI/JaGsuhY1Mx+IIOeprFZOJoBgnQTFOGDnkqNv4vV523PU38t74mA1X38PIv93FwMvP7XDtRqSqKjlPv8nuB58EIOW6i8j4wy9RzOajbu869STif3IGRR98zs77/sGEV/+Koii9WbKhyflLCG0YJVvSbBJC0NjYqHcJQgQsyZcxtd2RToaEt0sxmUiYP4t9j79CwcKlnWo2HS1f3tp69jzyNLkvvweAY8ggRj12b48vdTNZLIx89B6C4lxkPfYS2+/8M02FpQy+82ddbojUZ+ex/9m3CB89jMSL5gTUnCLV52Pn/U+Q+8K7wP+3d99xctz1/cdf353tu9cl3Ukn6U7dkovcY7AJ/BBgIICxcQUCIaaFGoIhlARMSQjgQOiQYBxMHGMwpjlUGyfGxhi5ybIl25LVy/V+23e+vz9m73TqbUer230/H499zM7s7uxnTn57dB995zuw7Pp30/m2qw/7s1r+yffS97s/0vvb++n55b20vvz5J6JcQecvEb/USrY0Y6WI0NbWVukSRKqW8lWbFjRHCQUMO4azjOf2nxdI9jbnNRcD0H3nPRTT2SP+3L756r3rD9z3gtez7T/vwAQdFr3vTVx413/6NqeSMYYlf/8WVnzugxAIsPGGG3nyA5/FLRSOaj+FsXGe/tTXuO/PX8u2m37EE3/3z/z+oqvZceudR72vk01hbJy+e1fz6F9/mG033o4Jh1j5zU+y4O3XHFFTLjKrhaUffhsA6//hixTGxv0uWUp0/hLxR61kS80mEaGrq6vSJYhULeWrNoWcAAtbYlhgQ59GNx1Ockkn9StPoTA6Ts9v7jviz03kK9c/xOPv+gQPv/46Mju7qV95Cs/9zU0s+fu3EIj4f4vp+W94NWfd+E8EomF2/NfPeOzaj1BMHf5frq3rsvO2X/D7517N5q/dgs0XaLtkFYnF80lv3cUT7/tn7rvoGnbe9otp0XSy1pLauotdP/o16z50A/eveiN3Lb2Yh658Lz2/vo9gfZJzb/0is1/9oqPa77w3vJqGM5eT2dXDxs/f6FP1si+dv0T8USvZqp6xuSJyzKLRaKVLEKlaylftWjojztO9KZ7pTXHmnNq4zfHxmHP5xYyseYrNX/sviuMp4gvnkVg4j/DM5oOOgIlEIuwuzeeT6x8iEA2z5INvpeOtVxIInti/5ra+7Pmc94Mv88gbPkDPr+9j9ZXv4eybP0+4ueGA7x96+AnW/8O/MfzoOgAazjmVFZ9+Hw1nrcAWi+z+8W/Z+IWbSG3aztr3fppnv/RdFr3vr5h96YtP+LEdjJvLM/LEMwz+6XGGVq9l6KEnyHb37fUeE3SoX7mCxvNOZ/4bLyWxaP5Rf49xHFZ87oM88NJr2frtHzLnipdSf9rSch2GHITOXyL+qJVsGWttpWvw1QMPPGBPOeWUSpchclIbGRmpiUnqRCpB+apdv3mmnxvu3cbzFjTyj6sWVLqck162d4D/PefS/e4a5yTjJBbOJ7FoHvEF80gs8ppQTl2CJz/+JQbv/iMAzc89m1P/9UMkFsytRPmTxp7ZwkPXvI/Mzm4SSzo497+/QGzenruoZbp6eebT32DX7b8CINI2g2X/8A5mX/aS/e7E5xYK7L7jtzz7he+Q2rITgPii+Sz+uzcx+9UvOujE2uVWTGUYf3YrY89sYWzDFsZLy9TmHdjC3peJhpobaDz3dJrOO43Gc0+nYeVynHh5frFa/4//xtb/+AENZ63ggju/dcKOv1bp/CXij2rK1iOPPPLwqlWrzj3Qa2o2iQhbt26lo6Oj0mWIVCXlq3ZtGUzz1h89RWsyzPeuPrXS5UwLgw+tpf/eh0ht2s74pu2MP7uNwvDoIT8TrEuw7GPvZO7rXrVfs6ZSMrt7eei1f8fY+meJtM7gnP/+VxKL5rPl329j0799l2IqTSASpvPtV7PwPW846F3xJriFArtu/zXPfvEm0lt3AZBY0sGiv3sTs1+1qqxNl9TWnQzc/yhjz2xmfMMWxjZsJb19NxzodwZjSCyeT9N5Z9B43uk0nnc6iUXzfbtjXGF0nN8/7xqyXX2s+OwHmP/GS335HvHo/CXij2rKlppNajaJHNLY2BjJZLLSZYhUJeWrdhVdy6U3P06m4PKD151GfTTIeK7IWLbIaLbISLbAaLbIaGk5li3gArPrIsypDzOnPkJrMkzIOTkaKJVgrSU/MMz4pu2lBtQ2xp/1nqd3dNFwwUpO/5cPEJ0zq9Kl7ic/PMojf/UhBh94lGBdglBTA+ltXqOo9eXPZ9nH30W8o/2o9unmC+z64a+8ptP23QDEF8yl829eS/uVL8OJRo653pG1T7PpK/9F1533gOvu9ZoJOsQXzCO5tJPk0k4SS0rLhfPLNmrpSHXdeQ+PvfmjBOuTPO/+7xOZ2XxCv7+W6Pwl4o9qypaaTWo2iRzS7t27mT179uHfKCJHTfmqbe+/cwNru8aIhwJkCi7uUf61K2BgVjLM7LoI7fWlJlRDhNl1EWYkQsRDDk7An1Ek08HJnq9iJsvad3+Krp//DoDksgUs//T7aHneAf9efsTcfIGdP/gFm75082QDKzyjiY63XMn8N15KqPHILs+w1jL4wGNs+srN9N3zIAAmFGTWSy6i/rQlJJYuILmkk/iCuQRCJ8c8UdZaHnn9dfTe/QCzL3sJK79+faVLqlone75Epqtqytahmk0nx1lDRCoql8tVugSRqqV81bYL5teztmuMVN4bKRIPBaiLBKmLOKVHcK+ltbB7NMuukSy7RnL0jOXoGvUej+468OVksVCARMghEXaIhwMkwg6JkEM87G1LhB0aY0Fa4iFa4iFmxEM0xIIEfLrU6UQ62fPlRCOs/NYnafyzM3BiUdqvenlZJvcOhILMe92raL/q5XTfeQ+bv3YLI2ufYcNnvsWmL3+PeX95CZ1vveqgI76s69L72/vZ9JXvMfTQE16t8Rhz//JVLHjbNSflSLEJxhiW//P76X/+a9l9x29ov/ovmPHn51W6rKp0sudLZLqqlWxpZJOIkM1miUSOfei9iByc8lXbrLX0jucJO4ZkJEjwKEch5You3aO5UvPJa0BNPB9M50nnXY7lb3KOgaZS82myCZUI0RQLEQkanIDBMYZgYM9zJ2BwAnjbjCEWCjC7PlLRppXy5bHW0n/vajZ/7Rb6710NeCOU5lz2Eha843Ukl3kT1Lv5Al0/vYtNX/keY09vBiDUVE/HtVcw/68vP+id805Gz375Zjb88zeJL5jL2Td/juSSzkqXVHWULxF/VFO2dBmdmk0ih1RNk9SJnGyUL/GTay3pvMt4rsh4rkgqV2Q8Xyyte9vHckWG0nn6U3n6x73lSLZ4+J0fgUTYYfmsOCtmJVjRmmDZzASJ8Im7Q5jytb/hNU+x+Wu37DX30syXXETT+Wew/bs/npzrKTJ7Jgvefg1zX/+qw05QfjJyc3n+8KK/YuwZr2nW8vzz6Lj2Cmaueo7uUlcmypeIP6opW2o2qdkkckg9PT3MmnXyDpkXmc6ULzkZ5QouA/s0oPpTeQbSBfJFl6JrKbpQcC1Fa0vr3vNC6bWRTIG+VH6v/RpgQXOU5aXm04pZSebUh327O5nydXCpLTvY/I1b2Xnb/+Bm9lyyEV80n4XvfD1zLr+YQDhUwQqPX2ZXDxu/eBO7bv8VbjoLQKxjDvPf9BrmXvMKQg11Fa7Qf+ntu7GuJd4xp+z7Vr5E/FFN2VKzSc0mkUMaGhqisbGx0mWIVCXlS6pZ73iO9d3jPNkzzrrucZ7tT1PYZxb0hmiQ5y1o5G8uaC/7nfWUr8PL9g6w7Tu3M/bMFmZf+mJaX/bnVTfyJzc4ws5b72TbTT+aHLnlxKLMueKlzH/Ta6hbvqjCFZafLRbZ/PVb2PC5b2MCAc666V+Y+cILyvodypeIP6opW2o2qdkkckjVNJRT5GSjfEktyRZcNvSlWFdqPq3rHmcoUwDgfc+bz8uWtZT1+5QvmcoWi/Te9Qe23nj75NxVAM0Xnk3HtVcw6+KLqqLRltqyg8ff/SmGVq+d3GbCIc7+zmeY+aLnlu17lC8Rf1RTtg7VbHKuv/76E1zOibVjx47rZ8yYUekyRE5qoVCIcDhc6TJEqpLyJbUkGDDMSoY5tTXJCxY1cfnps5iVDPPAtmG2DWV45fIZZZ1QXPmSqUwgQGJxB+1XvIy2V60Caxl7ZgupTdvp+und7LztF+SHRonNayPUWF/pco+atZbt3/spj77pw6S37iTSNoMz//3ThBrqGH7oCbruvIf6U5eSWDS/LN+nfIn4o5qytXv37t0LFy789wO9Vt6xzCIyLQ0PD1e6BJGqpXxJLTPG8OIlzcyuC7NrJMu9mwfLun/lSw4mubSTFf9yHS947Kec8sn3El8wl8zObp794k3c+2dX8KfL3sXOH/6SYipT6VKPSKa7j4dfdx3rPvg5iqk0sy99MRfe81/MfOEFLP+n99Hx5iuwuTyPXvthen79+7J8p/Il4o9ayZaaTSJCPp8//JtE5JgoX1LrnIDhqpWtANz6WDduGadwUL7kcEL1STrfehXPu//7nPejrzLn8pcSiEUY+MMjrH33p/jdGa/giev+haGHn8Cv6UWs6zL29GZ6fnM/qW27j/p7dv/0bu5/wevp+90DhBrrWPnNT7LyG58g3OSNzjLGcMqn/paOt12FzRd49M0fpfuX/3fcdR8uX/mhEfruXc2uH/2awuj4cX+fSK2olXOX5mwSEbLZLJFIpNJliFQl5UsEckWXv7ptHX2pPJ948UKe09FQlv0qX3Is8iNjdP3sbnbceifDDz85uT2xpIO5V7+COVe8lMisY59fLLO7l+FH1zH06DqGH13H8GPrKY6lJl+PtM2g6bwzaDzvdJrOO52605YSCAX3r3NohHUf+QK77/gNADP+3wWc9sUPE22becDvtdby9Ce+ypZv3ooJOqz81qdo+4sXHPNxTM1XYTzFyONPM7zmKYYfW8/ImqdIbd4x+d5QcyOL3//XzPvLS6b9XQ5F/FZN5y5NEK5mk8ghVdMkdSInG+VLxHPHEz188487WTYzzpdftRRThrmblC85XmNPb2bH9/+HXbf/ilzvAADGcUgsnk+ouZFwcwOh5gbCTVOWTQ2EW7xlMBln7JnNXlPp0fUMPbqO7O7e/b4n2t5KvKOd0XUbyA+N7vVaIBah4cwVNJ1/uteEOvc0htc8xdq//Seyu3txYlGWXf9u5r3h1YfNjbWWZz79dTZ/7RaM47Dym5+g7ZUvPKqfiXVdRtY8xaa778PZ1sPIY+sZ27AF9vm9MRAJU3fqEnBdhh9bD0B8wVyWfuTttL7i/5Ul4yLVqJrOXWo2qdkkckh9fX1oIn0RfyhfIp50vsgbblvHcKbAZ1+2mLPa6457n8qXlIubL9D3uwfYceud9N71B2yheMz7CtYlaDhrBQ1nLS8tVxBt9f47ta7L+MZtDK5+nKHVaxlcvZbUs9sOuq/Gc0/j9K98jMSCuUf8/dZaNnzmW2z68s0Yx+GMr1/P7EtWHfozrsvQ6rV0/fx3dN15D9muvr1eN0GHuuWLqF95Cg1nLqdh5SkkT1lEIBTEWkvPr+7l6U9/Y/JYGs4+lWUfeyfNF5x5xHWL1IpqOnep2aRmk8ghDQ4O0tTUVOkyRKqS8iWyx62PdXHTQ7tZOTvJ5/9iyXHvT/kSP+SHRkjv7CY/OEyuf5j8oPfIDUwsR8gPDJEbHKYwMkZs/hwazz51ssGUWDQfEzjyqXFzfYMMPfwEg396nMHVaxlZ8xTWWhZfdy0L3vFaAsH9L7E7HGstGz7772z6t+96DaevfYzZr37x3u85RIMp2t5K8rzTmHn+mTSceQp1KxbjRA992Y+bL7Djv3/OxhtunBwlNuvii1j60XeQXNp51McgUq2q6dx1qGbT0f+fS0SqzsjISNX8D0/kZKN8iezxyuUzuG1NN2t2j7Gue5wVrYnj2p/yJX4INdYTaqw/Yd8XntHErIufx6yLnweAm81hXYsTO/Y5XYwxLPn7t2ICDs9+4TuseccnsK5l9qtfdPAG09w22l75Qtpe+UIazlrOtm3bjupSn0AoyPw3Xsqcyy9myzduZfPX/5ueX99Hz2//wNzXvZLF1107OcLrYKy1uOkshbFxiukstljEFoqlZQFbKOJObJvYXnSpP30pkZnNx/zzEjmRauXcpZFNIkIqlSIej1e6DJGqpHyJ7O2m1bu4dU03fzavnk9dvOi49qV8iRzexhtuZOMNN0IgQGRmM9nugzeYps6zdLz5yvb0s/GG77Djlp9hi0WcWJTZl3mjqwpjKQqjKQpj4xRGvUdxbJzCaApbPPpLGAOxCPPfeBkL3vk6NZ3kpFdN5y6NbBKRQxoYGKia/+GJnGyUL5G9XXraTO54oocHt4/wbH+KRS3Hng/lS+TwFl93LQQCbPzcf5Dt7jtkg2mq481XZFYLp37uA3S89Uo2/PM36f7F/7Hjlp8f9nOBaJhgMkEgEiYQCmJCQYzjYILO5DIQ3LOtmM4wtHotW755K9u/+2Pm//VrWPCO1xFuaTzm2kX8VCvnLjWbRIRqH+EoUknKl8jeGmMhXn7KDH78ZC/ff6ybj65acMz7Ur5Ejsziv3sTTeefjhOPH7LBNFW58pVc3MFZ3/mMNy/V6rUEEzGCdQmCyYS3rEvgJOKlbXEC4dBRf8fwmqfYeMON9P72fjZ/7Ra23XQHHW++gs63X0O4ueGo92etpTA6TrAuobvqSdnVyrlLl9GJCJlMhmg0WukyRKqS8iWyv97xHG+8bR1F1/Lty5czr/HYMqJ8ifhnOuZr+NF1XtPp7gcAcJJxr+n0tmsINx18Hq5Mdx8jj61n6NF1DD+2npE1T5EfHMFJxInNn018/mxi8+cQ65hDfP4cYvO89WAidsD9WWsppjLkh0YoDI+SHxolPzxCfmh0ck4u6xbBtVjXhaKLdV2vCeG62NJ6ZGaz952dc4nNbSMQ0liRajAds3Uwuhudmk0ih7R169ajmgBSRI6c8iVyYF/8/TZ++XQ/Fy9t5v1/fmwZUb5E/DOd8zX0yJNs/Py36bvnQQCCdQk63nIVnW+7CoxhZM1TDD26jpHH1jP82Hoyu3r220cgEsbN5g75PeEZTcTmzyHUUEd+ZHRKY2kUmy+U9ZiM4xBtbyXe2U68s53Y/DmTz+Od7QSTx3fDBTlxpnO29qVmk5pNIofU399PS0tLpcsQqUrKl8iB7RzOcu3t6zDAf155Kq114aPeh/Il4p9qyNfg6rVs/Py36b93NeDNB+Vm9m8gOck4DWcu3/M4awXRObMoDI+S2rqL9LZdpLft9p5v30Vq227S23djc/mDfncgFiHUUOc9GusJlp47sSgmYCAQwDgBCBiMmXgewAQMJuAAkO3uI7VlJ6mtO72G2CF+d493tlM/5RjqT1920JFXUlnVkK0JmiBcRERERE4q7Q0Rnr+wiXueHeSHa7t513PnVbokEakyTeedznk/+BKDD65hw+e/zcB9DxOIhKk7dUmpqeQ1ZhKL5mMiKcwmAAAfjUlEQVQCgf0+H2qsp6GxnoaV+w9esK5LtquP1LZdFEbHCTXWlxpLdQTrkzjRSFmPpZjJkt7RRXrLzskGVGrLTtJbd00+T23ZSddP7vI+EAiQXNq5VxOtbsXiY5oTS+RYqNkkIoyNjVVNd13kZKN8iRzc1StbuefZQX75dD+vPbON5vjR/RKkfIn4p5ry1fRnKzn/9q+Q7ekn1FhfloaLCQSIzplFdM6sMlR4eE40QnJxB8nF+19+5eYLjD29ieHSZYHDj61nbP0mxp7yHju//z9ezeEQyaWdhJsbCTXUEWxITmmQ1U3ZVk+osY5AKEhhPE0xlaY4nqYwnvKWY6m91oupNMZxJhttE58PlvY98R1OIo4xxpvTajxFrn+IXP8wuf5Bcv1D5PuHyA0MlbYPURgdJzKzmWh7K9H2WcTa24i2txJrbyXU0nhSTN5uXZf84Ai5vkEwhkA0ghOL4EQjBKKRA86zVU3ZOhQ1m0SE1tbWSpcgUrWUL5GDW9Ac4zkdDTywdZg7nujhzee3H9XnlS8R/1RjviKzqvMX/EAoSP1pS6k/bSnzXn8JAMV0lpEnn/EmPC81oMY3bmP0iQ0Vq9MEHYJ1CYqpzGHnwzqcQDRMtL2NWHsr0fZWIjObwQDWawBhrfd8YtJ1vHWsxQQCBGIRnFjUawqVlk4sUmoWRSefF1MZsj39ZLv7yfX2e897Bsh295Pt7SfXO4AtFA95zIHonuaTE4tgwiGca69g7mtfeVw/g5Odmk0iQm9vL/Pm6fIFET8oXyKH9tozW3lg6zA/X9/HlWe0Uh898r+eKl8i/lG+pjcnFqHp3NNpOvf0yW35kTHGN24jP1y6S97wGPnhUQpDo+RHvMnNCyNjpeUobr6AE48RTMZxEjGCiRhOovQ87j0PJmI48Shusejtp7TfwvCI97y0rTA0SjGdIT84AnhzWoWbGwm3NBFuaSTc0kiopWGv9WAyTrZ3gMyObjI7u0nv9JaZXd3kh0ZJPbuN1LPbKvUjnhRsqCM8owkAN5OlmM56y0wWWyhSHEtRHEvt9Zlc/1AlSj2h1GwSkZNiCKpItVK+RA5t2cwEZ7fX8cjOUX62rpfXnz37iD+rfIn4R/mqPqH6JI1nr6jY97u5PIWRMZy416A6HoWxcTI7e0oNqK7Jy9gmHt5/vsabi8sYb9STMd5lfEWXYiZLMZ0pNYcyk00i77FnuxOPEZnVTGRWC+GZzURaZ0yuR2Y2E57ZfND5uay12HyBYia7VxNq99ZtzDmjcn8OJ4qaTSJCc3NzpUsQqVrKl8jhXbOylUd2jvLjJ3t5zemziIWcI/qc8iXiH+VLyi0QDk2OADpewWSC5LIFJJctKMv+/GCMwYRD3hxh9cnJ7e3zWonG4xWs7MTYf8p9Eak5vb29lS5BpGopXyKHd8bsJCtmJRjNFvnR2h6yBfeIPleJfOWLLtuHMjy4bZj7tgyxYzhD0T347chFpiudv0T8USvZ0sgmEaG+vr7SJYhULeVL5PCMMVxzZiv/+JtN3PxIFzc/0kVTLEhbXZi2ugityXDpeZjWZIRZyRAhJ7BXvoquJVNwyeRd0oViaemtZ4suYccQDTrEQgGiwcDkMhpyCAb2vlwoV3DpGs2xcyTLrpHs5HLXSJaesRz79pbCjmF+Y5TO5hidTVEWNMXobI4yIx7SpUgyben8JeKPWsmWmk0iQrF48DsoiMjxUb5Ejsz58+p55fIZPLxzhJ6xPIPpAoPpAut7Uvu9N2CgOR4C1yXnbiddcMkXj310UShgiJaaTwB943kOtreAgdZkmDn1EZwAbB3M0DueZ2N/mo396b3emww7dDZF6WyK0VYXpi7iUBcNUh9xqIsEqY8GqYs4hB1dbCAnH52/RPxRK9lSs0lEGB8fZ8aMGZUuQ6QqKV8iR8YYw7sv9O58VXQt/ak83WM5ukazdI3m6B7N0TWao2ssS994nr7x/F6fDxhKI5UCRIPOXqOXwsEA+aK712inTMElnS+SKbjkXUs+W2Q0W5zc1+w6r6E09dFeH6G1Lrxfc2gsW2DrYIbNgxm2DKbZMpBh82Ca0WyRJ7rHeaJ7/JDHHg0GqI+WGlARh/pSI6q+1JiqjwZpmLLeEA0SDQY0akp8pfOXiD9qJVtqNokIbW1tlS5BpGopXyJHzwkYZiXDzEqGOb0tud/rBdfSN54jl8vRkIh5DSXHHFPzxVpLvmhLzScX11pmJsP7XVp3KMlIkFPbkpw6pVZrLQPpAlsG0mwZzNCfyjOSKTCaLTKSLS0zBUazBe/yvzGXnrH8Ib5lb6GAoSEaZE59hHmNEeY1Rpnb4C1nJcI4R1G/yIHo/CXij1rJlppNIkJXVxcdHR2VLkOkKilfIuUXDBja6iJs3dpFQ8vx5csYQzhoCAcD1B/fnbj3229LPERLPMQ5cw8+P4e1llTe9RpQGa8RNZIpMFJqRo1kCwxnCoxMfS1TIFu09KXy9KXyPN41ttc+w46hvd5rPE00odrqwjjGECjdErx0F3ACpQZdwJTunITX7AsGDKGAIeiUnjsBnNJ7pDbo/CXij1rJlppNIkIoFKp0CSJVS/kS8U815MsYQyLskAg7zK478s9lCi6D6Tw7h7NsH8qwvbTcMZylP5Vnc+myvrLWCgSdUhOq1IiaaGA5AUPAgGMMTsBrYgWmPHeMIRFxaCxdEjjxaIwFvW0xb13zV508qiFfIiejWsmWmk0iQkNDQ6VLEKlaypeIf2o5X9FggNl1EWbXRTh3n5FT47kiO4YzbB/Ksr207B3PYS1YLNZSuqOexbWUtoNrvdeK1lJwLYWit8wXvXmtXAv5oj2uydgPJx4KUBfxfkWxWFwX3Ck1T9ToWq+e1mSYj67qpLMp5ltNtaqW8yXip1rJlppNIkJfXx+JRKLSZYhUJeVLxD/K14Elwg7LZiZYNrO8P5uiaym6lry7pwlVdL3GT9F6jaGitaV1cN3SduvNszWWLTKcKTCUKTCcznvLTIHhdGmZKZDKu6TyuSOuaetQho//ZhNfuWQZ9VH9alNOypeIP2olW/o/sojUTHddpBKULxH/KF8nlhPwLpcL+7R/ay1jOe+ugFPnlJqYTyowZT1gDEXX8qFfbmRjf5pP3b2Zz7xs8VFN7C6HpnyJ+KNWsqWLokWEXO7I/wVRRI6O8iXiH+WruhhjqIt4d9ibXR+hrS7CrGSYGYkwLfEQTbEQDdEgdZEgibBDfTTI9S9eSFMsyJrdY3zrjzsqfQhVRfkS8UetZEvNJhEhnU5XugSRqqV8ifhH+ZJZyTAff9FCQgHDT9f18Yun+ipdUtVQvkT8USvZUrNJRGhra6t0CSJVS/kS8Y/yJQArWhO856J5AHz1DztY2zVW4Yqqg/Il4o9ayZaaTSJCV1dXpUsQqVrKl4h/lC+ZcPHSFi47bSYF1/LJuzbTPVobl6n4SfkS8UetZEvNJhEhHPZrqk8RUb5E/KN8yVRvOb+dc9rrGM4U+PhvN5HOFytd0rSmfIn4o1aydcKaTcaYlxpjnjbGbDTGfOgAr0eMMbeVXn/QGNNZ2t5ijLnHGDNmjPnqPp85xxiztvSZLxtjdPsJkWNQV1dX6RJEqpbyJeIf5UumcgKGj7ywk/b6CJsG0txw7zastZUua9pSvkT8USvZOiHNJmOMA3wNeBmwArjGGLNin7ddCwxaaxcDXwQ+W9qeAf4RuO4Au/4G8BZgSenx0vJXL1L9+vv7K12CSNVSvkT8o3zJvuoiQT7x4oXEQwF+v3mIWx7rrnRJ05byJeKPWsnWiRrZdD6w0Vq7yVqbA74PXLLPey4Bvlt6fjuwyhhjrLXj1tr78JpOk4wxs4F6a+0frfdPFjcDr/b1KESqVFNTU6VLEKlaypeIf5QvOZD5TVE+8sJODHDzw7u5b8tQpUualpQvEX/USrZOVLOpHdg+ZX1HadsB32OtLQDDQMth9rnjMPsUkSNQK7ffFKkE5UvEP8qXHMz58xq49vw5AHzuf7eyeUD/rRwt5UvEH7WSrWClC/BbT08P1157LcFgkGKxyGWXXcY73/lOurq6SCQSOI7DyMgIM2fOZGBgAGstM2fOpLu7m2QyCcDY2Bitra309vZijKG5uZne3l7q6+spFouMj4/T1tZGV1cXoVCIhoYG+vr6aGhoIJfLkU6nJ18Ph8PU1dXR399PU1MT6XSaTCYz+Xo0GiUWizE4OEhLSwujo6PkcrnJ12OxGOFwmOHhYWbMmMHw8DD5fH7ydR2TjulYjqm72xtiXk3HVI1/Tjqm6XlMuVwO13Wr6piq8c9JxzQ9j6m7uxtjTFUdUzX+OVXqmC5sCbKhs47/2zLKP/xqI5983gyCbm5aH9OJ/HPK5XIUi8WqOqZq/HPSMU2/YyoWi2zdurUqjulQzImYNM8Y8xzgemvtxaX1DwNYaz8z5T2/Lr3nAWNMEOgCZpYukcMY81fAudbad5XWZwP3WGtPKa1fA7zAWvu2qd/9wAMP2FNOOcXvQxSZ1rLZLJFIpNJliFQl5UvEP8qXHE6u4PL+/9nA070pWpNh2urCRIIBwk6AsGP2ex4qLZ3SfYcmbj9kgKn3IjJmz7ZgAIKBAKGAIeQYgpPLwD7rR34vo4AxJMIO0WAA5yg+V07Kl4g/qilbjzzyyMOrVq0690CvnaiRTauBJcaYBcBO4Grgtfu852fAG4EHgMuB39lDdMKstbuNMSPGmAuAB4E3AF/xo3iRatfV1UVHR0elyxCpSsqXiH+ULzmccDDA9S9ayHt+9jTdYzm6x3KVLumoxUIB4iGHeChAPOwQDzkkwqVtYYdQwDDxS5O1FgveuvWWdmIFiIYc6iMO9dEg9ZEg9VGH+kiQhmiQRNjZq7FVznxZa8kXvdoiwRN2Q3SRk1KtnLtOSLPJWlswxrwL+DXgAN+x1j5pjPkk8JC19mfAjcD3jDEbgQG8hhQAxpgtQD0QNsa8GniJtXYd8A7gP4EY8MvSQ0SOUjQarXQJIlVL+RLxj/IlR6IlEeLbly9n00CaXMGSK7pki+6e5wWXXNGSLbjkiy7ZosW1FmunNm3slIbOnqXFUnQteddrphRKy7zrUthr3VJwXQxHNkqp4FrS+SKpvEu69PD7/lUGSEYcGqJB6iIOFAvE120kGDA4AW9k1sRj6roxkC24pPIumbxLulCcrDmVL3rb8kWKpZ9bPBSgOR6iORaiOR6kKR6iJRaiKR4sbfMe8VAAY/b8xKaOJhOZzmrl3HXC5myy1v4C+MU+2z425XkGuOIgn+08yPaHgNPKV6VIbYrFYpUuQaRqKV8i/lG+5EjFQg6ntiYrXcZRc62dbNqkcl7zaTxXLK172/NF6zVkJpoxAKUmzUSDZkI67zKSLTCSKTCSLZaWBUYyRcZyRUaz3mOP8o0Ec4zXKErlXVLDWXYMZ49rfxODsBxjOLu9jrdfMJf2huq4NEmqW62cu6p+gnARObzBwUHq6+srXYZIVVK+RPyjfEm1m5i7KRF2IOHvdxVdy0i2wGimyEi2wI5dXbTMnEXB9UZvFfZ5TGxzrSUW8uaXioUmHo63DDqT20JOAGsto9kiA+k8g6kC/ak8g+k8A6k8A+mCtyw9z+SLe40m23d+FddOLC0Pbh/hkV3ruXplK1ed0UpYl+rJSaxWzl1qNokILS0tlS5BpGopXyL+Ub5EyscJGJpiIZpiIQA6k22Td8MqF2OMN19UNEhn07HtY3JeqlKzaThT4MbVu/jthgG+90gXd28c4J3Pmcd586r/l3mZnmrl3KWWr4gwOjpa6RJEqpbyJeIf5UvEPydrvowxBIw3b5QTMDTHQ3zg+R3c8BdL6GiKsmskx0d//SyfvGszPdNwQnipfidrtspNzSYRIZfTiVjEL8qXiH+ULxH/TLd8nTE7yTcuPYU3nz+HSDDAfVuGePPt6/nh490U3IPe5FzkhJtu2TpWajaJCG1tbZUuQaRqKV8i/lG+RPwzHfMVDBiuPKOVGy9fzkWdjWQKLv/xp138zY+fYm3XWKXLEwGmZ7aOhZpNIkJXV1elSxCpWsqXiH+ULxH/TOd8zUqG+diLFvDpixcyuy7M1sEM779zA5/73y38dkM/920Z4pGdI6zvGWfLYJqesRyj2YJGQMkJMZ2zdTQ0QbiI1MztN0UqQfkS8Y/yJeKfasjX+fMaWPmaOm5b081tj3dz18ZB7to4eMjPhBxDPOQQCRqs9e56Z62laPdMTl50vaXrWlwACwEDgYA3n1TAcMClE2Byn0Xr3cnPdb076k1uc73nrrVEggGSEYdk2CEZDpKYfO7doXDitfpokBWzEtRH9ev9dFAN2ToS+q9RRAiHw5UuQaRqKV8i/lG+RPxTLfmKBAO84ZzZrFrczM/W9zKcLpDOu6QLRdJ5l1SuSLrgetvyRfJFy3CxcGxfVizvyKhU3iWVd+khf9j3BgysnJ3kws5GntvRwIxEdfz5VaNqydbhqNkkIgwPD9PY2FjpMkSqkvIl4h/lS8Q/1Zav9oYIf3PB3EO+x1pLrmhJ5YtkCy4BYzATo5PwRi4ZmBypZAw4xgATI5W8EUnW7r2+Z/SSBQyBgPe5PSOe9h4F5ZT2nS24jOWKjGWL3jJXZLy0Pp4rMpotMp4r0DOW54nuMR7d5T2++ocdLJsZ58LOBi7saGReY9T3n68cuWrL1sGo2SQizJgxo9IliFQt5UvEP8qXiH9qMV/GGCJBQyR4ckxtHHICJCNBqDv8e0cyBR7cPsz9W4Z5eMcIT/emeLo3xXdW72Z+Y5QLOxq4sLORJTNimFKDTCqjVrKlZpOIMDw8TCKRqHQZIlVJ+RLxj/Il4h/la3qpjwZ58ZIWXrykhXS+yMM7R/nDliH+uG2EbUMZtg1luHVNN3URh4gTYOKCP4tlYmVy2z7rR8IxXnMsGDCEnNIjEDjg873msTLeSK+9t5XWA2ZypJgtjRSz7Bk9NjHXlbXeXFsdTVEWNMfobIoSCznl+cH6oFaypWaTiJDPH/46cBE5NsqXiH+ULxH/KF/TVyzkcFFnIxd1NlJwLWt2jXL/1mH+sHWIgVSBUYqVLtFXBphTH2FBc4yFLTEWNkdZ2ByjNRk+KUZ11Uq21GwSEdra2ipdgkjVUr5E/KN8ifhH+aoOwYDhnLn1nDO3nnc9dy4DqfzkiCUDeLNQlVb2LCaXHGFvxnUh57oUipZ80ZJ33dLSki+Wnpe2u9a7k19xyugkd8qd+IqTI5YspjTiyRgI4M1lZfa505/Bm0x9y2CaTf1ptg1l2DmSZedIlvu2DE3WGA8FWFBqOgUMUJqLyxjv5zDRhwrss76vg434ckp3JHRK83A5xvv5O4GJEVzeNuuGyfWlWDIjfmQ/3GlKzSYRoauri46OjkqXIVKVlC8R/yhfIv5RvqpPwJiauEtdvuiybSjD5oEMmwbS3qM/zVCmwJPd4zzZPV7pEnnTuUbNJhGpfrVwzbBIpShfIv5RvkT8o3zJdBVyAixqibOoZe9mzmAqz7MDaQbT+cl5qSbmgcJaXJiy3ZsX6miuunMtFF1L0VpvWRq9tee5pejCWKr6RzWBmk0iAjjOyTuBnsh0p3yJ+Ef5EvGP8iXVpike4tx4qNJlMDg4SFNTfaXL8N3JcU9HEamokZGRSpcgUrWULxH/KF8i/lG+RPxRK9lSs0lEmDlzZqVLEKlaypeIf5QvEf8oXyL+qJVsqdkkIgwMDFS6BJGqpXyJ+Ef5EvGP8iXij1rJlppNIoK1B7uBp4gcL+VLxD/Kl4h/lC8Rf9RKttRsEpGaGcopUgnKl4h/lC8R/yhfIv6olWyp2SQidHd3V7oEkaqlfIn4R/kS8Y/yJeKPWsmWmk0iQjKZrHQJIlVL+RLxj/Il4h/lS8QftZItNZtERERERERERKRs1GwSEcbGxipdgkjVUr5E/KN8ifhH+RLxR61kS80mEaG1tbXSJYhULeVLxD/Kl4h/lC8Rf9RKttRsEhF6e3srXYJI1VK+RPyjfIn4R/kS8UetZEvNJhHBGFPpEkSqlvIl4h/lS8Q/ypeIP2olW2o2iQjNzc2VLkGkailfIv5RvkT8o3yJ+KNWsqVmk4jUzFBOkUpQvkT8o3yJ+Ef5EvFHrWRLzSYRob6+vtIliFQt5UvEP8qXiH+ULxF/1Eq21GwSEYrFYqVLEKlaypeIf5QvEf8oXyL+qJVsqdkkIoyPj1e6BJGqpXyJ+Ef5EvGP8iXij1rJlppNIkJbW1ulSxCpWsqXiH+ULxH/KF8i/qiVbKnZJCJ0dXVVugSRqqV8ifhH+RLxj/Il4o9ayZaaTSLCT37yk0qXIFK1lC8R/yhfIv5RvkT8USvZUrNJRLjjjjsqXYJI1VK+RPyjfIn4R/kS8UetZEvNJhGhUChUugSRqqV8ifhH+RLxj/Il4o9ayZax1la6Bl/dfffdvcDWStchcjIbGBiY0dzc3FfpOkSqkfIl4h/lS8Q/ypeIP6osWx2rVq2aeaAXqr7ZJCIiIiIiIiIiJ44uoxMRERERERERkbJRs0lERERERERERMpGzSaRGmKMmWeMuccYs84Y86Qx5r2l7c3GmN8aYzaUlk2VrlVkujLGOMaYR40xd5bWFxhjHjTGbDTG3GaMCVe6RpHpyBjTaIy53RjzlDFmvTHmOTp/iZSHMeZ9pb8bPmGMudUYE9X5S+TYGGO+Y4zpMcY8MWXbAc9XxvPlUs4eN8acXbnKy0vNJpHaUgDeb61dAVwAvNMYswL4EHC3tXYJcHdpXUSOzXuB9VPWPwt80Vq7GBgErq1IVSLT35eAX1lrTwFW4uVM5y+R42SMaQfeA5xrrT0NcICr0flL5Fj9J/DSfbYd7Hz1MmBJ6fFW4BsnqEbfqdkkUkOstbuttY+Uno/i/UW9HbgE+G7pbd8FXl2ZCkWmN2PMXOAvgG+X1g3wQuD20luUL5FjYIxpAP4cuBHAWpuz1g6h85dIuQSBmDEmCMSB3ej8JXJMrLX3AgP7bD7Y+eoS4Gbr+SPQaIyZfWIq9ZeaTSI1yhjTCZwFPAi0Wmt3l17qAlorVJbIdPdvwAcBt7TeAgxZawul9R14DV4ROToLgF7gptJlqt82xiTQ+UvkuFlrdwI3ANvwmkzDwMPo/CVSTgc7X7UD26e8r2qypmaTSA0yxiSBHwF/a60dmfqatdYCtiKFiUxjxphXAD3W2ocrXYtIFQoCZwPfsNaeBYyzzyVzOn+JHJvS3DGX4DV15wAJ9r8ESETKpFbOV2o2idQYY0wIr9F0i7X2jtLm7onhmqVlT6XqE5nGLgReZYzZAnwf7/KDL+ENhw6W3jMX2FmZ8kSmtR3ADmvtg6X12/GaTzp/iRy/FwGbrbW91to8cAfeOU3nL5HyOdj5aicwb8r7qiZrajaJ1JDS/DE3AuuttV+Y8tLPgDeWnr8R+OmJrk1kurPWfthaO9da24k3servrLWvA+4BLi+9TfkSOQbW2i5guzFmWWnTKmAdOn+JlMM24AJjTLz0d8WJfOn8JVI+Bztf/Qx4Q+mudBcAw1Mut5vWjDeCS0RqgTHmIuD3wFr2zCnzEbx5m34AzAe2Aldaa/ed1E5EjpAx5gXAddbaVxhjFuKNdGoGHgVeb63NVrI+kenIGHMm3uT7YWAT8Ca8fzjV+UvkOBljPgFchXfn4keBN+PNG6Pzl8hRMsbcCrwAmAF0Ax8HfsIBzlelBu9X8S5dTQFvstY+VIm6y03NJhERERERERERKRtdRiciIiIiIiIiImWjZpOIiIiIiIiIiJSNmk0iIiIiIiIiIlI2ajaJiIiIiIiIiEjZqNkkIiIiIiIiIiJlo2aTiIiIyDRkjOk0xlhjTLDStYiIiIhMpWaTiIiIiIiIiIiUjZpNIiIiIiIiIiJSNmo2iYiIiJSJMWaOMeZHxpheY8xmY8x7StuvN8bcboy5zRgzaox5xBizcsrnlhtj/tcYM2SMedIY86opr8WMMf9qjNlqjBk2xtxnjIlN+drXGWO2GWP6jDEfPYGHKyIiInJAajaJiIiIlIExJgD8HFgDtAOrgL81xlxcesslwA+BZuC/gZ8YY0LGmFDpc78BZgHvBm4xxiwrfe4G4BzguaXPfhBwp3z1RcCy0vd9zBiz3LeDFBERETkCxlpb6RpEREREpj1jzJ8BP7TWzp+y7cPAUmAr8FJr7QWl7QFgJ3Bl6a0/BOZYa93S67cCTwOfBMaBC6y1a/b5vk5gMzDPWrujtO1PwBestd/36TBFREREDkt3LxEREREpjw5gjjFmaMo2B/g9XrNp+8RGa61rjNkBzClt2j7RaCrZijc6agYQBZ49xPd2TXmeApLHfAQiIiIiZaDL6ERERETKYzuw2VrbOOVRZ619een1eRNvLI1smgvsKj3mlbZNmI838qkPyACLTsgRiIiIiJSBmk0iIiIi5fEnYNQY8/elSb0dY8xpxpjzSq+fY4y5zBgTBP4WyAJ/BB7EG5H0wdIcTi8AXgl8vzTa6TvAF0qTjzvGmOcYYyIn/OhEREREjpCaTSIiIiJlYK0tAq8AzsSbS6kP+DbQUHrLT4GrgEHgL4HLrLV5a20Or7n0stJnvg68wVr7VOlz1wFrgdXAAPBZ9Hc4EREROYlpgnARERERnxljrgcWW2tfX+laRERERPymfxUTEREREREREZGyUbNJRERERERERETKRpfRiYiIiIiIiIhI2Whkk4iIiIiIiIiIlI2aTSIiIiIiIiIiUjZqNomIiIiIiIiISNmo2SQiIiIiIiIiImWjZpOIiIiIiIiIiJSNmk0iIiIiIiIiIlI2/x/DeTYUv94TRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='RoboschoolHalfCheetah-v1 MSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = calc_mse(model, dataset_name, X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'RoboschoolHalfCheetah-v1',\n",
       " 'test_mse': 0.011333423760387033,\n",
       " 'train_mse': 0.008962756900149079,\n",
       " 'val_mse': 0.011190289824628143}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoboschoolReacher-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolReacher-v1\n",
      "DOmain name: RoboschoolReacher-v1\n",
      "(6000, 9) (750, 9) (750, 9) (6000, 2) (750, 2) (750, 2)\n",
      "model_name='model_RoboschoolReacher-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "model_path='/tf/srv/hw1/notebooks/model_RoboschoolReacher-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='RoboschoolReacher-v1 MSE')\n"
     ]
    }
   ],
   "source": [
    "# Get the datasets\n",
    "dataset_name = 'RoboschoolReacher-v1'\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_datasets(dataset_name)\n",
    "\n",
    "\n",
    "# Define model\n",
    "config_dict = dict(\n",
    "    dataset_name=dataset_name,\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    units=100,\n",
    "    layers = 3,\n",
    "    l2_reg = 1e-04,\n",
    "    lr = 1e-03,\n",
    "    dropout=None,\n",
    "    use_batchnorm=False)\n",
    "\n",
    "model, model_name, model_path = get_compiled_model(**config_dict)\n",
    "\n",
    "\n",
    "### Callbacks\n",
    "# Reduce learning rate dynamically\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mean_squared_error', factor=0.5, patience=5, verbose=1)\n",
    "tf_board = TensorBoard()\n",
    "\n",
    "# Define a scope object\n",
    "scope = KerasTrainScope(model_name=model_name, history_dir=model_path)\n",
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 750 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 1s 189us/sample - loss: 0.1177 - mean_squared_error: 0.0987 - val_loss: 0.1005 - val_mean_squared_error: 0.0830\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 0s 51us/sample - loss: 0.0964 - mean_squared_error: 0.0794 - val_loss: 0.0884 - val_mean_squared_error: 0.0717\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 0s 57us/sample - loss: 0.0827 - mean_squared_error: 0.0662 - val_loss: 0.0761 - val_mean_squared_error: 0.0595\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 0s 55us/sample - loss: 0.0692 - mean_squared_error: 0.0527 - val_loss: 0.0691 - val_mean_squared_error: 0.0526\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 0s 43us/sample - loss: 0.0625 - mean_squared_error: 0.0460 - val_loss: 0.0602 - val_mean_squared_error: 0.0438\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 0s 44us/sample - loss: 0.0569 - mean_squared_error: 0.0406 - val_loss: 0.0557 - val_mean_squared_error: 0.0394\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 0s 44us/sample - loss: 0.0515 - mean_squared_error: 0.0352 - val_loss: 0.0522 - val_mean_squared_error: 0.0359\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0469 - mean_squared_error: 0.0306 - val_loss: 0.0465 - val_mean_squared_error: 0.0302\n",
      "Epoch 9/100\n",
      "6000/6000 [==============================] - 0s 51us/sample - loss: 0.0433 - mean_squared_error: 0.0270 - val_loss: 0.0433 - val_mean_squared_error: 0.0271\n",
      "Epoch 10/100\n",
      "6000/6000 [==============================] - 0s 43us/sample - loss: 0.0395 - mean_squared_error: 0.0233 - val_loss: 0.0422 - val_mean_squared_error: 0.0261\n",
      "Epoch 11/100\n",
      "6000/6000 [==============================] - 0s 46us/sample - loss: 0.0368 - mean_squared_error: 0.0207 - val_loss: 0.0385 - val_mean_squared_error: 0.0224\n",
      "Epoch 12/100\n",
      "6000/6000 [==============================] - 0s 47us/sample - loss: 0.0341 - mean_squared_error: 0.0181 - val_loss: 0.0373 - val_mean_squared_error: 0.0213\n",
      "Epoch 13/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0330 - mean_squared_error: 0.0171 - val_loss: 0.0362 - val_mean_squared_error: 0.0204\n",
      "Epoch 14/100\n",
      "6000/6000 [==============================] - 0s 44us/sample - loss: 0.0316 - mean_squared_error: 0.0158 - val_loss: 0.0354 - val_mean_squared_error: 0.0198\n",
      "Epoch 15/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0308 - mean_squared_error: 0.0151 - val_loss: 0.0341 - val_mean_squared_error: 0.0186\n",
      "Epoch 16/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0291 - mean_squared_error: 0.0137 - val_loss: 0.0342 - val_mean_squared_error: 0.0189\n",
      "Epoch 17/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0289 - mean_squared_error: 0.0137 - val_loss: 0.0316 - val_mean_squared_error: 0.0166\n",
      "Epoch 18/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0273 - mean_squared_error: 0.0123 - val_loss: 0.0356 - val_mean_squared_error: 0.0207\n",
      "Epoch 19/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0278 - mean_squared_error: 0.0131 - val_loss: 0.0301 - val_mean_squared_error: 0.0154\n",
      "Epoch 20/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0262 - mean_squared_error: 0.0117 - val_loss: 0.0293 - val_mean_squared_error: 0.0148\n",
      "Epoch 21/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0254 - mean_squared_error: 0.0110 - val_loss: 0.0292 - val_mean_squared_error: 0.0149\n",
      "Epoch 22/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0252 - mean_squared_error: 0.0110 - val_loss: 0.0280 - val_mean_squared_error: 0.0138\n",
      "Epoch 23/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0249 - mean_squared_error: 0.0108 - val_loss: 0.0307 - val_mean_squared_error: 0.0167\n",
      "Epoch 24/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0247 - mean_squared_error: 0.0108 - val_loss: 0.0283 - val_mean_squared_error: 0.0145\n",
      "Epoch 25/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0237 - mean_squared_error: 0.0099 - val_loss: 0.0272 - val_mean_squared_error: 0.0136\n",
      "Epoch 26/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0232 - mean_squared_error: 0.0097 - val_loss: 0.0263 - val_mean_squared_error: 0.0128\n",
      "Epoch 27/100\n",
      "6000/6000 [==============================] - 0s 48us/sample - loss: 0.0235 - mean_squared_error: 0.0101 - val_loss: 0.0263 - val_mean_squared_error: 0.0130\n",
      "Epoch 28/100\n",
      "6000/6000 [==============================] - 0s 59us/sample - loss: 0.0225 - mean_squared_error: 0.0093 - val_loss: 0.0271 - val_mean_squared_error: 0.0139\n",
      "Epoch 29/100\n",
      "6000/6000 [==============================] - 0s 43us/sample - loss: 0.0218 - mean_squared_error: 0.0087 - val_loss: 0.0252 - val_mean_squared_error: 0.0122\n",
      "Epoch 30/100\n",
      "6000/6000 [==============================] - 0s 44us/sample - loss: 0.0216 - mean_squared_error: 0.0086 - val_loss: 0.0249 - val_mean_squared_error: 0.0120\n",
      "Epoch 31/100\n",
      "6000/6000 [==============================] - 0s 53us/sample - loss: 0.0223 - mean_squared_error: 0.0096 - val_loss: 0.0273 - val_mean_squared_error: 0.0146\n",
      "Epoch 32/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0216 - mean_squared_error: 0.0090 - val_loss: 0.0249 - val_mean_squared_error: 0.0123\n",
      "Epoch 33/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0210 - mean_squared_error: 0.0085 - val_loss: 0.0248 - val_mean_squared_error: 0.0124\n",
      "Epoch 34/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0205 - mean_squared_error: 0.0081 - val_loss: 0.0269 - val_mean_squared_error: 0.0146\n",
      "Epoch 35/100\n",
      "5824/6000 [============================>.] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0086\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "6000/6000 [==============================] - 1s 138us/sample - loss: 0.0208 - mean_squared_error: 0.0086 - val_loss: 0.0242 - val_mean_squared_error: 0.0120\n",
      "Epoch 36/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0187 - mean_squared_error: 0.0065 - val_loss: 0.0232 - val_mean_squared_error: 0.0110\n",
      "Epoch 37/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0185 - mean_squared_error: 0.0064 - val_loss: 0.0228 - val_mean_squared_error: 0.0108\n",
      "Epoch 38/100\n",
      "6000/6000 [==============================] - 0s 43us/sample - loss: 0.0180 - mean_squared_error: 0.0059 - val_loss: 0.0226 - val_mean_squared_error: 0.0106\n",
      "Epoch 39/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0179 - mean_squared_error: 0.0059 - val_loss: 0.0222 - val_mean_squared_error: 0.0102\n",
      "Epoch 40/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0178 - mean_squared_error: 0.0059 - val_loss: 0.0229 - val_mean_squared_error: 0.0110\n",
      "Epoch 41/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0176 - mean_squared_error: 0.0058 - val_loss: 0.0221 - val_mean_squared_error: 0.0103\n",
      "Epoch 42/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0176 - mean_squared_error: 0.0058 - val_loss: 0.0219 - val_mean_squared_error: 0.0102\n",
      "Epoch 43/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0174 - mean_squared_error: 0.0057 - val_loss: 0.0214 - val_mean_squared_error: 0.0097\n",
      "Epoch 44/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0174 - mean_squared_error: 0.0058 - val_loss: 0.0221 - val_mean_squared_error: 0.0105\n",
      "Epoch 45/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0172 - mean_squared_error: 0.0056 - val_loss: 0.0218 - val_mean_squared_error: 0.0102\n",
      "Epoch 46/100\n",
      "6000/6000 [==============================] - 0s 36us/sample - loss: 0.0170 - mean_squared_error: 0.0055 - val_loss: 0.0221 - val_mean_squared_error: 0.0106\n",
      "Epoch 47/100\n",
      "6000/6000 [==============================] - 0s 44us/sample - loss: 0.0173 - mean_squared_error: 0.0059 - val_loss: 0.0213 - val_mean_squared_error: 0.0099\n",
      "Epoch 48/100\n",
      "5184/6000 [========================>.....] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0053\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "6000/6000 [==============================] - 0s 58us/sample - loss: 0.0168 - mean_squared_error: 0.0054 - val_loss: 0.0227 - val_mean_squared_error: 0.0114\n",
      "Epoch 49/100\n",
      "6000/6000 [==============================] - 0s 62us/sample - loss: 0.0162 - mean_squared_error: 0.0049 - val_loss: 0.0205 - val_mean_squared_error: 0.0092\n",
      "Epoch 50/100\n",
      "6000/6000 [==============================] - 0s 44us/sample - loss: 0.0159 - mean_squared_error: 0.0047 - val_loss: 0.0211 - val_mean_squared_error: 0.0098\n",
      "Epoch 51/100\n",
      "6000/6000 [==============================] - 0s 43us/sample - loss: 0.0159 - mean_squared_error: 0.0046 - val_loss: 0.0203 - val_mean_squared_error: 0.0091\n",
      "Epoch 52/100\n",
      "6000/6000 [==============================] - 0s 45us/sample - loss: 0.0157 - mean_squared_error: 0.0045 - val_loss: 0.0201 - val_mean_squared_error: 0.0089\n",
      "Epoch 53/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0157 - mean_squared_error: 0.0045 - val_loss: 0.0206 - val_mean_squared_error: 0.0094\n",
      "Epoch 54/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0156 - mean_squared_error: 0.0045 - val_loss: 0.0200 - val_mean_squared_error: 0.0089\n",
      "Epoch 55/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0156 - mean_squared_error: 0.0045 - val_loss: 0.0201 - val_mean_squared_error: 0.0090\n",
      "Epoch 56/100\n",
      "6000/6000 [==============================] - 0s 39us/sample - loss: 0.0156 - mean_squared_error: 0.0045 - val_loss: 0.0199 - val_mean_squared_error: 0.0088\n",
      "Epoch 57/100\n",
      "5440/6000 [==========================>...] - ETA: 0s - loss: 0.0153 - mean_squared_error: 0.0043\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "6000/6000 [==============================] - 0s 45us/sample - loss: 0.0155 - mean_squared_error: 0.0045 - val_loss: 0.0201 - val_mean_squared_error: 0.0091\n",
      "Epoch 58/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0151 - mean_squared_error: 0.0041 - val_loss: 0.0197 - val_mean_squared_error: 0.0087\n",
      "Epoch 59/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0150 - mean_squared_error: 0.0040 - val_loss: 0.0195 - val_mean_squared_error: 0.0085\n",
      "Epoch 60/100\n",
      "6000/6000 [==============================] - 0s 39us/sample - loss: 0.0149 - mean_squared_error: 0.0040 - val_loss: 0.0195 - val_mean_squared_error: 0.0085\n",
      "Epoch 61/100\n",
      "6000/6000 [==============================] - 0s 43us/sample - loss: 0.0149 - mean_squared_error: 0.0040 - val_loss: 0.0195 - val_mean_squared_error: 0.0086\n",
      "Epoch 62/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0150 - mean_squared_error: 0.0040 - val_loss: 0.0195 - val_mean_squared_error: 0.0085\n",
      "Epoch 63/100\n",
      "6000/6000 [==============================] - 0s 39us/sample - loss: 0.0149 - mean_squared_error: 0.0040 - val_loss: 0.0195 - val_mean_squared_error: 0.0086\n",
      "Epoch 64/100\n",
      "4736/6000 [======================>.......] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0038\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "6000/6000 [==============================] - 0s 37us/sample - loss: 0.0149 - mean_squared_error: 0.0040 - val_loss: 0.0195 - val_mean_squared_error: 0.0086\n",
      "Epoch 65/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0146 - mean_squared_error: 0.0038 - val_loss: 0.0194 - val_mean_squared_error: 0.0085\n",
      "Epoch 66/100\n",
      "6000/6000 [==============================] - 0s 44us/sample - loss: 0.0146 - mean_squared_error: 0.0037 - val_loss: 0.0192 - val_mean_squared_error: 0.0084\n",
      "Epoch 67/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0146 - mean_squared_error: 0.0037 - val_loss: 0.0192 - val_mean_squared_error: 0.0084\n",
      "Epoch 68/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0146 - mean_squared_error: 0.0037 - val_loss: 0.0192 - val_mean_squared_error: 0.0084\n",
      "Epoch 69/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0145 - mean_squared_error: 0.0037 - val_loss: 0.0192 - val_mean_squared_error: 0.0083\n",
      "Epoch 70/100\n",
      "6000/6000 [==============================] - 0s 38us/sample - loss: 0.0145 - mean_squared_error: 0.0037 - val_loss: 0.0192 - val_mean_squared_error: 0.0084\n",
      "Epoch 71/100\n",
      "5632/6000 [===========================>..] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0037\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0145 - mean_squared_error: 0.0037 - val_loss: 0.0192 - val_mean_squared_error: 0.0084\n",
      "Epoch 72/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0144 - mean_squared_error: 0.0036 - val_loss: 0.0192 - val_mean_squared_error: 0.0084\n",
      "Epoch 73/100\n",
      "6000/6000 [==============================] - 0s 37us/sample - loss: 0.0144 - mean_squared_error: 0.0036 - val_loss: 0.0191 - val_mean_squared_error: 0.0083\n",
      "Epoch 74/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0144 - mean_squared_error: 0.0036 - val_loss: 0.0191 - val_mean_squared_error: 0.0083\n",
      "Epoch 75/100\n",
      "6000/6000 [==============================] - 0s 39us/sample - loss: 0.0144 - mean_squared_error: 0.0036 - val_loss: 0.0190 - val_mean_squared_error: 0.0083\n",
      "Epoch 76/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0144 - mean_squared_error: 0.0036 - val_loss: 0.0191 - val_mean_squared_error: 0.0083\n",
      "Epoch 77/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0144 - mean_squared_error: 0.0036 - val_loss: 0.0190 - val_mean_squared_error: 0.0083\n",
      "Epoch 78/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0143 - mean_squared_error: 0.0036 - val_loss: 0.0191 - val_mean_squared_error: 0.0084\n",
      "Epoch 79/100\n",
      "4544/6000 [=====================>........] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0037\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "6000/6000 [==============================] - 0s 39us/sample - loss: 0.0143 - mean_squared_error: 0.0036 - val_loss: 0.0190 - val_mean_squared_error: 0.0083\n",
      "Epoch 80/100\n",
      "6000/6000 [==============================] - 0s 38us/sample - loss: 0.0143 - mean_squared_error: 0.0035 - val_loss: 0.0190 - val_mean_squared_error: 0.0082\n",
      "Epoch 81/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0142 - mean_squared_error: 0.0035 - val_loss: 0.0190 - val_mean_squared_error: 0.0082\n",
      "Epoch 82/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0142 - mean_squared_error: 0.0035 - val_loss: 0.0190 - val_mean_squared_error: 0.0083\n",
      "Epoch 83/100\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0142 - mean_squared_error: 0.0035 - val_loss: 0.0190 - val_mean_squared_error: 0.0083\n",
      "Epoch 84/100\n",
      "5760/6000 [===========================>..] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0035\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "6000/6000 [==============================] - 0s 40us/sample - loss: 0.0142 - mean_squared_error: 0.0035 - val_loss: 0.0190 - val_mean_squared_error: 0.0082\n",
      "Epoch 85/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0142 - mean_squared_error: 0.0035 - val_loss: 0.0190 - val_mean_squared_error: 0.0082\n",
      "Epoch 86/100\n",
      "6000/6000 [==============================] - 0s 41us/sample - loss: 0.0142 - mean_squared_error: 0.0035 - val_loss: 0.0190 - val_mean_squared_error: 0.0083\n",
      "Epoch 87/100\n",
      "6000/6000 [==============================] - 0s 38us/sample - loss: 0.0142 - mean_squared_error: 0.0035 - val_loss: 0.0189 - val_mean_squared_error: 0.0082\n",
      "Epoch 88/100\n",
      "6000/6000 [==============================] - 0s 46us/sample - loss: 0.0142 - mean_squared_error: 0.0035 - val_loss: 0.0190 - val_mean_squared_error: 0.0082\n",
      "Epoch 89/100\n",
      "5440/6000 [==========================>...] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0034\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "6000/6000 [==============================] - 0s 44us/sample - loss: 0.0142 - mean_squared_error: 0.0035 - val_loss: 0.0190 - val_mean_squared_error: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "6000/6000 [==============================] - 0s 44us/sample - loss: 0.0142 - mean_squared_error: 0.0035 - val_loss: 0.0190 - val_mean_squared_error: 0.0082\n",
      "Epoch 91/100\n",
      "6000/6000 [==============================] - 0s 45us/sample - loss: 0.0142 - mean_squared_error: 0.0034 - val_loss: 0.0189 - val_mean_squared_error: 0.0082\n",
      "Epoch 92/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0142 - mean_squared_error: 0.0034 - val_loss: 0.0190 - val_mean_squared_error: 0.0082\n",
      "Epoch 93/100\n",
      "6000/6000 [==============================] - 0s 43us/sample - loss: 0.0142 - mean_squared_error: 0.0034 - val_loss: 0.0189 - val_mean_squared_error: 0.0082\n",
      "Epoch 94/100\n",
      "5248/6000 [=========================>....] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0034\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "6000/6000 [==============================] - 0s 45us/sample - loss: 0.0142 - mean_squared_error: 0.0034 - val_loss: 0.0189 - val_mean_squared_error: 0.0082\n",
      "Epoch 95/100\n",
      "6000/6000 [==============================] - 0s 43us/sample - loss: 0.0142 - mean_squared_error: 0.0034 - val_loss: 0.0189 - val_mean_squared_error: 0.0082\n",
      "Epoch 96/100\n",
      "6000/6000 [==============================] - 0s 43us/sample - loss: 0.0142 - mean_squared_error: 0.0034 - val_loss: 0.0189 - val_mean_squared_error: 0.0082\n",
      "Epoch 97/100\n",
      "6000/6000 [==============================] - 0s 44us/sample - loss: 0.0142 - mean_squared_error: 0.0034 - val_loss: 0.0189 - val_mean_squared_error: 0.0082\n",
      "Epoch 98/100\n",
      "6000/6000 [==============================] - 0s 42us/sample - loss: 0.0142 - mean_squared_error: 0.0034 - val_loss: 0.0189 - val_mean_squared_error: 0.0082\n",
      "Epoch 99/100\n",
      "4864/6000 [=======================>......] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0034\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "6000/6000 [==============================] - 0s 46us/sample - loss: 0.0142 - mean_squared_error: 0.0034 - val_loss: 0.0189 - val_mean_squared_error: 0.0082\n",
      "Epoch 100/100\n",
      "6000/6000 [==============================] - 0s 43us/sample - loss: 0.0141 - mean_squared_error: 0.0034 - val_loss: 0.0189 - val_mean_squared_error: 0.0082\n",
      "Saved model for RoboschoolReacher-v1: /tf/srv/hw1/notebooks/model_RoboschoolReacher-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolReacher-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\n"
     ]
    }
   ],
   "source": [
    "_ = model.fit([X_train], y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[scope.print_callback, reduce_lr, tf_board],\n",
    "          validation_data=([X_val], y_val)\n",
    "          )\n",
    "\n",
    "model_filename = os.path.join(model_path, model_name)\n",
    "model.save(model_filename)\n",
    "print(\"Saved model for %s: %s\" % (dataset_name, model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='RoboschoolHalfCheetah-v1 MSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'RoboschoolReacher-v1',\n",
       " 'test_mse': 0.011196816612996997,\n",
       " 'train_mse': 0.003426155398305948,\n",
       " 'val_mse': 0.008209465235887255}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = calc_mse(model, dataset_name, X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoboschoolHopper-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolHopper-v1\n",
      "DOmain name: RoboschoolHopper-v1\n",
      "(29718, 15) (3715, 15) (3715, 15) (29718, 3) (3715, 3) (3715, 3)\n",
      "model_name='model_RoboschoolHopper-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "model_path='/tf/srv/hw1/notebooks/model_RoboschoolHopper-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='RoboschoolHopper-v1 MSE')\n"
     ]
    }
   ],
   "source": [
    "# Get the datasets\n",
    "dataset_name = 'RoboschoolHopper-v1'\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_datasets(dataset_name)\n",
    "\n",
    "\n",
    "# Define model\n",
    "config_dict = dict(\n",
    "    dataset_name=dataset_name,\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    units=100,\n",
    "    layers = 3,\n",
    "    l2_reg = 1e-04,\n",
    "    lr = 1e-03,\n",
    "    dropout=None,\n",
    "    use_batchnorm=False)\n",
    "\n",
    "model, model_name, model_path = get_compiled_model(**config_dict)\n",
    "\n",
    "\n",
    "### Callbacks\n",
    "# Reduce learning rate dynamically\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mean_squared_error', factor=0.5, patience=5, verbose=1)\n",
    "tf_board = TensorBoard()\n",
    "\n",
    "# Define a scope object\n",
    "scope = KerasTrainScope(model_name=model_name, history_dir=model_path)\n",
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29718 samples, validate on 3715 samples\n",
      "Epoch 1/100\n",
      "29718/29718 [==============================] - 2s 69us/sample - loss: 0.3090 - mean_squared_error: 0.2899 - val_loss: 0.1196 - val_mean_squared_error: 0.0996\n",
      "Epoch 2/100\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0951 - mean_squared_error: 0.0744 - val_loss: 0.0806 - val_mean_squared_error: 0.0593\n",
      "Epoch 3/100\n",
      "29718/29718 [==============================] - 1s 44us/sample - loss: 0.0697 - mean_squared_error: 0.0482 - val_loss: 0.0639 - val_mean_squared_error: 0.0423\n",
      "Epoch 4/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0585 - mean_squared_error: 0.0370 - val_loss: 0.0541 - val_mean_squared_error: 0.0326\n",
      "Epoch 5/100\n",
      "29718/29718 [==============================] - 1s 43us/sample - loss: 0.0523 - mean_squared_error: 0.0310 - val_loss: 0.0497 - val_mean_squared_error: 0.0286\n",
      "Epoch 6/100\n",
      "29718/29718 [==============================] - 1s 45us/sample - loss: 0.0475 - mean_squared_error: 0.0266 - val_loss: 0.0461 - val_mean_squared_error: 0.0254\n",
      "Epoch 7/100\n",
      "29718/29718 [==============================] - 1s 42us/sample - loss: 0.0445 - mean_squared_error: 0.0242 - val_loss: 0.0517 - val_mean_squared_error: 0.0316\n",
      "Epoch 8/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0423 - mean_squared_error: 0.0225 - val_loss: 0.0437 - val_mean_squared_error: 0.0241\n",
      "Epoch 9/100\n",
      "29718/29718 [==============================] - 1s 42us/sample - loss: 0.0400 - mean_squared_error: 0.0207 - val_loss: 0.0413 - val_mean_squared_error: 0.0222\n",
      "Epoch 10/100\n",
      "29718/29718 [==============================] - 1s 39us/sample - loss: 0.0387 - mean_squared_error: 0.0200 - val_loss: 0.0391 - val_mean_squared_error: 0.0206\n",
      "Epoch 11/100\n",
      "29718/29718 [==============================] - 1s 38us/sample - loss: 0.0368 - mean_squared_error: 0.0185 - val_loss: 0.0383 - val_mean_squared_error: 0.0203\n",
      "Epoch 12/100\n",
      "29718/29718 [==============================] - 1s 39us/sample - loss: 0.0360 - mean_squared_error: 0.0182 - val_loss: 0.0372 - val_mean_squared_error: 0.0197\n",
      "Epoch 13/100\n",
      "29718/29718 [==============================] - 1s 38us/sample - loss: 0.0347 - mean_squared_error: 0.0173 - val_loss: 0.0366 - val_mean_squared_error: 0.0195\n",
      "Epoch 14/100\n",
      "29718/29718 [==============================] - 1s 38us/sample - loss: 0.0336 - mean_squared_error: 0.0167 - val_loss: 0.0334 - val_mean_squared_error: 0.0167\n",
      "Epoch 15/100\n",
      "29718/29718 [==============================] - 1s 38us/sample - loss: 0.0337 - mean_squared_error: 0.0172 - val_loss: 0.0326 - val_mean_squared_error: 0.0163\n",
      "Epoch 16/100\n",
      "29718/29718 [==============================] - 1s 37us/sample - loss: 0.0320 - mean_squared_error: 0.0159 - val_loss: 0.0346 - val_mean_squared_error: 0.0186\n",
      "Epoch 17/100\n",
      "29718/29718 [==============================] - 1s 38us/sample - loss: 0.0313 - mean_squared_error: 0.0155 - val_loss: 0.0333 - val_mean_squared_error: 0.0177\n",
      "Epoch 18/100\n",
      "29718/29718 [==============================] - 1s 38us/sample - loss: 0.0307 - mean_squared_error: 0.0152 - val_loss: 0.0326 - val_mean_squared_error: 0.0173\n",
      "Epoch 19/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0299 - mean_squared_error: 0.0147 - val_loss: 0.0327 - val_mean_squared_error: 0.0177\n",
      "Epoch 20/100\n",
      "29718/29718 [==============================] - 1s 49us/sample - loss: 0.0293 - mean_squared_error: 0.0144 - val_loss: 0.0296 - val_mean_squared_error: 0.0148\n",
      "Epoch 21/100\n",
      "29718/29718 [==============================] - 1s 46us/sample - loss: 0.0288 - mean_squared_error: 0.0142 - val_loss: 0.0296 - val_mean_squared_error: 0.0151\n",
      "Epoch 22/100\n",
      "29718/29718 [==============================] - 1s 39us/sample - loss: 0.0283 - mean_squared_error: 0.0140 - val_loss: 0.0286 - val_mean_squared_error: 0.0144\n",
      "Epoch 23/100\n",
      "29718/29718 [==============================] - 1s 38us/sample - loss: 0.0278 - mean_squared_error: 0.0137 - val_loss: 0.0289 - val_mean_squared_error: 0.0149\n",
      "Epoch 24/100\n",
      "29718/29718 [==============================] - 1s 38us/sample - loss: 0.0275 - mean_squared_error: 0.0136 - val_loss: 0.0282 - val_mean_squared_error: 0.0144\n",
      "Epoch 25/100\n",
      "29718/29718 [==============================] - 1s 38us/sample - loss: 0.0270 - mean_squared_error: 0.0133 - val_loss: 0.0268 - val_mean_squared_error: 0.0132\n",
      "Epoch 26/100\n",
      "29718/29718 [==============================] - 1s 39us/sample - loss: 0.0269 - mean_squared_error: 0.0134 - val_loss: 0.0271 - val_mean_squared_error: 0.0137\n",
      "Epoch 27/100\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0269 - mean_squared_error: 0.0136 - val_loss: 0.0325 - val_mean_squared_error: 0.0193\n",
      "Epoch 28/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0258 - mean_squared_error: 0.0126 - val_loss: 0.0297 - val_mean_squared_error: 0.0166\n",
      "Epoch 29/100\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0252 - mean_squared_error: 0.0122 - val_loss: 0.0284 - val_mean_squared_error: 0.0155\n",
      "Epoch 30/100\n",
      "28480/29718 [===========================>..] - ETA: 0s - loss: 0.0259 - mean_squared_error: 0.0130\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "29718/29718 [==============================] - 2s 62us/sample - loss: 0.0259 - mean_squared_error: 0.0131 - val_loss: 0.0262 - val_mean_squared_error: 0.0135\n",
      "Epoch 31/100\n",
      "29718/29718 [==============================] - 1s 44us/sample - loss: 0.0224 - mean_squared_error: 0.0097 - val_loss: 0.0245 - val_mean_squared_error: 0.0119\n",
      "Epoch 32/100\n",
      "29718/29718 [==============================] - 1s 49us/sample - loss: 0.0222 - mean_squared_error: 0.0096 - val_loss: 0.0240 - val_mean_squared_error: 0.0115\n",
      "Epoch 33/100\n",
      "29718/29718 [==============================] - 2s 75us/sample - loss: 0.0221 - mean_squared_error: 0.0096 - val_loss: 0.0244 - val_mean_squared_error: 0.0119\n",
      "Epoch 34/100\n",
      "29718/29718 [==============================] - 2s 72us/sample - loss: 0.0219 - mean_squared_error: 0.0095 - val_loss: 0.0245 - val_mean_squared_error: 0.0122\n",
      "Epoch 35/100\n",
      "29718/29718 [==============================] - 2s 70us/sample - loss: 0.0218 - mean_squared_error: 0.0095 - val_loss: 0.0238 - val_mean_squared_error: 0.0116\n",
      "Epoch 36/100\n",
      "29718/29718 [==============================] - 2s 66us/sample - loss: 0.0216 - mean_squared_error: 0.0094 - val_loss: 0.0235 - val_mean_squared_error: 0.0113\n",
      "Epoch 37/100\n",
      "29718/29718 [==============================] - 2s 65us/sample - loss: 0.0216 - mean_squared_error: 0.0095 - val_loss: 0.0229 - val_mean_squared_error: 0.0109\n",
      "Epoch 38/100\n",
      "29718/29718 [==============================] - 2s 67us/sample - loss: 0.0213 - mean_squared_error: 0.0093 - val_loss: 0.0228 - val_mean_squared_error: 0.0109\n",
      "Epoch 39/100\n",
      "29718/29718 [==============================] - 2s 72us/sample - loss: 0.0214 - mean_squared_error: 0.0095 - val_loss: 0.0231 - val_mean_squared_error: 0.0112\n",
      "Epoch 40/100\n",
      "29718/29718 [==============================] - 2s 68us/sample - loss: 0.0208 - mean_squared_error: 0.0090 - val_loss: 0.0227 - val_mean_squared_error: 0.0109\n",
      "Epoch 41/100\n",
      "29718/29718 [==============================] - 2s 73us/sample - loss: 0.0209 - mean_squared_error: 0.0092 - val_loss: 0.0219 - val_mean_squared_error: 0.0102\n",
      "Epoch 42/100\n",
      "29718/29718 [==============================] - 2s 80us/sample - loss: 0.0206 - mean_squared_error: 0.0089 - val_loss: 0.0235 - val_mean_squared_error: 0.0118\n",
      "Epoch 43/100\n",
      "29718/29718 [==============================] - 2s 70us/sample - loss: 0.0205 - mean_squared_error: 0.0089 - val_loss: 0.0215 - val_mean_squared_error: 0.0099\n",
      "Epoch 44/100\n",
      "29718/29718 [==============================] - 2s 66us/sample - loss: 0.0204 - mean_squared_error: 0.0089 - val_loss: 0.0219 - val_mean_squared_error: 0.0104\n",
      "Epoch 45/100\n",
      "29718/29718 [==============================] - 2s 68us/sample - loss: 0.0202 - mean_squared_error: 0.0088 - val_loss: 0.0222 - val_mean_squared_error: 0.0108\n",
      "Epoch 46/100\n",
      "29718/29718 [==============================] - 2s 70us/sample - loss: 0.0202 - mean_squared_error: 0.0088 - val_loss: 0.0221 - val_mean_squared_error: 0.0108\n",
      "Epoch 47/100\n",
      "29718/29718 [==============================] - 2s 69us/sample - loss: 0.0199 - mean_squared_error: 0.0086 - val_loss: 0.0216 - val_mean_squared_error: 0.0104\n",
      "Epoch 48/100\n",
      "29376/29718 [============================>.] - ETA: 0s - loss: 0.0198 - mean_squared_error: 0.0086\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "29718/29718 [==============================] - 2s 71us/sample - loss: 0.0198 - mean_squared_error: 0.0086 - val_loss: 0.0222 - val_mean_squared_error: 0.0110\n",
      "Epoch 49/100\n",
      "29718/29718 [==============================] - 2s 71us/sample - loss: 0.0186 - mean_squared_error: 0.0074 - val_loss: 0.0205 - val_mean_squared_error: 0.0093\n",
      "Epoch 50/100\n",
      "29718/29718 [==============================] - 2s 70us/sample - loss: 0.0184 - mean_squared_error: 0.0073 - val_loss: 0.0203 - val_mean_squared_error: 0.0092\n",
      "Epoch 51/100\n",
      "29718/29718 [==============================] - 2s 77us/sample - loss: 0.0185 - mean_squared_error: 0.0074 - val_loss: 0.0204 - val_mean_squared_error: 0.0093\n",
      "Epoch 52/100\n",
      "29718/29718 [==============================] - 2s 79us/sample - loss: 0.0184 - mean_squared_error: 0.0073 - val_loss: 0.0204 - val_mean_squared_error: 0.0094\n",
      "Epoch 53/100\n",
      "29718/29718 [==============================] - 1s 42us/sample - loss: 0.0184 - mean_squared_error: 0.0074 - val_loss: 0.0197 - val_mean_squared_error: 0.0087\n",
      "Epoch 54/100\n",
      "29718/29718 [==============================] - 1s 48us/sample - loss: 0.0182 - mean_squared_error: 0.0072 - val_loss: 0.0201 - val_mean_squared_error: 0.0092\n",
      "Epoch 55/100\n",
      "29718/29718 [==============================] - 1s 48us/sample - loss: 0.0182 - mean_squared_error: 0.0073 - val_loss: 0.0199 - val_mean_squared_error: 0.0090\n",
      "Epoch 56/100\n",
      "29718/29718 [==============================] - 1s 50us/sample - loss: 0.0180 - mean_squared_error: 0.0071 - val_loss: 0.0200 - val_mean_squared_error: 0.0091\n",
      "Epoch 57/100\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0180 - mean_squared_error: 0.0071 - val_loss: 0.0199 - val_mean_squared_error: 0.0091\n",
      "Epoch 58/100\n",
      "28608/29718 [===========================>..] - ETA: 0s - loss: 0.0180 - mean_squared_error: 0.0072\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0180 - mean_squared_error: 0.0072 - val_loss: 0.0199 - val_mean_squared_error: 0.0092\n",
      "Epoch 59/100\n",
      "29718/29718 [==============================] - 1s 44us/sample - loss: 0.0173 - mean_squared_error: 0.0066 - val_loss: 0.0196 - val_mean_squared_error: 0.0088\n",
      "Epoch 60/100\n",
      "29718/29718 [==============================] - 1s 44us/sample - loss: 0.0172 - mean_squared_error: 0.0065 - val_loss: 0.0194 - val_mean_squared_error: 0.0087\n",
      "Epoch 61/100\n",
      "29718/29718 [==============================] - 1s 42us/sample - loss: 0.0172 - mean_squared_error: 0.0065 - val_loss: 0.0193 - val_mean_squared_error: 0.0085\n",
      "Epoch 62/100\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0172 - mean_squared_error: 0.0065 - val_loss: 0.0193 - val_mean_squared_error: 0.0086\n",
      "Epoch 63/100\n",
      "29718/29718 [==============================] - 1s 43us/sample - loss: 0.0172 - mean_squared_error: 0.0065 - val_loss: 0.0192 - val_mean_squared_error: 0.0085\n",
      "Epoch 64/100\n",
      "29718/29718 [==============================] - 1s 45us/sample - loss: 0.0171 - mean_squared_error: 0.0065 - val_loss: 0.0191 - val_mean_squared_error: 0.0084\n",
      "Epoch 65/100\n",
      "29718/29718 [==============================] - 1s 44us/sample - loss: 0.0171 - mean_squared_error: 0.0064 - val_loss: 0.0190 - val_mean_squared_error: 0.0084\n",
      "Epoch 66/100\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0170 - mean_squared_error: 0.0064 - val_loss: 0.0195 - val_mean_squared_error: 0.0089\n",
      "Epoch 67/100\n",
      "29718/29718 [==============================] - 1s 42us/sample - loss: 0.0170 - mean_squared_error: 0.0064 - val_loss: 0.0191 - val_mean_squared_error: 0.0085\n",
      "Epoch 68/100\n",
      "29718/29718 [==============================] - 1s 43us/sample - loss: 0.0170 - mean_squared_error: 0.0064 - val_loss: 0.0191 - val_mean_squared_error: 0.0086\n",
      "Epoch 69/100\n",
      "29248/29718 [============================>.] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0064\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "29718/29718 [==============================] - 1s 42us/sample - loss: 0.0169 - mean_squared_error: 0.0064 - val_loss: 0.0192 - val_mean_squared_error: 0.0086\n",
      "Epoch 70/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0166 - mean_squared_error: 0.0061 - val_loss: 0.0190 - val_mean_squared_error: 0.0084\n",
      "Epoch 71/100\n",
      "29718/29718 [==============================] - 1s 38us/sample - loss: 0.0166 - mean_squared_error: 0.0060 - val_loss: 0.0188 - val_mean_squared_error: 0.0083\n",
      "Epoch 72/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0166 - mean_squared_error: 0.0060 - val_loss: 0.0187 - val_mean_squared_error: 0.0082\n",
      "Epoch 73/100\n",
      "29718/29718 [==============================] - 1s 39us/sample - loss: 0.0165 - mean_squared_error: 0.0060 - val_loss: 0.0186 - val_mean_squared_error: 0.0081\n",
      "Epoch 74/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0165 - mean_squared_error: 0.0060 - val_loss: 0.0186 - val_mean_squared_error: 0.0081\n",
      "Epoch 75/100\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0165 - mean_squared_error: 0.0060 - val_loss: 0.0186 - val_mean_squared_error: 0.0081\n",
      "Epoch 76/100\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0165 - mean_squared_error: 0.0060 - val_loss: 0.0187 - val_mean_squared_error: 0.0083\n",
      "Epoch 77/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0165 - mean_squared_error: 0.0060 - val_loss: 0.0185 - val_mean_squared_error: 0.0081\n",
      "Epoch 78/100\n",
      "28736/29718 [============================>.] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0060 ETA: 0s - loss: 0.0165 - me\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0164 - mean_squared_error: 0.0060 - val_loss: 0.0185 - val_mean_squared_error: 0.0081\n",
      "Epoch 79/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0163 - mean_squared_error: 0.0058 - val_loss: 0.0184 - val_mean_squared_error: 0.0080\n",
      "Epoch 80/100\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0162 - mean_squared_error: 0.0058 - val_loss: 0.0184 - val_mean_squared_error: 0.0080\n",
      "Epoch 81/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0162 - mean_squared_error: 0.0058 - val_loss: 0.0183 - val_mean_squared_error: 0.0079\n",
      "Epoch 82/100\n",
      "29718/29718 [==============================] - 1s 49us/sample - loss: 0.0162 - mean_squared_error: 0.0058 - val_loss: 0.0185 - val_mean_squared_error: 0.0081\n",
      "Epoch 83/100\n",
      "29718/29718 [==============================] - 2s 57us/sample - loss: 0.0162 - mean_squared_error: 0.0058 - val_loss: 0.0183 - val_mean_squared_error: 0.0078\n",
      "Epoch 84/100\n",
      "29718/29718 [==============================] - 1s 48us/sample - loss: 0.0162 - mean_squared_error: 0.0058 - val_loss: 0.0183 - val_mean_squared_error: 0.0079\n",
      "Epoch 85/100\n",
      "29718/29718 [==============================] - 1s 50us/sample - loss: 0.0162 - mean_squared_error: 0.0058 - val_loss: 0.0183 - val_mean_squared_error: 0.0079\n",
      "Epoch 86/100\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0162 - mean_squared_error: 0.0058 - val_loss: 0.0182 - val_mean_squared_error: 0.0078\n",
      "Epoch 87/100\n",
      "29718/29718 [==============================] - 1s 39us/sample - loss: 0.0161 - mean_squared_error: 0.0058 - val_loss: 0.0183 - val_mean_squared_error: 0.0080\n",
      "Epoch 88/100\n",
      "29504/29718 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0057\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "29718/29718 [==============================] - 1s 39us/sample - loss: 0.0161 - mean_squared_error: 0.0057 - val_loss: 0.0182 - val_mean_squared_error: 0.0078\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29718/29718 [==============================] - 1s 43us/sample - loss: 0.0160 - mean_squared_error: 0.0057 - val_loss: 0.0182 - val_mean_squared_error: 0.0078\n",
      "Epoch 90/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0160 - mean_squared_error: 0.0057 - val_loss: 0.0182 - val_mean_squared_error: 0.0078\n",
      "Epoch 91/100\n",
      "29718/29718 [==============================] - 1s 43us/sample - loss: 0.0160 - mean_squared_error: 0.0057 - val_loss: 0.0182 - val_mean_squared_error: 0.0078\n",
      "Epoch 92/100\n",
      "29718/29718 [==============================] - 1s 44us/sample - loss: 0.0160 - mean_squared_error: 0.0057 - val_loss: 0.0182 - val_mean_squared_error: 0.0079\n",
      "Epoch 93/100\n",
      "28928/29718 [============================>.] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0056\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "29718/29718 [==============================] - 1s 42us/sample - loss: 0.0160 - mean_squared_error: 0.0057 - val_loss: 0.0182 - val_mean_squared_error: 0.0078\n",
      "Epoch 94/100\n",
      "29718/29718 [==============================] - 1s 40us/sample - loss: 0.0160 - mean_squared_error: 0.0056 - val_loss: 0.0181 - val_mean_squared_error: 0.0078\n",
      "Epoch 95/100\n",
      "29718/29718 [==============================] - 1s 42us/sample - loss: 0.0160 - mean_squared_error: 0.0056 - val_loss: 0.0182 - val_mean_squared_error: 0.0078\n",
      "Epoch 96/100\n",
      "29718/29718 [==============================] - 1s 41us/sample - loss: 0.0160 - mean_squared_error: 0.0056 - val_loss: 0.0181 - val_mean_squared_error: 0.0078\n",
      "Epoch 97/100\n",
      "29718/29718 [==============================] - 1s 43us/sample - loss: 0.0160 - mean_squared_error: 0.0056 - val_loss: 0.0181 - val_mean_squared_error: 0.0078\n",
      "Epoch 98/100\n",
      "28416/29718 [===========================>..] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0056\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "29718/29718 [==============================] - 1s 46us/sample - loss: 0.0160 - mean_squared_error: 0.0056 - val_loss: 0.0181 - val_mean_squared_error: 0.0078\n",
      "Epoch 99/100\n",
      "29718/29718 [==============================] - 1s 38us/sample - loss: 0.0159 - mean_squared_error: 0.0056 - val_loss: 0.0181 - val_mean_squared_error: 0.0077\n",
      "Epoch 100/100\n",
      "29718/29718 [==============================] - 1s 39us/sample - loss: 0.0159 - mean_squared_error: 0.0056 - val_loss: 0.0181 - val_mean_squared_error: 0.0077\n",
      "Saved model for RoboschoolHopper-v1: /tf/srv/hw1/notebooks/model_RoboschoolHopper-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolHopper-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\n"
     ]
    }
   ],
   "source": [
    "_ = model.fit([X_train], y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[scope.print_callback, reduce_lr, tf_board],\n",
    "          validation_data=([X_val], y_val)\n",
    "          )\n",
    "\n",
    "model_filename = os.path.join(model_path, model_name)\n",
    "model.save(model_filename)\n",
    "print(\"Saved model for %s: %s\" % (dataset_name, model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='RoboschoolHopper-v1 MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'RoboschoolHopper-v1',\n",
       " 'test_mse': 0.007527259528122922,\n",
       " 'train_mse': 0.0055560871057687795,\n",
       " 'val_mse': 0.007748533566072244}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = calc_mse(model, dataset_name, X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7.97332513,  9.66824644, 11.36994428]),\n",
       " array([-3.12346591, -5.6478762 , -5.78081917]))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max(axis=0), y_train.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = KerasTrainScope(model_name=model_name, history_dir=model_path).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(history['mean_squared_error'], bins=100, label='train mse', density=True)\n",
    "plt.hist(history['val_mean_squared_error'], bins=100, label='test mse', alpha=0.5, density=True)\n",
    "plt.xlim(0, 0.1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoboschoolWalker2d-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset RoboschoolWalker2d-v1\n",
      "DOmain name: RoboschoolWalker2d-v1\n",
      "(39312, 22) (4914, 22) (4914, 22) (39312, 6) (4914, 6) (4914, 6)\n",
      "model_name='model_RoboschoolWalker2d-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "model_path='/tf/srv/hw1/notebooks/model_RoboschoolWalker2d-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001'\n",
      "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='RoboschoolWalker2d-v1 MSE')\n"
     ]
    }
   ],
   "source": [
    "# Get the datasets\n",
    "dataset_name = 'RoboschoolWalker2d-v1'\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_datasets(dataset_name)\n",
    "\n",
    "\n",
    "# Define model\n",
    "config_dict = dict(\n",
    "    dataset_name=dataset_name,\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    units=100,\n",
    "    layers = 3,\n",
    "    l2_reg = 1e-04,\n",
    "    lr = 1e-03,\n",
    "    dropout=None,\n",
    "    use_batchnorm=False)\n",
    "\n",
    "model, model_name, model_path = get_compiled_model(**config_dict)\n",
    "\n",
    "\n",
    "### Callbacks\n",
    "# Reduce learning rate dynamically\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mean_squared_error', factor=0.5, patience=5, verbose=1)\n",
    "tf_board = TensorBoard()\n",
    "\n",
    "# Define a scope object\n",
    "scope = KerasTrainScope(model_name=model_name, history_dir=model_path)\n",
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39312 samples, validate on 4914 samples\n",
      "Epoch 1/100\n",
      "39312/39312 [==============================] - 3s 72us/sample - loss: 0.1222 - mean_squared_error: 0.1030 - val_loss: 0.0645 - val_mean_squared_error: 0.0449\n",
      "Epoch 2/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0553 - mean_squared_error: 0.0358 - val_loss: 0.0493 - val_mean_squared_error: 0.0299\n",
      "Epoch 3/100\n",
      "39312/39312 [==============================] - 1s 38us/sample - loss: 0.0462 - mean_squared_error: 0.0271 - val_loss: 0.0436 - val_mean_squared_error: 0.0249\n",
      "Epoch 4/100\n",
      "39312/39312 [==============================] - 1s 38us/sample - loss: 0.0416 - mean_squared_error: 0.0233 - val_loss: 0.0404 - val_mean_squared_error: 0.0226\n",
      "Epoch 5/100\n",
      "39312/39312 [==============================] - 1s 38us/sample - loss: 0.0380 - mean_squared_error: 0.0205 - val_loss: 0.0365 - val_mean_squared_error: 0.0194\n",
      "Epoch 6/100\n",
      "39312/39312 [==============================] - 1s 38us/sample - loss: 0.0356 - mean_squared_error: 0.0189 - val_loss: 0.0348 - val_mean_squared_error: 0.0185\n",
      "Epoch 7/100\n",
      "39312/39312 [==============================] - 1s 38us/sample - loss: 0.0337 - mean_squared_error: 0.0177 - val_loss: 0.0363 - val_mean_squared_error: 0.0207\n",
      "Epoch 8/100\n",
      "39312/39312 [==============================] - 1s 38us/sample - loss: 0.0321 - mean_squared_error: 0.0167 - val_loss: 0.0323 - val_mean_squared_error: 0.0173\n",
      "Epoch 9/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0306 - mean_squared_error: 0.0158 - val_loss: 0.0319 - val_mean_squared_error: 0.0174\n",
      "Epoch 10/100\n",
      "39312/39312 [==============================] - 1s 37us/sample - loss: 0.0295 - mean_squared_error: 0.0153 - val_loss: 0.0286 - val_mean_squared_error: 0.0146\n",
      "Epoch 11/100\n",
      "39312/39312 [==============================] - 1s 38us/sample - loss: 0.0285 - mean_squared_error: 0.0147 - val_loss: 0.0281 - val_mean_squared_error: 0.0145\n",
      "Epoch 12/100\n",
      "39312/39312 [==============================] - 1s 37us/sample - loss: 0.0276 - mean_squared_error: 0.0142 - val_loss: 0.0284 - val_mean_squared_error: 0.0152\n",
      "Epoch 13/100\n",
      "39312/39312 [==============================] - 1s 38us/sample - loss: 0.0267 - mean_squared_error: 0.0138 - val_loss: 0.0276 - val_mean_squared_error: 0.0148\n",
      "Epoch 14/100\n",
      "39312/39312 [==============================] - 2s 38us/sample - loss: 0.0262 - mean_squared_error: 0.0136 - val_loss: 0.0257 - val_mean_squared_error: 0.0132\n",
      "Epoch 15/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0254 - mean_squared_error: 0.0131 - val_loss: 0.0262 - val_mean_squared_error: 0.0140\n",
      "Epoch 16/100\n",
      "39312/39312 [==============================] - 2s 47us/sample - loss: 0.0248 - mean_squared_error: 0.0128 - val_loss: 0.0243 - val_mean_squared_error: 0.0125\n",
      "Epoch 17/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0242 - mean_squared_error: 0.0125 - val_loss: 0.0243 - val_mean_squared_error: 0.0126\n",
      "Epoch 18/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0237 - mean_squared_error: 0.0122 - val_loss: 0.0239 - val_mean_squared_error: 0.0125\n",
      "Epoch 19/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0233 - mean_squared_error: 0.0120 - val_loss: 0.0234 - val_mean_squared_error: 0.0122\n",
      "Epoch 20/100\n",
      "39312/39312 [==============================] - 1s 38us/sample - loss: 0.0228 - mean_squared_error: 0.0118 - val_loss: 0.0229 - val_mean_squared_error: 0.0120\n",
      "Epoch 21/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0224 - mean_squared_error: 0.0115 - val_loss: 0.0225 - val_mean_squared_error: 0.0118\n",
      "Epoch 22/100\n",
      "39312/39312 [==============================] - 2s 43us/sample - loss: 0.0220 - mean_squared_error: 0.0113 - val_loss: 0.0227 - val_mean_squared_error: 0.0122\n",
      "Epoch 23/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0219 - mean_squared_error: 0.0114 - val_loss: 0.0221 - val_mean_squared_error: 0.0117\n",
      "Epoch 24/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0215 - mean_squared_error: 0.0112 - val_loss: 0.0211 - val_mean_squared_error: 0.0109\n",
      "Epoch 25/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0211 - mean_squared_error: 0.0109 - val_loss: 0.0207 - val_mean_squared_error: 0.0106\n",
      "Epoch 26/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0209 - mean_squared_error: 0.0108 - val_loss: 0.0210 - val_mean_squared_error: 0.0110\n",
      "Epoch 27/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0206 - mean_squared_error: 0.0107 - val_loss: 0.0203 - val_mean_squared_error: 0.0105\n",
      "Epoch 28/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0204 - mean_squared_error: 0.0106 - val_loss: 0.0231 - val_mean_squared_error: 0.0134\n",
      "Epoch 29/100\n",
      "39312/39312 [==============================] - 2s 38us/sample - loss: 0.0202 - mean_squared_error: 0.0105 - val_loss: 0.0207 - val_mean_squared_error: 0.0111\n",
      "Epoch 30/100\n",
      "39296/39312 [============================>.] - ETA: 0s - loss: 0.0199 - mean_squared_error: 0.0103\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "39312/39312 [==============================] - 2s 56us/sample - loss: 0.0199 - mean_squared_error: 0.0103 - val_loss: 0.0202 - val_mean_squared_error: 0.0107\n",
      "Epoch 31/100\n",
      "39312/39312 [==============================] - 2s 42us/sample - loss: 0.0183 - mean_squared_error: 0.0089 - val_loss: 0.0189 - val_mean_squared_error: 0.0095\n",
      "Epoch 32/100\n",
      "39312/39312 [==============================] - 2s 46us/sample - loss: 0.0182 - mean_squared_error: 0.0088 - val_loss: 0.0182 - val_mean_squared_error: 0.0089\n",
      "Epoch 33/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0181 - mean_squared_error: 0.0088 - val_loss: 0.0180 - val_mean_squared_error: 0.0087\n",
      "Epoch 34/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0180 - mean_squared_error: 0.0088 - val_loss: 0.0184 - val_mean_squared_error: 0.0092\n",
      "Epoch 35/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0179 - mean_squared_error: 0.0087 - val_loss: 0.0178 - val_mean_squared_error: 0.0087\n",
      "Epoch 36/100\n",
      "39312/39312 [==============================] - 2s 47us/sample - loss: 0.0178 - mean_squared_error: 0.0086 - val_loss: 0.0180 - val_mean_squared_error: 0.0089\n",
      "Epoch 37/100\n",
      "39312/39312 [==============================] - 2s 53us/sample - loss: 0.0176 - mean_squared_error: 0.0085 - val_loss: 0.0178 - val_mean_squared_error: 0.0088\n",
      "Epoch 38/100\n",
      "39312/39312 [==============================] - 2s 42us/sample - loss: 0.0175 - mean_squared_error: 0.0085 - val_loss: 0.0173 - val_mean_squared_error: 0.0083\n",
      "Epoch 39/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0174 - mean_squared_error: 0.0085 - val_loss: 0.0181 - val_mean_squared_error: 0.0092\n",
      "Epoch 40/100\n",
      "39312/39312 [==============================] - 2s 43us/sample - loss: 0.0173 - mean_squared_error: 0.0084 - val_loss: 0.0180 - val_mean_squared_error: 0.0091\n",
      "Epoch 41/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0172 - mean_squared_error: 0.0083 - val_loss: 0.0176 - val_mean_squared_error: 0.0088\n",
      "Epoch 42/100\n",
      "39312/39312 [==============================] - 2s 42us/sample - loss: 0.0171 - mean_squared_error: 0.0083 - val_loss: 0.0177 - val_mean_squared_error: 0.0089\n",
      "Epoch 43/100\n",
      "39232/39312 [============================>.] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0082\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0169 - mean_squared_error: 0.0082 - val_loss: 0.0171 - val_mean_squared_error: 0.0084\n",
      "Epoch 44/100\n",
      "39312/39312 [==============================] - 2s 38us/sample - loss: 0.0161 - mean_squared_error: 0.0074 - val_loss: 0.0166 - val_mean_squared_error: 0.0080\n",
      "Epoch 45/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0161 - mean_squared_error: 0.0074 - val_loss: 0.0164 - val_mean_squared_error: 0.0077\n",
      "Epoch 46/100\n",
      "39312/39312 [==============================] - 2s 38us/sample - loss: 0.0161 - mean_squared_error: 0.0074 - val_loss: 0.0162 - val_mean_squared_error: 0.0076\n",
      "Epoch 47/100\n",
      "39312/39312 [==============================] - 2s 38us/sample - loss: 0.0160 - mean_squared_error: 0.0073 - val_loss: 0.0166 - val_mean_squared_error: 0.0080\n",
      "Epoch 48/100\n",
      "39312/39312 [==============================] - 2s 45us/sample - loss: 0.0160 - mean_squared_error: 0.0074 - val_loss: 0.0162 - val_mean_squared_error: 0.0076\n",
      "Epoch 49/100\n",
      "39312/39312 [==============================] - 2s 45us/sample - loss: 0.0159 - mean_squared_error: 0.0074 - val_loss: 0.0164 - val_mean_squared_error: 0.0078\n",
      "Epoch 50/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0158 - mean_squared_error: 0.0073 - val_loss: 0.0168 - val_mean_squared_error: 0.0083\n",
      "Epoch 51/100\n",
      "39104/39312 [============================>.] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0073\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0158 - mean_squared_error: 0.0073 - val_loss: 0.0163 - val_mean_squared_error: 0.0078\n",
      "Epoch 52/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0154 - mean_squared_error: 0.0069 - val_loss: 0.0160 - val_mean_squared_error: 0.0076\n",
      "Epoch 53/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0153 - mean_squared_error: 0.0068 - val_loss: 0.0157 - val_mean_squared_error: 0.0073\n",
      "Epoch 54/100\n",
      "39312/39312 [==============================] - 2s 42us/sample - loss: 0.0153 - mean_squared_error: 0.0069 - val_loss: 0.0158 - val_mean_squared_error: 0.0074\n",
      "Epoch 55/100\n",
      "39312/39312 [==============================] - 2s 44us/sample - loss: 0.0153 - mean_squared_error: 0.0068 - val_loss: 0.0156 - val_mean_squared_error: 0.0071\n",
      "Epoch 56/100\n",
      "39312/39312 [==============================] - 2s 42us/sample - loss: 0.0152 - mean_squared_error: 0.0068 - val_loss: 0.0156 - val_mean_squared_error: 0.0072\n",
      "Epoch 57/100\n",
      "39312/39312 [==============================] - 2s 44us/sample - loss: 0.0152 - mean_squared_error: 0.0068 - val_loss: 0.0158 - val_mean_squared_error: 0.0074\n",
      "Epoch 58/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0152 - mean_squared_error: 0.0068 - val_loss: 0.0156 - val_mean_squared_error: 0.0073\n",
      "Epoch 59/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0151 - mean_squared_error: 0.0068 - val_loss: 0.0156 - val_mean_squared_error: 0.0072\n",
      "Epoch 60/100\n",
      "38720/39312 [============================>.] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0067\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0151 - mean_squared_error: 0.0068 - val_loss: 0.0154 - val_mean_squared_error: 0.0071\n",
      "Epoch 61/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0149 - mean_squared_error: 0.0066 - val_loss: 0.0154 - val_mean_squared_error: 0.0071\n",
      "Epoch 62/100\n",
      "39312/39312 [==============================] - 2s 56us/sample - loss: 0.0149 - mean_squared_error: 0.0065 - val_loss: 0.0154 - val_mean_squared_error: 0.0071\n",
      "Epoch 63/100\n",
      "39312/39312 [==============================] - 3s 77us/sample - loss: 0.0148 - mean_squared_error: 0.0065 - val_loss: 0.0154 - val_mean_squared_error: 0.0070\n",
      "Epoch 64/100\n",
      "39312/39312 [==============================] - 2s 63us/sample - loss: 0.0148 - mean_squared_error: 0.0065 - val_loss: 0.0153 - val_mean_squared_error: 0.0070\n",
      "Epoch 65/100\n",
      "39312/39312 [==============================] - 3s 66us/sample - loss: 0.0148 - mean_squared_error: 0.0065 - val_loss: 0.0153 - val_mean_squared_error: 0.0070\n",
      "Epoch 66/100\n",
      "39312/39312 [==============================] - 3s 64us/sample - loss: 0.0148 - mean_squared_error: 0.0065 - val_loss: 0.0151 - val_mean_squared_error: 0.0068\n",
      "Epoch 67/100\n",
      "39312/39312 [==============================] - 2s 42us/sample - loss: 0.0148 - mean_squared_error: 0.0065 - val_loss: 0.0152 - val_mean_squared_error: 0.0070\n",
      "Epoch 68/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0147 - mean_squared_error: 0.0065 - val_loss: 0.0152 - val_mean_squared_error: 0.0070\n",
      "Epoch 69/100\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0147 - mean_squared_error: 0.0065 - val_loss: 0.0151 - val_mean_squared_error: 0.0069\n",
      "Epoch 70/100\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0147 - mean_squared_error: 0.0065 - val_loss: 0.0152 - val_mean_squared_error: 0.0069\n",
      "Epoch 71/100\n",
      "38784/39312 [============================>.] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0065\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0147 - mean_squared_error: 0.0065 - val_loss: 0.0151 - val_mean_squared_error: 0.0069\n",
      "Epoch 72/100\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0146 - mean_squared_error: 0.0063 - val_loss: 0.0150 - val_mean_squared_error: 0.0068\n",
      "Epoch 73/100\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0146 - mean_squared_error: 0.0063 - val_loss: 0.0150 - val_mean_squared_error: 0.0068\n",
      "Epoch 74/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0146 - mean_squared_error: 0.0063 - val_loss: 0.0150 - val_mean_squared_error: 0.0068\n",
      "Epoch 75/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0145 - mean_squared_error: 0.0063 - val_loss: 0.0150 - val_mean_squared_error: 0.0068\n",
      "Epoch 76/100\n",
      "38976/39312 [============================>.] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0063\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0145 - mean_squared_error: 0.0063 - val_loss: 0.0151 - val_mean_squared_error: 0.0068\n",
      "Epoch 77/100\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0145 - mean_squared_error: 0.0063 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 78/100\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0145 - mean_squared_error: 0.0063 - val_loss: 0.0150 - val_mean_squared_error: 0.0067\n",
      "Epoch 79/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0145 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 80/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 81/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 82/100\n",
      "38976/39312 [============================>.] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0062\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 83/100\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 84/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 85/100\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 86/100\n",
      "39312/39312 [==============================] - 2s 43us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 87/100\n",
      "39296/39312 [============================>.] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0062\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "39312/39312 [==============================] - 2s 45us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 89/100\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 90/100\n",
      "39312/39312 [==============================] - 2s 42us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 91/100\n",
      "39312/39312 [==============================] - 2s 41us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 92/100\n",
      "39040/39312 [============================>.] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0062\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 93/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 94/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 95/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 96/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 97/100\n",
      "38400/39312 [============================>.] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0062\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 98/100\n",
      "39312/39312 [==============================] - 2s 40us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 99/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Epoch 100/100\n",
      "39312/39312 [==============================] - 2s 39us/sample - loss: 0.0144 - mean_squared_error: 0.0062 - val_loss: 0.0149 - val_mean_squared_error: 0.0067\n",
      "Saved model for RoboschoolWalker2d-v1: /tf/srv/hw1/notebooks/model_RoboschoolWalker2d-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolWalker2d-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001\n"
     ]
    }
   ],
   "source": [
    "_ = model.fit([X_train], y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[scope.print_callback, reduce_lr, tf_board],\n",
    "          validation_data=([X_val], y_val)\n",
    "          )\n",
    "\n",
    "model_filename = os.path.join(model_path, model_name)\n",
    "model.save(model_filename)\n",
    "print(\"Saved model for %s: %s\" % (dataset_name, model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "KerasTrainScope(model_name=model_name, history_dir=model_path).plt_history(start_epoch=5, metric_str='mean_squared_error', title='RoboschoolWalker2d-v1 MSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'RoboschoolWalker2d-v1',\n",
       " 'test_mse': 0.00652572098632578,\n",
       " 'train_mse': 0.006158397129541189,\n",
       " 'val_mse': 0.006682982918667695}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = calc_mse(model, dataset_name, X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have trained a model for each task. Lets train them agains an expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run trained agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_to_model = {\n",
    "    'RoboschoolAnt-v1': '/tf/srv/hw1/notebooks/model_task_1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_task_1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001',\n",
    "    'RoboschoolHumanoid-v1': '/tf/srv/hw1/notebooks/model_RoboschoolHumanoid-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolHumanoid-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001',\n",
    "    'RoboschoolReacher-v1': '/tf/srv/hw1/notebooks/model_RoboschoolReacher-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolReacher-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001',\n",
    "    'RoboschoolHopper-v1': '/tf/srv/hw1/notebooks/model_RoboschoolHopper-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolHopper-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001',\n",
    "    'RoboschoolWalker2d-v1': '/tf/srv/hw1/notebooks/model_RoboschoolWalker2d-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolWalker2d-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "module_name = 'RoboschoolWalker2d-v1'\n",
    "model_filename = env_to_model[module_name]\n",
    "\n",
    "model = tf.keras.models.load_model(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import roboschool\n",
    "module_name = 'RoboschoolWalker2d-v1'\n",
    "env = gym.make(module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/.local/lib/python3.5/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import roboschool\n",
    "env = gym.make(module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, module_name):\n",
    "        self._module_name = module_name\n",
    "        model_filename = env_to_model[module_name]\n",
    "        self._model = tf.keras.models.load_model(model_filename)\n",
    "        \n",
    "    def act(self, ob):\n",
    "        action = model.predict(ob.reshape(1, ob.shape[0]))\n",
    "        return action[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent = Agent(module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "reward = 0\n",
    "action = agent.act(ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.88038486, -1.5795506 ,  1.0640422 ,  0.9625253 , -0.01311826,\n",
       "        0.90140086], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob, reward, done, _ = env.step(action[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00148367,  0.        ,  1.        , -0.07704903,  0.        ,\n",
       "       -0.07407972,  0.        , -0.00638885,  1.035067  ,  0.        ,\n",
       "        0.92176765, -0.2730872 , -0.03594019,  0.42815846,  0.9351618 ,\n",
       "        0.04873459,  0.95061046, -0.30241162,  0.15511477,  0.3764817 ,\n",
       "        0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35228758559387646"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = model.predict(state.reshape(1, state.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.88038486, -1.5795506 ,  1.0640422 ,  0.9625253 , -0.01311826,\n",
       "         0.90140086]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import roboschool\n",
    "import tensorflow as tf\n",
    "\n",
    "env_to_model = {\n",
    "    'RoboschoolAnt-v1': '/tf/srv/hw1/notebooks/model_task_1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_task_1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001',\n",
    "    'RoboschoolHumanoid-v1': '/tf/srv/hw1/notebooks/model_RoboschoolHumanoid-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolHumanoid-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001',\n",
    "    'RoboschoolReacher-v1': '/tf/srv/hw1/notebooks/model_RoboschoolReacher-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolReacher-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001',\n",
    "    'RoboschoolHopper-v1': '/tf/srv/hw1/notebooks/model_RoboschoolHopper-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolHopper-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001',\n",
    "    'RoboschoolWalker2d-v1': '/tf/srv/hw1/notebooks/model_RoboschoolWalker2d-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001/model_RoboschoolWalker2d-v1__0.001_lr_None_dropout_3_layers_100_neurons_batch_norm_l2_0.0001',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_name = [i for i in env_to_model.keys()][0]\n",
    "#module_name = 'RoboschoolWalker2d-v1'\n",
    "env = gym.make(module_name)\n",
    "agent = Agent(module_name)\n",
    "\n",
    "episode_count = 1\n",
    "reward = 0\n",
    "done = False\n",
    "\n",
    "for i in range(episode_count):\n",
    "    ob = env.reset()\n",
    "    env.render()\n",
    "    while True:\n",
    "        action = agent.act(ob)\n",
    "        ob, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_count = 1\n",
    "reward = 0\n",
    "done = False\n",
    "\n",
    "for i in range(episode_count):\n",
    "    ob = env.reset()\n",
    "    while True:\n",
    "        action = agent.act(ob)\n",
    "        ob, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  1.0401742 ,  0.        ,\n",
       "        1.0358782 ,  0.        ,  0.09403914,  0.        ,  0.9861809 ,\n",
       "        0.        ,  1.0021865 ,  0.        ,  0.00988968,  0.        ,\n",
       "        0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "step() missing 1 required positional argument: 'action'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-110042b28e3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: step() missing 1 required positional argument: 'action'"
     ]
    }
   ],
   "source": [
    "env.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'RoboschoolWalker2d-v1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-a525582675e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpolicy_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_env_and_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#max_steps = args.max_timesteps or env.spec.timestep_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/lib/python3.5/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~usr/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~usr/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'RoboschoolWalker2d-v1'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "policy_module = importlib.import_module(module_name)\n",
    "\n",
    "env, policy = policy_module.get_env_and_policy()\n",
    "#max_steps = args.max_timesteps or env.spec.timestep_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29719454,  0.        ,  1.        ,  0.5148433 ,  0.        ,\n",
       "       -0.05942878,  0.        , -0.85780895,  1.0010046 , -0.00782464,\n",
       "        0.07210448,  0.0862384 ,  0.8365169 , -0.17222126,  0.10294461,\n",
       "       -0.10733211,  0.4205966 , -0.27900338,  0.74042314, -0.44582543,\n",
       "        1.        ,  1.        ], dtype=float32)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4610083 ,  0.52578616,  1.0755655 ,  0.98221153,  0.6696826 ,\n",
       "        -0.33750072]], dtype=float32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([X_train[0:1, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 22)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
